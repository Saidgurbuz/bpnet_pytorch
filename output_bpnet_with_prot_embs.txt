nohup: ignoring input
/scratch/guerbuez/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The variance of predictions or target is close to zero. This can cause instability in Pearson correlationcoefficient, leading to wrong results. Consider re-scaling the input if possible or computing using alarger dtype (currently using torch.float32).
  warnings.warn(*args, **kwargs)  # noqa: B028
Epoch [1/100], Batch [1/147] train loss: 976.45, train corr: -0.00069
Epoch [1/100], Batch [2/147] train loss: 12910.44, train corr: 0.00023
Epoch [1/100], Batch [3/147] train loss: 338219.88, train corr: 0.01587
Epoch [1/100], Batch [4/147] train loss: 14083.61, train corr: 0.00157
Epoch [1/100], Batch [5/147] train loss: 10008.42, train corr: 0.01299
Epoch [1/100], Batch [6/147] train loss: 9204.53, train corr: 0.00834
Epoch [1/100], Batch [7/147] train loss: 2291.13, train corr: -0.02972
Epoch [1/100], Batch [8/147] train loss: 2100.16, train corr: -0.01594
Epoch [1/100], Batch [9/147] train loss: 2560.32, train corr: -0.00084
Epoch [1/100], Batch [10/147] train loss: 1506.96, train corr: 0.00658
Epoch [1/100], Batch [11/147] train loss: 2773.40, train corr: -0.00012
Epoch [1/100], Batch [12/147] train loss: 4033.38, train corr: -0.01640
Epoch [1/100], Batch [13/147] train loss: 1341.00, train corr: 0.00446
Epoch [1/100], Batch [14/147] train loss: 3602.11, train corr: 0.01069
Epoch [1/100], Batch [15/147] train loss: 1171.62, train corr: -0.01410
Epoch [1/100], Batch [16/147] train loss: 7509.96, train corr: -0.00459
Epoch [1/100], Batch [17/147] train loss: 2512.83, train corr: 0.00334
Epoch [1/100], Batch [18/147] train loss: 8659.37, train corr: 0.00317
Epoch [1/100], Batch [19/147] train loss: 1724.63, train corr: -0.02463
Epoch [1/100], Batch [20/147] train loss: 8686.55, train corr: 0.01429
Epoch [1/100], Batch [21/147] train loss: 3218.27, train corr: 0.00419
Epoch [1/100], Batch [22/147] train loss: 3371.87, train corr: -0.00005
Epoch [1/100], Batch [23/147] train loss: 3796.91, train corr: -0.02845
Epoch [1/100], Batch [24/147] train loss: 3383.16, train corr: -0.01696
Epoch [1/100], Batch [25/147] train loss: 1725.63, train corr: -0.02667
Epoch [1/100], Batch [26/147] train loss: 5788.98, train corr: 0.02606
Epoch [1/100], Batch [27/147] train loss: 2720.30, train corr: -0.02843
Epoch [1/100], Batch [28/147] train loss: 2403.92, train corr: 0.01498
Epoch [1/100], Batch [29/147] train loss: 3927.33, train corr: 0.00006
Epoch [1/100], Batch [30/147] train loss: 17882.30, train corr: 0.02414
Epoch [1/100], Batch [31/147] train loss: 6161.39, train corr: 0.02173
Epoch [1/100], Batch [32/147] train loss: 2909.31, train corr: 0.01735
Epoch [1/100], Batch [33/147] train loss: 21070.32, train corr: 0.02447
Epoch [1/100], Batch [34/147] train loss: 3676.39, train corr: -0.00917
Epoch [1/100], Batch [35/147] train loss: 1879.34, train corr: 0.01638
Epoch [1/100], Batch [36/147] train loss: 1714.86, train corr: -0.03001
Epoch [1/100], Batch [37/147] train loss: 6887.88, train corr: -0.02331
Epoch [1/100], Batch [38/147] train loss: 5948.60, train corr: -0.01045
Epoch [1/100], Batch [39/147] train loss: 1182.53, train corr: -0.02199
Epoch [1/100], Batch [40/147] train loss: 1488.77, train corr: 0.01725
Epoch [1/100], Batch [41/147] train loss: 2464.85, train corr: -0.00629
Epoch [1/100], Batch [42/147] train loss: 5579.12, train corr: -0.02910
Epoch [1/100], Batch [43/147] train loss: 2523.37, train corr: -0.03193
Epoch [1/100], Batch [44/147] train loss: 3548.20, train corr: -0.00956
Epoch [1/100], Batch [45/147] train loss: 4484.28, train corr: 0.00883
Epoch [1/100], Batch [46/147] train loss: 3763.86, train corr: -0.01655
Epoch [1/100], Batch [47/147] train loss: 2996.32, train corr: -0.00405
Epoch [1/100], Batch [48/147] train loss: 2079.06, train corr: 0.00120
Epoch [1/100], Batch [49/147] train loss: 2323.40, train corr: 0.02137
Epoch [1/100], Batch [50/147] train loss: 5764.98, train corr: 0.00172
Epoch [1/100], Batch [51/147] train loss: 4088.17, train corr: -0.01145
Epoch [1/100], Batch [52/147] train loss: 4521.96, train corr: 0.00583
Epoch [1/100], Batch [53/147] train loss: 4415.19, train corr: -0.00251
Epoch [1/100], Batch [54/147] train loss: 6548.13, train corr: 0.02456
Epoch [1/100], Batch [55/147] train loss: 6163.70, train corr: 0.01882
Epoch [1/100], Batch [56/147] train loss: 4096.28, train corr: 0.00067
Epoch [1/100], Batch [57/147] train loss: 5108.80, train corr: -0.02997
Epoch [1/100], Batch [58/147] train loss: 3515.89, train corr: 0.02940
Epoch [1/100], Batch [59/147] train loss: 2322.51, train corr: 0.00953
Epoch [1/100], Batch [60/147] train loss: 1401.11, train corr: 0.00025
Epoch [1/100], Batch [61/147] train loss: 2741.37, train corr: 0.02451
Epoch [1/100], Batch [62/147] train loss: 8464.32, train corr: 0.02744
Epoch [1/100], Batch [63/147] train loss: 3487.11, train corr: 0.00281
Epoch [1/100], Batch [64/147] train loss: 4576.17, train corr: -0.02597
Epoch [1/100], Batch [65/147] train loss: 3263.66, train corr: 0.00337
Epoch [1/100], Batch [66/147] train loss: 3243.06, train corr: -0.01380
Epoch [1/100], Batch [67/147] train loss: 2693.72, train corr: 0.00612
Epoch [1/100], Batch [68/147] train loss: 3080.28, train corr: 0.01556
Epoch [1/100], Batch [69/147] train loss: 1778.76, train corr: -0.00953
Epoch [1/100], Batch [70/147] train loss: 2587.64, train corr: -0.03154
Epoch [1/100], Batch [71/147] train loss: 3281.05, train corr: -0.02578
Epoch [1/100], Batch [72/147] train loss: 2914.03, train corr: -0.02477
Epoch [1/100], Batch [73/147] train loss: 1827.07, train corr: 0.00052
Epoch [1/100], Batch [74/147] train loss: 1490.22, train corr: -0.00666
Epoch [1/100], Batch [75/147] train loss: 1806.35, train corr: -0.00150
Epoch [1/100], Batch [76/147] train loss: 1388.66, train corr: 0.01031
Epoch [1/100], Batch [77/147] train loss: 2296.10, train corr: 0.00767
Epoch [1/100], Batch [78/147] train loss: 1584.73, train corr: -0.01772
Epoch [1/100], Batch [79/147] train loss: 1550.45, train corr: -0.00978
Epoch [1/100], Batch [80/147] train loss: 2141.87, train corr: 0.01632
Epoch [1/100], Batch [81/147] train loss: 1472.29, train corr: -0.00229
Epoch [1/100], Batch [82/147] train loss: 1578.79, train corr: 0.02684
Epoch [1/100], Batch [83/147] train loss: 1221.00, train corr: 0.02479
Epoch [1/100], Batch [84/147] train loss: 1722.61, train corr: -0.01534
Epoch [1/100], Batch [85/147] train loss: 1828.00, train corr: 0.00354
Epoch [1/100], Batch [86/147] train loss: 1693.80, train corr: 0.02585
Epoch [1/100], Batch [87/147] train loss: 1147.09, train corr: -0.00983
Epoch [1/100], Batch [88/147] train loss: 2439.52, train corr: -0.00482
Epoch [1/100], Batch [89/147] train loss: 1375.08, train corr: -0.03067
Epoch [1/100], Batch [90/147] train loss: 1059.04, train corr: -0.01929
Epoch [1/100], Batch [91/147] train loss: 1043.17, train corr: -0.00451
Epoch [1/100], Batch [92/147] train loss: 966.30, train corr: 0.01485
Epoch [1/100], Batch [93/147] train loss: 1895.85, train corr: -0.02425
Epoch [1/100], Batch [94/147] train loss: 1145.40, train corr: 0.00398
Epoch [1/100], Batch [95/147] train loss: 1202.11, train corr: 0.00836
Epoch [1/100], Batch [96/147] train loss: 1127.61, train corr: -0.00039
Epoch [1/100], Batch [97/147] train loss: 1138.59, train corr: 0.01363
Epoch [1/100], Batch [98/147] train loss: 1016.43, train corr: 0.03060
Epoch [1/100], Batch [99/147] train loss: 924.22, train corr: 0.03009
Epoch [1/100], Batch [100/147] train loss: 904.34, train corr: 0.03169
Epoch [1/100], Batch [101/147] train loss: 996.90, train corr: 0.01974
Epoch [1/100], Batch [102/147] train loss: 1037.75, train corr: 0.02037
Epoch [1/100], Batch [103/147] train loss: 972.57, train corr: 0.02488
Epoch [1/100], Batch [104/147] train loss: 727.43, train corr: -0.01516
Epoch [1/100], Batch [105/147] train loss: 735.48, train corr: 0.00352
Epoch [1/100], Batch [106/147] train loss: 765.22, train corr: 0.01452
Epoch [1/100], Batch [107/147] train loss: 677.97, train corr: -0.00013
Epoch [1/100], Batch [108/147] train loss: 968.51, train corr: 0.00664
Epoch [1/100], Batch [109/147] train loss: 916.81, train corr: 0.00011
Epoch [1/100], Batch [110/147] train loss: 675.54, train corr: -0.00762
Epoch [1/100], Batch [111/147] train loss: 738.78, train corr: 0.02012
Epoch [1/100], Batch [112/147] train loss: 755.06, train corr: 0.00589
Epoch [1/100], Batch [113/147] train loss: 796.20, train corr: -0.02439
Epoch [1/100], Batch [114/147] train loss: 743.52, train corr: -0.00280
Epoch [1/100], Batch [115/147] train loss: 692.78, train corr: 0.01137
Epoch [1/100], Batch [116/147] train loss: 675.17, train corr: 0.00987
Epoch [1/100], Batch [117/147] train loss: 673.57, train corr: -0.01832
Epoch [1/100], Batch [118/147] train loss: 637.72, train corr: 0.01232
Epoch [1/100], Batch [119/147] train loss: 631.51, train corr: -0.01536
Epoch [1/100], Batch [120/147] train loss: 656.53, train corr: -0.00272
Epoch [1/100], Batch [121/147] train loss: 614.95, train corr: 0.01565
Epoch [1/100], Batch [122/147] train loss: 651.71, train corr: -0.00671
Epoch [1/100], Batch [123/147] train loss: 611.03, train corr: 0.01078
Epoch [1/100], Batch [124/147] train loss: 801.80, train corr: 0.00943
Epoch [1/100], Batch [125/147] train loss: 632.44, train corr: -0.01389
Epoch [1/100], Batch [126/147] train loss: 627.13, train corr: -0.01613
Epoch [1/100], Batch [127/147] train loss: 642.90, train corr: -0.02933
Epoch [1/100], Batch [128/147] train loss: 677.50, train corr: 0.02422
Epoch [1/100], Batch [129/147] train loss: 643.66, train corr: -0.02228
Epoch [1/100], Batch [130/147] train loss: 669.47, train corr: 0.01500
Epoch [1/100], Batch [131/147] train loss: 638.97, train corr: -0.00874
Epoch [1/100], Batch [132/147] train loss: 729.71, train corr: 0.02350
Epoch [1/100], Batch [133/147] train loss: 656.76, train corr: 0.01579
Epoch [1/100], Batch [134/147] train loss: 648.90, train corr: 0.03418
Epoch [1/100], Batch [135/147] train loss: 613.71, train corr: 0.01631
Epoch [1/100], Batch [136/147] train loss: 636.67, train corr: 0.02388
Epoch [1/100], Batch [137/147] train loss: 625.28, train corr: -0.01873
Epoch [1/100], Batch [138/147] train loss: 595.59, train corr: -0.02383
Epoch [1/100], Batch [139/147] train loss: 600.86, train corr: -0.01404
Epoch [1/100], Batch [140/147] train loss: 709.70, train corr: -0.01502
Epoch [1/100], Batch [141/147] train loss: 620.88, train corr: -0.03438
Epoch [1/100], Batch [142/147] train loss: 589.87, train corr: 0.00047
Epoch [1/100], Batch [143/147] train loss: 626.90, train corr: 0.00963
Epoch [1/100], Batch [144/147] train loss: 609.31, train corr: 0.01788
Epoch [1/100], Batch [145/147] train loss: 599.47, train corr: -0.02409
Epoch [1/100], Batch [146/147] train loss: 595.67, train corr: -0.02895
Epoch [1/100], Batch [147/147] train loss: 583.96, train corr: 0.00336
Epoch [1/100], validation loss: 620.64, validation correlation: -0.02894
Epoch [2/100], Batch [1/147] train loss: 603.05, train corr: -0.02543
Epoch [2/100], Batch [2/147] train loss: 593.10, train corr: -0.02754
Epoch [2/100], Batch [3/147] train loss: 579.60, train corr: -0.03065
Epoch [2/100], Batch [4/147] train loss: 609.59, train corr: -0.02192
Epoch [2/100], Batch [5/147] train loss: 574.52, train corr: -0.02967
Epoch [2/100], Batch [6/147] train loss: 577.90, train corr: -0.02812
Epoch [2/100], Batch [7/147] train loss: 576.26, train corr: -0.03106
Epoch [2/100], Batch [8/147] train loss: 590.65, train corr: -0.03004
Epoch [2/100], Batch [9/147] train loss: 589.81, train corr: -0.02614
Epoch [2/100], Batch [10/147] train loss: 590.33, train corr: -0.02970
Epoch [2/100], Batch [11/147] train loss: 575.81, train corr: -0.02793
Epoch [2/100], Batch [12/147] train loss: 601.89, train corr: -0.02374
Epoch [2/100], Batch [13/147] train loss: 573.29, train corr: -0.02886
Epoch [2/100], Batch [14/147] train loss: 567.01, train corr: -0.03035
Epoch [2/100], Batch [15/147] train loss: 565.80, train corr: -0.03089
Epoch [2/100], Batch [16/147] train loss: 568.59, train corr: -0.02992
Epoch [2/100], Batch [17/147] train loss: 579.96, train corr: -0.02974
Epoch [2/100], Batch [18/147] train loss: 566.23, train corr: -0.03242
Epoch [2/100], Batch [19/147] train loss: 743.17, train corr: -0.02804
Epoch [2/100], Batch [20/147] train loss: 576.42, train corr: -0.03155
Epoch [2/100], Batch [21/147] train loss: 585.71, train corr: -0.03082
Epoch [2/100], Batch [22/147] train loss: 568.39, train corr: -0.03016
Epoch [2/100], Batch [23/147] train loss: 571.43, train corr: -0.03159
Epoch [2/100], Batch [24/147] train loss: 569.19, train corr: -0.03368
Epoch [2/100], Batch [25/147] train loss: 585.48, train corr: -0.03382
Epoch [2/100], Batch [26/147] train loss: 579.87, train corr: -0.03111
Epoch [2/100], Batch [27/147] train loss: 579.83, train corr: -0.03370
Epoch [2/100], Batch [28/147] train loss: 565.27, train corr: -0.03466
Epoch [2/100], Batch [29/147] train loss: 575.74, train corr: -0.03363
Epoch [2/100], Batch [30/147] train loss: 563.03, train corr: -0.03308
Epoch [2/100], Batch [31/147] train loss: 563.98, train corr: -0.03337
Epoch [2/100], Batch [32/147] train loss: 574.09, train corr: -0.03423
Epoch [2/100], Batch [33/147] train loss: 564.47, train corr: -0.03304
Epoch [2/100], Batch [34/147] train loss: 581.64, train corr: -0.03119
Epoch [2/100], Batch [35/147] train loss: 568.80, train corr: -0.03168
Epoch [2/100], Batch [36/147] train loss: 642.39, train corr: -0.02487
Epoch [2/100], Batch [37/147] train loss: 580.17, train corr: -0.03298
Epoch [2/100], Batch [38/147] train loss: 570.86, train corr: -0.03123
Epoch [2/100], Batch [39/147] train loss: 568.91, train corr: -0.02900
Epoch [2/100], Batch [40/147] train loss: 561.45, train corr: -0.02779
Epoch [2/100], Batch [41/147] train loss: 562.59, train corr: -0.02511
Epoch [2/100], Batch [42/147] train loss: 583.58, train corr: -0.02478
Epoch [2/100], Batch [43/147] train loss: 569.28, train corr: -0.01972
Epoch [2/100], Batch [44/147] train loss: 577.81, train corr: -0.01879
Epoch [2/100], Batch [45/147] train loss: 832.23, train corr: -0.01156
Epoch [2/100], Batch [46/147] train loss: 572.76, train corr: -0.02501
Epoch [2/100], Batch [47/147] train loss: 573.33, train corr: -0.03031
Epoch [2/100], Batch [48/147] train loss: 583.42, train corr: -0.03126
Epoch [2/100], Batch [49/147] train loss: 591.17, train corr: -0.02804
Epoch [2/100], Batch [50/147] train loss: 569.64, train corr: -0.03343
Epoch [2/100], Batch [51/147] train loss: 575.09, train corr: -0.03291
Epoch [2/100], Batch [52/147] train loss: 609.51, train corr: -0.02935
Epoch [2/100], Batch [53/147] train loss: 558.06, train corr: -0.03157
Epoch [2/100], Batch [54/147] train loss: 572.62, train corr: -0.02935
Epoch [2/100], Batch [55/147] train loss: 571.97, train corr: -0.02556
Epoch [2/100], Batch [56/147] train loss: 570.99, train corr: -0.02165
Epoch [2/100], Batch [57/147] train loss: 569.50, train corr: -0.02188
Epoch [2/100], Batch [58/147] train loss: 575.77, train corr: -0.02164
Epoch [2/100], Batch [59/147] train loss: 571.00, train corr: -0.02414
Epoch [2/100], Batch [60/147] train loss: 567.02, train corr: -0.02369
Epoch [2/100], Batch [61/147] train loss: 562.34, train corr: -0.02724
Epoch [2/100], Batch [62/147] train loss: 563.45, train corr: -0.02866
Epoch [2/100], Batch [63/147] train loss: 560.60, train corr: -0.03163
Epoch [2/100], Batch [64/147] train loss: 572.57, train corr: -0.03266
Epoch [2/100], Batch [65/147] train loss: 556.83, train corr: -0.03252
Epoch [2/100], Batch [66/147] train loss: 566.02, train corr: -0.03323
Epoch [2/100], Batch [67/147] train loss: 560.74, train corr: -0.03219
Epoch [2/100], Batch [68/147] train loss: 573.01, train corr: -0.03184
Epoch [2/100], Batch [69/147] train loss: 564.04, train corr: -0.03072
Epoch [2/100], Batch [70/147] train loss: 563.85, train corr: -0.02708
Epoch [2/100], Batch [71/147] train loss: 561.70, train corr: -0.02654
Epoch [2/100], Batch [72/147] train loss: 581.79, train corr: -0.02720
Epoch [2/100], Batch [73/147] train loss: 575.51, train corr: -0.02626
Epoch [2/100], Batch [74/147] train loss: 579.49, train corr: -0.02822
Epoch [2/100], Batch [75/147] train loss: 556.13, train corr: -0.02641
Epoch [2/100], Batch [76/147] train loss: 573.93, train corr: -0.02850
Epoch [2/100], Batch [77/147] train loss: 565.86, train corr: -0.02816
Epoch [2/100], Batch [78/147] train loss: 572.35, train corr: -0.02811
Epoch [2/100], Batch [79/147] train loss: 552.97, train corr: -0.02705
Epoch [2/100], Batch [80/147] train loss: 556.53, train corr: -0.02638
Epoch [2/100], Batch [81/147] train loss: 563.31, train corr: -0.02788
Epoch [2/100], Batch [82/147] train loss: 564.84, train corr: -0.02789
Epoch [2/100], Batch [83/147] train loss: 572.26, train corr: -0.02834
Epoch [2/100], Batch [84/147] train loss: 561.55, train corr: -0.02967
Epoch [2/100], Batch [85/147] train loss: 556.11, train corr: -0.02971
Epoch [2/100], Batch [86/147] train loss: 560.69, train corr: -0.03021
Epoch [2/100], Batch [87/147] train loss: 569.04, train corr: -0.02924
Epoch [2/100], Batch [88/147] train loss: 570.34, train corr: -0.02866
Epoch [2/100], Batch [89/147] train loss: 570.02, train corr: -0.03021
Epoch [2/100], Batch [90/147] train loss: 569.18, train corr: -0.02834
Epoch [2/100], Batch [91/147] train loss: 576.02, train corr: -0.03091
Epoch [2/100], Batch [92/147] train loss: 582.89, train corr: -0.02717
Epoch [2/100], Batch [93/147] train loss: 572.39, train corr: -0.02949
Epoch [2/100], Batch [94/147] train loss: 586.43, train corr: -0.02951
Epoch [2/100], Batch [95/147] train loss: 573.27, train corr: -0.02934
Epoch [2/100], Batch [96/147] train loss: 563.95, train corr: -0.02968
Epoch [2/100], Batch [97/147] train loss: 572.70, train corr: -0.03025
Epoch [2/100], Batch [98/147] train loss: 559.78, train corr: -0.03071
Epoch [2/100], Batch [99/147] train loss: 577.14, train corr: -0.03081
Epoch [2/100], Batch [100/147] train loss: 570.41, train corr: -0.02790
Epoch [2/100], Batch [101/147] train loss: 590.03, train corr: -0.02850
Epoch [2/100], Batch [102/147] train loss: 556.98, train corr: -0.03200
Epoch [2/100], Batch [103/147] train loss: 576.23, train corr: -0.03188
Epoch [2/100], Batch [104/147] train loss: 568.87, train corr: -0.03175
Epoch [2/100], Batch [105/147] train loss: 564.39, train corr: -0.03239
Epoch [2/100], Batch [106/147] train loss: 553.13, train corr: -0.03272
Epoch [2/100], Batch [107/147] train loss: 566.58, train corr: -0.03223
Epoch [2/100], Batch [108/147] train loss: 569.20, train corr: -0.03302
Epoch [2/100], Batch [109/147] train loss: 561.40, train corr: -0.03399
Epoch [2/100], Batch [110/147] train loss: 568.04, train corr: -0.03306
Epoch [2/100], Batch [111/147] train loss: 574.37, train corr: -0.02933
Epoch [2/100], Batch [112/147] train loss: 572.56, train corr: -0.03342
Epoch [2/100], Batch [113/147] train loss: 563.86, train corr: -0.03216
Epoch [2/100], Batch [114/147] train loss: 561.61, train corr: -0.03273
Epoch [2/100], Batch [115/147] train loss: 556.51, train corr: -0.03036
Epoch [2/100], Batch [116/147] train loss: 579.10, train corr: -0.03127
Epoch [2/100], Batch [117/147] train loss: 552.29, train corr: -0.03234
Epoch [2/100], Batch [118/147] train loss: 554.43, train corr: -0.03308
Epoch [2/100], Batch [119/147] train loss: 581.38, train corr: -0.03291
Epoch [2/100], Batch [120/147] train loss: 548.03, train corr: -0.03306
Epoch [2/100], Batch [121/147] train loss: 581.56, train corr: -0.03077
Epoch [2/100], Batch [122/147] train loss: 555.36, train corr: -0.03311
Epoch [2/100], Batch [123/147] train loss: 561.94, train corr: -0.03265
Epoch [2/100], Batch [124/147] train loss: 569.43, train corr: -0.03219
Epoch [2/100], Batch [125/147] train loss: 568.55, train corr: -0.03307
Epoch [2/100], Batch [126/147] train loss: 570.47, train corr: -0.03281
Epoch [2/100], Batch [127/147] train loss: 554.03, train corr: -0.03244
Epoch [2/100], Batch [128/147] train loss: 632.93, train corr: -0.02811
Epoch [2/100], Batch [129/147] train loss: 584.34, train corr: -0.03208
Epoch [2/100], Batch [130/147] train loss: 569.69, train corr: -0.03228
Epoch [2/100], Batch [131/147] train loss: 573.07, train corr: -0.02867
Epoch [2/100], Batch [132/147] train loss: 583.91, train corr: -0.03047
Epoch [2/100], Batch [133/147] train loss: 568.45, train corr: -0.03081
Epoch [2/100], Batch [134/147] train loss: 561.03, train corr: -0.03195
Epoch [2/100], Batch [135/147] train loss: 562.45, train corr: -0.03245
Epoch [2/100], Batch [136/147] train loss: 578.83, train corr: -0.03002
Epoch [2/100], Batch [137/147] train loss: 569.54, train corr: -0.03099
Epoch [2/100], Batch [138/147] train loss: 574.06, train corr: -0.03032
Epoch [2/100], Batch [139/147] train loss: 572.54, train corr: -0.02663
Epoch [2/100], Batch [140/147] train loss: 558.21, train corr: -0.03120
Epoch [2/100], Batch [141/147] train loss: 574.42, train corr: -0.03224
Epoch [2/100], Batch [142/147] train loss: 558.17, train corr: -0.03112
Epoch [2/100], Batch [143/147] train loss: 570.36, train corr: -0.02989
Epoch [2/100], Batch [144/147] train loss: 547.96, train corr: -0.02980
Epoch [2/100], Batch [145/147] train loss: 560.96, train corr: -0.03119
Epoch [2/100], Batch [146/147] train loss: 557.84, train corr: -0.03085
Epoch [2/100], Batch [147/147] train loss: 561.81, train corr: -0.02956
Epoch [2/100], validation loss: 597.91, validation correlation: -0.03082
Epoch [3/100], Batch [1/147] train loss: 580.29, train corr: -0.02745
Epoch [3/100], Batch [2/147] train loss: 580.54, train corr: -0.02824
Epoch [3/100], Batch [3/147] train loss: 566.71, train corr: -0.02802
Epoch [3/100], Batch [4/147] train loss: 566.63, train corr: -0.02921
Epoch [3/100], Batch [5/147] train loss: 558.44, train corr: -0.03137
Epoch [3/100], Batch [6/147] train loss: 579.23, train corr: -0.02906
Epoch [3/100], Batch [7/147] train loss: 565.87, train corr: -0.02804
Epoch [3/100], Batch [8/147] train loss: 569.01, train corr: -0.02607
Epoch [3/100], Batch [9/147] train loss: 563.75, train corr: -0.03015
Epoch [3/100], Batch [10/147] train loss: 572.15, train corr: -0.02898
Epoch [3/100], Batch [11/147] train loss: 569.86, train corr: -0.02883
Epoch [3/100], Batch [12/147] train loss: 566.91, train corr: -0.02980
Epoch [3/100], Batch [13/147] train loss: 575.35, train corr: -0.02969
Epoch [3/100], Batch [14/147] train loss: 571.71, train corr: -0.02797
Epoch [3/100], Batch [15/147] train loss: 558.48, train corr: -0.03052
Epoch [3/100], Batch [16/147] train loss: 563.33, train corr: -0.02855
Epoch [3/100], Batch [17/147] train loss: 584.68, train corr: -0.02455
Epoch [3/100], Batch [18/147] train loss: 565.43, train corr: -0.02862
Epoch [3/100], Batch [19/147] train loss: 578.68, train corr: -0.02759
Epoch [3/100], Batch [20/147] train loss: 576.68, train corr: -0.02818
Epoch [3/100], Batch [21/147] train loss: 575.70, train corr: -0.03084
Epoch [3/100], Batch [22/147] train loss: 553.68, train corr: -0.02935
Epoch [3/100], Batch [23/147] train loss: 570.35, train corr: -0.02998
Epoch [3/100], Batch [24/147] train loss: 571.19, train corr: -0.03139
Epoch [3/100], Batch [25/147] train loss: 579.54, train corr: -0.03140
Epoch [3/100], Batch [26/147] train loss: 561.07, train corr: -0.03113
Epoch [3/100], Batch [27/147] train loss: 558.02, train corr: -0.03002
Epoch [3/100], Batch [28/147] train loss: 569.40, train corr: -0.03101
Epoch [3/100], Batch [29/147] train loss: 568.15, train corr: -0.03178
Epoch [3/100], Batch [30/147] train loss: 561.97, train corr: -0.03121
Epoch [3/100], Batch [31/147] train loss: 568.07, train corr: -0.03216
Epoch [3/100], Batch [32/147] train loss: 573.98, train corr: -0.03073
Epoch [3/100], Batch [33/147] train loss: 567.40, train corr: -0.03106
Epoch [3/100], Batch [34/147] train loss: 569.15, train corr: -0.03216
Epoch [3/100], Batch [35/147] train loss: 555.83, train corr: -0.03273
Epoch [3/100], Batch [36/147] train loss: 549.80, train corr: -0.03217
Epoch [3/100], Batch [37/147] train loss: 565.53, train corr: -0.03072
Epoch [3/100], Batch [38/147] train loss: 557.87, train corr: -0.03192
Epoch [3/100], Batch [39/147] train loss: 565.78, train corr: -0.03260
Epoch [3/100], Batch [40/147] train loss: 568.98, train corr: -0.03333
Epoch [3/100], Batch [41/147] train loss: 566.28, train corr: -0.03226
Epoch [3/100], Batch [42/147] train loss: 647.53, train corr: -0.02692
Epoch [3/100], Batch [43/147] train loss: 587.43, train corr: -0.03095
Epoch [3/100], Batch [44/147] train loss: 567.51, train corr: -0.03392
Epoch [3/100], Batch [45/147] train loss: 566.50, train corr: -0.03131
Epoch [3/100], Batch [46/147] train loss: 576.24, train corr: -0.02975
Epoch [3/100], Batch [47/147] train loss: 557.70, train corr: -0.02818
Epoch [3/100], Batch [48/147] train loss: 555.77, train corr: -0.02856
Epoch [3/100], Batch [49/147] train loss: 563.84, train corr: -0.02755
Epoch [3/100], Batch [50/147] train loss: 569.65, train corr: -0.02790
Epoch [3/100], Batch [51/147] train loss: 575.18, train corr: -0.02743
Epoch [3/100], Batch [52/147] train loss: 575.93, train corr: -0.02619
Epoch [3/100], Batch [53/147] train loss: 572.60, train corr: -0.02735
Epoch [3/100], Batch [54/147] train loss: 567.12, train corr: -0.02702
Epoch [3/100], Batch [55/147] train loss: 799.60, train corr: -0.02176
Epoch [3/100], Batch [56/147] train loss: 566.14, train corr: -0.02959
Epoch [3/100], Batch [57/147] train loss: 582.33, train corr: -0.02953
Epoch [3/100], Batch [58/147] train loss: 580.39, train corr: -0.02765
Epoch [3/100], Batch [59/147] train loss: 579.54, train corr: -0.02844
Epoch [3/100], Batch [60/147] train loss: 563.29, train corr: -0.03328
Epoch [3/100], Batch [61/147] train loss: 586.70, train corr: -0.03270
Epoch [3/100], Batch [62/147] train loss: 563.98, train corr: -0.02712
Epoch [3/100], Batch [63/147] train loss: 546.66, train corr: -0.00559
Epoch [3/100], Batch [64/147] train loss: 565.23, train corr: -0.00044
Epoch [3/100], Batch [65/147] train loss: 577.94, train corr: 0.00062
Epoch [3/100], Batch [66/147] train loss: 569.60, train corr: 0.00241
Epoch [3/100], Batch [67/147] train loss: 556.63, train corr: 0.00496
Epoch [3/100], Batch [68/147] train loss: 568.22, train corr: -0.00127
Epoch [3/100], Batch [69/147] train loss: 562.59, train corr: -0.00852
Epoch [3/100], Batch [70/147] train loss: 587.32, train corr: -0.01967
Epoch [3/100], Batch [71/147] train loss: 562.67, train corr: -0.03209
Epoch [3/100], Batch [72/147] train loss: 562.58, train corr: -0.03515
Epoch [3/100], Batch [73/147] train loss: 582.84, train corr: -0.03300
Epoch [3/100], Batch [74/147] train loss: 576.24, train corr: -0.03085
Epoch [3/100], Batch [75/147] train loss: 567.99, train corr: -0.03136
Epoch [3/100], Batch [76/147] train loss: 563.40, train corr: -0.02893
Epoch [3/100], Batch [77/147] train loss: 558.04, train corr: -0.02591
Epoch [3/100], Batch [78/147] train loss: 557.07, train corr: -0.02453
Epoch [3/100], Batch [79/147] train loss: 551.39, train corr: -0.02402
Epoch [3/100], Batch [80/147] train loss: 571.51, train corr: -0.02569
Epoch [3/100], Batch [81/147] train loss: 566.14, train corr: -0.02552
Epoch [3/100], Batch [82/147] train loss: 578.56, train corr: -0.02450
Epoch [3/100], Batch [83/147] train loss: 578.32, train corr: -0.02194
Epoch [3/100], Batch [84/147] train loss: 562.38, train corr: -0.02183
Epoch [3/100], Batch [85/147] train loss: 572.73, train corr: -0.02146
Epoch [3/100], Batch [86/147] train loss: 561.39, train corr: -0.01988
Epoch [3/100], Batch [87/147] train loss: 551.49, train corr: -0.01819
Epoch [3/100], Batch [88/147] train loss: 570.12, train corr: -0.01990
Epoch [3/100], Batch [89/147] train loss: 565.31, train corr: -0.02018
Epoch [3/100], Batch [90/147] train loss: 581.09, train corr: -0.01773
Epoch [3/100], Batch [91/147] train loss: 567.12, train corr: -0.02239
Epoch [3/100], Batch [92/147] train loss: 560.33, train corr: -0.02223
Epoch [3/100], Batch [93/147] train loss: 555.06, train corr: -0.02243
Epoch [3/100], Batch [94/147] train loss: 569.64, train corr: -0.02197
Epoch [3/100], Batch [95/147] train loss: 631.33, train corr: -0.01902
Epoch [3/100], Batch [96/147] train loss: 574.77, train corr: -0.02189
Epoch [3/100], Batch [97/147] train loss: 559.97, train corr: -0.02520
Epoch [3/100], Batch [98/147] train loss: 586.28, train corr: -0.02591
Epoch [3/100], Batch [99/147] train loss: 543.68, train corr: -0.02275
Epoch [3/100], Batch [100/147] train loss: 567.45, train corr: -0.02340
Epoch [3/100], Batch [101/147] train loss: 568.73, train corr: -0.02344
Epoch [3/100], Batch [102/147] train loss: 569.85, train corr: -0.02494
Epoch [3/100], Batch [103/147] train loss: 566.83, train corr: -0.02707
Epoch [3/100], Batch [104/147] train loss: 563.37, train corr: -0.02818
Epoch [3/100], Batch [105/147] train loss: 588.94, train corr: -0.03056
Epoch [3/100], Batch [106/147] train loss: 557.65, train corr: -0.03080
Epoch [3/100], Batch [107/147] train loss: 586.48, train corr: -0.02778
Epoch [3/100], Batch [108/147] train loss: 564.02, train corr: -0.02960
Epoch [3/100], Batch [109/147] train loss: 569.97, train corr: -0.03168
Epoch [3/100], Batch [110/147] train loss: 549.27, train corr: -0.03002
Epoch [3/100], Batch [111/147] train loss: 570.02, train corr: -0.02910
Epoch [3/100], Batch [112/147] train loss: 556.64, train corr: -0.03211
Epoch [3/100], Batch [113/147] train loss: 566.68, train corr: -0.03167
Epoch [3/100], Batch [114/147] train loss: 571.94, train corr: -0.02960
Epoch [3/100], Batch [115/147] train loss: 620.59, train corr: -0.02563
Epoch [3/100], Batch [116/147] train loss: 572.20, train corr: -0.02841
Epoch [3/100], Batch [117/147] train loss: 565.39, train corr: -0.03210
Epoch [3/100], Batch [118/147] train loss: 563.73, train corr: -0.03016
Epoch [3/100], Batch [119/147] train loss: 572.77, train corr: -0.02909
Epoch [3/100], Batch [120/147] train loss: 588.58, train corr: -0.02911
Epoch [3/100], Batch [121/147] train loss: 581.91, train corr: -0.02535
Epoch [3/100], Batch [122/147] train loss: 561.05, train corr: -0.03027
Epoch [3/100], Batch [123/147] train loss: 564.21, train corr: -0.02828
Epoch [3/100], Batch [124/147] train loss: 562.11, train corr: -0.03094
Epoch [3/100], Batch [125/147] train loss: 554.82, train corr: -0.02976
Epoch [3/100], Batch [126/147] train loss: 562.83, train corr: -0.02979
Epoch [3/100], Batch [127/147] train loss: 565.02, train corr: -0.02897
Epoch [3/100], Batch [128/147] train loss: 555.23, train corr: -0.02902
Epoch [3/100], Batch [129/147] train loss: 573.63, train corr: -0.02935
Epoch [3/100], Batch [130/147] train loss: 555.97, train corr: -0.02911
Epoch [3/100], Batch [131/147] train loss: 554.88, train corr: -0.02730
Epoch [3/100], Batch [132/147] train loss: 578.35, train corr: -0.02891
Epoch [3/100], Batch [133/147] train loss: 573.18, train corr: -0.02942
Epoch [3/100], Batch [134/147] train loss: 555.72, train corr: -0.02962
Epoch [3/100], Batch [135/147] train loss: 549.81, train corr: -0.02872
Epoch [3/100], Batch [136/147] train loss: 756.52, train corr: -0.02766
Epoch [3/100], Batch [137/147] train loss: 574.51, train corr: -0.02776
Epoch [3/100], Batch [138/147] train loss: 554.34, train corr: -0.02897
Epoch [3/100], Batch [139/147] train loss: 571.98, train corr: -0.02602
Epoch [3/100], Batch [140/147] train loss: 576.92, train corr: -0.02866
Epoch [3/100], Batch [141/147] train loss: 573.12, train corr: -0.02828
Epoch [3/100], Batch [142/147] train loss: 587.62, train corr: -0.02415
Epoch [3/100], Batch [143/147] train loss: 582.68, train corr: -0.03045
Epoch [3/100], Batch [144/147] train loss: 570.95, train corr: -0.01454
Epoch [3/100], Batch [145/147] train loss: 588.97, train corr: -0.00129
Epoch [3/100], Batch [146/147] train loss: 565.33, train corr: 0.00682
Epoch [3/100], Batch [147/147] train loss: 569.49, train corr: -0.00168
Epoch [3/100], validation loss: 597.69, validation correlation: -0.01142
Epoch [4/100], Batch [1/147] train loss: 616.30, train corr: -0.00759
Epoch [4/100], Batch [2/147] train loss: 588.69, train corr: -0.02886
Epoch [4/100], Batch [3/147] train loss: 569.42, train corr: -0.03241
Epoch [4/100], Batch [4/147] train loss: 570.40, train corr: -0.02760
Epoch [4/100], Batch [5/147] train loss: 552.55, train corr: -0.02982
Epoch [4/100], Batch [6/147] train loss: 557.35, train corr: -0.02851
Epoch [4/100], Batch [7/147] train loss: 568.74, train corr: -0.02446
Epoch [4/100], Batch [8/147] train loss: 572.52, train corr: -0.02159
Epoch [4/100], Batch [9/147] train loss: 555.23, train corr: -0.02579
Epoch [4/100], Batch [10/147] train loss: 565.08, train corr: -0.02645
Epoch [4/100], Batch [11/147] train loss: 571.97, train corr: -0.02520
Epoch [4/100], Batch [12/147] train loss: 574.41, train corr: -0.02364
Epoch [4/100], Batch [13/147] train loss: 568.03, train corr: -0.02668
Epoch [4/100], Batch [14/147] train loss: 561.78, train corr: -0.02242
Epoch [4/100], Batch [15/147] train loss: 574.15, train corr: -0.02160
Epoch [4/100], Batch [16/147] train loss: 567.79, train corr: -0.02302
Epoch [4/100], Batch [17/147] train loss: 571.26, train corr: -0.02199
Epoch [4/100], Batch [18/147] train loss: 577.38, train corr: -0.02186
Epoch [4/100], Batch [19/147] train loss: 562.09, train corr: -0.02392
Epoch [4/100], Batch [20/147] train loss: 566.40, train corr: -0.02679
Epoch [4/100], Batch [21/147] train loss: 561.36, train corr: -0.02470
Epoch [4/100], Batch [22/147] train loss: 554.83, train corr: -0.02543
Epoch [4/100], Batch [23/147] train loss: 565.31, train corr: -0.02664
Epoch [4/100], Batch [24/147] train loss: 571.07, train corr: -0.02603
Epoch [4/100], Batch [25/147] train loss: 555.59, train corr: -0.02670
Epoch [4/100], Batch [26/147] train loss: 566.73, train corr: -0.02819
Epoch [4/100], Batch [27/147] train loss: 568.33, train corr: -0.02713
Epoch [4/100], Batch [28/147] train loss: 577.91, train corr: -0.02628
Epoch [4/100], Batch [29/147] train loss: 561.04, train corr: -0.02740
Epoch [4/100], Batch [30/147] train loss: 572.23, train corr: -0.02490
Epoch [4/100], Batch [31/147] train loss: 565.51, train corr: -0.02705
Epoch [4/100], Batch [32/147] train loss: 553.58, train corr: -0.02884
Epoch [4/100], Batch [33/147] train loss: 560.71, train corr: -0.02972
Epoch [4/100], Batch [34/147] train loss: 565.74, train corr: -0.02821
Epoch [4/100], Batch [35/147] train loss: 575.06, train corr: -0.02986
Epoch [4/100], Batch [36/147] train loss: 552.19, train corr: -0.02701
Epoch [4/100], Batch [37/147] train loss: 586.41, train corr: -0.02312
Epoch [4/100], Batch [38/147] train loss: 563.73, train corr: -0.02630
Epoch [4/100], Batch [39/147] train loss: 564.07, train corr: -0.02770
Epoch [4/100], Batch [40/147] train loss: 566.04, train corr: -0.02846
Epoch [4/100], Batch [41/147] train loss: 564.87, train corr: -0.02931
Epoch [4/100], Batch [42/147] train loss: 582.15, train corr: -0.02614
Epoch [4/100], Batch [43/147] train loss: 574.97, train corr: -0.02563
Epoch [4/100], Batch [44/147] train loss: 559.55, train corr: -0.02687
Epoch [4/100], Batch [45/147] train loss: 560.67, train corr: -0.02512
Epoch [4/100], Batch [46/147] train loss: 572.14, train corr: -0.02629
Epoch [4/100], Batch [47/147] train loss: 567.23, train corr: -0.02543
Epoch [4/100], Batch [48/147] train loss: 570.95, train corr: -0.02484
Epoch [4/100], Batch [49/147] train loss: 561.47, train corr: -0.02564
Epoch [4/100], Batch [50/147] train loss: 571.98, train corr: -0.02463
Epoch [4/100], Batch [51/147] train loss: 552.42, train corr: -0.02623
Epoch [4/100], Batch [52/147] train loss: 565.11, train corr: -0.02723
Epoch [4/100], Batch [53/147] train loss: 568.12, train corr: -0.02733
Epoch [4/100], Batch [54/147] train loss: 574.75, train corr: -0.02255
Epoch [4/100], Batch [55/147] train loss: 575.66, train corr: -0.02576
Epoch [4/100], Batch [56/147] train loss: 572.17, train corr: -0.02926
Epoch [4/100], Batch [57/147] train loss: 570.05, train corr: -0.02623
Epoch [4/100], Batch [58/147] train loss: 575.51, train corr: -0.03296
Epoch [4/100], Batch [59/147] train loss: 572.47, train corr: -0.02965
Epoch [4/100], Batch [60/147] train loss: 564.04, train corr: -0.03058
Epoch [4/100], Batch [61/147] train loss: 568.84, train corr: -0.02940
Epoch [4/100], Batch [62/147] train loss: 558.17, train corr: -0.03332
Epoch [4/100], Batch [63/147] train loss: 570.27, train corr: -0.02971
Epoch [4/100], Batch [64/147] train loss: 562.57, train corr: -0.02749
Epoch [4/100], Batch [65/147] train loss: 553.93, train corr: -0.03126
Epoch [4/100], Batch [66/147] train loss: 569.61, train corr: -0.02937
Epoch [4/100], Batch [67/147] train loss: 571.55, train corr: -0.02945
Epoch [4/100], Batch [68/147] train loss: 572.09, train corr: -0.02916
Epoch [4/100], Batch [69/147] train loss: 574.73, train corr: -0.03160
Epoch [4/100], Batch [70/147] train loss: 560.52, train corr: -0.03279
Epoch [4/100], Batch [71/147] train loss: 577.05, train corr: -0.02659
Epoch [4/100], Batch [72/147] train loss: 573.77, train corr: -0.02906
Epoch [4/100], Batch [73/147] train loss: 575.85, train corr: -0.02978
Epoch [4/100], Batch [74/147] train loss: 560.55, train corr: -0.03016
Epoch [4/100], Batch [75/147] train loss: 814.78, train corr: -0.02363
Epoch [4/100], Batch [76/147] train loss: 560.82, train corr: -0.02371
Epoch [4/100], Batch [77/147] train loss: 569.62, train corr: -0.02740
Epoch [4/100], Batch [78/147] train loss: 572.70, train corr: -0.02600
Epoch [4/100], Batch [79/147] train loss: 581.05, train corr: -0.02112
Epoch [4/100], Batch [80/147] train loss: 555.89, train corr: -0.02826
Epoch [4/100], Batch [81/147] train loss: 563.81, train corr: -0.02073
Epoch [4/100], Batch [82/147] train loss: 561.76, train corr: -0.00030
Epoch [4/100], Batch [83/147] train loss: 581.78, train corr: 0.01292
Epoch [4/100], Batch [84/147] train loss: 570.27, train corr: 0.01715
Epoch [4/100], Batch [85/147] train loss: 557.11, train corr: 0.02041
Epoch [4/100], Batch [86/147] train loss: 639.98, train corr: 0.01610
Epoch [4/100], Batch [87/147] train loss: 577.32, train corr: 0.01812
Epoch [4/100], Batch [88/147] train loss: 568.69, train corr: 0.01865
Epoch [4/100], Batch [89/147] train loss: 566.08, train corr: 0.02165
Epoch [4/100], Batch [90/147] train loss: 547.18, train corr: 0.01825
Epoch [4/100], Batch [91/147] train loss: 567.03, train corr: 0.02142
Epoch [4/100], Batch [92/147] train loss: 582.27, train corr: 0.01984
Epoch [4/100], Batch [93/147] train loss: 571.18, train corr: 0.01854
Epoch [4/100], Batch [94/147] train loss: 599.22, train corr: 0.02371
Epoch [4/100], Batch [95/147] train loss: 605.88, train corr: 0.00882
Epoch [4/100], Batch [96/147] train loss: 567.09, train corr: 0.00597
Epoch [4/100], Batch [97/147] train loss: 579.93, train corr: -0.00257
Epoch [4/100], Batch [98/147] train loss: 568.60, train corr: -0.00872
Epoch [4/100], Batch [99/147] train loss: 573.63, train corr: -0.00579
Epoch [4/100], Batch [100/147] train loss: 568.84, train corr: -0.00535
Epoch [4/100], Batch [101/147] train loss: 569.22, train corr: 0.00905
Epoch [4/100], Batch [102/147] train loss: 564.33, train corr: 0.02018
Epoch [4/100], Batch [103/147] train loss: 568.74, train corr: 0.02839
Epoch [4/100], Batch [104/147] train loss: 554.53, train corr: 0.03046
Epoch [4/100], Batch [105/147] train loss: 568.48, train corr: 0.02956
Epoch [4/100], Batch [106/147] train loss: 577.55, train corr: 0.02584
Epoch [4/100], Batch [107/147] train loss: 575.52, train corr: 0.02040
Epoch [4/100], Batch [108/147] train loss: 563.77, train corr: 0.00758
Epoch [4/100], Batch [109/147] train loss: 578.98, train corr: -0.00032
Epoch [4/100], Batch [110/147] train loss: 577.15, train corr: -0.01310
Epoch [4/100], Batch [111/147] train loss: 572.25, train corr: -0.01034
Epoch [4/100], Batch [112/147] train loss: 561.29, train corr: -0.01702
Epoch [4/100], Batch [113/147] train loss: 562.90, train corr: -0.01938
Epoch [4/100], Batch [114/147] train loss: 564.28, train corr: -0.02176
Epoch [4/100], Batch [115/147] train loss: 585.64, train corr: -0.01412
Epoch [4/100], Batch [116/147] train loss: 575.68, train corr: -0.01287
Epoch [4/100], Batch [117/147] train loss: 568.04, train corr: -0.01754
Epoch [4/100], Batch [118/147] train loss: 564.44, train corr: -0.01812
Epoch [4/100], Batch [119/147] train loss: 571.86, train corr: -0.01661
Epoch [4/100], Batch [120/147] train loss: 571.80, train corr: -0.02408
Epoch [4/100], Batch [121/147] train loss: 577.48, train corr: -0.02027
Epoch [4/100], Batch [122/147] train loss: 542.74, train corr: -0.02528
Epoch [4/100], Batch [123/147] train loss: 560.51, train corr: -0.02166
Epoch [4/100], Batch [124/147] train loss: 546.23, train corr: -0.02715
Epoch [4/100], Batch [125/147] train loss: 567.98, train corr: -0.02016
Epoch [4/100], Batch [126/147] train loss: 563.08, train corr: -0.02347
Epoch [4/100], Batch [127/147] train loss: 568.83, train corr: -0.02436
Epoch [4/100], Batch [128/147] train loss: 582.90, train corr: -0.02015
Epoch [4/100], Batch [129/147] train loss: 581.58, train corr: -0.02183
Epoch [4/100], Batch [130/147] train loss: 579.52, train corr: -0.02318
Epoch [4/100], Batch [131/147] train loss: 568.01, train corr: -0.02392
Epoch [4/100], Batch [132/147] train loss: 586.77, train corr: -0.01914
Epoch [4/100], Batch [133/147] train loss: 554.23, train corr: -0.02925
Epoch [4/100], Batch [134/147] train loss: 570.32, train corr: -0.02558
Epoch [4/100], Batch [135/147] train loss: 552.54, train corr: -0.02740
Epoch [4/100], Batch [136/147] train loss: 561.73, train corr: -0.02582
Epoch [4/100], Batch [137/147] train loss: 746.77, train corr: -0.02316
Epoch [4/100], Batch [138/147] train loss: 562.75, train corr: -0.02619
Epoch [4/100], Batch [139/147] train loss: 558.58, train corr: -0.02834
Epoch [4/100], Batch [140/147] train loss: 583.94, train corr: -0.02551
Epoch [4/100], Batch [141/147] train loss: 593.80, train corr: -0.02441
Epoch [4/100], Batch [142/147] train loss: 592.90, train corr: -0.02473
Epoch [4/100], Batch [143/147] train loss: 582.31, train corr: -0.02174
Epoch [4/100], Batch [144/147] train loss: 562.05, train corr: -0.00633
Epoch [4/100], Batch [145/147] train loss: 547.33, train corr: 0.01707
Epoch [4/100], Batch [146/147] train loss: 558.37, train corr: 0.02269
Epoch [4/100], Batch [147/147] train loss: 577.57, train corr: 0.02056
Epoch [4/100], validation loss: 598.80, validation correlation: 0.02295
Epoch [5/100], Batch [1/147] train loss: 587.78, train corr: 0.01846
Epoch [5/100], Batch [2/147] train loss: 571.41, train corr: 0.01969
Epoch [5/100], Batch [3/147] train loss: 568.73, train corr: 0.02042
Epoch [5/100], Batch [4/147] train loss: 558.08, train corr: 0.01727
Epoch [5/100], Batch [5/147] train loss: 568.51, train corr: -0.00819
Epoch [5/100], Batch [6/147] train loss: 565.51, train corr: -0.02626
Epoch [5/100], Batch [7/147] train loss: 562.12, train corr: -0.02485
Epoch [5/100], Batch [8/147] train loss: 565.74, train corr: -0.02504
Epoch [5/100], Batch [9/147] train loss: 618.79, train corr: -0.01842
Epoch [5/100], Batch [10/147] train loss: 593.80, train corr: -0.01870
Epoch [5/100], Batch [11/147] train loss: 637.14, train corr: -0.02139
Epoch [5/100], Batch [12/147] train loss: 554.51, train corr: -0.01820
Epoch [5/100], Batch [13/147] train loss: 573.36, train corr: 0.01017
Epoch [5/100], Batch [14/147] train loss: 574.46, train corr: 0.01937
Epoch [5/100], Batch [15/147] train loss: 563.31, train corr: 0.02307
Epoch [5/100], Batch [16/147] train loss: 596.47, train corr: 0.01599
Epoch [5/100], Batch [17/147] train loss: 575.27, train corr: 0.02233
Epoch [5/100], Batch [18/147] train loss: 571.85, train corr: 0.02103
Epoch [5/100], Batch [19/147] train loss: 560.83, train corr: 0.02005
Epoch [5/100], Batch [20/147] train loss: 568.12, train corr: 0.01371
Epoch [5/100], Batch [21/147] train loss: 568.48, train corr: 0.00570
Epoch [5/100], Batch [22/147] train loss: 558.64, train corr: -0.00041
Epoch [5/100], Batch [23/147] train loss: 565.60, train corr: -0.00545
Epoch [5/100], Batch [24/147] train loss: 560.38, train corr: -0.01233
Epoch [5/100], Batch [25/147] train loss: 569.45, train corr: -0.01116
Epoch [5/100], Batch [26/147] train loss: 562.26, train corr: -0.01514
Epoch [5/100], Batch [27/147] train loss: 568.41, train corr: -0.01296
Epoch [5/100], Batch [28/147] train loss: 561.57, train corr: -0.01705
Epoch [5/100], Batch [29/147] train loss: 561.27, train corr: -0.01864
Epoch [5/100], Batch [30/147] train loss: 585.60, train corr: -0.02170
Epoch [5/100], Batch [31/147] train loss: 567.94, train corr: -0.02052
Epoch [5/100], Batch [32/147] train loss: 560.04, train corr: -0.02208
Epoch [5/100], Batch [33/147] train loss: 570.00, train corr: -0.02602
Epoch [5/100], Batch [34/147] train loss: 558.73, train corr: -0.02961
Epoch [5/100], Batch [35/147] train loss: 572.09, train corr: -0.03001
Epoch [5/100], Batch [36/147] train loss: 586.88, train corr: -0.02658
Epoch [5/100], Batch [37/147] train loss: 570.42, train corr: -0.03070
Epoch [5/100], Batch [38/147] train loss: 572.80, train corr: -0.03117
Epoch [5/100], Batch [39/147] train loss: 586.62, train corr: -0.03268
Epoch [5/100], Batch [40/147] train loss: 580.29, train corr: -0.03053
Epoch [5/100], Batch [41/147] train loss: 565.93, train corr: -0.03336
Epoch [5/100], Batch [42/147] train loss: 552.41, train corr: -0.03250
Epoch [5/100], Batch [43/147] train loss: 571.69, train corr: -0.03069
Epoch [5/100], Batch [44/147] train loss: 565.59, train corr: -0.03240
Epoch [5/100], Batch [45/147] train loss: 558.06, train corr: -0.03127
Epoch [5/100], Batch [46/147] train loss: 562.22, train corr: -0.03380
Epoch [5/100], Batch [47/147] train loss: 581.12, train corr: -0.03334
Epoch [5/100], Batch [48/147] train loss: 572.59, train corr: -0.03335
Epoch [5/100], Batch [49/147] train loss: 560.37, train corr: -0.03494
Epoch [5/100], Batch [50/147] train loss: 553.04, train corr: -0.03479
Epoch [5/100], Batch [51/147] train loss: 574.78, train corr: -0.03146
Epoch [5/100], Batch [52/147] train loss: 554.44, train corr: -0.03501
Epoch [5/100], Batch [53/147] train loss: 579.65, train corr: -0.03156
Epoch [5/100], Batch [54/147] train loss: 568.37, train corr: -0.03110
Epoch [5/100], Batch [55/147] train loss: 561.69, train corr: -0.03368
Epoch [5/100], Batch [56/147] train loss: 570.60, train corr: -0.03318
Epoch [5/100], Batch [57/147] train loss: 553.64, train corr: -0.03371
Epoch [5/100], Batch [58/147] train loss: 572.02, train corr: -0.03145
Epoch [5/100], Batch [59/147] train loss: 569.08, train corr: -0.03327
Epoch [5/100], Batch [60/147] train loss: 565.99, train corr: -0.03310
Epoch [5/100], Batch [61/147] train loss: 561.57, train corr: -0.03347
Epoch [5/100], Batch [62/147] train loss: 579.54, train corr: -0.03219
Epoch [5/100], Batch [63/147] train loss: 569.10, train corr: -0.03103
Epoch [5/100], Batch [64/147] train loss: 575.89, train corr: -0.03131
Epoch [5/100], Batch [65/147] train loss: 571.99, train corr: -0.03243
Epoch [5/100], Batch [66/147] train loss: 580.17, train corr: -0.02986
Epoch [5/100], Batch [67/147] train loss: 571.91, train corr: -0.03270
Epoch [5/100], Batch [68/147] train loss: 560.88, train corr: -0.03142
Epoch [5/100], Batch [69/147] train loss: 578.54, train corr: -0.03307
Epoch [5/100], Batch [70/147] train loss: 578.29, train corr: -0.02969
Epoch [5/100], Batch [71/147] train loss: 570.18, train corr: -0.03251
Epoch [5/100], Batch [72/147] train loss: 560.61, train corr: -0.03231
Epoch [5/100], Batch [73/147] train loss: 611.86, train corr: -0.02689
Epoch [5/100], Batch [74/147] train loss: 565.71, train corr: -0.03165
Epoch [5/100], Batch [75/147] train loss: 573.98, train corr: -0.03250
Epoch [5/100], Batch [76/147] train loss: 574.01, train corr: -0.03110
Epoch [5/100], Batch [77/147] train loss: 557.84, train corr: -0.03102
Epoch [5/100], Batch [78/147] train loss: 577.08, train corr: -0.02912
Epoch [5/100], Batch [79/147] train loss: 574.43, train corr: -0.02964
Epoch [5/100], Batch [80/147] train loss: 567.98, train corr: -0.02912
Epoch [5/100], Batch [81/147] train loss: 550.17, train corr: -0.02816
Epoch [5/100], Batch [82/147] train loss: 573.15, train corr: -0.02709
Epoch [5/100], Batch [83/147] train loss: 567.48, train corr: -0.02783
Epoch [5/100], Batch [84/147] train loss: 567.52, train corr: -0.02416
Epoch [5/100], Batch [85/147] train loss: 561.31, train corr: -0.02807
Epoch [5/100], Batch [86/147] train loss: 560.48, train corr: -0.02802
Epoch [5/100], Batch [87/147] train loss: 579.30, train corr: -0.02958
Epoch [5/100], Batch [88/147] train loss: 572.10, train corr: -0.02797
Epoch [5/100], Batch [89/147] train loss: 559.63, train corr: -0.02732
Epoch [5/100], Batch [90/147] train loss: 555.60, train corr: -0.02713
Epoch [5/100], Batch [91/147] train loss: 560.42, train corr: -0.02781
Epoch [5/100], Batch [92/147] train loss: 572.07, train corr: -0.02588
Epoch [5/100], Batch [93/147] train loss: 555.21, train corr: -0.02578
Epoch [5/100], Batch [94/147] train loss: 566.69, train corr: -0.02711
Epoch [5/100], Batch [95/147] train loss: 563.39, train corr: -0.02718
Epoch [5/100], Batch [96/147] train loss: 568.61, train corr: -0.02819
Epoch [5/100], Batch [97/147] train loss: 559.28, train corr: -0.02883
Epoch [5/100], Batch [98/147] train loss: 555.26, train corr: -0.02848
Epoch [5/100], Batch [99/147] train loss: 579.27, train corr: -0.02719
Epoch [5/100], Batch [100/147] train loss: 570.64, train corr: -0.02748
Epoch [5/100], Batch [101/147] train loss: 563.46, train corr: -0.02495
Epoch [5/100], Batch [102/147] train loss: 566.56, train corr: -0.02774
Epoch [5/100], Batch [103/147] train loss: 573.52, train corr: -0.03171
Epoch [5/100], Batch [104/147] train loss: 573.42, train corr: -0.02892
Epoch [5/100], Batch [105/147] train loss: 564.30, train corr: -0.02844
Epoch [5/100], Batch [106/147] train loss: 556.48, train corr: -0.02936
Epoch [5/100], Batch [107/147] train loss: 573.42, train corr: -0.02665
Epoch [5/100], Batch [108/147] train loss: 564.37, train corr: -0.02949
Epoch [5/100], Batch [109/147] train loss: 554.45, train corr: -0.02927
Epoch [5/100], Batch [110/147] train loss: 553.20, train corr: -0.02989
Epoch [5/100], Batch [111/147] train loss: 570.27, train corr: -0.03015
Epoch [5/100], Batch [112/147] train loss: 576.64, train corr: -0.03151
Epoch [5/100], Batch [113/147] train loss: 560.27, train corr: -0.02902
Epoch [5/100], Batch [114/147] train loss: 558.86, train corr: -0.03165
Epoch [5/100], Batch [115/147] train loss: 556.69, train corr: -0.03110
Epoch [5/100], Batch [116/147] train loss: 568.18, train corr: -0.02905
Epoch [5/100], Batch [117/147] train loss: 563.98, train corr: -0.03209
Epoch [5/100], Batch [118/147] train loss: 571.22, train corr: -0.03075
Epoch [5/100], Batch [119/147] train loss: 582.86, train corr: -0.03132
Epoch [5/100], Batch [120/147] train loss: 569.55, train corr: -0.03171
Epoch [5/100], Batch [121/147] train loss: 565.46, train corr: -0.03135
Epoch [5/100], Batch [122/147] train loss: 574.49, train corr: -0.03234
Epoch [5/100], Batch [123/147] train loss: 582.15, train corr: -0.03080
Epoch [5/100], Batch [124/147] train loss: 554.52, train corr: -0.03275
Epoch [5/100], Batch [125/147] train loss: 560.37, train corr: -0.03246
Epoch [5/100], Batch [126/147] train loss: 570.86, train corr: -0.03155
Epoch [5/100], Batch [127/147] train loss: 560.16, train corr: -0.03335
Epoch [5/100], Batch [128/147] train loss: 555.12, train corr: -0.03331
Epoch [5/100], Batch [129/147] train loss: 566.65, train corr: -0.03355
Epoch [5/100], Batch [130/147] train loss: 556.71, train corr: -0.03282
Epoch [5/100], Batch [131/147] train loss: 559.76, train corr: -0.03339
Epoch [5/100], Batch [132/147] train loss: 782.26, train corr: -0.02442
Epoch [5/100], Batch [133/147] train loss: 563.88, train corr: -0.02954
Epoch [5/100], Batch [134/147] train loss: 574.48, train corr: -0.02662
Epoch [5/100], Batch [135/147] train loss: 570.13, train corr: -0.02586
Epoch [5/100], Batch [136/147] train loss: 572.27, train corr: -0.02733
Epoch [5/100], Batch [137/147] train loss: 563.73, train corr: -0.02824
Epoch [5/100], Batch [138/147] train loss: 797.58, train corr: -0.02510
Epoch [5/100], Batch [139/147] train loss: 566.57, train corr: -0.02779
Epoch [5/100], Batch [140/147] train loss: 568.90, train corr: -0.02611
Epoch [5/100], Batch [141/147] train loss: 573.54, train corr: -0.01983
Epoch [5/100], Batch [142/147] train loss: 575.50, train corr: -0.01537
Epoch [5/100], Batch [143/147] train loss: 576.02, train corr: -0.00705
Epoch [5/100], Batch [144/147] train loss: 574.37, train corr: 0.00849
Epoch [5/100], Batch [145/147] train loss: 592.89, train corr: 0.01449
Epoch [5/100], Batch [146/147] train loss: 561.98, train corr: 0.01952
Epoch [5/100], Batch [147/147] train loss: 549.17, train corr: 0.02159
Epoch [5/100], validation loss: 600.86, validation correlation: 0.02262
Epoch [6/100], Batch [1/147] train loss: 578.83, train corr: 0.01960
Epoch [6/100], Batch [2/147] train loss: 578.98, train corr: 0.02307
Epoch [6/100], Batch [3/147] train loss: 580.79, train corr: 0.02239
Epoch [6/100], Batch [4/147] train loss: 576.77, train corr: 0.02434
Epoch [6/100], Batch [5/147] train loss: 578.28, train corr: 0.02417
Epoch [6/100], Batch [6/147] train loss: 568.27, train corr: 0.02619
Epoch [6/100], Batch [7/147] train loss: 580.83, train corr: 0.02772
Epoch [6/100], Batch [8/147] train loss: 570.53, train corr: 0.03349
Epoch [6/100], Batch [9/147] train loss: 558.60, train corr: 0.02994
Epoch [6/100], Batch [10/147] train loss: 571.08, train corr: 0.02851
Epoch [6/100], Batch [11/147] train loss: 558.32, train corr: 0.02355
Epoch [6/100], Batch [12/147] train loss: 568.11, train corr: 0.01821
Epoch [6/100], Batch [13/147] train loss: 558.70, train corr: 0.01642
Epoch [6/100], Batch [14/147] train loss: 569.63, train corr: 0.01761
Epoch [6/100], Batch [15/147] train loss: 573.16, train corr: 0.01658
Epoch [6/100], Batch [16/147] train loss: 580.62, train corr: 0.01939
Epoch [6/100], Batch [17/147] train loss: 568.07, train corr: 0.01889
Epoch [6/100], Batch [18/147] train loss: 568.07, train corr: 0.02570
Epoch [6/100], Batch [19/147] train loss: 547.22, train corr: 0.02550
Epoch [6/100], Batch [20/147] train loss: 558.09, train corr: 0.02725
Epoch [6/100], Batch [21/147] train loss: 560.15, train corr: 0.02585
Epoch [6/100], Batch [22/147] train loss: 543.90, train corr: 0.02844
Epoch [6/100], Batch [23/147] train loss: 572.43, train corr: 0.02802
Epoch [6/100], Batch [24/147] train loss: 580.66, train corr: 0.03026
Epoch [6/100], Batch [25/147] train loss: 575.92, train corr: 0.03262
Epoch [6/100], Batch [26/147] train loss: 580.28, train corr: 0.03117
Epoch [6/100], Batch [27/147] train loss: 578.52, train corr: 0.02834
Epoch [6/100], Batch [28/147] train loss: 551.24, train corr: 0.02701
Epoch [6/100], Batch [29/147] train loss: 560.80, train corr: 0.02665
Epoch [6/100], Batch [30/147] train loss: 559.91, train corr: 0.02493
Epoch [6/100], Batch [31/147] train loss: 565.66, train corr: 0.02274
Epoch [6/100], Batch [32/147] train loss: 575.12, train corr: 0.02218
Epoch [6/100], Batch [33/147] train loss: 567.54, train corr: 0.02059
Epoch [6/100], Batch [34/147] train loss: 564.48, train corr: 0.02080
Epoch [6/100], Batch [35/147] train loss: 567.96, train corr: 0.01224
Epoch [6/100], Batch [36/147] train loss: 568.71, train corr: 0.00614
Epoch [6/100], Batch [37/147] train loss: 568.90, train corr: 0.00264
Epoch [6/100], Batch [38/147] train loss: 580.16, train corr: 0.00777
Epoch [6/100], Batch [39/147] train loss: 577.39, train corr: 0.01715
Epoch [6/100], Batch [40/147] train loss: 560.02, train corr: 0.02330
Epoch [6/100], Batch [41/147] train loss: 554.47, train corr: 0.02120
Epoch [6/100], Batch [42/147] train loss: 575.85, train corr: 0.01309
Epoch [6/100], Batch [43/147] train loss: 576.43, train corr: 0.00762
Epoch [6/100], Batch [44/147] train loss: 567.37, train corr: 0.00481
Epoch [6/100], Batch [45/147] train loss: 574.29, train corr: 0.00415
Epoch [6/100], Batch [46/147] train loss: 563.94, train corr: 0.00708
Epoch [6/100], Batch [47/147] train loss: 562.91, train corr: 0.00811
Epoch [6/100], Batch [48/147] train loss: 570.86, train corr: 0.00892
Epoch [6/100], Batch [49/147] train loss: 576.99, train corr: 0.00824
Epoch [6/100], Batch [50/147] train loss: 581.68, train corr: 0.01080
Epoch [6/100], Batch [51/147] train loss: 564.77, train corr: 0.01596
Epoch [6/100], Batch [52/147] train loss: 563.51, train corr: 0.02014
Epoch [6/100], Batch [53/147] train loss: 577.90, train corr: 0.01966
Epoch [6/100], Batch [54/147] train loss: 562.75, train corr: 0.02014
Epoch [6/100], Batch [55/147] train loss: 570.42, train corr: 0.02010
Epoch [6/100], Batch [56/147] train loss: 564.01, train corr: 0.02054
Epoch [6/100], Batch [57/147] train loss: 569.77, train corr: 0.01843
Epoch [6/100], Batch [58/147] train loss: 572.10, train corr: 0.01425
Epoch [6/100], Batch [59/147] train loss: 560.41, train corr: 0.01659
Epoch [6/100], Batch [60/147] train loss: 575.94, train corr: 0.00970
Epoch [6/100], Batch [61/147] train loss: 559.45, train corr: 0.01490
Epoch [6/100], Batch [62/147] train loss: 564.70, train corr: 0.01588
Epoch [6/100], Batch [63/147] train loss: 753.18, train corr: 0.01052
Epoch [6/100], Batch [64/147] train loss: 587.49, train corr: 0.02514
Epoch [6/100], Batch [65/147] train loss: 561.66, train corr: 0.02187
Epoch [6/100], Batch [66/147] train loss: 585.82, train corr: -0.02647
Epoch [6/100], Batch [67/147] train loss: 580.85, train corr: -0.02218
Epoch [6/100], Batch [68/147] train loss: 579.33, train corr: -0.02274
Epoch [6/100], Batch [69/147] train loss: 556.90, train corr: -0.02614
Epoch [6/100], Batch [70/147] train loss: 575.12, train corr: -0.02255
Epoch [6/100], Batch [71/147] train loss: 570.32, train corr: -0.02286
Epoch [6/100], Batch [72/147] train loss: 568.43, train corr: -0.01764
Epoch [6/100], Batch [73/147] train loss: 553.26, train corr: 0.00122
Epoch [6/100], Batch [74/147] train loss: 565.74, train corr: 0.01693
Epoch [6/100], Batch [75/147] train loss: 567.68, train corr: 0.02158
Epoch [6/100], Batch [76/147] train loss: 562.68, train corr: 0.02020
Epoch [6/100], Batch [77/147] train loss: 573.49, train corr: 0.02122
Epoch [6/100], Batch [78/147] train loss: 576.00, train corr: 0.02212
Epoch [6/100], Batch [79/147] train loss: 569.74, train corr: 0.02009
Epoch [6/100], Batch [80/147] train loss: 568.97, train corr: 0.02191
Epoch [6/100], Batch [81/147] train loss: 569.15, train corr: 0.02367
Epoch [6/100], Batch [82/147] train loss: 567.55, train corr: 0.02296
Epoch [6/100], Batch [83/147] train loss: 583.02, train corr: 0.01729
Epoch [6/100], Batch [84/147] train loss: 566.58, train corr: 0.01942
Epoch [6/100], Batch [85/147] train loss: 556.07, train corr: 0.01535
Epoch [6/100], Batch [86/147] train loss: 568.39, train corr: -0.00006
Epoch [6/100], Batch [87/147] train loss: 562.09, train corr: -0.02292
Epoch [6/100], Batch [88/147] train loss: 567.74, train corr: -0.02734
Epoch [6/100], Batch [89/147] train loss: 571.51, train corr: -0.02949
Epoch [6/100], Batch [90/147] train loss: 563.48, train corr: -0.02689
Epoch [6/100], Batch [91/147] train loss: 560.11, train corr: -0.02639
Epoch [6/100], Batch [92/147] train loss: 587.17, train corr: -0.02513
Epoch [6/100], Batch [93/147] train loss: 617.18, train corr: -0.02748
Epoch [6/100], Batch [94/147] train loss: 565.27, train corr: -0.02762
Epoch [6/100], Batch [95/147] train loss: 568.40, train corr: -0.02791
Epoch [6/100], Batch [96/147] train loss: 563.27, train corr: -0.02901
Epoch [6/100], Batch [97/147] train loss: 565.35, train corr: -0.02820
Epoch [6/100], Batch [98/147] train loss: 569.31, train corr: -0.02818
Epoch [6/100], Batch [99/147] train loss: 573.21, train corr: -0.02602
Epoch [6/100], Batch [100/147] train loss: 562.37, train corr: -0.02888
Epoch [6/100], Batch [101/147] train loss: 814.87, train corr: -0.02661
Epoch [6/100], Batch [102/147] train loss: 570.02, train corr: -0.02874
Epoch [6/100], Batch [103/147] train loss: 575.70, train corr: -0.02133
Epoch [6/100], Batch [104/147] train loss: 579.15, train corr: -0.02698
Epoch [6/100], Batch [105/147] train loss: 568.84, train corr: -0.00927
Epoch [6/100], Batch [106/147] train loss: 567.14, train corr: 0.02056
Epoch [6/100], Batch [107/147] train loss: 575.76, train corr: 0.02185
Epoch [6/100], Batch [108/147] train loss: 577.53, train corr: 0.02417
Epoch [6/100], Batch [109/147] train loss: 562.21, train corr: 0.02471
Epoch [6/100], Batch [110/147] train loss: 562.07, train corr: 0.02604
Epoch [6/100], Batch [111/147] train loss: 580.10, train corr: 0.02238
Epoch [6/100], Batch [112/147] train loss: 564.71, train corr: 0.02735
Epoch [6/100], Batch [113/147] train loss: 584.56, train corr: 0.02367
Epoch [6/100], Batch [114/147] train loss: 553.25, train corr: 0.02634
Epoch [6/100], Batch [115/147] train loss: 558.17, train corr: 0.02935
Epoch [6/100], Batch [116/147] train loss: 558.21, train corr: 0.02909
Epoch [6/100], Batch [117/147] train loss: 571.77, train corr: 0.02678
Epoch [6/100], Batch [118/147] train loss: 559.46, train corr: 0.03116
Epoch [6/100], Batch [119/147] train loss: 589.30, train corr: 0.03079
Epoch [6/100], Batch [120/147] train loss: 549.40, train corr: 0.03209
Epoch [6/100], Batch [121/147] train loss: 558.20, train corr: 0.03106
Epoch [6/100], Batch [122/147] train loss: 568.26, train corr: 0.02765
Epoch [6/100], Batch [123/147] train loss: 568.60, train corr: 0.02238
Epoch [6/100], Batch [124/147] train loss: 581.25, train corr: 0.01982
Epoch [6/100], Batch [125/147] train loss: 567.90, train corr: 0.01729
Epoch [6/100], Batch [126/147] train loss: 592.54, train corr: 0.01686
Epoch [6/100], Batch [127/147] train loss: 570.53, train corr: 0.00928
Epoch [6/100], Batch [128/147] train loss: 562.91, train corr: 0.00460
Epoch [6/100], Batch [129/147] train loss: 561.58, train corr: -0.00180
Epoch [6/100], Batch [130/147] train loss: 562.15, train corr: -0.00252
Epoch [6/100], Batch [131/147] train loss: 571.01, train corr: -0.00059
Epoch [6/100], Batch [132/147] train loss: 575.90, train corr: 0.00468
Epoch [6/100], Batch [133/147] train loss: 562.60, train corr: 0.00548
Epoch [6/100], Batch [134/147] train loss: 638.90, train corr: 0.00352
Epoch [6/100], Batch [135/147] train loss: 575.17, train corr: -0.00085
Epoch [6/100], Batch [136/147] train loss: 554.34, train corr: -0.00831
Epoch [6/100], Batch [137/147] train loss: 586.34, train corr: -0.00380
Epoch [6/100], Batch [138/147] train loss: 558.03, train corr: -0.00217
Epoch [6/100], Batch [139/147] train loss: 565.62, train corr: 0.02462
Epoch [6/100], Batch [140/147] train loss: 563.76, train corr: 0.03379
Epoch [6/100], Batch [141/147] train loss: 573.83, train corr: 0.03083
Epoch [6/100], Batch [142/147] train loss: 544.67, train corr: 0.02941
Epoch [6/100], Batch [143/147] train loss: 578.56, train corr: 0.02429
Epoch [6/100], Batch [144/147] train loss: 561.91, train corr: 0.02609
Epoch [6/100], Batch [145/147] train loss: 563.13, train corr: 0.02577
Epoch [6/100], Batch [146/147] train loss: 634.90, train corr: 0.02520
Epoch [6/100], Batch [147/147] train loss: 573.52, train corr: 0.02354
Epoch [6/100], validation loss: 597.25, validation correlation: 0.02569
Epoch [7/100], Batch [1/147] train loss: 553.27, train corr: 0.02402
Epoch [7/100], Batch [2/147] train loss: 565.22, train corr: 0.02382
Epoch [7/100], Batch [3/147] train loss: 568.59, train corr: 0.02275
Epoch [7/100], Batch [4/147] train loss: 605.87, train corr: 0.02108
Epoch [7/100], Batch [5/147] train loss: 577.51, train corr: 0.01963
Epoch [7/100], Batch [6/147] train loss: 561.83, train corr: 0.01922
Epoch [7/100], Batch [7/147] train loss: 568.18, train corr: 0.01791
Epoch [7/100], Batch [8/147] train loss: 565.99, train corr: 0.01893
Epoch [7/100], Batch [9/147] train loss: 561.97, train corr: 0.01515
Epoch [7/100], Batch [10/147] train loss: 555.64, train corr: 0.01708
Epoch [7/100], Batch [11/147] train loss: 577.34, train corr: 0.01140
Epoch [7/100], Batch [12/147] train loss: 549.52, train corr: 0.01893
Epoch [7/100], Batch [13/147] train loss: 570.59, train corr: 0.01754
Epoch [7/100], Batch [14/147] train loss: 565.63, train corr: 0.01248
Epoch [7/100], Batch [15/147] train loss: 568.60, train corr: 0.00608
Epoch [7/100], Batch [16/147] train loss: 570.15, train corr: -0.00638
Epoch [7/100], Batch [17/147] train loss: 561.98, train corr: -0.01218
Epoch [7/100], Batch [18/147] train loss: 569.92, train corr: -0.01835
Epoch [7/100], Batch [19/147] train loss: 565.67, train corr: -0.01649
Epoch [7/100], Batch [20/147] train loss: 579.23, train corr: -0.01300
Epoch [7/100], Batch [21/147] train loss: 572.91, train corr: -0.00569
Epoch [7/100], Batch [22/147] train loss: 563.72, train corr: -0.00419
Epoch [7/100], Batch [23/147] train loss: 562.83, train corr: -0.00534
Epoch [7/100], Batch [24/147] train loss: 576.60, train corr: -0.01477
Epoch [7/100], Batch [25/147] train loss: 558.90, train corr: -0.01448
Epoch [7/100], Batch [26/147] train loss: 557.62, train corr: -0.01628
Epoch [7/100], Batch [27/147] train loss: 566.77, train corr: -0.01767
Epoch [7/100], Batch [28/147] train loss: 562.39, train corr: -0.01606
Epoch [7/100], Batch [29/147] train loss: 564.42, train corr: -0.01518
Epoch [7/100], Batch [30/147] train loss: 571.10, train corr: -0.01706
Epoch [7/100], Batch [31/147] train loss: 562.10, train corr: -0.01600
Epoch [7/100], Batch [32/147] train loss: 555.94, train corr: -0.01158
Epoch [7/100], Batch [33/147] train loss: 574.18, train corr: -0.00821
Epoch [7/100], Batch [34/147] train loss: 561.20, train corr: 0.00015
Epoch [7/100], Batch [35/147] train loss: 569.69, train corr: 0.00100
Epoch [7/100], Batch [36/147] train loss: 561.59, train corr: -0.00024
Epoch [7/100], Batch [37/147] train loss: 560.38, train corr: -0.00310
Epoch [7/100], Batch [38/147] train loss: 559.77, train corr: -0.00740
Epoch [7/100], Batch [39/147] train loss: 556.64, train corr: -0.00642
Epoch [7/100], Batch [40/147] train loss: 564.08, train corr: -0.00472
Epoch [7/100], Batch [41/147] train loss: 570.58, train corr: 0.00008
Epoch [7/100], Batch [42/147] train loss: 573.38, train corr: 0.00248
Epoch [7/100], Batch [43/147] train loss: 578.65, train corr: 0.00816
Epoch [7/100], Batch [44/147] train loss: 566.03, train corr: 0.01096
Epoch [7/100], Batch [45/147] train loss: 577.53, train corr: 0.00817
Epoch [7/100], Batch [46/147] train loss: 642.29, train corr: 0.00899
Epoch [7/100], Batch [47/147] train loss: 564.72, train corr: -0.01423
Epoch [7/100], Batch [48/147] train loss: 569.46, train corr: -0.01560
Epoch [7/100], Batch [49/147] train loss: 567.88, train corr: -0.02317
Epoch [7/100], Batch [50/147] train loss: 555.33, train corr: -0.01946
Epoch [7/100], Batch [51/147] train loss: 566.17, train corr: -0.02173
Epoch [7/100], Batch [52/147] train loss: 556.11, train corr: 0.00960
Epoch [7/100], Batch [53/147] train loss: 571.00, train corr: 0.02085
Epoch [7/100], Batch [54/147] train loss: 565.21, train corr: 0.02287
Epoch [7/100], Batch [55/147] train loss: 559.97, train corr: 0.02056
Epoch [7/100], Batch [56/147] train loss: 566.54, train corr: 0.02001
Epoch [7/100], Batch [57/147] train loss: 565.58, train corr: 0.01880
Epoch [7/100], Batch [58/147] train loss: 553.04, train corr: 0.01910
Epoch [7/100], Batch [59/147] train loss: 552.03, train corr: 0.01947
Epoch [7/100], Batch [60/147] train loss: 575.47, train corr: 0.01800
Epoch [7/100], Batch [61/147] train loss: 566.61, train corr: 0.02090
Epoch [7/100], Batch [62/147] train loss: 573.55, train corr: 0.00817
Epoch [7/100], Batch [63/147] train loss: 567.81, train corr: 0.00688
Epoch [7/100], Batch [64/147] train loss: 577.19, train corr: -0.00727
Epoch [7/100], Batch [65/147] train loss: 564.96, train corr: -0.02250
Epoch [7/100], Batch [66/147] train loss: 578.57, train corr: -0.02361
Epoch [7/100], Batch [67/147] train loss: 566.99, train corr: -0.01897
Epoch [7/100], Batch [68/147] train loss: 564.55, train corr: -0.01195
Epoch [7/100], Batch [69/147] train loss: 566.80, train corr: -0.00062
Epoch [7/100], Batch [70/147] train loss: 562.35, train corr: 0.00744
Epoch [7/100], Batch [71/147] train loss: 581.59, train corr: 0.00950
Epoch [7/100], Batch [72/147] train loss: 563.62, train corr: 0.01348
Epoch [7/100], Batch [73/147] train loss: 563.78, train corr: 0.01237
Epoch [7/100], Batch [74/147] train loss: 563.74, train corr: 0.00826
Epoch [7/100], Batch [75/147] train loss: 567.91, train corr: 0.00257
Epoch [7/100], Batch [76/147] train loss: 562.52, train corr: -0.00714
Epoch [7/100], Batch [77/147] train loss: 571.39, train corr: -0.01905
Epoch [7/100], Batch [78/147] train loss: 803.88, train corr: -0.01512
Epoch [7/100], Batch [79/147] train loss: 602.03, train corr: -0.02512
Epoch [7/100], Batch [80/147] train loss: 629.88, train corr: -0.02311
Epoch [7/100], Batch [81/147] train loss: 573.68, train corr: -0.02339
Epoch [7/100], Batch [82/147] train loss: 566.22, train corr: -0.01489
Epoch [7/100], Batch [83/147] train loss: 566.14, train corr: 0.00613
Epoch [7/100], Batch [84/147] train loss: 750.28, train corr: 0.01266
Epoch [7/100], Batch [85/147] train loss: 576.22, train corr: 0.01776
Epoch [7/100], Batch [86/147] train loss: 579.13, train corr: 0.01856
Epoch [7/100], Batch [87/147] train loss: 568.18, train corr: 0.01927
Epoch [7/100], Batch [88/147] train loss: 611.86, train corr: 0.01612
Epoch [7/100], Batch [89/147] train loss: 587.17, train corr: 0.01922
Epoch [7/100], Batch [90/147] train loss: 582.26, train corr: 0.01717
Epoch [7/100], Batch [91/147] train loss: 566.41, train corr: 0.01760
Epoch [7/100], Batch [92/147] train loss: 577.55, train corr: 0.02240
Epoch [7/100], Batch [93/147] train loss: 576.37, train corr: 0.02657
Epoch [7/100], Batch [94/147] train loss: 577.40, train corr: 0.03156
Epoch [7/100], Batch [95/147] train loss: 556.31, train corr: 0.02420
Epoch [7/100], Batch [96/147] train loss: 571.50, train corr: 0.01916
Epoch [7/100], Batch [97/147] train loss: 607.25, train corr: 0.01296
Epoch [7/100], Batch [98/147] train loss: 566.64, train corr: 0.00836
Epoch [7/100], Batch [99/147] train loss: 574.70, train corr: 0.01354
Epoch [7/100], Batch [100/147] train loss: 579.71, train corr: 0.03144
Epoch [7/100], Batch [101/147] train loss: 572.76, train corr: 0.03419
Epoch [7/100], Batch [102/147] train loss: 563.13, train corr: 0.03036
Epoch [7/100], Batch [103/147] train loss: 588.79, train corr: 0.02535
Epoch [7/100], Batch [104/147] train loss: 575.23, train corr: 0.02508
Epoch [7/100], Batch [105/147] train loss: 569.01, train corr: 0.01373
Epoch [7/100], Batch [106/147] train loss: 565.89, train corr: -0.00500
Epoch [7/100], Batch [107/147] train loss: 569.48, train corr: -0.02031
Epoch [7/100], Batch [108/147] train loss: 570.60, train corr: -0.00918
Epoch [7/100], Batch [109/147] train loss: 570.23, train corr: 0.00990
Epoch [7/100], Batch [110/147] train loss: 571.38, train corr: 0.00748
Epoch [7/100], Batch [111/147] train loss: 562.26, train corr: 0.01211
Epoch [7/100], Batch [112/147] train loss: 580.62, train corr: 0.01276
Epoch [7/100], Batch [113/147] train loss: 583.66, train corr: 0.01546
Epoch [7/100], Batch [114/147] train loss: 555.36, train corr: 0.02422
Epoch [7/100], Batch [115/147] train loss: 564.26, train corr: 0.02362
Epoch [7/100], Batch [116/147] train loss: 560.64, train corr: 0.02487
Epoch [7/100], Batch [117/147] train loss: 558.69, train corr: 0.02412
Epoch [7/100], Batch [118/147] train loss: 575.65, train corr: -0.00063
Epoch [7/100], Batch [119/147] train loss: 567.34, train corr: -0.02086
Epoch [7/100], Batch [120/147] train loss: 556.87, train corr: -0.01845
Epoch [7/100], Batch [121/147] train loss: 564.16, train corr: 0.00335
Epoch [7/100], Batch [122/147] train loss: 559.39, train corr: 0.02570
Epoch [7/100], Batch [123/147] train loss: 570.35, train corr: 0.03043
Epoch [7/100], Batch [124/147] train loss: 576.93, train corr: 0.03209
Epoch [7/100], Batch [125/147] train loss: 571.01, train corr: 0.03173
Epoch [7/100], Batch [126/147] train loss: 569.41, train corr: 0.03108
Epoch [7/100], Batch [127/147] train loss: 573.36, train corr: 0.03221
Epoch [7/100], Batch [128/147] train loss: 585.36, train corr: 0.03575
Epoch [7/100], Batch [129/147] train loss: 566.86, train corr: 0.03372
Epoch [7/100], Batch [130/147] train loss: 584.64, train corr: 0.03156
Epoch [7/100], Batch [131/147] train loss: 585.51, train corr: 0.02720
Epoch [7/100], Batch [132/147] train loss: 564.27, train corr: 0.02821
Epoch [7/100], Batch [133/147] train loss: 580.37, train corr: 0.02722
Epoch [7/100], Batch [134/147] train loss: 577.84, train corr: 0.02709
Epoch [7/100], Batch [135/147] train loss: 570.81, train corr: 0.02506
Epoch [7/100], Batch [136/147] train loss: 572.67, train corr: 0.02435
Epoch [7/100], Batch [137/147] train loss: 549.28, train corr: 0.02612
Epoch [7/100], Batch [138/147] train loss: 559.75, train corr: 0.02470
Epoch [7/100], Batch [139/147] train loss: 563.35, train corr: 0.02983
Epoch [7/100], Batch [140/147] train loss: 571.12, train corr: 0.00808
Epoch [7/100], Batch [141/147] train loss: 576.74, train corr: 0.00392
Epoch [7/100], Batch [142/147] train loss: 558.89, train corr: 0.01554
Epoch [7/100], Batch [143/147] train loss: 574.64, train corr: 0.02855
Epoch [7/100], Batch [144/147] train loss: 567.28, train corr: 0.03015
Epoch [7/100], Batch [145/147] train loss: 559.74, train corr: 0.03201
Epoch [7/100], Batch [146/147] train loss: 556.85, train corr: 0.03218
Epoch [7/100], Batch [147/147] train loss: 574.39, train corr: 0.03019
Epoch [7/100], validation loss: 597.94, validation correlation: 0.02542
Epoch [8/100], Batch [1/147] train loss: 567.26, train corr: 0.02308
Epoch [8/100], Batch [2/147] train loss: 571.01, train corr: 0.01730
Epoch [8/100], Batch [3/147] train loss: 551.56, train corr: 0.01577
Epoch [8/100], Batch [4/147] train loss: 569.13, train corr: 0.01598
Epoch [8/100], Batch [5/147] train loss: 572.23, train corr: 0.01195
Epoch [8/100], Batch [6/147] train loss: 553.87, train corr: 0.01114
Epoch [8/100], Batch [7/147] train loss: 575.42, train corr: 0.02353
Epoch [8/100], Batch [8/147] train loss: 560.59, train corr: 0.02936
Epoch [8/100], Batch [9/147] train loss: 574.00, train corr: 0.03401
Epoch [8/100], Batch [10/147] train loss: 552.16, train corr: 0.03379
Epoch [8/100], Batch [11/147] train loss: 571.54, train corr: 0.03445
Epoch [8/100], Batch [12/147] train loss: 550.12, train corr: 0.03417
Epoch [8/100], Batch [13/147] train loss: 550.05, train corr: 0.03007
Epoch [8/100], Batch [14/147] train loss: 565.86, train corr: 0.02918
Epoch [8/100], Batch [15/147] train loss: 567.77, train corr: 0.02898
Epoch [8/100], Batch [16/147] train loss: 599.66, train corr: 0.02671
Epoch [8/100], Batch [17/147] train loss: 563.95, train corr: 0.02879
Epoch [8/100], Batch [18/147] train loss: 583.75, train corr: 0.02837
Epoch [8/100], Batch [19/147] train loss: 575.43, train corr: 0.02617
Epoch [8/100], Batch [20/147] train loss: 558.56, train corr: 0.02260
Epoch [8/100], Batch [21/147] train loss: 563.27, train corr: 0.01838
Epoch [8/100], Batch [22/147] train loss: 582.39, train corr: 0.01898
Epoch [8/100], Batch [23/147] train loss: 575.77, train corr: 0.02446
Epoch [8/100], Batch [24/147] train loss: 563.69, train corr: 0.02732
Epoch [8/100], Batch [25/147] train loss: 561.79, train corr: 0.02459
Epoch [8/100], Batch [26/147] train loss: 574.93, train corr: 0.02376
Epoch [8/100], Batch [27/147] train loss: 585.35, train corr: 0.02804
Epoch [8/100], Batch [28/147] train loss: 565.79, train corr: 0.02779
Epoch [8/100], Batch [29/147] train loss: 562.98, train corr: -0.00708
Epoch [8/100], Batch [30/147] train loss: 570.80, train corr: -0.00794
Epoch [8/100], Batch [31/147] train loss: 557.69, train corr: 0.00886
Epoch [8/100], Batch [32/147] train loss: 572.30, train corr: 0.01696
Epoch [8/100], Batch [33/147] train loss: 579.77, train corr: 0.02006
Epoch [8/100], Batch [34/147] train loss: 564.79, train corr: 0.02701
Epoch [8/100], Batch [35/147] train loss: 567.76, train corr: 0.03346
Epoch [8/100], Batch [36/147] train loss: 582.26, train corr: 0.02865
Epoch [8/100], Batch [37/147] train loss: 577.54, train corr: 0.03057
Epoch [8/100], Batch [38/147] train loss: 567.21, train corr: 0.02983
Epoch [8/100], Batch [39/147] train loss: 563.43, train corr: 0.02858
Epoch [8/100], Batch [40/147] train loss: 566.86, train corr: 0.01744
Epoch [8/100], Batch [41/147] train loss: 589.80, train corr: 0.01675
Epoch [8/100], Batch [42/147] train loss: 551.06, train corr: 0.00576
Epoch [8/100], Batch [43/147] train loss: 576.19, train corr: 0.00993
Epoch [8/100], Batch [44/147] train loss: 588.64, train corr: 0.02314
Epoch [8/100], Batch [45/147] train loss: 558.00, train corr: 0.02773
Epoch [8/100], Batch [46/147] train loss: 571.33, train corr: 0.03054
Epoch [8/100], Batch [47/147] train loss: 601.59, train corr: 0.03117
Epoch [8/100], Batch [48/147] train loss: 556.21, train corr: 0.03043
Epoch [8/100], Batch [49/147] train loss: 556.76, train corr: 0.02397
Epoch [8/100], Batch [50/147] train loss: 572.43, train corr: 0.03199
Epoch [8/100], Batch [51/147] train loss: 555.51, train corr: 0.03007
Epoch [8/100], Batch [52/147] train loss: 562.73, train corr: 0.02973
Epoch [8/100], Batch [53/147] train loss: 562.07, train corr: 0.02231
Epoch [8/100], Batch [54/147] train loss: 552.00, train corr: 0.01239
Epoch [8/100], Batch [55/147] train loss: 573.87, train corr: 0.01638
Epoch [8/100], Batch [56/147] train loss: 563.68, train corr: 0.01442
Epoch [8/100], Batch [57/147] train loss: 634.02, train corr: 0.01174
Epoch [8/100], Batch [58/147] train loss: 566.91, train corr: -0.00196
Epoch [8/100], Batch [59/147] train loss: 563.90, train corr: -0.00243
Epoch [8/100], Batch [60/147] train loss: 578.25, train corr: 0.01946
Epoch [8/100], Batch [61/147] train loss: 562.08, train corr: 0.02723
Epoch [8/100], Batch [62/147] train loss: 548.70, train corr: 0.02796
Epoch [8/100], Batch [63/147] train loss: 573.22, train corr: 0.00703
Epoch [8/100], Batch [64/147] train loss: 590.07, train corr: 0.01062
Epoch [8/100], Batch [65/147] train loss: 575.03, train corr: 0.02754
Epoch [8/100], Batch [66/147] train loss: 565.09, train corr: 0.03257
Epoch [8/100], Batch [67/147] train loss: 561.95, train corr: 0.02909
Epoch [8/100], Batch [68/147] train loss: 562.07, train corr: 0.02240
Epoch [8/100], Batch [69/147] train loss: 743.34, train corr: 0.00891
Epoch [8/100], Batch [70/147] train loss: 565.50, train corr: 0.00772
Epoch [8/100], Batch [71/147] train loss: 565.33, train corr: 0.01617
Epoch [8/100], Batch [72/147] train loss: 572.28, train corr: 0.01848
Epoch [8/100], Batch [73/147] train loss: 568.59, train corr: 0.00765
Epoch [8/100], Batch [74/147] train loss: 575.16, train corr: -0.00422
Epoch [8/100], Batch [75/147] train loss: 577.54, train corr: 0.00495
Epoch [8/100], Batch [76/147] train loss: 573.53, train corr: 0.02629
Epoch [8/100], Batch [77/147] train loss: 602.41, train corr: 0.03075
Epoch [8/100], Batch [78/147] train loss: 571.60, train corr: 0.01683
Epoch [8/100], Batch [79/147] train loss: 564.37, train corr: -0.00780
Epoch [8/100], Batch [80/147] train loss: 568.11, train corr: -0.00385
Epoch [8/100], Batch [81/147] train loss: 559.21, train corr: 0.01140
Epoch [8/100], Batch [82/147] train loss: 631.91, train corr: 0.01530
Epoch [8/100], Batch [83/147] train loss: 574.65, train corr: 0.02641
Epoch [8/100], Batch [84/147] train loss: 568.25, train corr: -0.01829
Epoch [8/100], Batch [85/147] train loss: 570.38, train corr: -0.02048
Epoch [8/100], Batch [86/147] train loss: 1020.03, train corr: -0.01742
Epoch [8/100], Batch [87/147] train loss: 4846.89, train corr: 0.02376
Epoch [8/100], Batch [88/147] train loss: 1871.00, train corr: -0.00788
Epoch [8/100], Batch [89/147] train loss: 2952.37, train corr: -0.00503
Epoch [8/100], Batch [90/147] train loss: 13845.43, train corr: -0.00904
Epoch [8/100], Batch [91/147] train loss: 76844.13, train corr: 0.02619
Epoch [8/100], Batch [92/147] train loss: 101785.58, train corr: -0.01621
Epoch [8/100], Batch [93/147] train loss: 1872965.50, train corr: 0.02491
Epoch [8/100], Batch [94/147] train loss: 8925.83, train corr: 0.01184
Epoch [8/100], Batch [95/147] train loss: 82201.63, train corr: -0.00950
Epoch [8/100], Batch [96/147] train loss: 11384652.00, train corr: 0.01781
Epoch [8/100], Batch [97/147] train loss: 352098.41, train corr: -0.01750
Epoch [8/100], Batch [98/147] train loss: 31400916.00, train corr: -0.02977
Epoch [8/100], Batch [99/147] train loss: 715744.00, train corr: -0.02796
Epoch [8/100], Batch [100/147] train loss: 1711039.75, train corr: -0.02037
Epoch [8/100], Batch [101/147] train loss: 2679644.50, train corr: -0.02557
Epoch [8/100], Batch [102/147] train loss: 883720.88, train corr: -0.02023
Epoch [8/100], Batch [103/147] train loss: 5087440.50, train corr: -0.02931
Epoch [8/100], Batch [104/147] train loss: 417173.47, train corr: 0.00628
Epoch [8/100], Batch [105/147] train loss: 904530.06, train corr: 0.01634
Epoch [8/100], Batch [106/147] train loss: 1751720.75, train corr: 0.02956
Epoch [8/100], Batch [107/147] train loss: 1088233.62, train corr: 0.00161
Epoch [8/100], Batch [108/147] train loss: 440048.88, train corr: -0.00712
Epoch [8/100], Batch [109/147] train loss: 574307.62, train corr: -0.00155
Epoch [8/100], Batch [110/147] train loss: 387796.28, train corr: -0.00356
Epoch [8/100], Batch [111/147] train loss: 237114.48, train corr: -0.00438
Epoch [8/100], Batch [112/147] train loss: 142191.34, train corr: -0.01065
Epoch [8/100], Batch [113/147] train loss: 292087.25, train corr: -0.02014
Epoch [8/100], Batch [114/147] train loss: 168850.91, train corr: -0.00154
Epoch [8/100], Batch [115/147] train loss: 204320.38, train corr: 0.02123
Epoch [8/100], Batch [116/147] train loss: 201679.52, train corr: 0.03190
Epoch [8/100], Batch [117/147] train loss: 284872.44, train corr: 0.02722
Epoch [8/100], Batch [118/147] train loss: 142399.16, train corr: 0.01614
Epoch [8/100], Batch [119/147] train loss: 211171.80, train corr: 0.01179
Epoch [8/100], Batch [120/147] train loss: 165057.16, train corr: 0.01378
Epoch [8/100], Batch [121/147] train loss: 206697.98, train corr: 0.01951
Epoch [8/100], Batch [122/147] train loss: 163716.92, train corr: 0.02515
Epoch [8/100], Batch [123/147] train loss: 147498.17, train corr: 0.02334
Epoch [8/100], Batch [124/147] train loss: 108232.04, train corr: 0.01998
Epoch [8/100], Batch [125/147] train loss: 150625.36, train corr: 0.02053
Epoch [8/100], Batch [126/147] train loss: 127613.55, train corr: 0.01759
Epoch [8/100], Batch [127/147] train loss: 84754.27, train corr: 0.02620
Epoch [8/100], Batch [128/147] train loss: 84826.86, train corr: 0.02648
Epoch [8/100], Batch [129/147] train loss: 67572.80, train corr: 0.02416
Epoch [8/100], Batch [130/147] train loss: 98623.41, train corr: 0.01726
Epoch [8/100], Batch [131/147] train loss: 109764.54, train corr: 0.03087
Epoch [8/100], Batch [132/147] train loss: 88123.57, train corr: 0.03363
Epoch [8/100], Batch [133/147] train loss: 80339.82, train corr: 0.03334
Epoch [8/100], Batch [134/147] train loss: 51501.98, train corr: 0.01755
Epoch [8/100], Batch [135/147] train loss: 55262.12, train corr: -0.00163
Epoch [8/100], Batch [136/147] train loss: 53763.66, train corr: -0.00906
Epoch [8/100], Batch [137/147] train loss: 36422.64, train corr: -0.00592
Epoch [8/100], Batch [138/147] train loss: 73937.97, train corr: -0.00245
Epoch [8/100], Batch [139/147] train loss: 25168.20, train corr: -0.01505
Epoch [8/100], Batch [140/147] train loss: 52378.38, train corr: -0.02137
Epoch [8/100], Batch [141/147] train loss: 96471.89, train corr: -0.01813
Epoch [8/100], Batch [142/147] train loss: 80089.66, train corr: -0.01089
Epoch [8/100], Batch [143/147] train loss: 71365.08, train corr: -0.01415
Epoch [8/100], Batch [144/147] train loss: 67109.05, train corr: -0.01367
Epoch [8/100], Batch [145/147] train loss: 62930.54, train corr: -0.01835
Epoch [8/100], Batch [146/147] train loss: 66190.77, train corr: -0.02157
Epoch [8/100], Batch [147/147] train loss: 65609.86, train corr: -0.02341
Epoch [8/100], validation loss: 84437.47, validation correlation: -0.02419
Epoch [9/100], Batch [1/147] train loss: 78739.11, train corr: -0.02729
Epoch [9/100], Batch [2/147] train loss: 44401.02, train corr: -0.01936
Epoch [9/100], Batch [3/147] train loss: 97144.22, train corr: -0.00742
Epoch [9/100], Batch [4/147] train loss: 51009.85, train corr: 0.01107
Epoch [9/100], Batch [5/147] train loss: 63718.23, train corr: 0.01607
Epoch [9/100], Batch [6/147] train loss: 58461.18, train corr: 0.01896
Epoch [9/100], Batch [7/147] train loss: 42866.01, train corr: 0.01812
Epoch [9/100], Batch [8/147] train loss: 29507.29, train corr: -0.00574
Epoch [9/100], Batch [9/147] train loss: 47933.10, train corr: -0.02688
Epoch [9/100], Batch [10/147] train loss: 41415.21, train corr: -0.00523
Epoch [9/100], Batch [11/147] train loss: 366246.88, train corr: -0.01336
Epoch [9/100], Batch [12/147] train loss: 66695.66, train corr: -0.00575
Epoch [9/100], Batch [13/147] train loss: 112121.40, train corr: 0.01085
Epoch [9/100], Batch [14/147] train loss: 111596.12, train corr: 0.01385
Epoch [9/100], Batch [15/147] train loss: 102922.69, train corr: 0.01549
Epoch [9/100], Batch [16/147] train loss: 133348.17, train corr: 0.01487
Epoch [9/100], Batch [17/147] train loss: 146575.61, train corr: 0.01611
Epoch [9/100], Batch [18/147] train loss: 93300.84, train corr: 0.00984
Epoch [9/100], Batch [19/147] train loss: 97850.58, train corr: 0.00534
Epoch [9/100], Batch [20/147] train loss: 97578.64, train corr: 0.00433
Epoch [9/100], Batch [21/147] train loss: 98708.52, train corr: 0.00194
Epoch [9/100], Batch [22/147] train loss: 77035.78, train corr: 0.00236
Epoch [9/100], Batch [23/147] train loss: 50020.29, train corr: -0.00240
Epoch [9/100], Batch [24/147] train loss: 31084.79, train corr: 0.01743
Epoch [9/100], Batch [25/147] train loss: 73381.16, train corr: 0.00675
Epoch [9/100], Batch [26/147] train loss: 52133.45, train corr: -0.00638
Epoch [9/100], Batch [27/147] train loss: 79179.62, train corr: -0.01911
Epoch [9/100], Batch [28/147] train loss: 81576.89, train corr: -0.02923
Epoch [9/100], Batch [29/147] train loss: 61908.15, train corr: -0.03017
Epoch [9/100], Batch [30/147] train loss: 35184.63, train corr: -0.02934
Epoch [9/100], Batch [31/147] train loss: 90376.02, train corr: -0.03321
Epoch [9/100], Batch [32/147] train loss: 28400.55, train corr: -0.00872
Epoch [9/100], Batch [33/147] train loss: 29279.58, train corr: 0.01454
Epoch [9/100], Batch [34/147] train loss: 38030.16, train corr: 0.02261
Epoch [9/100], Batch [35/147] train loss: 38562.90, train corr: 0.02198
Epoch [9/100], Batch [36/147] train loss: 33416.87, train corr: 0.01698
Epoch [9/100], Batch [37/147] train loss: 26175.30, train corr: 0.01212
Epoch [9/100], Batch [38/147] train loss: 19871.17, train corr: -0.02601
Epoch [9/100], Batch [39/147] train loss: 33900.77, train corr: -0.01097
Epoch [9/100], Batch [40/147] train loss: 40307.19, train corr: -0.00715
Epoch [9/100], Batch [41/147] train loss: 53842.73, train corr: -0.00414
Epoch [9/100], Batch [42/147] train loss: 46085.24, train corr: -0.00359
Epoch [9/100], Batch [43/147] train loss: 47023.79, train corr: 0.00349
Epoch [9/100], Batch [44/147] train loss: 31457.86, train corr: 0.01605
Epoch [9/100], Batch [45/147] train loss: 41066.88, train corr: 0.01755
Epoch [9/100], Batch [46/147] train loss: 19405.52, train corr: 0.01711
Epoch [9/100], Batch [47/147] train loss: 24575.37, train corr: 0.00109
Epoch [9/100], Batch [48/147] train loss: 38418.79, train corr: -0.00339
Epoch [9/100], Batch [49/147] train loss: 23149.80, train corr: -0.01032
Epoch [9/100], Batch [50/147] train loss: 11920.40, train corr: -0.01803
Epoch [9/100], Batch [51/147] train loss: 75790.85, train corr: -0.00315
Epoch [9/100], Batch [52/147] train loss: 64135.34, train corr: 0.00616
Epoch [9/100], Batch [53/147] train loss: 110665.66, train corr: 0.01074
Epoch [9/100], Batch [54/147] train loss: 121854.91, train corr: 0.00920
Epoch [9/100], Batch [55/147] train loss: 125802.28, train corr: 0.00845
Epoch [9/100], Batch [56/147] train loss: 111081.38, train corr: 0.01147
Epoch [9/100], Batch [57/147] train loss: 89293.91, train corr: 0.01449
Epoch [9/100], Batch [58/147] train loss: 54099.40, train corr: 0.01211
Epoch [9/100], Batch [59/147] train loss: 97867.91, train corr: 0.00912
Epoch [9/100], Batch [60/147] train loss: 36053.18, train corr: 0.02442
Epoch [9/100], Batch [61/147] train loss: 46088.35, train corr: 0.00226
Epoch [9/100], Batch [62/147] train loss: 79423.62, train corr: -0.00450
Epoch [9/100], Batch [63/147] train loss: 89190.63, train corr: -0.00456
Epoch [9/100], Batch [64/147] train loss: 78976.56, train corr: -0.00746
Epoch [9/100], Batch [65/147] train loss: 72643.17, train corr: -0.00743
Epoch [9/100], Batch [66/147] train loss: 39024.74, train corr: -0.01140
Epoch [9/100], Batch [67/147] train loss: 30494.70, train corr: -0.01340
Epoch [9/100], Batch [68/147] train loss: 97233.77, train corr: -0.01228
Epoch [9/100], Batch [69/147] train loss: 42318.87, train corr: -0.00679
Epoch [9/100], Batch [70/147] train loss: 55596.52, train corr: 0.02224
Epoch [9/100], Batch [71/147] train loss: 89980.09, train corr: 0.01119
Epoch [9/100], Batch [72/147] train loss: 79014.47, train corr: 0.01280
Epoch [9/100], Batch [73/147] train loss: 79814.22, train corr: 0.01342
Epoch [9/100], Batch [74/147] train loss: 106841.48, train corr: 0.00688
Epoch [9/100], Batch [75/147] train loss: 151975.64, train corr: 0.00459
Epoch [9/100], Batch [76/147] train loss: 69157.20, train corr: 0.01248
Epoch [9/100], Batch [77/147] train loss: 58922.58, train corr: 0.01330
Epoch [9/100], Batch [78/147] train loss: 36002.94, train corr: 0.01558
Epoch [9/100], Batch [79/147] train loss: 59047.51, train corr: 0.01296
Epoch [9/100], Batch [80/147] train loss: 24581.92, train corr: 0.00136
Epoch [9/100], Batch [81/147] train loss: 50575.11, train corr: -0.00960
Epoch [9/100], Batch [82/147] train loss: 71099.48, train corr: -0.01225
Epoch [9/100], Batch [83/147] train loss: 104512.63, train corr: -0.01205
Epoch [9/100], Batch [84/147] train loss: 93463.88, train corr: -0.00627
Epoch [9/100], Batch [85/147] train loss: 90297.23, train corr: -0.00684
Epoch [9/100], Batch [86/147] train loss: 107350.67, train corr: -0.00512
Epoch [9/100], Batch [87/147] train loss: 83543.25, train corr: 0.00124
Epoch [9/100], Batch [88/147] train loss: 87666.52, train corr: 0.00321
Epoch [9/100], Batch [89/147] train loss: 89009.48, train corr: 0.00953
Epoch [9/100], Batch [90/147] train loss: 62720.24, train corr: 0.01649
Epoch [9/100], Batch [91/147] train loss: 49232.88, train corr: 0.01736
Epoch [9/100], Batch [92/147] train loss: 49451.34, train corr: 0.01831
Epoch [9/100], Batch [93/147] train loss: 45173.13, train corr: 0.00916
Epoch [9/100], Batch [94/147] train loss: 24520.02, train corr: 0.00079
Epoch [9/100], Batch [95/147] train loss: 30225.75, train corr: -0.01253
Epoch [9/100], Batch [96/147] train loss: 40163.30, train corr: -0.02165
Epoch [9/100], Batch [97/147] train loss: 32615.87, train corr: -0.02960
Epoch [9/100], Batch [98/147] train loss: 29266.96, train corr: -0.03210
Epoch [9/100], Batch [99/147] train loss: 38296.25, train corr: -0.03374
Epoch [9/100], Batch [100/147] train loss: 32689.90, train corr: -0.03074
Epoch [9/100], Batch [101/147] train loss: 71490.16, train corr: -0.01666
Epoch [9/100], Batch [102/147] train loss: 47273.84, train corr: -0.02738
Epoch [9/100], Batch [103/147] train loss: 19715.37, train corr: -0.01771
Epoch [9/100], Batch [104/147] train loss: 23928.73, train corr: -0.00104
Epoch [9/100], Batch [105/147] train loss: 17802.64, train corr: 0.02614
Epoch [9/100], Batch [106/147] train loss: 30525.72, train corr: 0.03067
Epoch [9/100], Batch [107/147] train loss: 21972.66, train corr: 0.02746
Epoch [9/100], Batch [108/147] train loss: 27068.87, train corr: 0.01819
Epoch [9/100], Batch [109/147] train loss: 26762.70, train corr: 0.00095
Epoch [9/100], Batch [110/147] train loss: 29750.77, train corr: -0.00330
Epoch [9/100], Batch [111/147] train loss: 20226.75, train corr: -0.01527
Epoch [9/100], Batch [112/147] train loss: 15391.52, train corr: 0.01845
Epoch [9/100], Batch [113/147] train loss: 11516.83, train corr: 0.01987
Epoch [9/100], Batch [114/147] train loss: 32214.06, train corr: 0.02208
Epoch [9/100], Batch [115/147] train loss: 19539.27, train corr: 0.02136
Epoch [9/100], Batch [116/147] train loss: 26176.45, train corr: 0.02134
Epoch [9/100], Batch [117/147] train loss: 20380.75, train corr: 0.02090
Epoch [9/100], Batch [118/147] train loss: 11621.43, train corr: 0.00762
Epoch [9/100], Batch [119/147] train loss: 32746.73, train corr: -0.02072
Epoch [9/100], Batch [120/147] train loss: 34466.93, train corr: 0.01236
Epoch [9/100], Batch [121/147] train loss: 59398.15, train corr: 0.01228
Epoch [9/100], Batch [122/147] train loss: 72805.98, train corr: 0.00705
Epoch [9/100], Batch [123/147] train loss: 65288.83, train corr: 0.00505
Epoch [9/100], Batch [124/147] train loss: 54520.15, train corr: -0.00269
Epoch [9/100], Batch [125/147] train loss: 36285.95, train corr: -0.00701
Epoch [9/100], Batch [126/147] train loss: 28405.06, train corr: -0.01241
Epoch [9/100], Batch [127/147] train loss: 46397.72, train corr: -0.01400
Epoch [9/100], Batch [128/147] train loss: 22520.71, train corr: 0.00170
Epoch [9/100], Batch [129/147] train loss: 33917.92, train corr: 0.01884
Epoch [9/100], Batch [130/147] train loss: 36341.31, train corr: 0.02120
Epoch [9/100], Batch [131/147] train loss: 28783.02, train corr: 0.02213
Epoch [9/100], Batch [132/147] train loss: 21414.81, train corr: 0.02115
Epoch [9/100], Batch [133/147] train loss: 31804.36, train corr: 0.02115
Epoch [9/100], Batch [134/147] train loss: 17761.49, train corr: 0.03052
Epoch [9/100], Batch [135/147] train loss: 21952.79, train corr: 0.03285
Epoch [9/100], Batch [136/147] train loss: 21219.32, train corr: 0.02352
Epoch [9/100], Batch [137/147] train loss: 21189.86, train corr: 0.00947
Epoch [9/100], Batch [138/147] train loss: 16736.74, train corr: 0.00594
Epoch [9/100], Batch [139/147] train loss: 16634.47, train corr: -0.00727
Epoch [9/100], Batch [140/147] train loss: 14133.47, train corr: -0.02277
Epoch [9/100], Batch [141/147] train loss: 11385.23, train corr: -0.03390
Epoch [9/100], Batch [142/147] train loss: 9964.36, train corr: -0.02918
Epoch [9/100], Batch [143/147] train loss: 8222.45, train corr: -0.01413
Epoch [9/100], Batch [144/147] train loss: 8542.67, train corr: 0.00247
Epoch [9/100], Batch [145/147] train loss: 8927.28, train corr: 0.01779
Epoch [9/100], Batch [146/147] train loss: 8299.36, train corr: 0.03181
Epoch [9/100], Batch [147/147] train loss: 10140.14, train corr: 0.01327
Epoch [9/100], validation loss: 10980.94, validation correlation: -0.00612
Epoch [10/100], Batch [1/147] train loss: 10368.26, train corr: -0.00530
Epoch [10/100], Batch [2/147] train loss: 14491.83, train corr: -0.01815
Epoch [10/100], Batch [3/147] train loss: 15978.37, train corr: -0.00811
Epoch [10/100], Batch [4/147] train loss: 22352.67, train corr: -0.00072
Epoch [10/100], Batch [5/147] train loss: 14678.32, train corr: 0.00426
Epoch [10/100], Batch [6/147] train loss: 15065.21, train corr: 0.00343
Epoch [10/100], Batch [7/147] train loss: 7266.57, train corr: -0.02065
Epoch [10/100], Batch [8/147] train loss: 13371.28, train corr: -0.00269
Epoch [10/100], Batch [9/147] train loss: 18227.98, train corr: 0.00064
Epoch [10/100], Batch [10/147] train loss: 18366.09, train corr: -0.00123
Epoch [10/100], Batch [11/147] train loss: 17559.99, train corr: 0.00554
Epoch [10/100], Batch [12/147] train loss: 18104.87, train corr: 0.01032
Epoch [10/100], Batch [13/147] train loss: 15454.43, train corr: 0.01513
Epoch [10/100], Batch [14/147] train loss: 15457.92, train corr: 0.01115
Epoch [10/100], Batch [15/147] train loss: 13565.65, train corr: 0.00921
Epoch [10/100], Batch [16/147] train loss: 17456.17, train corr: 0.00062
Epoch [10/100], Batch [17/147] train loss: 16143.78, train corr: 0.01918
Epoch [10/100], Batch [18/147] train loss: 15703.02, train corr: 0.03433
Epoch [10/100], Batch [19/147] train loss: 9339.13, train corr: 0.02508
Epoch [10/100], Batch [20/147] train loss: 28822.42, train corr: 0.01604
Epoch [10/100], Batch [21/147] train loss: 12682.75, train corr: 0.00446
Epoch [10/100], Batch [22/147] train loss: 17877.59, train corr: 0.00004
Epoch [10/100], Batch [23/147] train loss: 21206.72, train corr: -0.02733
Epoch [10/100], Batch [24/147] train loss: 14530.57, train corr: -0.02860
Epoch [10/100], Batch [25/147] train loss: 30185.84, train corr: -0.02693
Epoch [10/100], Batch [26/147] train loss: 18069.67, train corr: -0.01601
Epoch [10/100], Batch [27/147] train loss: 18020.05, train corr: 0.02406
Epoch [10/100], Batch [28/147] train loss: 24627.45, train corr: 0.02598
Epoch [10/100], Batch [29/147] train loss: 20636.61, train corr: 0.02994
Epoch [10/100], Batch [30/147] train loss: 21462.21, train corr: 0.02892
Epoch [10/100], Batch [31/147] train loss: 23107.42, train corr: 0.02786
Epoch [10/100], Batch [32/147] train loss: 25587.82, train corr: 0.02627
Epoch [10/100], Batch [33/147] train loss: 32256.44, train corr: 0.02130
Epoch [10/100], Batch [34/147] train loss: 31317.32, train corr: 0.02049
Epoch [10/100], Batch [35/147] train loss: 26964.84, train corr: 0.01258
Epoch [10/100], Batch [36/147] train loss: 17727.13, train corr: 0.00241
Epoch [10/100], Batch [37/147] train loss: 26056.53, train corr: -0.01107
Epoch [10/100], Batch [38/147] train loss: 16984.43, train corr: -0.01800
Epoch [10/100], Batch [39/147] train loss: 18067.11, train corr: -0.02250
Epoch [10/100], Batch [40/147] train loss: 23681.74, train corr: -0.03294
Epoch [10/100], Batch [41/147] train loss: 25454.88, train corr: -0.01775
Epoch [10/100], Batch [42/147] train loss: 21706.35, train corr: -0.00987
Epoch [10/100], Batch [43/147] train loss: 18086.13, train corr: -0.01335
Epoch [10/100], Batch [44/147] train loss: 15682.02, train corr: -0.00405
Epoch [10/100], Batch [45/147] train loss: 11990.20, train corr: -0.00080
Epoch [10/100], Batch [46/147] train loss: 10589.40, train corr: -0.00180
Epoch [10/100], Batch [47/147] train loss: 10060.75, train corr: -0.00393
Epoch [10/100], Batch [48/147] train loss: 13139.36, train corr: -0.00880
Epoch [10/100], Batch [49/147] train loss: 10943.72, train corr: -0.00908
Epoch [10/100], Batch [50/147] train loss: 20790.71, train corr: -0.01055
Epoch [10/100], Batch [51/147] train loss: 8852.79, train corr: -0.00089
Epoch [10/100], Batch [52/147] train loss: 9713.86, train corr: 0.01568
Epoch [10/100], Batch [53/147] train loss: 13507.71, train corr: 0.02567
Epoch [10/100], Batch [54/147] train loss: 18437.00, train corr: 0.02159
Epoch [10/100], Batch [55/147] train loss: 16775.79, train corr: 0.01995
Epoch [10/100], Batch [56/147] train loss: 13779.74, train corr: 0.01172
Epoch [10/100], Batch [57/147] train loss: 11210.11, train corr: 0.00692
Epoch [10/100], Batch [58/147] train loss: 9030.29, train corr: -0.00498
Epoch [10/100], Batch [59/147] train loss: 8386.88, train corr: 0.01256
Epoch [10/100], Batch [60/147] train loss: 10530.50, train corr: 0.00419
Epoch [10/100], Batch [61/147] train loss: 10651.58, train corr: -0.00016
Epoch [10/100], Batch [62/147] train loss: 13258.79, train corr: -0.00719
Epoch [10/100], Batch [63/147] train loss: 15125.09, train corr: 0.00016
Epoch [10/100], Batch [64/147] train loss: 17849.48, train corr: 0.01263
Epoch [10/100], Batch [65/147] train loss: 12834.98, train corr: 0.01305
Epoch [10/100], Batch [66/147] train loss: 8297.14, train corr: 0.00808
Epoch [10/100], Batch [67/147] train loss: 18173.62, train corr: -0.01525
Epoch [10/100], Batch [68/147] train loss: 18282.36, train corr: 0.00847
Epoch [10/100], Batch [69/147] train loss: 28676.92, train corr: 0.01011
Epoch [10/100], Batch [70/147] train loss: 33348.16, train corr: 0.00877
Epoch [10/100], Batch [71/147] train loss: 33298.96, train corr: -0.00270
Epoch [10/100], Batch [72/147] train loss: 24242.54, train corr: -0.00416
Epoch [10/100], Batch [73/147] train loss: 18776.65, train corr: -0.00575
Epoch [10/100], Batch [74/147] train loss: 26095.77, train corr: -0.00928
Epoch [10/100], Batch [75/147] train loss: 15369.60, train corr: -0.01391
Epoch [10/100], Batch [76/147] train loss: 12426.77, train corr: -0.01993
Epoch [10/100], Batch [77/147] train loss: 12265.66, train corr: -0.02814
Epoch [10/100], Batch [78/147] train loss: 13357.09, train corr: -0.03253
Epoch [10/100], Batch [79/147] train loss: 13476.18, train corr: -0.03003
Epoch [10/100], Batch [80/147] train loss: 12691.11, train corr: -0.02028
Epoch [10/100], Batch [81/147] train loss: 9560.27, train corr: -0.01087
Epoch [10/100], Batch [82/147] train loss: 11903.22, train corr: -0.00667
Epoch [10/100], Batch [83/147] train loss: 9411.76, train corr: 0.00391
Epoch [10/100], Batch [84/147] train loss: 11772.34, train corr: 0.00551
Epoch [10/100], Batch [85/147] train loss: 9466.19, train corr: 0.00161
Epoch [10/100], Batch [86/147] train loss: 8796.30, train corr: -0.00032
Epoch [10/100], Batch [87/147] train loss: 8385.22, train corr: -0.00419
Epoch [10/100], Batch [88/147] train loss: 6727.60, train corr: -0.01687
Epoch [10/100], Batch [89/147] train loss: 11896.43, train corr: -0.02286
Epoch [10/100], Batch [90/147] train loss: 7772.51, train corr: 0.02957
Epoch [10/100], Batch [91/147] train loss: 10124.72, train corr: 0.02991
Epoch [10/100], Batch [92/147] train loss: 9209.46, train corr: 0.02850
Epoch [10/100], Batch [93/147] train loss: 9823.42, train corr: 0.03312
Epoch [10/100], Batch [94/147] train loss: 7209.60, train corr: 0.02630
Epoch [10/100], Batch [95/147] train loss: 6264.18, train corr: 0.01249
Epoch [10/100], Batch [96/147] train loss: 5156.88, train corr: -0.00276
Epoch [10/100], Batch [97/147] train loss: 4841.14, train corr: -0.02867
Epoch [10/100], Batch [98/147] train loss: 5446.76, train corr: -0.03508
Epoch [10/100], Batch [99/147] train loss: 8671.29, train corr: -0.03231
Epoch [10/100], Batch [100/147] train loss: 9817.64, train corr: -0.01016
Epoch [10/100], Batch [101/147] train loss: 6840.60, train corr: -0.00514
Epoch [10/100], Batch [102/147] train loss: 5447.55, train corr: -0.00495
Epoch [10/100], Batch [103/147] train loss: 5180.72, train corr: 0.01605
Epoch [10/100], Batch [104/147] train loss: 5507.11, train corr: 0.02186
Epoch [10/100], Batch [105/147] train loss: 4638.27, train corr: 0.01991
Epoch [10/100], Batch [106/147] train loss: 6746.26, train corr: 0.02155
Epoch [10/100], Batch [107/147] train loss: 7818.61, train corr: 0.02986
Epoch [10/100], Batch [108/147] train loss: 12191.11, train corr: 0.02726
Epoch [10/100], Batch [109/147] train loss: 10106.47, train corr: 0.01578
Epoch [10/100], Batch [110/147] train loss: 6313.51, train corr: -0.00475
Epoch [10/100], Batch [111/147] train loss: 17551.14, train corr: -0.00652
Epoch [10/100], Batch [112/147] train loss: 11628.21, train corr: 0.02670
Epoch [10/100], Batch [113/147] train loss: 17100.39, train corr: 0.03267
Epoch [10/100], Batch [114/147] train loss: 17882.38, train corr: 0.02904
Epoch [10/100], Batch [115/147] train loss: 13671.55, train corr: 0.02971
Epoch [10/100], Batch [116/147] train loss: 19265.62, train corr: 0.02395
Epoch [10/100], Batch [117/147] train loss: 8287.04, train corr: 0.02514
Epoch [10/100], Batch [118/147] train loss: 4623.27, train corr: -0.01749
Epoch [10/100], Batch [119/147] train loss: 5979.71, train corr: -0.02750
Epoch [10/100], Batch [120/147] train loss: 7496.10, train corr: -0.02850
Epoch [10/100], Batch [121/147] train loss: 8700.75, train corr: -0.02498
Epoch [10/100], Batch [122/147] train loss: 9296.92, train corr: -0.02519
Epoch [10/100], Batch [123/147] train loss: 12404.98, train corr: -0.01762
Epoch [10/100], Batch [124/147] train loss: 13701.81, train corr: -0.01983
Epoch [10/100], Batch [125/147] train loss: 15683.55, train corr: -0.01651
Epoch [10/100], Batch [126/147] train loss: 14868.70, train corr: -0.01635
Epoch [10/100], Batch [127/147] train loss: 10147.87, train corr: -0.01191
Epoch [10/100], Batch [128/147] train loss: 18219.23, train corr: -0.01887
Epoch [10/100], Batch [129/147] train loss: 8159.08, train corr: -0.01420
Epoch [10/100], Batch [130/147] train loss: 8803.82, train corr: -0.01415
Epoch [10/100], Batch [131/147] train loss: 6877.73, train corr: -0.01625
Epoch [10/100], Batch [132/147] train loss: 5851.73, train corr: -0.02077
Epoch [10/100], Batch [133/147] train loss: 6270.76, train corr: -0.03012
Epoch [10/100], Batch [134/147] train loss: 5923.27, train corr: 0.01917
Epoch [10/100], Batch [135/147] train loss: 7512.48, train corr: 0.02607
Epoch [10/100], Batch [136/147] train loss: 9100.24, train corr: 0.02660
Epoch [10/100], Batch [137/147] train loss: 8975.36, train corr: 0.02808
Epoch [10/100], Batch [138/147] train loss: 5365.81, train corr: 0.02753
Epoch [10/100], Batch [139/147] train loss: 4423.95, train corr: 0.01193
Epoch [10/100], Batch [140/147] train loss: 6525.25, train corr: -0.00529
Epoch [10/100], Batch [141/147] train loss: 5903.90, train corr: -0.01481
Epoch [10/100], Batch [142/147] train loss: 7191.51, train corr: -0.02046
Epoch [10/100], Batch [143/147] train loss: 6241.60, train corr: -0.02796
Epoch [10/100], Batch [144/147] train loss: 13590.71, train corr: -0.02643
Epoch [10/100], Batch [145/147] train loss: 8910.56, train corr: -0.02397
Epoch [10/100], Batch [146/147] train loss: 11283.05, train corr: -0.01540
Epoch [10/100], Batch [147/147] train loss: 10494.23, train corr: -0.01141
Epoch [10/100], validation loss: 7325.92, validation correlation: -0.01469
Epoch [11/100], Batch [1/147] train loss: 6966.67, train corr: -0.01371
Epoch [11/100], Batch [2/147] train loss: 3834.56, train corr: -0.01887
Epoch [11/100], Batch [3/147] train loss: 3389.07, train corr: -0.01980
Epoch [11/100], Batch [4/147] train loss: 5675.04, train corr: 0.02144
Epoch [11/100], Batch [5/147] train loss: 8343.06, train corr: 0.02364
Epoch [11/100], Batch [6/147] train loss: 7994.14, train corr: 0.02000
Epoch [11/100], Batch [7/147] train loss: 9975.99, train corr: 0.01698
Epoch [11/100], Batch [8/147] train loss: 7915.87, train corr: 0.01238
Epoch [11/100], Batch [9/147] train loss: 4916.59, train corr: -0.00697
Epoch [11/100], Batch [10/147] train loss: 6739.28, train corr: -0.02632
Epoch [11/100], Batch [11/147] train loss: 6924.53, train corr: -0.02996
Epoch [11/100], Batch [12/147] train loss: 8069.14, train corr: -0.02668
Epoch [11/100], Batch [13/147] train loss: 8190.59, train corr: -0.02092
Epoch [11/100], Batch [14/147] train loss: 5910.77, train corr: -0.03106
Epoch [11/100], Batch [15/147] train loss: 11152.00, train corr: -0.02901
Epoch [11/100], Batch [16/147] train loss: 9960.89, train corr: -0.00556
Epoch [11/100], Batch [17/147] train loss: 20368.83, train corr: 0.01553
Epoch [11/100], Batch [18/147] train loss: 19242.90, train corr: 0.01873
Epoch [11/100], Batch [19/147] train loss: 17395.87, train corr: 0.02343
Epoch [11/100], Batch [20/147] train loss: 14393.89, train corr: 0.02704
Epoch [11/100], Batch [21/147] train loss: 10151.98, train corr: 0.02807
Epoch [11/100], Batch [22/147] train loss: 10826.30, train corr: 0.02959
Epoch [11/100], Batch [23/147] train loss: 15078.71, train corr: 0.02813
Epoch [11/100], Batch [24/147] train loss: 7009.33, train corr: 0.02927
Epoch [11/100], Batch [25/147] train loss: 7305.21, train corr: 0.02444
Epoch [11/100], Batch [26/147] train loss: 8387.42, train corr: 0.02081
Epoch [11/100], Batch [27/147] train loss: 7626.12, train corr: -0.00348
Epoch [11/100], Batch [28/147] train loss: 4363.66, train corr: -0.02759
Epoch [11/100], Batch [29/147] train loss: 15286.25, train corr: -0.02910
Epoch [11/100], Batch [30/147] train loss: 7045.82, train corr: -0.02112
Epoch [11/100], Batch [31/147] train loss: 10739.17, train corr: -0.00914
Epoch [11/100], Batch [32/147] train loss: 10997.62, train corr: -0.00309
Epoch [11/100], Batch [33/147] train loss: 9882.85, train corr: -0.00081
Epoch [11/100], Batch [34/147] train loss: 6827.99, train corr: 0.00010
Epoch [11/100], Batch [35/147] train loss: 5264.60, train corr: -0.00302
Epoch [11/100], Batch [36/147] train loss: 13991.32, train corr: -0.01298
Epoch [11/100], Batch [37/147] train loss: 9994.00, train corr: 0.00420
Epoch [11/100], Batch [38/147] train loss: 16396.02, train corr: 0.01217
Epoch [11/100], Batch [39/147] train loss: 21131.92, train corr: 0.01577
Epoch [11/100], Batch [40/147] train loss: 22536.86, train corr: 0.01664
Epoch [11/100], Batch [41/147] train loss: 45184.71, train corr: 0.00941
Epoch [11/100], Batch [42/147] train loss: 18023.98, train corr: 0.01077
Epoch [11/100], Batch [43/147] train loss: 12217.87, train corr: 0.00205
Epoch [11/100], Batch [44/147] train loss: 6063.07, train corr: -0.01724
Epoch [11/100], Batch [45/147] train loss: 21734.20, train corr: -0.02961
Epoch [11/100], Batch [46/147] train loss: 4421.14, train corr: -0.01483
Epoch [11/100], Batch [47/147] train loss: 6924.98, train corr: 0.01452
Epoch [11/100], Batch [48/147] train loss: 8930.67, train corr: 0.02136
Epoch [11/100], Batch [49/147] train loss: 8848.69, train corr: 0.02240
Epoch [11/100], Batch [50/147] train loss: 6563.20, train corr: 0.02644
Epoch [11/100], Batch [51/147] train loss: 5178.98, train corr: 0.02980
Epoch [11/100], Batch [52/147] train loss: 7277.48, train corr: 0.03214
Epoch [11/100], Batch [53/147] train loss: 3439.05, train corr: 0.03158
Epoch [11/100], Batch [54/147] train loss: 7660.45, train corr: 0.00577
Epoch [11/100], Batch [55/147] train loss: 3636.09, train corr: -0.02509
Epoch [11/100], Batch [56/147] train loss: 5538.90, train corr: -0.02770
Epoch [11/100], Batch [57/147] train loss: 4785.51, train corr: -0.02021
Epoch [11/100], Batch [58/147] train loss: 6423.85, train corr: -0.01174
Epoch [11/100], Batch [59/147] train loss: 6322.90, train corr: -0.00729
Epoch [11/100], Batch [60/147] train loss: 4538.55, train corr: -0.00838
Epoch [11/100], Batch [61/147] train loss: 4817.44, train corr: -0.01464
Epoch [11/100], Batch [62/147] train loss: 4086.08, train corr: -0.00973
Epoch [11/100], Batch [63/147] train loss: 3213.17, train corr: -0.01637
Epoch [11/100], Batch [64/147] train loss: 3023.26, train corr: -0.02073
Epoch [11/100], Batch [65/147] train loss: 2973.42, train corr: -0.02273
Epoch [11/100], Batch [66/147] train loss: 2581.68, train corr: 0.01009
Epoch [11/100], Batch [67/147] train loss: 3140.42, train corr: 0.02316
Epoch [11/100], Batch [68/147] train loss: 2503.37, train corr: 0.02221
Epoch [11/100], Batch [69/147] train loss: 2145.88, train corr: 0.01025
Epoch [11/100], Batch [70/147] train loss: 1827.46, train corr: -0.00204
Epoch [11/100], Batch [71/147] train loss: 2650.49, train corr: -0.01808
Epoch [11/100], Batch [72/147] train loss: 2355.51, train corr: -0.01950
Epoch [11/100], Batch [73/147] train loss: 2071.99, train corr: -0.02817
Epoch [11/100], Batch [74/147] train loss: 2408.99, train corr: -0.03205
Epoch [11/100], Batch [75/147] train loss: 2623.95, train corr: -0.01534
Epoch [11/100], Batch [76/147] train loss: 2150.13, train corr: 0.02269
Epoch [11/100], Batch [77/147] train loss: 2414.68, train corr: 0.02496
Epoch [11/100], Batch [78/147] train loss: 2562.02, train corr: 0.02705
Epoch [11/100], Batch [79/147] train loss: 3191.56, train corr: 0.02404
Epoch [11/100], Batch [80/147] train loss: 1846.29, train corr: 0.02171
Epoch [11/100], Batch [81/147] train loss: 7484.07, train corr: 0.01825
Epoch [11/100], Batch [82/147] train loss: 6406.71, train corr: 0.02015
Epoch [11/100], Batch [83/147] train loss: 11407.15, train corr: 0.01827
Epoch [11/100], Batch [84/147] train loss: 13502.05, train corr: 0.01686
Epoch [11/100], Batch [85/147] train loss: 13069.00, train corr: 0.01742
Epoch [11/100], Batch [86/147] train loss: 11805.17, train corr: 0.00631
Epoch [11/100], Batch [87/147] train loss: 8226.62, train corr: -0.01360
Epoch [11/100], Batch [88/147] train loss: 4034.77, train corr: -0.02931
Epoch [11/100], Batch [89/147] train loss: 19051.24, train corr: -0.02537
Epoch [11/100], Batch [90/147] train loss: 3119.04, train corr: -0.03169
Epoch [11/100], Batch [91/147] train loss: 5855.17, train corr: 0.01548
Epoch [11/100], Batch [92/147] train loss: 5967.80, train corr: 0.02697
Epoch [11/100], Batch [93/147] train loss: 5804.18, train corr: 0.02624
Epoch [11/100], Batch [94/147] train loss: 3839.37, train corr: 0.02740
Epoch [11/100], Batch [95/147] train loss: 5092.18, train corr: 0.02270
Epoch [11/100], Batch [96/147] train loss: 2150.98, train corr: 0.02360
Epoch [11/100], Batch [97/147] train loss: 2546.46, train corr: -0.01592
Epoch [11/100], Batch [98/147] train loss: 3195.06, train corr: -0.02436
Epoch [11/100], Batch [99/147] train loss: 3952.96, train corr: -0.01525
Epoch [11/100], Batch [100/147] train loss: 4331.38, train corr: -0.00628
Epoch [11/100], Batch [101/147] train loss: 3740.03, train corr: -0.01039
Epoch [11/100], Batch [102/147] train loss: 2814.82, train corr: -0.01295
Epoch [11/100], Batch [103/147] train loss: 3748.41, train corr: -0.01932
Epoch [11/100], Batch [104/147] train loss: 5341.63, train corr: 0.00492
Epoch [11/100], Batch [105/147] train loss: 8281.96, train corr: 0.01554
Epoch [11/100], Batch [106/147] train loss: 8779.50, train corr: 0.01876
Epoch [11/100], Batch [107/147] train loss: 8112.87, train corr: 0.02074
Epoch [11/100], Batch [108/147] train loss: 5426.09, train corr: 0.01543
Epoch [11/100], Batch [109/147] train loss: 3593.61, train corr: 0.00345
Epoch [11/100], Batch [110/147] train loss: 9347.80, train corr: -0.00988
Epoch [11/100], Batch [111/147] train loss: 6208.74, train corr: 0.01135
Epoch [11/100], Batch [112/147] train loss: 10694.50, train corr: 0.01335
Epoch [11/100], Batch [113/147] train loss: 12824.06, train corr: 0.01184
Epoch [11/100], Batch [114/147] train loss: 12667.63, train corr: 0.00911
Epoch [11/100], Batch [115/147] train loss: 10921.15, train corr: 0.00803
Epoch [11/100], Batch [116/147] train loss: 8487.76, train corr: 0.00258
Epoch [11/100], Batch [117/147] train loss: 5182.85, train corr: -0.00309
Epoch [11/100], Batch [118/147] train loss: 7247.47, train corr: -0.01241
Epoch [11/100], Batch [119/147] train loss: 6297.42, train corr: -0.02019
Epoch [11/100], Batch [120/147] train loss: 5490.20, train corr: -0.01354
Epoch [11/100], Batch [121/147] train loss: 9025.66, train corr: -0.00943
Epoch [11/100], Batch [122/147] train loss: 9666.18, train corr: -0.00047
Epoch [11/100], Batch [123/147] train loss: 9356.39, train corr: -0.00737
Epoch [11/100], Batch [124/147] train loss: 7774.41, train corr: -0.00954
Epoch [11/100], Batch [125/147] train loss: 6515.47, train corr: -0.01223
Epoch [11/100], Batch [126/147] train loss: 11664.54, train corr: -0.01010
Epoch [11/100], Batch [127/147] train loss: 7015.65, train corr: 0.00644
Epoch [11/100], Batch [128/147] train loss: 8810.84, train corr: 0.02148
Epoch [11/100], Batch [129/147] train loss: 10206.24, train corr: 0.02952
Epoch [11/100], Batch [130/147] train loss: 8429.27, train corr: 0.02925
Epoch [11/100], Batch [131/147] train loss: 6822.10, train corr: 0.02941
Epoch [11/100], Batch [132/147] train loss: 6665.03, train corr: 0.02854
Epoch [11/100], Batch [133/147] train loss: 5391.86, train corr: 0.02828
Epoch [11/100], Batch [134/147] train loss: 3349.27, train corr: 0.01631
Epoch [11/100], Batch [135/147] train loss: 3627.19, train corr: -0.00472
Epoch [11/100], Batch [136/147] train loss: 3679.81, train corr: -0.01408
Epoch [11/100], Batch [137/147] train loss: 3215.06, train corr: -0.02148
Epoch [11/100], Batch [138/147] train loss: 3188.63, train corr: -0.02432
Epoch [11/100], Batch [139/147] train loss: 3290.00, train corr: -0.02658
Epoch [11/100], Batch [140/147] train loss: 3691.30, train corr: -0.02465
Epoch [11/100], Batch [141/147] train loss: 3587.52, train corr: -0.02582
Epoch [11/100], Batch [142/147] train loss: 3577.43, train corr: -0.02680
Epoch [11/100], Batch [143/147] train loss: 3904.59, train corr: -0.02682
Epoch [11/100], Batch [144/147] train loss: 3689.94, train corr: -0.02510
Epoch [11/100], Batch [145/147] train loss: 3781.80, train corr: -0.02560
Epoch [11/100], Batch [146/147] train loss: 3710.67, train corr: -0.02265
Epoch [11/100], Batch [147/147] train loss: 3860.71, train corr: -0.02406
Epoch [11/100], validation loss: 3150.43, validation correlation: -0.02346
Epoch [12/100], Batch [1/147] train loss: 2943.15, train corr: -0.02312
Epoch [12/100], Batch [2/147] train loss: 4076.90, train corr: -0.02228
Epoch [12/100], Batch [3/147] train loss: 3543.02, train corr: -0.01513
Epoch [12/100], Batch [4/147] train loss: 4434.43, train corr: -0.00846
Epoch [12/100], Batch [5/147] train loss: 4090.13, train corr: -0.00363
Epoch [12/100], Batch [6/147] train loss: 3061.01, train corr: -0.00923
Epoch [12/100], Batch [7/147] train loss: 5166.00, train corr: -0.01871
Epoch [12/100], Batch [8/147] train loss: 4815.23, train corr: 0.02722
Epoch [12/100], Batch [9/147] train loss: 8513.80, train corr: 0.02838
Epoch [12/100], Batch [10/147] train loss: 9477.98, train corr: 0.02837
Epoch [12/100], Batch [11/147] train loss: 9492.40, train corr: 0.02539
Epoch [12/100], Batch [12/147] train loss: 8669.51, train corr: 0.02587
Epoch [12/100], Batch [13/147] train loss: 8122.29, train corr: 0.02930
Epoch [12/100], Batch [14/147] train loss: 7515.21, train corr: 0.02808
Epoch [12/100], Batch [15/147] train loss: 4644.06, train corr: 0.02315
Epoch [12/100], Batch [16/147] train loss: 4110.49, train corr: 0.01922
Epoch [12/100], Batch [17/147] train loss: 3963.39, train corr: 0.01154
Epoch [12/100], Batch [18/147] train loss: 3125.34, train corr: -0.00871
Epoch [12/100], Batch [19/147] train loss: 3374.90, train corr: -0.01644
Epoch [12/100], Batch [20/147] train loss: 3213.61, train corr: -0.02143
Epoch [12/100], Batch [21/147] train loss: 3351.61, train corr: -0.02306
Epoch [12/100], Batch [22/147] train loss: 3636.62, train corr: -0.02503
Epoch [12/100], Batch [23/147] train loss: 4211.84, train corr: -0.02480
Epoch [12/100], Batch [24/147] train loss: 4459.07, train corr: -0.02601
Epoch [12/100], Batch [25/147] train loss: 4042.72, train corr: -0.02420
Epoch [12/100], Batch [26/147] train loss: 3553.37, train corr: -0.02607
Epoch [12/100], Batch [27/147] train loss: 3128.51, train corr: -0.02251
Epoch [12/100], Batch [28/147] train loss: 2849.54, train corr: -0.02203
Epoch [12/100], Batch [29/147] train loss: 2657.06, train corr: -0.01900
Epoch [12/100], Batch [30/147] train loss: 2658.49, train corr: -0.01977
Epoch [12/100], Batch [31/147] train loss: 2621.37, train corr: -0.01639
Epoch [12/100], Batch [32/147] train loss: 2680.79, train corr: -0.01640
Epoch [12/100], Batch [33/147] train loss: 2261.90, train corr: -0.01431
Epoch [12/100], Batch [34/147] train loss: 1791.39, train corr: -0.02054
Epoch [12/100], Batch [35/147] train loss: 3559.89, train corr: -0.02582
Epoch [12/100], Batch [36/147] train loss: 4611.91, train corr: 0.02494
Epoch [12/100], Batch [37/147] train loss: 7589.20, train corr: 0.02730
Epoch [12/100], Batch [38/147] train loss: 9029.38, train corr: 0.02605
Epoch [12/100], Batch [39/147] train loss: 9061.77, train corr: 0.03097
Epoch [12/100], Batch [40/147] train loss: 8078.76, train corr: 0.03166
Epoch [12/100], Batch [41/147] train loss: 6287.75, train corr: 0.03096
Epoch [12/100], Batch [42/147] train loss: 5930.46, train corr: 0.02936
Epoch [12/100], Batch [43/147] train loss: 5139.66, train corr: 0.02785
Epoch [12/100], Batch [44/147] train loss: 2370.84, train corr: 0.01389
Epoch [12/100], Batch [45/147] train loss: 6600.61, train corr: -0.01062
Epoch [12/100], Batch [46/147] train loss: 6413.05, train corr: 0.00218
Epoch [12/100], Batch [47/147] train loss: 9705.20, train corr: 0.01201
Epoch [12/100], Batch [48/147] train loss: 12158.79, train corr: 0.01210
Epoch [12/100], Batch [49/147] train loss: 12896.96, train corr: 0.00855
Epoch [12/100], Batch [50/147] train loss: 13016.26, train corr: 0.00617
Epoch [12/100], Batch [51/147] train loss: 12123.74, train corr: -0.00078
Epoch [12/100], Batch [52/147] train loss: 10079.23, train corr: 0.00066
Epoch [12/100], Batch [53/147] train loss: 7145.09, train corr: -0.00511
Epoch [12/100], Batch [54/147] train loss: 5118.08, train corr: -0.01380
Epoch [12/100], Batch [55/147] train loss: 11167.53, train corr: -0.01803
Epoch [12/100], Batch [56/147] train loss: 5011.59, train corr: -0.01050
Epoch [12/100], Batch [57/147] train loss: 8162.85, train corr: -0.00609
Epoch [12/100], Batch [58/147] train loss: 9973.58, train corr: -0.00156
Epoch [12/100], Batch [59/147] train loss: 10010.00, train corr: 0.00363
Epoch [12/100], Batch [60/147] train loss: 9977.06, train corr: 0.00169
Epoch [12/100], Batch [61/147] train loss: 8488.34, train corr: -0.00043
Epoch [12/100], Batch [62/147] train loss: 6859.42, train corr: -0.01493
Epoch [12/100], Batch [63/147] train loss: 4682.38, train corr: -0.02877
Epoch [12/100], Batch [64/147] train loss: 8367.94, train corr: -0.03158
Epoch [12/100], Batch [65/147] train loss: 3588.71, train corr: -0.01638
Epoch [12/100], Batch [66/147] train loss: 4901.83, train corr: 0.01456
Epoch [12/100], Batch [67/147] train loss: 4921.66, train corr: 0.02476
Epoch [12/100], Batch [68/147] train loss: 4488.01, train corr: 0.02135
Epoch [12/100], Batch [69/147] train loss: 4837.14, train corr: 0.02523
Epoch [12/100], Batch [70/147] train loss: 6221.07, train corr: 0.02470
Epoch [12/100], Batch [71/147] train loss: 3980.57, train corr: 0.02583
Epoch [12/100], Batch [72/147] train loss: 2615.05, train corr: 0.02796
Epoch [12/100], Batch [73/147] train loss: 2711.79, train corr: 0.01979
Epoch [12/100], Batch [74/147] train loss: 2615.98, train corr: -0.00409
Epoch [12/100], Batch [75/147] train loss: 3303.71, train corr: -0.01820
Epoch [12/100], Batch [76/147] train loss: 3969.04, train corr: -0.01407
Epoch [12/100], Batch [77/147] train loss: 4861.74, train corr: -0.01317
Epoch [12/100], Batch [78/147] train loss: 5217.14, train corr: -0.01889
Epoch [12/100], Batch [79/147] train loss: 4388.92, train corr: -0.02572
Epoch [12/100], Batch [80/147] train loss: 3222.82, train corr: -0.02907
Epoch [12/100], Batch [81/147] train loss: 7098.44, train corr: -0.03020
Epoch [12/100], Batch [82/147] train loss: 4181.44, train corr: -0.02180
Epoch [12/100], Batch [83/147] train loss: 5528.96, train corr: 0.00960
Epoch [12/100], Batch [84/147] train loss: 6380.60, train corr: 0.01229
Epoch [12/100], Batch [85/147] train loss: 5945.69, train corr: 0.01483
Epoch [12/100], Batch [86/147] train loss: 4911.58, train corr: 0.01802
Epoch [12/100], Batch [87/147] train loss: 3495.54, train corr: 0.01204
Epoch [12/100], Batch [88/147] train loss: 5567.13, train corr: 0.01902
Epoch [12/100], Batch [89/147] train loss: 2582.93, train corr: 0.01935
Epoch [12/100], Batch [90/147] train loss: 3268.98, train corr: 0.02301
Epoch [12/100], Batch [91/147] train loss: 3586.76, train corr: 0.03102
Epoch [12/100], Batch [92/147] train loss: 3332.27, train corr: 0.03397
Epoch [12/100], Batch [93/147] train loss: 2382.46, train corr: 0.02127
Epoch [12/100], Batch [94/147] train loss: 6139.56, train corr: 0.00398
Epoch [12/100], Batch [95/147] train loss: 3361.70, train corr: 0.02420
Epoch [12/100], Batch [96/147] train loss: 5506.42, train corr: 0.03239
Epoch [12/100], Batch [97/147] train loss: 5673.00, train corr: 0.03262
Epoch [12/100], Batch [98/147] train loss: 5334.68, train corr: 0.03270
Epoch [12/100], Batch [99/147] train loss: 4329.64, train corr: 0.02911
Epoch [12/100], Batch [100/147] train loss: 2935.30, train corr: 0.02101
Epoch [12/100], Batch [101/147] train loss: 6108.96, train corr: 0.00536
Epoch [12/100], Batch [102/147] train loss: 3578.92, train corr: 0.03026
Epoch [12/100], Batch [103/147] train loss: 5057.85, train corr: 0.03242
Epoch [12/100], Batch [104/147] train loss: 5614.82, train corr: 0.03210
Epoch [12/100], Batch [105/147] train loss: 7191.36, train corr: 0.02740
Epoch [12/100], Batch [106/147] train loss: 4401.62, train corr: 0.03124
Epoch [12/100], Batch [107/147] train loss: 3100.70, train corr: 0.02889
Epoch [12/100], Batch [108/147] train loss: 3451.77, train corr: 0.03140
Epoch [12/100], Batch [109/147] train loss: 1519.24, train corr: 0.02693
Epoch [12/100], Batch [110/147] train loss: 2301.21, train corr: 0.01245
Epoch [12/100], Batch [111/147] train loss: 1881.98, train corr: -0.02513
Epoch [12/100], Batch [112/147] train loss: 2194.56, train corr: -0.03169
Epoch [12/100], Batch [113/147] train loss: 2180.31, train corr: -0.02970
Epoch [12/100], Batch [114/147] train loss: 2176.72, train corr: -0.02337
Epoch [12/100], Batch [115/147] train loss: 1982.99, train corr: -0.03170
Epoch [12/100], Batch [116/147] train loss: 2084.94, train corr: -0.02895
Epoch [12/100], Batch [117/147] train loss: 1895.94, train corr: -0.02103
Epoch [12/100], Batch [118/147] train loss: 1834.00, train corr: -0.01616
Epoch [12/100], Batch [119/147] train loss: 2164.10, train corr: -0.01931
Epoch [12/100], Batch [120/147] train loss: 1557.03, train corr: -0.00605
Epoch [12/100], Batch [121/147] train loss: 1686.62, train corr: 0.01157
Epoch [12/100], Batch [122/147] train loss: 1617.65, train corr: 0.01794
Epoch [12/100], Batch [123/147] train loss: 2602.35, train corr: 0.01365
Epoch [12/100], Batch [124/147] train loss: 2438.08, train corr: 0.02871
Epoch [12/100], Batch [125/147] train loss: 3406.30, train corr: 0.02402
Epoch [12/100], Batch [126/147] train loss: 3428.96, train corr: 0.01700
Epoch [12/100], Batch [127/147] train loss: 2881.72, train corr: 0.00566
Epoch [12/100], Batch [128/147] train loss: 1850.25, train corr: -0.01341
Epoch [12/100], Batch [129/147] train loss: 7578.98, train corr: -0.02324
Epoch [12/100], Batch [130/147] train loss: 4403.67, train corr: 0.01700
Epoch [12/100], Batch [131/147] train loss: 7674.74, train corr: 0.02173
Epoch [12/100], Batch [132/147] train loss: 10028.03, train corr: 0.02589
Epoch [12/100], Batch [133/147] train loss: 11179.35, train corr: 0.02663
Epoch [12/100], Batch [134/147] train loss: 10678.44, train corr: 0.02636
Epoch [12/100], Batch [135/147] train loss: 10599.14, train corr: 0.02225
Epoch [12/100], Batch [136/147] train loss: 9909.73, train corr: 0.02527
Epoch [12/100], Batch [137/147] train loss: 7830.42, train corr: 0.02360
Epoch [12/100], Batch [138/147] train loss: 5680.87, train corr: 0.02600
Epoch [12/100], Batch [139/147] train loss: 3808.27, train corr: 0.02720
Epoch [12/100], Batch [140/147] train loss: 6657.27, train corr: 0.02976
Epoch [12/100], Batch [141/147] train loss: 1759.75, train corr: 0.02735
Epoch [12/100], Batch [142/147] train loss: 2282.65, train corr: 0.01904
Epoch [12/100], Batch [143/147] train loss: 2337.54, train corr: -0.00832
Epoch [12/100], Batch [144/147] train loss: 3998.22, train corr: -0.02484
Epoch [12/100], Batch [145/147] train loss: 4522.97, train corr: -0.02118
Epoch [12/100], Batch [146/147] train loss: 4987.65, train corr: 0.01125
Epoch [12/100], Batch [147/147] train loss: 7519.35, train corr: 0.01791
Epoch [12/100], validation loss: 9613.08, validation correlation: 0.02089
Epoch [13/100], Batch [1/147] train loss: 8769.06, train corr: 0.02127
Epoch [13/100], Batch [2/147] train loss: 9738.29, train corr: 0.01866
Epoch [13/100], Batch [3/147] train loss: 9439.88, train corr: 0.01812
Epoch [13/100], Batch [4/147] train loss: 8344.64, train corr: 0.02188
Epoch [13/100], Batch [5/147] train loss: 6388.10, train corr: 0.02395
Epoch [13/100], Batch [6/147] train loss: 4446.09, train corr: 0.02222
Epoch [13/100], Batch [7/147] train loss: 8041.96, train corr: 0.02349
Epoch [13/100], Batch [8/147] train loss: 4373.98, train corr: 0.02009
Epoch [13/100], Batch [9/147] train loss: 4897.50, train corr: 0.02697
Epoch [13/100], Batch [10/147] train loss: 5471.43, train corr: 0.02766
Epoch [13/100], Batch [11/147] train loss: 5566.62, train corr: 0.02884
Epoch [13/100], Batch [12/147] train loss: 5154.42, train corr: 0.02829
Epoch [13/100], Batch [13/147] train loss: 4083.42, train corr: 0.02847
Epoch [13/100], Batch [14/147] train loss: 2726.53, train corr: 0.01091
Epoch [13/100], Batch [15/147] train loss: 8751.17, train corr: -0.00696
Epoch [13/100], Batch [16/147] train loss: 3744.55, train corr: 0.02777
Epoch [13/100], Batch [17/147] train loss: 5658.14, train corr: 0.03255
Epoch [13/100], Batch [18/147] train loss: 6866.86, train corr: 0.03278
Epoch [13/100], Batch [19/147] train loss: 7512.39, train corr: 0.03195
Epoch [13/100], Batch [20/147] train loss: 7387.18, train corr: 0.03089
Epoch [13/100], Batch [21/147] train loss: 6145.14, train corr: 0.03052
Epoch [13/100], Batch [22/147] train loss: 5222.73, train corr: 0.03054
Epoch [13/100], Batch [23/147] train loss: 3813.71, train corr: 0.03100
Epoch [13/100], Batch [24/147] train loss: 3123.92, train corr: 0.02663
Epoch [13/100], Batch [25/147] train loss: 4238.05, train corr: 0.01580
Epoch [13/100], Batch [26/147] train loss: 3411.62, train corr: 0.02818
Epoch [13/100], Batch [27/147] train loss: 5229.97, train corr: 0.01721
Epoch [13/100], Batch [28/147] train loss: 6924.63, train corr: 0.01473
Epoch [13/100], Batch [29/147] train loss: 7530.67, train corr: 0.00663
Epoch [13/100], Batch [30/147] train loss: 7319.12, train corr: 0.00140
Epoch [13/100], Batch [31/147] train loss: 6117.76, train corr: -0.00323
Epoch [13/100], Batch [32/147] train loss: 5169.47, train corr: -0.01213
Epoch [13/100], Batch [33/147] train loss: 3494.56, train corr: -0.02131
Epoch [13/100], Batch [34/147] train loss: 7008.98, train corr: -0.02381
Epoch [13/100], Batch [35/147] train loss: 4245.85, train corr: -0.01725
Epoch [13/100], Batch [36/147] train loss: 6212.78, train corr: -0.00797
Epoch [13/100], Batch [37/147] train loss: 7398.48, train corr: -0.00036
Epoch [13/100], Batch [38/147] train loss: 7588.42, train corr: 0.00199
Epoch [13/100], Batch [39/147] train loss: 8421.90, train corr: -0.00351
Epoch [13/100], Batch [40/147] train loss: 7500.68, train corr: -0.00228
Epoch [13/100], Batch [41/147] train loss: 5943.71, train corr: -0.00385
Epoch [13/100], Batch [42/147] train loss: 4684.11, train corr: -0.00703
Epoch [13/100], Batch [43/147] train loss: 3830.21, train corr: -0.01944
Epoch [13/100], Batch [44/147] train loss: 4076.42, train corr: -0.02173
Epoch [13/100], Batch [45/147] train loss: 2611.11, train corr: -0.02219
Epoch [13/100], Batch [46/147] train loss: 2994.97, train corr: -0.01535
Epoch [13/100], Batch [47/147] train loss: 3879.06, train corr: -0.00914
Epoch [13/100], Batch [48/147] train loss: 4267.56, train corr: -0.00583
Epoch [13/100], Batch [49/147] train loss: 3727.04, train corr: -0.00393
Epoch [13/100], Batch [50/147] train loss: 3626.10, train corr: -0.01957
Epoch [13/100], Batch [51/147] train loss: 4074.89, train corr: -0.03089
Epoch [13/100], Batch [52/147] train loss: 3330.48, train corr: -0.00793
Epoch [13/100], Batch [53/147] train loss: 2745.01, train corr: 0.01981
Epoch [13/100], Batch [54/147] train loss: 2731.23, train corr: 0.02309
Epoch [13/100], Batch [55/147] train loss: 2375.47, train corr: 0.02433
Epoch [13/100], Batch [56/147] train loss: 2403.99, train corr: 0.02133
Epoch [13/100], Batch [57/147] train loss: 1916.34, train corr: 0.01315
Epoch [13/100], Batch [58/147] train loss: 1791.94, train corr: -0.00135
Epoch [13/100], Batch [59/147] train loss: 1873.37, train corr: -0.01183
Epoch [13/100], Batch [60/147] train loss: 1642.62, train corr: -0.02907
Epoch [13/100], Batch [61/147] train loss: 1670.48, train corr: -0.03170
Epoch [13/100], Batch [62/147] train loss: 1659.43, train corr: -0.02864
Epoch [13/100], Batch [63/147] train loss: 1553.64, train corr: -0.02439
Epoch [13/100], Batch [64/147] train loss: 1714.37, train corr: -0.02432
Epoch [13/100], Batch [65/147] train loss: 1650.41, train corr: -0.01561
Epoch [13/100], Batch [66/147] train loss: 1638.70, train corr: -0.01063
Epoch [13/100], Batch [67/147] train loss: 1652.40, train corr: -0.01052
Epoch [13/100], Batch [68/147] train loss: 1463.55, train corr: -0.00924
Epoch [13/100], Batch [69/147] train loss: 1464.24, train corr: -0.00737
Epoch [13/100], Batch [70/147] train loss: 1293.49, train corr: -0.01704
Epoch [13/100], Batch [71/147] train loss: 1639.19, train corr: -0.02777
Epoch [13/100], Batch [72/147] train loss: 2371.17, train corr: -0.00052
Epoch [13/100], Batch [73/147] train loss: 2992.01, train corr: 0.01206
Epoch [13/100], Batch [74/147] train loss: 3235.25, train corr: 0.01176
Epoch [13/100], Batch [75/147] train loss: 2677.30, train corr: 0.01678
Epoch [13/100], Batch [76/147] train loss: 1746.68, train corr: 0.00852
Epoch [13/100], Batch [77/147] train loss: 2790.79, train corr: -0.03082
Epoch [13/100], Batch [78/147] train loss: 3333.08, train corr: 0.02584
Epoch [13/100], Batch [79/147] train loss: 5362.45, train corr: 0.02522
Epoch [13/100], Batch [80/147] train loss: 6680.77, train corr: 0.02631
Epoch [13/100], Batch [81/147] train loss: 7324.76, train corr: 0.02690
Epoch [13/100], Batch [82/147] train loss: 7619.27, train corr: 0.02354
Epoch [13/100], Batch [83/147] train loss: 7320.67, train corr: 0.02296
Epoch [13/100], Batch [84/147] train loss: 7953.53, train corr: 0.02244
Epoch [13/100], Batch [85/147] train loss: 4622.14, train corr: 0.02774
Epoch [13/100], Batch [86/147] train loss: 2929.27, train corr: 0.02722
Epoch [13/100], Batch [87/147] train loss: 4212.99, train corr: 0.02724
Epoch [13/100], Batch [88/147] train loss: 4816.86, train corr: 0.02790
Epoch [13/100], Batch [89/147] train loss: 3028.45, train corr: 0.02009
Epoch [13/100], Batch [90/147] train loss: 4717.49, train corr: 0.00533
Epoch [13/100], Batch [91/147] train loss: 5917.50, train corr: -0.00992
Epoch [13/100], Batch [92/147] train loss: 6513.83, train corr: -0.02167
Epoch [13/100], Batch [93/147] train loss: 6367.89, train corr: -0.02792
Epoch [13/100], Batch [94/147] train loss: 5547.39, train corr: -0.03094
Epoch [13/100], Batch [95/147] train loss: 4825.17, train corr: -0.02963
Epoch [13/100], Batch [96/147] train loss: 9833.78, train corr: -0.02974
Epoch [13/100], Batch [97/147] train loss: 5494.48, train corr: -0.02861
Epoch [13/100], Batch [98/147] train loss: 6690.64, train corr: -0.02166
Epoch [13/100], Batch [99/147] train loss: 7940.89, train corr: -0.01450
Epoch [13/100], Batch [100/147] train loss: 7849.78, train corr: -0.01164
Epoch [13/100], Batch [101/147] train loss: 7412.61, train corr: -0.00767
Epoch [13/100], Batch [102/147] train loss: 6411.09, train corr: -0.00855
Epoch [13/100], Batch [103/147] train loss: 5394.16, train corr: -0.01139
Epoch [13/100], Batch [104/147] train loss: 3685.51, train corr: -0.01669
Epoch [13/100], Batch [105/147] train loss: 3664.53, train corr: -0.01996
Epoch [13/100], Batch [106/147] train loss: 3284.10, train corr: -0.02082
Epoch [13/100], Batch [107/147] train loss: 3654.53, train corr: -0.01445
Epoch [13/100], Batch [108/147] train loss: 4963.22, train corr: -0.00692
Epoch [13/100], Batch [109/147] train loss: 5912.35, train corr: -0.00305
Epoch [13/100], Batch [110/147] train loss: 5655.68, train corr: 0.00658
Epoch [13/100], Batch [111/147] train loss: 5656.11, train corr: 0.00654
Epoch [13/100], Batch [112/147] train loss: 4895.55, train corr: -0.00604
Epoch [13/100], Batch [113/147] train loss: 5418.52, train corr: -0.00936
Epoch [13/100], Batch [114/147] train loss: 3538.46, train corr: -0.00703
Epoch [13/100], Batch [115/147] train loss: 3642.99, train corr: -0.00916
Epoch [13/100], Batch [116/147] train loss: 3348.21, train corr: 0.01599
Epoch [13/100], Batch [117/147] train loss: 3472.34, train corr: 0.02471
Epoch [13/100], Batch [118/147] train loss: 3516.31, train corr: 0.02998
Epoch [13/100], Batch [119/147] train loss: 3287.03, train corr: 0.02971
Epoch [13/100], Batch [120/147] train loss: 3172.11, train corr: 0.02995
Epoch [13/100], Batch [121/147] train loss: 2499.38, train corr: 0.03243
Epoch [13/100], Batch [122/147] train loss: 2243.07, train corr: 0.02823
Epoch [13/100], Batch [123/147] train loss: 2587.03, train corr: 0.01071
Epoch [13/100], Batch [124/147] train loss: 2132.81, train corr: 0.00449
Epoch [13/100], Batch [125/147] train loss: 2097.55, train corr: 0.00470
Epoch [13/100], Batch [126/147] train loss: 2082.78, train corr: -0.00186
Epoch [13/100], Batch [127/147] train loss: 2072.64, train corr: -0.00471
Epoch [13/100], Batch [128/147] train loss: 2192.55, train corr: 0.00380
Epoch [13/100], Batch [129/147] train loss: 2063.87, train corr: 0.00907
Epoch [13/100], Batch [130/147] train loss: 2131.97, train corr: 0.00605
Epoch [13/100], Batch [131/147] train loss: 1963.31, train corr: 0.00980
Epoch [13/100], Batch [132/147] train loss: 1901.80, train corr: 0.00787
Epoch [13/100], Batch [133/147] train loss: 4387.37, train corr: -0.00019
Epoch [13/100], Batch [134/147] train loss: 3534.38, train corr: 0.02551
Epoch [13/100], Batch [135/147] train loss: 4791.59, train corr: 0.02589
Epoch [13/100], Batch [136/147] train loss: 5743.73, train corr: 0.02426
Epoch [13/100], Batch [137/147] train loss: 5885.97, train corr: 0.02264
Epoch [13/100], Batch [138/147] train loss: 5080.73, train corr: 0.02675
Epoch [13/100], Batch [139/147] train loss: 4418.06, train corr: 0.02400
Epoch [13/100], Batch [140/147] train loss: 4306.81, train corr: 0.02257
Epoch [13/100], Batch [141/147] train loss: 3796.46, train corr: 0.02211
Epoch [13/100], Batch [142/147] train loss: 2322.84, train corr: 0.01731
Epoch [13/100], Batch [143/147] train loss: 1881.93, train corr: 0.00558
Epoch [13/100], Batch [144/147] train loss: 1487.40, train corr: -0.02874
Epoch [13/100], Batch [145/147] train loss: 5075.77, train corr: -0.03173
Epoch [13/100], Batch [146/147] train loss: 3133.71, train corr: -0.02421
Epoch [13/100], Batch [147/147] train loss: 4663.87, train corr: -0.00665
Epoch [13/100], validation loss: 6493.01, validation correlation: 0.00150
Epoch [14/100], Batch [1/147] train loss: 6012.94, train corr: 0.00363
Epoch [14/100], Batch [2/147] train loss: 6378.11, train corr: 0.00202
Epoch [14/100], Batch [3/147] train loss: 6383.51, train corr: 0.00515
Epoch [14/100], Batch [4/147] train loss: 6062.40, train corr: -0.00049
Epoch [14/100], Batch [5/147] train loss: 5134.59, train corr: -0.00628
Epoch [14/100], Batch [6/147] train loss: 4069.91, train corr: -0.01196
Epoch [14/100], Batch [7/147] train loss: 3036.44, train corr: -0.01945
Epoch [14/100], Batch [8/147] train loss: 5026.21, train corr: -0.02451
Epoch [14/100], Batch [9/147] train loss: 2403.47, train corr: -0.01875
Epoch [14/100], Batch [10/147] train loss: 2830.91, train corr: -0.00950
Epoch [14/100], Batch [11/147] train loss: 2987.85, train corr: -0.00277
Epoch [14/100], Batch [12/147] train loss: 2630.99, train corr: -0.00052
Epoch [14/100], Batch [13/147] train loss: 1911.51, train corr: -0.00168
Epoch [14/100], Batch [14/147] train loss: 4310.50, train corr: -0.00563
Epoch [14/100], Batch [15/147] train loss: 1862.97, train corr: 0.00317
Epoch [14/100], Batch [16/147] train loss: 2256.75, train corr: 0.00910
Epoch [14/100], Batch [17/147] train loss: 2171.57, train corr: 0.01106
Epoch [14/100], Batch [18/147] train loss: 1724.20, train corr: 0.01386
Epoch [14/100], Batch [19/147] train loss: 1398.90, train corr: -0.02071
Epoch [14/100], Batch [20/147] train loss: 1803.97, train corr: -0.01167
Epoch [14/100], Batch [21/147] train loss: 2140.28, train corr: 0.02073
Epoch [14/100], Batch [22/147] train loss: 2724.70, train corr: 0.02587
Epoch [14/100], Batch [23/147] train loss: 3205.16, train corr: 0.01571
Epoch [14/100], Batch [24/147] train loss: 2798.02, train corr: 0.02408
Epoch [14/100], Batch [25/147] train loss: 2442.87, train corr: 0.01893
Epoch [14/100], Batch [26/147] train loss: 1897.57, train corr: 0.02665
Epoch [14/100], Batch [27/147] train loss: 2033.26, train corr: 0.02373
Epoch [14/100], Batch [28/147] train loss: 1448.53, train corr: 0.02581
Epoch [14/100], Batch [29/147] train loss: 1442.84, train corr: 0.01618
Epoch [14/100], Batch [30/147] train loss: 1539.63, train corr: -0.01224
Epoch [14/100], Batch [31/147] train loss: 1763.43, train corr: -0.01278
Epoch [14/100], Batch [32/147] train loss: 2583.21, train corr: 0.00463
Epoch [14/100], Batch [33/147] train loss: 3518.42, train corr: 0.01235
Epoch [14/100], Batch [34/147] train loss: 3594.38, train corr: 0.01455
Epoch [14/100], Batch [35/147] train loss: 3243.26, train corr: 0.01950
Epoch [14/100], Batch [36/147] train loss: 2474.56, train corr: 0.01234
Epoch [14/100], Batch [37/147] train loss: 1846.01, train corr: 0.00321
Epoch [14/100], Batch [38/147] train loss: 3477.57, train corr: -0.00812
Epoch [14/100], Batch [39/147] train loss: 2250.28, train corr: 0.01880
Epoch [14/100], Batch [40/147] train loss: 3049.71, train corr: 0.02698
Epoch [14/100], Batch [41/147] train loss: 3501.29, train corr: 0.02519
Epoch [14/100], Batch [42/147] train loss: 7493.70, train corr: 0.02198
Epoch [14/100], Batch [43/147] train loss: 2564.65, train corr: 0.02177
Epoch [14/100], Batch [44/147] train loss: 2848.82, train corr: 0.02043
Epoch [14/100], Batch [45/147] train loss: 1759.03, train corr: 0.02310
Epoch [14/100], Batch [46/147] train loss: 1857.92, train corr: 0.02697
Epoch [14/100], Batch [47/147] train loss: 1732.84, train corr: 0.02601
Epoch [14/100], Batch [48/147] train loss: 1847.24, train corr: -0.00904
Epoch [14/100], Batch [49/147] train loss: 1784.42, train corr: -0.01661
Epoch [14/100], Batch [50/147] train loss: 1503.64, train corr: 0.00764
Epoch [14/100], Batch [51/147] train loss: 1629.01, train corr: 0.01938
Epoch [14/100], Batch [52/147] train loss: 1405.31, train corr: 0.01923
Epoch [14/100], Batch [53/147] train loss: 1801.89, train corr: 0.00121
Epoch [14/100], Batch [54/147] train loss: 2254.22, train corr: 0.03082
Epoch [14/100], Batch [55/147] train loss: 3516.33, train corr: 0.02337
Epoch [14/100], Batch [56/147] train loss: 3794.23, train corr: 0.02815
Epoch [14/100], Batch [57/147] train loss: 4664.96, train corr: 0.02006
Epoch [14/100], Batch [58/147] train loss: 3317.85, train corr: 0.02472
Epoch [14/100], Batch [59/147] train loss: 2818.47, train corr: 0.02489
Epoch [14/100], Batch [60/147] train loss: 2638.90, train corr: 0.02066
Epoch [14/100], Batch [61/147] train loss: 2904.77, train corr: 0.02718
Epoch [14/100], Batch [62/147] train loss: 2345.16, train corr: 0.02705
Epoch [14/100], Batch [63/147] train loss: 2992.36, train corr: 0.02516
Epoch [14/100], Batch [64/147] train loss: 3289.20, train corr: 0.02292
Epoch [14/100], Batch [65/147] train loss: 3219.85, train corr: 0.01705
Epoch [14/100], Batch [66/147] train loss: 2467.96, train corr: 0.01674
Epoch [14/100], Batch [67/147] train loss: 1541.84, train corr: -0.00898
Epoch [14/100], Batch [68/147] train loss: 8885.48, train corr: -0.02121
Epoch [14/100], Batch [69/147] train loss: 3191.15, train corr: 0.02476
Epoch [14/100], Batch [70/147] train loss: 5355.84, train corr: 0.02114
Epoch [14/100], Batch [71/147] train loss: 6758.33, train corr: 0.02148
Epoch [14/100], Batch [72/147] train loss: 7322.68, train corr: 0.02642
Epoch [14/100], Batch [73/147] train loss: 8099.85, train corr: 0.02089
Epoch [14/100], Batch [74/147] train loss: 7900.45, train corr: 0.02346
Epoch [14/100], Batch [75/147] train loss: 7527.27, train corr: 0.02583
Epoch [14/100], Batch [76/147] train loss: 6750.60, train corr: 0.02328
Epoch [14/100], Batch [77/147] train loss: 5846.88, train corr: 0.02886
Epoch [14/100], Batch [78/147] train loss: 4441.13, train corr: 0.02397
Epoch [14/100], Batch [79/147] train loss: 4536.27, train corr: 0.02291
Epoch [14/100], Batch [80/147] train loss: 4639.29, train corr: 0.02390
Epoch [14/100], Batch [81/147] train loss: 2587.97, train corr: 0.02348
Epoch [14/100], Batch [82/147] train loss: 2245.08, train corr: 0.02349
Epoch [14/100], Batch [83/147] train loss: 2780.65, train corr: 0.01946
Epoch [14/100], Batch [84/147] train loss: 2803.90, train corr: 0.00392
Epoch [14/100], Batch [85/147] train loss: 2470.93, train corr: -0.02960
Epoch [14/100], Batch [86/147] train loss: 2717.05, train corr: -0.02693
Epoch [14/100], Batch [87/147] train loss: 3708.44, train corr: -0.02709
Epoch [14/100], Batch [88/147] train loss: 3041.85, train corr: -0.02219
Epoch [14/100], Batch [89/147] train loss: 7106.19, train corr: -0.01541
Epoch [14/100], Batch [90/147] train loss: 3365.81, train corr: -0.01481
Epoch [14/100], Batch [91/147] train loss: 2540.60, train corr: -0.01768
Epoch [14/100], Batch [92/147] train loss: 1907.57, train corr: -0.01914
Epoch [14/100], Batch [93/147] train loss: 5372.06, train corr: -0.01942
Epoch [14/100], Batch [94/147] train loss: 2886.26, train corr: 0.00216
Epoch [14/100], Batch [95/147] train loss: 4167.02, train corr: 0.01945
Epoch [14/100], Batch [96/147] train loss: 5230.89, train corr: 0.02231
Epoch [14/100], Batch [97/147] train loss: 5726.89, train corr: 0.02246
Epoch [14/100], Batch [98/147] train loss: 5758.16, train corr: 0.01908
Epoch [14/100], Batch [99/147] train loss: 5494.32, train corr: 0.02392
Epoch [14/100], Batch [100/147] train loss: 4473.28, train corr: 0.02573
Epoch [14/100], Batch [101/147] train loss: 3843.68, train corr: 0.02374
Epoch [14/100], Batch [102/147] train loss: 3954.13, train corr: 0.02478
Epoch [14/100], Batch [103/147] train loss: 3790.66, train corr: 0.03179
Epoch [14/100], Batch [104/147] train loss: 2594.99, train corr: 0.02853
Epoch [14/100], Batch [105/147] train loss: 2281.79, train corr: 0.02647
Epoch [14/100], Batch [106/147] train loss: 2739.97, train corr: 0.01992
Epoch [14/100], Batch [107/147] train loss: 2539.04, train corr: 0.02357
Epoch [14/100], Batch [108/147] train loss: 2068.85, train corr: 0.02205
Epoch [14/100], Batch [109/147] train loss: 1414.33, train corr: 0.01153
Epoch [14/100], Batch [110/147] train loss: 5086.05, train corr: -0.02766
Epoch [14/100], Batch [111/147] train loss: 3580.52, train corr: 0.01232
Epoch [14/100], Batch [112/147] train loss: 5940.46, train corr: 0.02229
Epoch [14/100], Batch [113/147] train loss: 7778.73, train corr: 0.02181
Epoch [14/100], Batch [114/147] train loss: 9052.96, train corr: 0.01972
Epoch [14/100], Batch [115/147] train loss: 9324.35, train corr: 0.02469
Epoch [14/100], Batch [116/147] train loss: 9951.52, train corr: 0.02603
Epoch [14/100], Batch [117/147] train loss: 9554.82, train corr: 0.01888
Epoch [14/100], Batch [118/147] train loss: 9452.91, train corr: 0.02366
Epoch [14/100], Batch [119/147] train loss: 8788.82, train corr: 0.02459
Epoch [14/100], Batch [120/147] train loss: 7305.57, train corr: 0.02356
Epoch [14/100], Batch [121/147] train loss: 6359.85, train corr: 0.02439
Epoch [14/100], Batch [122/147] train loss: 5021.03, train corr: 0.02098
Epoch [14/100], Batch [123/147] train loss: 3797.80, train corr: 0.01709
Epoch [14/100], Batch [124/147] train loss: 2800.49, train corr: 0.00219
Epoch [14/100], Batch [125/147] train loss: 5329.46, train corr: -0.01483
Epoch [14/100], Batch [126/147] train loss: 1958.96, train corr: -0.00189
Epoch [14/100], Batch [127/147] train loss: 2262.93, train corr: 0.01669
Epoch [14/100], Batch [128/147] train loss: 2796.32, train corr: 0.01750
Epoch [14/100], Batch [129/147] train loss: 2943.13, train corr: 0.01939
Epoch [14/100], Batch [130/147] train loss: 2669.50, train corr: 0.01539
Epoch [14/100], Batch [131/147] train loss: 2117.91, train corr: 0.01944
Epoch [14/100], Batch [132/147] train loss: 3099.47, train corr: 0.01831
Epoch [14/100], Batch [133/147] train loss: 2481.87, train corr: 0.01759
Epoch [14/100], Batch [134/147] train loss: 2059.21, train corr: 0.02563
Epoch [14/100], Batch [135/147] train loss: 2361.97, train corr: 0.02580
Epoch [14/100], Batch [136/147] train loss: 2300.63, train corr: 0.03099
Epoch [14/100], Batch [137/147] train loss: 1793.75, train corr: 0.02997
Epoch [14/100], Batch [138/147] train loss: 1590.71, train corr: 0.01208
Epoch [14/100], Batch [139/147] train loss: 3295.45, train corr: 0.00521
Epoch [14/100], Batch [140/147] train loss: 3201.53, train corr: 0.03406
Epoch [14/100], Batch [141/147] train loss: 4958.78, train corr: 0.02881
Epoch [14/100], Batch [142/147] train loss: 5797.08, train corr: 0.02905
Epoch [14/100], Batch [143/147] train loss: 6492.72, train corr: 0.02891
Epoch [14/100], Batch [144/147] train loss: 6664.83, train corr: 0.02780
Epoch [14/100], Batch [145/147] train loss: 6877.21, train corr: 0.02669
Epoch [14/100], Batch [146/147] train loss: 6116.54, train corr: 0.02764
Epoch [14/100], Batch [147/147] train loss: 5330.84, train corr: 0.02968
Epoch [14/100], validation loss: 5033.16, validation correlation: 0.02943
Epoch [15/100], Batch [1/147] train loss: 4837.61, train corr: 0.02353
Epoch [15/100], Batch [2/147] train loss: 3951.97, train corr: 0.02974
Epoch [15/100], Batch [3/147] train loss: 3419.48, train corr: 0.03063
Epoch [15/100], Batch [4/147] train loss: 3798.14, train corr: 0.03102
Epoch [15/100], Batch [5/147] train loss: 2999.46, train corr: 0.03328
Epoch [15/100], Batch [6/147] train loss: 1831.25, train corr: 0.03248
Epoch [15/100], Batch [7/147] train loss: 1935.80, train corr: 0.02827
Epoch [15/100], Batch [8/147] train loss: 1739.64, train corr: 0.01404
Epoch [15/100], Batch [9/147] train loss: 1550.31, train corr: -0.01279
Epoch [15/100], Batch [10/147] train loss: 2951.24, train corr: -0.02241
Epoch [15/100], Batch [11/147] train loss: 2695.15, train corr: -0.00476
Epoch [15/100], Batch [12/147] train loss: 3878.55, train corr: 0.01100
Epoch [15/100], Batch [13/147] train loss: 4657.61, train corr: 0.01039
Epoch [15/100], Batch [14/147] train loss: 5054.40, train corr: 0.00835
Epoch [15/100], Batch [15/147] train loss: 5005.83, train corr: 0.00901
Epoch [15/100], Batch [16/147] train loss: 4965.12, train corr: 0.00559
Epoch [15/100], Batch [17/147] train loss: 4312.68, train corr: 0.00426
Epoch [15/100], Batch [18/147] train loss: 3615.74, train corr: -0.00475
Epoch [15/100], Batch [19/147] train loss: 2844.45, train corr: -0.00705
Epoch [15/100], Batch [20/147] train loss: 5058.86, train corr: -0.02330
Epoch [15/100], Batch [21/147] train loss: 3948.95, train corr: -0.02129
Epoch [15/100], Batch [22/147] train loss: 1919.57, train corr: -0.03143
Epoch [15/100], Batch [23/147] train loss: 2156.40, train corr: -0.03006
Epoch [15/100], Batch [24/147] train loss: 2577.24, train corr: -0.02209
Epoch [15/100], Batch [25/147] train loss: 2465.33, train corr: -0.02096
Epoch [15/100], Batch [26/147] train loss: 3035.46, train corr: -0.01390
Epoch [15/100], Batch [27/147] train loss: 2913.71, train corr: -0.00703
Epoch [15/100], Batch [28/147] train loss: 2594.42, train corr: -0.00813
Epoch [15/100], Batch [29/147] train loss: 2768.21, train corr: -0.00871
Epoch [15/100], Batch [30/147] train loss: 2540.71, train corr: 0.00266
Epoch [15/100], Batch [31/147] train loss: 2775.19, train corr: 0.00855
Epoch [15/100], Batch [32/147] train loss: 2495.52, train corr: 0.00871
Epoch [15/100], Batch [33/147] train loss: 2114.94, train corr: 0.01129
Epoch [15/100], Batch [34/147] train loss: 1664.51, train corr: 0.00926
Epoch [15/100], Batch [35/147] train loss: 2602.85, train corr: 0.01087
Epoch [15/100], Batch [36/147] train loss: 2911.69, train corr: 0.02842
Epoch [15/100], Batch [37/147] train loss: 3624.72, train corr: 0.03257
Epoch [15/100], Batch [38/147] train loss: 4252.07, train corr: 0.03280
Epoch [15/100], Batch [39/147] train loss: 4560.73, train corr: 0.03260
Epoch [15/100], Batch [40/147] train loss: 4500.96, train corr: 0.03291
Epoch [15/100], Batch [41/147] train loss: 4069.15, train corr: 0.03333
Epoch [15/100], Batch [42/147] train loss: 3171.09, train corr: 0.03427
Epoch [15/100], Batch [43/147] train loss: 2735.74, train corr: 0.03493
Epoch [15/100], Batch [44/147] train loss: 2916.26, train corr: 0.03385
Epoch [15/100], Batch [45/147] train loss: 3306.88, train corr: 0.03361
Epoch [15/100], Batch [46/147] train loss: 1760.21, train corr: 0.03316
Epoch [15/100], Batch [47/147] train loss: 1850.71, train corr: 0.02963
Epoch [15/100], Batch [48/147] train loss: 1734.79, train corr: 0.02039
Epoch [15/100], Batch [49/147] train loss: 1411.29, train corr: -0.00102
Epoch [15/100], Batch [50/147] train loss: 3923.54, train corr: -0.01050
Epoch [15/100], Batch [51/147] train loss: 2949.48, train corr: 0.01808
Epoch [15/100], Batch [52/147] train loss: 4373.01, train corr: 0.02529
Epoch [15/100], Batch [53/147] train loss: 5745.25, train corr: 0.02226
Epoch [15/100], Batch [54/147] train loss: 6119.95, train corr: 0.02455
Epoch [15/100], Batch [55/147] train loss: 6496.28, train corr: 0.02079
Epoch [15/100], Batch [56/147] train loss: 6540.55, train corr: 0.02352
Epoch [15/100], Batch [57/147] train loss: 6425.33, train corr: 0.01905
Epoch [15/100], Batch [58/147] train loss: 5672.42, train corr: 0.02223
Epoch [15/100], Batch [59/147] train loss: 5087.11, train corr: 0.02208
Epoch [15/100], Batch [60/147] train loss: 4459.18, train corr: 0.02125
Epoch [15/100], Batch [61/147] train loss: 3766.91, train corr: 0.01835
Epoch [15/100], Batch [62/147] train loss: 2938.08, train corr: 0.01712
Epoch [15/100], Batch [63/147] train loss: 2022.94, train corr: 0.01499
Epoch [15/100], Batch [64/147] train loss: 3206.29, train corr: -0.01527
Epoch [15/100], Batch [65/147] train loss: 1320.27, train corr: 0.02919
Epoch [15/100], Batch [66/147] train loss: 1844.24, train corr: 0.03253
Epoch [15/100], Batch [67/147] train loss: 1897.60, train corr: 0.03351
Epoch [15/100], Batch [68/147] train loss: 1765.88, train corr: 0.03404
Epoch [15/100], Batch [69/147] train loss: 1472.07, train corr: 0.02815
Epoch [15/100], Batch [70/147] train loss: 2580.88, train corr: 0.02009
Epoch [15/100], Batch [71/147] train loss: 1690.39, train corr: 0.03126
Epoch [15/100], Batch [72/147] train loss: 2324.01, train corr: 0.03222
Epoch [15/100], Batch [73/147] train loss: 2399.17, train corr: 0.03265
Epoch [15/100], Batch [74/147] train loss: 2322.85, train corr: 0.03153
Epoch [15/100], Batch [75/147] train loss: 2124.37, train corr: 0.02850
Epoch [15/100], Batch [76/147] train loss: 1573.55, train corr: 0.02116
Epoch [15/100], Batch [77/147] train loss: 1760.51, train corr: -0.00710
Epoch [15/100], Batch [78/147] train loss: 1774.43, train corr: 0.02704
Epoch [15/100], Batch [79/147] train loss: 2421.51, train corr: 0.02441
Epoch [15/100], Batch [80/147] train loss: 2655.50, train corr: 0.02561
Epoch [15/100], Batch [81/147] train loss: 2804.97, train corr: 0.02278
Epoch [15/100], Batch [82/147] train loss: 2269.83, train corr: 0.02174
Epoch [15/100], Batch [83/147] train loss: 1787.86, train corr: 0.02852
Epoch [15/100], Batch [84/147] train loss: 1575.66, train corr: 0.02383
Epoch [15/100], Batch [85/147] train loss: 1379.50, train corr: 0.02766
Epoch [15/100], Batch [86/147] train loss: 1397.07, train corr: 0.02751
Epoch [15/100], Batch [87/147] train loss: 1232.95, train corr: 0.02799
Epoch [15/100], Batch [88/147] train loss: 1003.32, train corr: 0.02962
Epoch [15/100], Batch [89/147] train loss: 1249.17, train corr: 0.01144
Epoch [15/100], Batch [90/147] train loss: 1368.37, train corr: 0.02471
Epoch [15/100], Batch [91/147] train loss: 1820.08, train corr: 0.01661
Epoch [15/100], Batch [92/147] train loss: 1909.01, train corr: 0.02143
Epoch [15/100], Batch [93/147] train loss: 1770.56, train corr: 0.01493
Epoch [15/100], Batch [94/147] train loss: 1282.92, train corr: -0.01813
Epoch [15/100], Batch [95/147] train loss: 1735.54, train corr: -0.02865
Epoch [15/100], Batch [96/147] train loss: 1403.57, train corr: 0.00734
Epoch [15/100], Batch [97/147] train loss: 1596.58, train corr: 0.01789
Epoch [15/100], Batch [98/147] train loss: 1705.16, train corr: 0.02238
Epoch [15/100], Batch [99/147] train loss: 1423.04, train corr: 0.02127
Epoch [15/100], Batch [100/147] train loss: 1250.46, train corr: 0.01900
Epoch [15/100], Batch [101/147] train loss: 1792.33, train corr: 0.01604
Epoch [15/100], Batch [102/147] train loss: 1075.48, train corr: 0.01976
Epoch [15/100], Batch [103/147] train loss: 1229.97, train corr: 0.00936
Epoch [15/100], Batch [104/147] train loss: 1051.44, train corr: -0.00328
Epoch [15/100], Batch [105/147] train loss: 1124.71, train corr: -0.03215
Epoch [15/100], Batch [106/147] train loss: 1287.25, train corr: 0.00124
Epoch [15/100], Batch [107/147] train loss: 1551.25, train corr: 0.00649
Epoch [15/100], Batch [108/147] train loss: 1523.69, train corr: 0.01023
Epoch [15/100], Batch [109/147] train loss: 1278.53, train corr: 0.01253
Epoch [15/100], Batch [110/147] train loss: 1136.41, train corr: 0.00358
Epoch [15/100], Batch [111/147] train loss: 1868.19, train corr: -0.00074
Epoch [15/100], Batch [112/147] train loss: 1551.27, train corr: 0.01495
Epoch [15/100], Batch [113/147] train loss: 2162.39, train corr: 0.01720
Epoch [15/100], Batch [114/147] train loss: 2441.42, train corr: 0.01889
Epoch [15/100], Batch [115/147] train loss: 2530.82, train corr: 0.02116
Epoch [15/100], Batch [116/147] train loss: 4057.54, train corr: 0.01753
Epoch [15/100], Batch [117/147] train loss: 1228.82, train corr: -0.01579
Epoch [15/100], Batch [118/147] train loss: 6001.05, train corr: -0.01851
Epoch [15/100], Batch [119/147] train loss: 1802.09, train corr: 0.02199
Epoch [15/100], Batch [120/147] train loss: 3003.74, train corr: 0.02685
Epoch [15/100], Batch [121/147] train loss: 4128.38, train corr: 0.01760
Epoch [15/100], Batch [122/147] train loss: 4083.34, train corr: 0.02348
Epoch [15/100], Batch [123/147] train loss: 10151.37, train corr: 0.02058
Epoch [15/100], Batch [124/147] train loss: 3838.76, train corr: 0.02443
Epoch [15/100], Batch [125/147] train loss: 3261.90, train corr: 0.02493
Epoch [15/100], Batch [126/147] train loss: 2598.77, train corr: 0.02347
Epoch [15/100], Batch [127/147] train loss: 2035.94, train corr: 0.02804
Epoch [15/100], Batch [128/147] train loss: 2648.40, train corr: 0.02945
Epoch [15/100], Batch [129/147] train loss: 1958.10, train corr: 0.02898
Epoch [15/100], Batch [130/147] train loss: 1633.37, train corr: 0.02245
Epoch [15/100], Batch [131/147] train loss: 2112.88, train corr: 0.02018
Epoch [15/100], Batch [132/147] train loss: 2153.90, train corr: 0.01364
Epoch [15/100], Batch [133/147] train loss: 2103.75, train corr: -0.00100
Epoch [15/100], Batch [134/147] train loss: 1712.51, train corr: -0.01369
Epoch [15/100], Batch [135/147] train loss: 1728.83, train corr: -0.02652
Epoch [15/100], Batch [136/147] train loss: 1937.95, train corr: -0.01047
Epoch [15/100], Batch [137/147] train loss: 2508.55, train corr: -0.00381
Epoch [15/100], Batch [138/147] train loss: 2608.18, train corr: 0.00026
Epoch [15/100], Batch [139/147] train loss: 2589.01, train corr: 0.00201
Epoch [15/100], Batch [140/147] train loss: 2263.18, train corr: -0.00063
Epoch [15/100], Batch [141/147] train loss: 1815.46, train corr: -0.00541
Epoch [15/100], Batch [142/147] train loss: 1391.56, train corr: -0.01260
Epoch [15/100], Batch [143/147] train loss: 1737.65, train corr: -0.01607
Epoch [15/100], Batch [144/147] train loss: 1838.79, train corr: -0.00918
Epoch [15/100], Batch [145/147] train loss: 2363.84, train corr: -0.00294
Epoch [15/100], Batch [146/147] train loss: 2640.84, train corr: -0.00394
Epoch [15/100], Batch [147/147] train loss: 2872.62, train corr: -0.01697
Epoch [15/100], validation loss: 2748.84, validation correlation: -0.01854
Epoch [16/100], Batch [1/147] train loss: 2574.71, train corr: -0.01650
Epoch [16/100], Batch [2/147] train loss: 2049.60, train corr: -0.02985
Epoch [16/100], Batch [3/147] train loss: 1673.92, train corr: -0.03492
Epoch [16/100], Batch [4/147] train loss: 4313.95, train corr: -0.03039
Epoch [16/100], Batch [5/147] train loss: 1934.68, train corr: -0.03091
Epoch [16/100], Batch [6/147] train loss: 2571.50, train corr: -0.00054
Epoch [16/100], Batch [7/147] train loss: 3054.11, train corr: 0.01061
Epoch [16/100], Batch [8/147] train loss: 3171.96, train corr: 0.01544
Epoch [16/100], Batch [9/147] train loss: 2936.03, train corr: 0.01926
Epoch [16/100], Batch [10/147] train loss: 2549.97, train corr: 0.01764
Epoch [16/100], Batch [11/147] train loss: 2023.33, train corr: 0.02001
Epoch [16/100], Batch [12/147] train loss: 1578.14, train corr: 0.01838
Epoch [16/100], Batch [13/147] train loss: 2345.43, train corr: 0.01159
Epoch [16/100], Batch [14/147] train loss: 1384.05, train corr: 0.01662
Epoch [16/100], Batch [15/147] train loss: 1397.06, train corr: 0.01726
Epoch [16/100], Batch [16/147] train loss: 1611.79, train corr: 0.02030
Epoch [16/100], Batch [17/147] train loss: 1467.61, train corr: 0.01372
Epoch [16/100], Batch [18/147] train loss: 1235.79, train corr: -0.02826
Epoch [16/100], Batch [19/147] train loss: 2158.03, train corr: -0.03107
Epoch [16/100], Batch [20/147] train loss: 1647.94, train corr: 0.01185
Epoch [16/100], Batch [21/147] train loss: 2320.25, train corr: 0.02212
Epoch [16/100], Batch [22/147] train loss: 2494.22, train corr: 0.02360
Epoch [16/100], Batch [23/147] train loss: 2575.87, train corr: 0.02282
Epoch [16/100], Batch [24/147] train loss: 2162.39, train corr: 0.02384
Epoch [16/100], Batch [25/147] train loss: 1831.57, train corr: 0.02160
Epoch [16/100], Batch [26/147] train loss: 1348.78, train corr: 0.02337
Epoch [16/100], Batch [27/147] train loss: 3487.24, train corr: 0.02462
Epoch [16/100], Batch [28/147] train loss: 1492.99, train corr: 0.02579
Epoch [16/100], Batch [29/147] train loss: 2198.25, train corr: 0.02320
Epoch [16/100], Batch [30/147] train loss: 2622.35, train corr: 0.02143
Epoch [16/100], Batch [31/147] train loss: 2849.01, train corr: 0.01272
Epoch [16/100], Batch [32/147] train loss: 2699.84, train corr: 0.01179
Epoch [16/100], Batch [33/147] train loss: 2279.30, train corr: 0.00105
Epoch [16/100], Batch [34/147] train loss: 1760.70, train corr: -0.02125
Epoch [16/100], Batch [35/147] train loss: 1783.43, train corr: -0.02726
Epoch [16/100], Batch [36/147] train loss: 1337.20, train corr: -0.02794
Epoch [16/100], Batch [37/147] train loss: 2737.76, train corr: -0.01786
Epoch [16/100], Batch [38/147] train loss: 1223.36, train corr: -0.02697
Epoch [16/100], Batch [39/147] train loss: 1354.41, train corr: -0.02556
Epoch [16/100], Batch [40/147] train loss: 1207.37, train corr: -0.01180
Epoch [16/100], Batch [41/147] train loss: 1285.82, train corr: 0.00722
Epoch [16/100], Batch [42/147] train loss: 1185.60, train corr: 0.01446
Epoch [16/100], Batch [43/147] train loss: 1038.69, train corr: 0.01301
Epoch [16/100], Batch [44/147] train loss: 1368.89, train corr: 0.01755
Epoch [16/100], Batch [45/147] train loss: 1218.79, train corr: 0.02382
Epoch [16/100], Batch [46/147] train loss: 1514.76, train corr: 0.02346
Epoch [16/100], Batch [47/147] train loss: 1687.62, train corr: 0.02381
Epoch [16/100], Batch [48/147] train loss: 1512.87, train corr: 0.02110
Epoch [16/100], Batch [49/147] train loss: 1133.16, train corr: 0.02437
Epoch [16/100], Batch [50/147] train loss: 1218.08, train corr: 0.01898
Epoch [16/100], Batch [51/147] train loss: 1451.00, train corr: -0.00294
Epoch [16/100], Batch [52/147] train loss: 1762.61, train corr: 0.01757
Epoch [16/100], Batch [53/147] train loss: 2616.34, train corr: 0.01246
Epoch [16/100], Batch [54/147] train loss: 3065.99, train corr: 0.01551
Epoch [16/100], Batch [55/147] train loss: 3231.70, train corr: 0.01768
Epoch [16/100], Batch [56/147] train loss: 3159.46, train corr: 0.01913
Epoch [16/100], Batch [57/147] train loss: 2757.69, train corr: 0.01325
Epoch [16/100], Batch [58/147] train loss: 2412.82, train corr: 0.00665
Epoch [16/100], Batch [59/147] train loss: 1826.70, train corr: -0.00463
Epoch [16/100], Batch [60/147] train loss: 1160.19, train corr: -0.02675
Epoch [16/100], Batch [61/147] train loss: 8869.17, train corr: -0.02565
Epoch [16/100], Batch [62/147] train loss: 3521.52, train corr: 0.01615
Epoch [16/100], Batch [63/147] train loss: 6315.14, train corr: 0.01877
Epoch [16/100], Batch [64/147] train loss: 8286.22, train corr: 0.02292
Epoch [16/100], Batch [65/147] train loss: 9575.97, train corr: 0.02464
Epoch [16/100], Batch [66/147] train loss: 11543.70, train corr: 0.02455
Epoch [16/100], Batch [67/147] train loss: 12006.39, train corr: 0.02339
Epoch [16/100], Batch [68/147] train loss: 12717.92, train corr: 0.01792
Epoch [16/100], Batch [69/147] train loss: 13825.57, train corr: 0.01647
Epoch [16/100], Batch [70/147] train loss: 13426.49, train corr: 0.01865
Epoch [16/100], Batch [71/147] train loss: 12948.70, train corr: 0.02510
Epoch [16/100], Batch [72/147] train loss: 29792.82, train corr: 0.02140
Epoch [16/100], Batch [73/147] train loss: 15931.48, train corr: 0.02155
Epoch [16/100], Batch [74/147] train loss: 11329.66, train corr: 0.02118
Epoch [16/100], Batch [75/147] train loss: 10151.23, train corr: 0.02571
Epoch [16/100], Batch [76/147] train loss: 8941.91, train corr: 0.01952
Epoch [16/100], Batch [77/147] train loss: 7456.73, train corr: 0.02962
Epoch [16/100], Batch [78/147] train loss: 5871.75, train corr: 0.02476
Epoch [16/100], Batch [79/147] train loss: 4689.21, train corr: 0.02520
Epoch [16/100], Batch [80/147] train loss: 3924.78, train corr: 0.02443
Epoch [16/100], Batch [81/147] train loss: 5142.63, train corr: 0.02569
Epoch [16/100], Batch [82/147] train loss: 5250.41, train corr: 0.02412
Epoch [16/100], Batch [83/147] train loss: 2304.37, train corr: 0.02728
Epoch [16/100], Batch [84/147] train loss: 1966.89, train corr: 0.02723
Epoch [16/100], Batch [85/147] train loss: 2275.22, train corr: 0.02066
Epoch [16/100], Batch [86/147] train loss: 2368.20, train corr: 0.01112
Epoch [16/100], Batch [87/147] train loss: 2332.21, train corr: -0.01601
Epoch [16/100], Batch [88/147] train loss: 2106.07, train corr: -0.02577
Epoch [16/100], Batch [89/147] train loss: 2891.76, train corr: -0.02974
Epoch [16/100], Batch [90/147] train loss: 2412.35, train corr: -0.02411
Epoch [16/100], Batch [91/147] train loss: 2678.18, train corr: -0.02282
Epoch [16/100], Batch [92/147] train loss: 2774.04, train corr: -0.02211
Epoch [16/100], Batch [93/147] train loss: 2875.01, train corr: -0.02276
Epoch [16/100], Batch [94/147] train loss: 2533.75, train corr: -0.02444
Epoch [16/100], Batch [95/147] train loss: 2113.21, train corr: -0.02524
Epoch [16/100], Batch [96/147] train loss: 3280.90, train corr: -0.02870
Epoch [16/100], Batch [97/147] train loss: 2206.47, train corr: -0.02306
Epoch [16/100], Batch [98/147] train loss: 2788.61, train corr: -0.01841
Epoch [16/100], Batch [99/147] train loss: 2957.90, train corr: -0.01276
Epoch [16/100], Batch [100/147] train loss: 2865.62, train corr: -0.00906
Epoch [16/100], Batch [101/147] train loss: 2679.54, train corr: -0.01271
Epoch [16/100], Batch [102/147] train loss: 2158.23, train corr: -0.01255
Epoch [16/100], Batch [103/147] train loss: 1615.09, train corr: -0.01686
Epoch [16/100], Batch [104/147] train loss: 2375.82, train corr: -0.01834
Epoch [16/100], Batch [105/147] train loss: 1342.21, train corr: -0.01855
Epoch [16/100], Batch [106/147] train loss: 1513.72, train corr: -0.01315
Epoch [16/100], Batch [107/147] train loss: 1666.78, train corr: -0.01598
Epoch [16/100], Batch [108/147] train loss: 1514.26, train corr: -0.01614
Epoch [16/100], Batch [109/147] train loss: 1493.63, train corr: -0.02228
Epoch [16/100], Batch [110/147] train loss: 1455.94, train corr: -0.02601
Epoch [16/100], Batch [111/147] train loss: 1258.09, train corr: -0.02726
Epoch [16/100], Batch [112/147] train loss: 1189.33, train corr: -0.02792
Epoch [16/100], Batch [113/147] train loss: 1376.53, train corr: -0.03223
Epoch [16/100], Batch [114/147] train loss: 1241.83, train corr: -0.03139
Epoch [16/100], Batch [115/147] train loss: 1242.63, train corr: -0.03190
Epoch [16/100], Batch [116/147] train loss: 1149.03, train corr: -0.03328
Epoch [16/100], Batch [117/147] train loss: 1073.56, train corr: -0.03291
Epoch [16/100], Batch [118/147] train loss: 1032.83, train corr: -0.03408
Epoch [16/100], Batch [119/147] train loss: 975.16, train corr: -0.03357
Epoch [16/100], Batch [120/147] train loss: 949.02, train corr: -0.03210
Epoch [16/100], Batch [121/147] train loss: 864.26, train corr: -0.02989
Epoch [16/100], Batch [122/147] train loss: 875.53, train corr: -0.03225
Epoch [16/100], Batch [123/147] train loss: 1217.19, train corr: 0.02216
Epoch [16/100], Batch [124/147] train loss: 1577.69, train corr: 0.02259
Epoch [16/100], Batch [125/147] train loss: 1668.05, train corr: 0.02633
Epoch [16/100], Batch [126/147] train loss: 1534.13, train corr: 0.02541
Epoch [16/100], Batch [127/147] train loss: 1434.73, train corr: 0.02622
Epoch [16/100], Batch [128/147] train loss: 1716.60, train corr: 0.02753
Epoch [16/100], Batch [129/147] train loss: 1294.58, train corr: 0.02362
Epoch [16/100], Batch [130/147] train loss: 1407.98, train corr: 0.02186
Epoch [16/100], Batch [131/147] train loss: 1282.61, train corr: 0.01998
Epoch [16/100], Batch [132/147] train loss: 1086.24, train corr: 0.01426
Epoch [16/100], Batch [133/147] train loss: 1215.02, train corr: 0.00262
Epoch [16/100], Batch [134/147] train loss: 892.07, train corr: -0.00694
Epoch [16/100], Batch [135/147] train loss: 834.86, train corr: -0.01980
Epoch [16/100], Batch [136/147] train loss: 1635.86, train corr: -0.03120
Epoch [16/100], Batch [137/147] train loss: 1944.03, train corr: 0.01147
Epoch [16/100], Batch [138/147] train loss: 3421.74, train corr: 0.02037
Epoch [16/100], Batch [139/147] train loss: 3621.25, train corr: 0.01952
Epoch [16/100], Batch [140/147] train loss: 3856.42, train corr: 0.02074
Epoch [16/100], Batch [141/147] train loss: 4066.82, train corr: 0.02046
Epoch [16/100], Batch [142/147] train loss: 3891.59, train corr: 0.02335
Epoch [16/100], Batch [143/147] train loss: 3562.28, train corr: 0.02153
Epoch [16/100], Batch [144/147] train loss: 3203.95, train corr: 0.01965
Epoch [16/100], Batch [145/147] train loss: 2539.68, train corr: 0.02277
Epoch [16/100], Batch [146/147] train loss: 1913.78, train corr: 0.02280
Epoch [16/100], Batch [147/147] train loss: 2395.20, train corr: 0.02363
Epoch [16/100], validation loss: 2707.54, validation correlation: 0.02190
Epoch [17/100], Batch [1/147] train loss: 2616.07, train corr: 0.02080
Epoch [17/100], Batch [2/147] train loss: 1195.03, train corr: 0.02088
Epoch [17/100], Batch [3/147] train loss: 1427.61, train corr: 0.01897
Epoch [17/100], Batch [4/147] train loss: 1248.27, train corr: 0.02040
Epoch [17/100], Batch [5/147] train loss: 981.67, train corr: -0.01410
Epoch [17/100], Batch [6/147] train loss: 2715.66, train corr: -0.02236
Epoch [17/100], Batch [7/147] train loss: 1602.53, train corr: 0.01862
Epoch [17/100], Batch [8/147] train loss: 2432.24, train corr: 0.02108
Epoch [17/100], Batch [9/147] train loss: 2975.01, train corr: 0.02129
Epoch [17/100], Batch [10/147] train loss: 3120.99, train corr: 0.02300
Epoch [17/100], Batch [11/147] train loss: 3083.30, train corr: 0.02414
Epoch [17/100], Batch [12/147] train loss: 2808.51, train corr: 0.02573
Epoch [17/100], Batch [13/147] train loss: 2573.47, train corr: 0.01990
Epoch [17/100], Batch [14/147] train loss: 1994.11, train corr: 0.02942
Epoch [17/100], Batch [15/147] train loss: 2001.84, train corr: 0.02548
Epoch [17/100], Batch [16/147] train loss: 1902.01, train corr: 0.00898
Epoch [17/100], Batch [17/147] train loss: 993.98, train corr: 0.02807
Epoch [17/100], Batch [18/147] train loss: 1279.02, train corr: 0.03193
Epoch [17/100], Batch [19/147] train loss: 1338.11, train corr: 0.03113
Epoch [17/100], Batch [20/147] train loss: 1209.25, train corr: 0.03482
Epoch [17/100], Batch [21/147] train loss: 1333.59, train corr: 0.03008
Epoch [17/100], Batch [22/147] train loss: 1058.23, train corr: 0.03404
Epoch [17/100], Batch [23/147] train loss: 1042.54, train corr: 0.03297
Epoch [17/100], Batch [24/147] train loss: 897.50, train corr: 0.01546
Epoch [17/100], Batch [25/147] train loss: 1938.39, train corr: -0.00956
Epoch [17/100], Batch [26/147] train loss: 1658.54, train corr: 0.02128
Epoch [17/100], Batch [27/147] train loss: 2367.90, train corr: 0.02510
Epoch [17/100], Batch [28/147] train loss: 2841.77, train corr: 0.02374
Epoch [17/100], Batch [29/147] train loss: 3018.24, train corr: 0.02429
Epoch [17/100], Batch [30/147] train loss: 3197.74, train corr: 0.02276
Epoch [17/100], Batch [31/147] train loss: 3172.55, train corr: 0.02137
Epoch [17/100], Batch [32/147] train loss: 3036.35, train corr: 0.02029
Epoch [17/100], Batch [33/147] train loss: 2385.89, train corr: 0.02465
Epoch [17/100], Batch [34/147] train loss: 1923.34, train corr: 0.02472
Epoch [17/100], Batch [35/147] train loss: 1575.56, train corr: 0.02546
Epoch [17/100], Batch [36/147] train loss: 2460.06, train corr: 0.02638
Epoch [17/100], Batch [37/147] train loss: 1232.57, train corr: 0.02374
Epoch [17/100], Batch [38/147] train loss: 1403.98, train corr: 0.02214
Epoch [17/100], Batch [39/147] train loss: 1604.53, train corr: 0.02064
Epoch [17/100], Batch [40/147] train loss: 1382.82, train corr: 0.02380
Epoch [17/100], Batch [41/147] train loss: 1194.31, train corr: -0.00075
Epoch [17/100], Batch [42/147] train loss: 3239.16, train corr: -0.02229
Epoch [17/100], Batch [43/147] train loss: 2643.50, train corr: 0.02228
Epoch [17/100], Batch [44/147] train loss: 4217.31, train corr: 0.02324
Epoch [17/100], Batch [45/147] train loss: 5390.19, train corr: 0.02247
Epoch [17/100], Batch [46/147] train loss: 6514.26, train corr: 0.01896
Epoch [17/100], Batch [47/147] train loss: 6972.35, train corr: 0.02330
Epoch [17/100], Batch [48/147] train loss: 6980.13, train corr: 0.02159
Epoch [17/100], Batch [49/147] train loss: 7277.70, train corr: 0.02528
Epoch [17/100], Batch [50/147] train loss: 7113.01, train corr: 0.02620
Epoch [17/100], Batch [51/147] train loss: 7432.96, train corr: 0.01430
Epoch [17/100], Batch [52/147] train loss: 6395.43, train corr: 0.02695
Epoch [17/100], Batch [53/147] train loss: 6150.49, train corr: 0.02621
Epoch [17/100], Batch [54/147] train loss: 5467.27, train corr: 0.02158
Epoch [17/100], Batch [55/147] train loss: 4926.12, train corr: 0.02550
Epoch [17/100], Batch [56/147] train loss: 3937.75, train corr: 0.02532
Epoch [17/100], Batch [57/147] train loss: 3288.82, train corr: 0.02654
Epoch [17/100], Batch [58/147] train loss: 2554.31, train corr: 0.02545
Epoch [17/100], Batch [59/147] train loss: 4479.19, train corr: 0.03020
Epoch [17/100], Batch [60/147] train loss: 2474.04, train corr: 0.02980
Epoch [17/100], Batch [61/147] train loss: 2298.60, train corr: 0.02787
Epoch [17/100], Batch [62/147] train loss: 2669.45, train corr: 0.02575
Epoch [17/100], Batch [63/147] train loss: 2775.57, train corr: 0.02309
Epoch [17/100], Batch [64/147] train loss: 2937.31, train corr: 0.02226
Epoch [17/100], Batch [65/147] train loss: 2669.38, train corr: 0.02088
Epoch [17/100], Batch [66/147] train loss: 2247.60, train corr: 0.01956
Epoch [17/100], Batch [67/147] train loss: 1805.26, train corr: 0.01597
Epoch [17/100], Batch [68/147] train loss: 1347.25, train corr: -0.00414
Epoch [17/100], Batch [69/147] train loss: 1864.24, train corr: -0.03351
Epoch [17/100], Batch [70/147] train loss: 1140.39, train corr: -0.02595
Epoch [17/100], Batch [71/147] train loss: 1303.31, train corr: -0.01056
Epoch [17/100], Batch [72/147] train loss: 1335.79, train corr: -0.00152
Epoch [17/100], Batch [73/147] train loss: 1357.67, train corr: -0.00721
Epoch [17/100], Batch [74/147] train loss: 1165.21, train corr: -0.01016
Epoch [17/100], Batch [75/147] train loss: 871.67, train corr: -0.02657
Epoch [17/100], Batch [76/147] train loss: 2443.52, train corr: -0.03250
Epoch [17/100], Batch [77/147] train loss: 1529.90, train corr: 0.01383
Epoch [17/100], Batch [78/147] train loss: 2546.14, train corr: 0.01574
Epoch [17/100], Batch [79/147] train loss: 3009.38, train corr: 0.02489
Epoch [17/100], Batch [80/147] train loss: 3385.06, train corr: 0.02264
Epoch [17/100], Batch [81/147] train loss: 3499.74, train corr: 0.02537
Epoch [17/100], Batch [82/147] train loss: 3430.13, train corr: 0.02485
Epoch [17/100], Batch [83/147] train loss: 3274.82, train corr: 0.02467
Epoch [17/100], Batch [84/147] train loss: 3125.81, train corr: 0.02268
Epoch [17/100], Batch [85/147] train loss: 2605.75, train corr: 0.02650
Epoch [17/100], Batch [86/147] train loss: 2031.24, train corr: 0.02603
Epoch [17/100], Batch [87/147] train loss: 1608.11, train corr: 0.02392
Epoch [17/100], Batch [88/147] train loss: 2119.01, train corr: 0.02271
Epoch [17/100], Batch [89/147] train loss: 1162.85, train corr: 0.02841
Epoch [17/100], Batch [90/147] train loss: 1235.79, train corr: 0.02917
Epoch [17/100], Batch [91/147] train loss: 1346.83, train corr: 0.02377
Epoch [17/100], Batch [92/147] train loss: 1169.32, train corr: 0.02684
Epoch [17/100], Batch [93/147] train loss: 1019.29, train corr: 0.02099
Epoch [17/100], Batch [94/147] train loss: 1090.68, train corr: -0.01538
Epoch [17/100], Batch [95/147] train loss: 1136.27, train corr: 0.01186
Epoch [17/100], Batch [96/147] train loss: 1395.17, train corr: 0.01571
Epoch [17/100], Batch [97/147] train loss: 1445.54, train corr: 0.01749
Epoch [17/100], Batch [98/147] train loss: 1425.19, train corr: 0.01073
Epoch [17/100], Batch [99/147] train loss: 1178.33, train corr: 0.00909
Epoch [17/100], Batch [100/147] train loss: 997.68, train corr: -0.02461
Epoch [17/100], Batch [101/147] train loss: 2357.34, train corr: -0.03123
Epoch [17/100], Batch [102/147] train loss: 1710.92, train corr: 0.01912
Epoch [17/100], Batch [103/147] train loss: 1954.77, train corr: 0.02290
Epoch [17/100], Batch [104/147] train loss: 2427.56, train corr: 0.02235
Epoch [17/100], Batch [105/147] train loss: 2690.51, train corr: 0.02127
Epoch [17/100], Batch [106/147] train loss: 2762.67, train corr: 0.01941
Epoch [17/100], Batch [107/147] train loss: 2539.00, train corr: 0.02524
Epoch [17/100], Batch [108/147] train loss: 2517.70, train corr: 0.02709
Epoch [17/100], Batch [109/147] train loss: 2093.17, train corr: 0.02627
Epoch [17/100], Batch [110/147] train loss: 2067.80, train corr: 0.02195
Epoch [17/100], Batch [111/147] train loss: 2115.58, train corr: 0.02690
Epoch [17/100], Batch [112/147] train loss: 1619.80, train corr: 0.02499
Epoch [17/100], Batch [113/147] train loss: 1547.36, train corr: 0.02586
Epoch [17/100], Batch [114/147] train loss: 1540.52, train corr: 0.02744
Epoch [17/100], Batch [115/147] train loss: 1518.82, train corr: 0.02743
Epoch [17/100], Batch [116/147] train loss: 1830.44, train corr: 0.02287
Epoch [17/100], Batch [117/147] train loss: 1560.29, train corr: 0.02673
Epoch [17/100], Batch [118/147] train loss: 1649.35, train corr: 0.03167
Epoch [17/100], Batch [119/147] train loss: 1613.75, train corr: 0.02975
Epoch [17/100], Batch [120/147] train loss: 1341.27, train corr: 0.03145
Epoch [17/100], Batch [121/147] train loss: 1012.46, train corr: 0.02897
Epoch [17/100], Batch [122/147] train loss: 1487.76, train corr: 0.00586
Epoch [17/100], Batch [123/147] train loss: 1224.15, train corr: 0.02748
Epoch [17/100], Batch [124/147] train loss: 1676.45, train corr: 0.02532
Epoch [17/100], Batch [125/147] train loss: 1812.90, train corr: 0.02651
Epoch [17/100], Batch [126/147] train loss: 1945.68, train corr: 0.02303
Epoch [17/100], Batch [127/147] train loss: 1914.85, train corr: 0.02387
Epoch [17/100], Batch [128/147] train loss: 1747.35, train corr: 0.02119
Epoch [17/100], Batch [129/147] train loss: 1527.60, train corr: 0.00853
Epoch [17/100], Batch [130/147] train loss: 1205.54, train corr: -0.03041
Epoch [17/100], Batch [131/147] train loss: 1741.69, train corr: -0.02689
Epoch [17/100], Batch [132/147] train loss: 1153.15, train corr: -0.01391
Epoch [17/100], Batch [133/147] train loss: 1339.35, train corr: 0.01893
Epoch [17/100], Batch [134/147] train loss: 1541.50, train corr: 0.02153
Epoch [17/100], Batch [135/147] train loss: 1465.87, train corr: 0.02217
Epoch [17/100], Batch [136/147] train loss: 1464.94, train corr: 0.02380
Epoch [17/100], Batch [137/147] train loss: 1074.30, train corr: 0.02042
Epoch [17/100], Batch [138/147] train loss: 1349.35, train corr: 0.02085
Epoch [17/100], Batch [139/147] train loss: 1045.29, train corr: 0.02430
Epoch [17/100], Batch [140/147] train loss: 887.42, train corr: 0.02436
Epoch [17/100], Batch [141/147] train loss: 970.76, train corr: 0.01588
Epoch [17/100], Batch [142/147] train loss: 941.43, train corr: 0.00385
Epoch [17/100], Batch [143/147] train loss: 871.20, train corr: -0.01040
Epoch [17/100], Batch [144/147] train loss: 1689.56, train corr: -0.01718
Epoch [17/100], Batch [145/147] train loss: 1832.30, train corr: 0.01550
Epoch [17/100], Batch [146/147] train loss: 2848.22, train corr: 0.02011
Epoch [17/100], Batch [147/147] train loss: 4002.20, train corr: 0.01384
Epoch [17/100], validation loss: 4429.65, validation correlation: 0.02181
Epoch [18/100], Batch [1/147] train loss: 4058.47, train corr: 0.02167
Epoch [18/100], Batch [2/147] train loss: 6315.95, train corr: 0.01886
Epoch [18/100], Batch [3/147] train loss: 4484.86, train corr: 0.02023
Epoch [18/100], Batch [4/147] train loss: 4312.38, train corr: 0.02392
Epoch [18/100], Batch [5/147] train loss: 4009.94, train corr: 0.02460
Epoch [18/100], Batch [6/147] train loss: 3787.75, train corr: 0.02086
Epoch [18/100], Batch [7/147] train loss: 3490.37, train corr: 0.01996
Epoch [18/100], Batch [8/147] train loss: 3123.81, train corr: 0.01872
Epoch [18/100], Batch [9/147] train loss: 2541.70, train corr: 0.01907
Epoch [18/100], Batch [10/147] train loss: 1977.43, train corr: 0.02390
Epoch [18/100], Batch [11/147] train loss: 1947.79, train corr: 0.02219
Epoch [18/100], Batch [12/147] train loss: 2503.17, train corr: 0.01662
Epoch [18/100], Batch [13/147] train loss: 1407.02, train corr: 0.01858
Epoch [18/100], Batch [14/147] train loss: 1512.72, train corr: 0.01741
Epoch [18/100], Batch [15/147] train loss: 1546.34, train corr: 0.01777
Epoch [18/100], Batch [16/147] train loss: 1503.75, train corr: 0.01420
Epoch [18/100], Batch [17/147] train loss: 1290.66, train corr: -0.00029
Epoch [18/100], Batch [18/147] train loss: 1095.19, train corr: -0.03425
Epoch [18/100], Batch [19/147] train loss: 2117.03, train corr: -0.02915
Epoch [18/100], Batch [20/147] train loss: 1369.80, train corr: -0.01256
Epoch [18/100], Batch [21/147] train loss: 1702.47, train corr: 0.01224
Epoch [18/100], Batch [22/147] train loss: 1960.17, train corr: 0.01477
Epoch [18/100], Batch [23/147] train loss: 4449.74, train corr: 0.01476
Epoch [18/100], Batch [24/147] train loss: 2034.05, train corr: 0.01291
Epoch [18/100], Batch [25/147] train loss: 1560.22, train corr: 0.01410
Epoch [18/100], Batch [26/147] train loss: 1339.42, train corr: 0.00751
Epoch [18/100], Batch [27/147] train loss: 1534.10, train corr: 0.00263
Epoch [18/100], Batch [28/147] train loss: 999.86, train corr: 0.00133
Epoch [18/100], Batch [29/147] train loss: 1043.77, train corr: -0.00536
Epoch [18/100], Batch [30/147] train loss: 955.73, train corr: -0.02637
Epoch [18/100], Batch [31/147] train loss: 1013.69, train corr: -0.03410
Epoch [18/100], Batch [32/147] train loss: 903.71, train corr: -0.03275
Epoch [18/100], Batch [33/147] train loss: 951.80, train corr: -0.02572
Epoch [18/100], Batch [34/147] train loss: 858.18, train corr: -0.02410
Epoch [18/100], Batch [35/147] train loss: 919.81, train corr: -0.02014
Epoch [18/100], Batch [36/147] train loss: 861.69, train corr: -0.00874
Epoch [18/100], Batch [37/147] train loss: 877.99, train corr: -0.00143
Epoch [18/100], Batch [38/147] train loss: 1040.16, train corr: -0.00259
Epoch [18/100], Batch [39/147] train loss: 883.26, train corr: -0.00059
Epoch [18/100], Batch [40/147] train loss: 828.27, train corr: 0.00078
Epoch [18/100], Batch [41/147] train loss: 878.58, train corr: -0.00348
Epoch [18/100], Batch [42/147] train loss: 801.69, train corr: -0.00825
Epoch [18/100], Batch [43/147] train loss: 783.43, train corr: -0.01516
Epoch [18/100], Batch [44/147] train loss: 799.79, train corr: -0.01266
Epoch [18/100], Batch [45/147] train loss: 781.70, train corr: -0.02110
Epoch [18/100], Batch [46/147] train loss: 867.44, train corr: -0.01385
Epoch [18/100], Batch [47/147] train loss: 874.33, train corr: -0.01331
Epoch [18/100], Batch [48/147] train loss: 719.98, train corr: -0.02323
Epoch [18/100], Batch [49/147] train loss: 1456.38, train corr: -0.02672
Epoch [18/100], Batch [50/147] train loss: 1674.87, train corr: 0.02336
Epoch [18/100], Batch [51/147] train loss: 2630.55, train corr: 0.02490
Epoch [18/100], Batch [52/147] train loss: 3318.04, train corr: 0.02186
Epoch [18/100], Batch [53/147] train loss: 3630.17, train corr: 0.02381
Epoch [18/100], Batch [54/147] train loss: 3963.30, train corr: 0.02422
Epoch [18/100], Batch [55/147] train loss: 4323.53, train corr: 0.01556
Epoch [18/100], Batch [56/147] train loss: 4032.17, train corr: 0.02320
Epoch [18/100], Batch [57/147] train loss: 3714.13, train corr: 0.02477
Epoch [18/100], Batch [58/147] train loss: 3618.51, train corr: 0.02709
Epoch [18/100], Batch [59/147] train loss: 3439.69, train corr: 0.02545
Epoch [18/100], Batch [60/147] train loss: 2865.68, train corr: 0.02802
Epoch [18/100], Batch [61/147] train loss: 2728.57, train corr: 0.01940
Epoch [18/100], Batch [62/147] train loss: 2309.98, train corr: 0.02669
Epoch [18/100], Batch [63/147] train loss: 2763.52, train corr: 0.02642
Epoch [18/100], Batch [64/147] train loss: 1827.49, train corr: 0.02682
Epoch [18/100], Batch [65/147] train loss: 1958.73, train corr: 0.02756
Epoch [18/100], Batch [66/147] train loss: 2056.92, train corr: 0.02600
Epoch [18/100], Batch [67/147] train loss: 1998.05, train corr: 0.02658
Epoch [18/100], Batch [68/147] train loss: 1854.37, train corr: 0.02464
Epoch [18/100], Batch [69/147] train loss: 1544.31, train corr: 0.02817
Epoch [18/100], Batch [70/147] train loss: 2118.50, train corr: 0.02222
Epoch [18/100], Batch [71/147] train loss: 1227.75, train corr: 0.02391
Epoch [18/100], Batch [72/147] train loss: 1202.52, train corr: 0.02447
Epoch [18/100], Batch [73/147] train loss: 1108.24, train corr: 0.02572
Epoch [18/100], Batch [74/147] train loss: 873.07, train corr: 0.01881
Epoch [18/100], Batch [75/147] train loss: 1405.62, train corr: -0.02649
Epoch [18/100], Batch [76/147] train loss: 1085.43, train corr: 0.01646
Epoch [18/100], Batch [77/147] train loss: 1383.66, train corr: 0.02153
Epoch [18/100], Batch [78/147] train loss: 1605.75, train corr: 0.02171
Epoch [18/100], Batch [79/147] train loss: 1648.98, train corr: 0.02163
Epoch [18/100], Batch [80/147] train loss: 1462.74, train corr: 0.02069
Epoch [18/100], Batch [81/147] train loss: 1294.46, train corr: 0.01785
Epoch [18/100], Batch [82/147] train loss: 1053.99, train corr: 0.01582
Epoch [18/100], Batch [83/147] train loss: 923.74, train corr: 0.00586
Epoch [18/100], Batch [84/147] train loss: 880.71, train corr: -0.00390
Epoch [18/100], Batch [85/147] train loss: 936.23, train corr: 0.01002
Epoch [18/100], Batch [86/147] train loss: 1127.83, train corr: 0.01563
Epoch [18/100], Batch [87/147] train loss: 1219.09, train corr: 0.01360
Epoch [18/100], Batch [88/147] train loss: 1148.28, train corr: 0.00285
Epoch [18/100], Batch [89/147] train loss: 974.87, train corr: -0.01221
Epoch [18/100], Batch [90/147] train loss: 1215.04, train corr: -0.03200
Epoch [18/100], Batch [91/147] train loss: 1288.09, train corr: 0.01634
Epoch [18/100], Batch [92/147] train loss: 1763.83, train corr: 0.02106
Epoch [18/100], Batch [93/147] train loss: 2061.80, train corr: 0.02474
Epoch [18/100], Batch [94/147] train loss: 2192.06, train corr: 0.02496
Epoch [18/100], Batch [95/147] train loss: 2144.09, train corr: 0.02288
Epoch [18/100], Batch [96/147] train loss: 2122.05, train corr: 0.02234
Epoch [18/100], Batch [97/147] train loss: 1849.66, train corr: 0.02454
Epoch [18/100], Batch [98/147] train loss: 1472.98, train corr: 0.02420
Epoch [18/100], Batch [99/147] train loss: 1157.37, train corr: 0.02720
Epoch [18/100], Batch [100/147] train loss: 1917.21, train corr: 0.02261
Epoch [18/100], Batch [101/147] train loss: 1343.11, train corr: 0.02408
Epoch [18/100], Batch [102/147] train loss: 1661.51, train corr: 0.01908
Epoch [18/100], Batch [103/147] train loss: 1759.30, train corr: 0.02351
Epoch [18/100], Batch [104/147] train loss: 1793.15, train corr: 0.02156
Epoch [18/100], Batch [105/147] train loss: 1733.21, train corr: 0.01683
Epoch [18/100], Batch [106/147] train loss: 1448.07, train corr: 0.00842
Epoch [18/100], Batch [107/147] train loss: 1163.38, train corr: 0.00038
Epoch [18/100], Batch [108/147] train loss: 991.17, train corr: -0.01858
Epoch [18/100], Batch [109/147] train loss: 3019.55, train corr: -0.02589
Epoch [18/100], Batch [110/147] train loss: 4009.44, train corr: 0.01453
Epoch [18/100], Batch [111/147] train loss: 2501.21, train corr: 0.02198
Epoch [18/100], Batch [112/147] train loss: 3091.04, train corr: 0.02190
Epoch [18/100], Batch [113/147] train loss: 3525.53, train corr: 0.02229
Epoch [18/100], Batch [114/147] train loss: 4037.92, train corr: 0.01943
Epoch [18/100], Batch [115/147] train loss: 3909.25, train corr: 0.02105
Epoch [18/100], Batch [116/147] train loss: 3983.14, train corr: 0.01609
Epoch [18/100], Batch [117/147] train loss: 3594.78, train corr: 0.02219
Epoch [18/100], Batch [118/147] train loss: 3368.43, train corr: 0.02097
Epoch [18/100], Batch [119/147] train loss: 3006.58, train corr: 0.02050
Epoch [18/100], Batch [120/147] train loss: 2712.15, train corr: 0.02157
Epoch [18/100], Batch [121/147] train loss: 2276.19, train corr: 0.01556
Epoch [18/100], Batch [122/147] train loss: 1681.51, train corr: 0.02094
Epoch [18/100], Batch [123/147] train loss: 1301.82, train corr: 0.01813
Epoch [18/100], Batch [124/147] train loss: 1703.82, train corr: 0.01788
Epoch [18/100], Batch [125/147] train loss: 1431.09, train corr: 0.01394
Epoch [18/100], Batch [126/147] train loss: 1130.88, train corr: 0.02241
Epoch [18/100], Batch [127/147] train loss: 1585.38, train corr: 0.02027
Epoch [18/100], Batch [128/147] train loss: 1802.21, train corr: 0.01723
Epoch [18/100], Batch [129/147] train loss: 1802.83, train corr: 0.02361
Epoch [18/100], Batch [130/147] train loss: 1799.34, train corr: 0.02234
Epoch [18/100], Batch [131/147] train loss: 1529.51, train corr: 0.01903
Epoch [18/100], Batch [132/147] train loss: 1478.40, train corr: 0.00424
Epoch [18/100], Batch [133/147] train loss: 1686.43, train corr: -0.02804
Epoch [18/100], Batch [134/147] train loss: 1591.15, train corr: 0.02402
Epoch [18/100], Batch [135/147] train loss: 2142.00, train corr: 0.02300
Epoch [18/100], Batch [136/147] train loss: 2449.26, train corr: 0.02337
Epoch [18/100], Batch [137/147] train loss: 2474.50, train corr: 0.02653
Epoch [18/100], Batch [138/147] train loss: 2859.35, train corr: 0.02331
Epoch [18/100], Batch [139/147] train loss: 2778.89, train corr: 0.02266
Epoch [18/100], Batch [140/147] train loss: 2477.83, train corr: 0.02395
Epoch [18/100], Batch [141/147] train loss: 2218.24, train corr: 0.02639
Epoch [18/100], Batch [142/147] train loss: 1966.99, train corr: 0.02295
Epoch [18/100], Batch [143/147] train loss: 1582.24, train corr: 0.03028
Epoch [18/100], Batch [144/147] train loss: 1864.80, train corr: 0.03068
Epoch [18/100], Batch [145/147] train loss: 1864.06, train corr: 0.02823
Epoch [18/100], Batch [146/147] train loss: 1295.04, train corr: 0.02832
Epoch [18/100], Batch [147/147] train loss: 1473.93, train corr: 0.02623
Epoch [18/100], validation loss: 1697.09, validation correlation: 0.02401
Epoch [19/100], Batch [1/147] train loss: 1586.48, train corr: 0.01825
Epoch [19/100], Batch [2/147] train loss: 1524.01, train corr: 0.01650
Epoch [19/100], Batch [3/147] train loss: 1326.26, train corr: 0.01532
Epoch [19/100], Batch [4/147] train loss: 1118.51, train corr: 0.00869
Epoch [19/100], Batch [5/147] train loss: 1183.55, train corr: -0.00869
Epoch [19/100], Batch [6/147] train loss: 1341.90, train corr: -0.01805
Epoch [19/100], Batch [7/147] train loss: 1107.35, train corr: -0.00640
Epoch [19/100], Batch [8/147] train loss: 1385.89, train corr: -0.00405
Epoch [19/100], Batch [9/147] train loss: 1566.62, train corr: -0.00560
Epoch [19/100], Batch [10/147] train loss: 1579.95, train corr: -0.00841
Epoch [19/100], Batch [11/147] train loss: 1492.97, train corr: -0.01055
Epoch [19/100], Batch [12/147] train loss: 1298.99, train corr: -0.02293
Epoch [19/100], Batch [13/147] train loss: 1053.40, train corr: -0.02920
Epoch [19/100], Batch [14/147] train loss: 1838.36, train corr: -0.03253
Epoch [19/100], Batch [15/147] train loss: 1229.54, train corr: -0.02151
Epoch [19/100], Batch [16/147] train loss: 1594.01, train corr: -0.00391
Epoch [19/100], Batch [17/147] train loss: 1781.30, train corr: 0.00629
Epoch [19/100], Batch [18/147] train loss: 1900.72, train corr: 0.00368
Epoch [19/100], Batch [19/147] train loss: 1790.11, train corr: 0.00839
Epoch [19/100], Batch [20/147] train loss: 1560.85, train corr: 0.00952
Epoch [19/100], Batch [21/147] train loss: 1312.00, train corr: 0.00255
Epoch [19/100], Batch [22/147] train loss: 1041.77, train corr: -0.00087
Epoch [19/100], Batch [23/147] train loss: 1146.49, train corr: -0.01953
Epoch [19/100], Batch [24/147] train loss: 1920.20, train corr: -0.02874
Epoch [19/100], Batch [25/147] train loss: 1406.01, train corr: 0.01886
Epoch [19/100], Batch [26/147] train loss: 2168.11, train corr: 0.02224
Epoch [19/100], Batch [27/147] train loss: 2682.81, train corr: 0.02411
Epoch [19/100], Batch [28/147] train loss: 3228.57, train corr: 0.01935
Epoch [19/100], Batch [29/147] train loss: 3424.68, train corr: 0.02588
Epoch [19/100], Batch [30/147] train loss: 3423.32, train corr: 0.02327
Epoch [19/100], Batch [31/147] train loss: 3439.99, train corr: 0.02299
Epoch [19/100], Batch [32/147] train loss: 3150.78, train corr: 0.02447
Epoch [19/100], Batch [33/147] train loss: 3105.71, train corr: 0.02324
Epoch [19/100], Batch [34/147] train loss: 2704.01, train corr: 0.02419
Epoch [19/100], Batch [35/147] train loss: 2255.42, train corr: 0.02779
Epoch [19/100], Batch [36/147] train loss: 4370.25, train corr: 0.02403
Epoch [19/100], Batch [37/147] train loss: 1249.99, train corr: 0.02545
Epoch [19/100], Batch [38/147] train loss: 2749.63, train corr: 0.02974
Epoch [19/100], Batch [39/147] train loss: 1040.74, train corr: 0.03010
Epoch [19/100], Batch [40/147] train loss: 959.78, train corr: 0.02887
Epoch [19/100], Batch [41/147] train loss: 1049.19, train corr: 0.02793
Epoch [19/100], Batch [42/147] train loss: 1022.74, train corr: 0.02263
Epoch [19/100], Batch [43/147] train loss: 936.61, train corr: -0.02338
Epoch [19/100], Batch [44/147] train loss: 1838.64, train corr: -0.02686
Epoch [19/100], Batch [45/147] train loss: 1763.31, train corr: 0.01431
Epoch [19/100], Batch [46/147] train loss: 2099.88, train corr: 0.02277
Epoch [19/100], Batch [47/147] train loss: 2454.64, train corr: 0.02302
Epoch [19/100], Batch [48/147] train loss: 3016.72, train corr: 0.01529
Epoch [19/100], Batch [49/147] train loss: 2808.12, train corr: 0.02496
Epoch [19/100], Batch [50/147] train loss: 2799.36, train corr: 0.02375
Epoch [19/100], Batch [51/147] train loss: 2790.54, train corr: 0.02393
Epoch [19/100], Batch [52/147] train loss: 2826.18, train corr: 0.02079
Epoch [19/100], Batch [53/147] train loss: 2415.96, train corr: 0.02252
Epoch [19/100], Batch [54/147] train loss: 2169.01, train corr: 0.02143
Epoch [19/100], Batch [55/147] train loss: 1800.34, train corr: 0.02045
Epoch [19/100], Batch [56/147] train loss: 1350.55, train corr: 0.02005
Epoch [19/100], Batch [57/147] train loss: 923.33, train corr: 0.02052
Epoch [19/100], Batch [58/147] train loss: 2370.83, train corr: -0.02136
Epoch [19/100], Batch [59/147] train loss: 1080.04, train corr: 0.02182
Epoch [19/100], Batch [60/147] train loss: 1565.34, train corr: 0.01819
Epoch [19/100], Batch [61/147] train loss: 1941.51, train corr: 0.02264
Epoch [19/100], Batch [62/147] train loss: 2015.41, train corr: 0.02400
Epoch [19/100], Batch [63/147] train loss: 2821.12, train corr: 0.02175
Epoch [19/100], Batch [64/147] train loss: 2122.09, train corr: 0.02007
Epoch [19/100], Batch [65/147] train loss: 1713.96, train corr: 0.02337
Epoch [19/100], Batch [66/147] train loss: 1415.11, train corr: 0.02418
Epoch [19/100], Batch [67/147] train loss: 1139.37, train corr: 0.02521
Epoch [19/100], Batch [68/147] train loss: 1316.21, train corr: 0.02896
Epoch [19/100], Batch [69/147] train loss: 1247.56, train corr: 0.02613
Epoch [19/100], Batch [70/147] train loss: 935.59, train corr: 0.02258
Epoch [19/100], Batch [71/147] train loss: 1095.65, train corr: 0.02381
Epoch [19/100], Batch [72/147] train loss: 1140.61, train corr: 0.02206
Epoch [19/100], Batch [73/147] train loss: 1107.71, train corr: 0.01462
Epoch [19/100], Batch [74/147] train loss: 965.47, train corr: -0.02661
Epoch [19/100], Batch [75/147] train loss: 1027.79, train corr: -0.02882
Epoch [19/100], Batch [76/147] train loss: 944.80, train corr: -0.03037
Epoch [19/100], Batch [77/147] train loss: 988.24, train corr: -0.02882
Epoch [19/100], Batch [78/147] train loss: 1018.79, train corr: -0.02859
Epoch [19/100], Batch [79/147] train loss: 922.29, train corr: -0.02756
Epoch [19/100], Batch [80/147] train loss: 1388.80, train corr: -0.02212
Epoch [19/100], Batch [81/147] train loss: 1261.04, train corr: 0.01409
Epoch [19/100], Batch [82/147] train loss: 1673.01, train corr: 0.02076
Epoch [19/100], Batch [83/147] train loss: 1842.35, train corr: 0.02372
Epoch [19/100], Batch [84/147] train loss: 1893.13, train corr: 0.02477
Epoch [19/100], Batch [85/147] train loss: 1937.51, train corr: 0.02623
Epoch [19/100], Batch [86/147] train loss: 1885.35, train corr: 0.02232
Epoch [19/100], Batch [87/147] train loss: 1719.83, train corr: 0.02309
Epoch [19/100], Batch [88/147] train loss: 1381.48, train corr: 0.02659
Epoch [19/100], Batch [89/147] train loss: 1159.35, train corr: 0.02738
Epoch [19/100], Batch [90/147] train loss: 1122.87, train corr: 0.02670
Epoch [19/100], Batch [91/147] train loss: 965.72, train corr: 0.02525
Epoch [19/100], Batch [92/147] train loss: 909.79, train corr: 0.02668
Epoch [19/100], Batch [93/147] train loss: 914.28, train corr: 0.02607
Epoch [19/100], Batch [94/147] train loss: 842.20, train corr: 0.02415
Epoch [19/100], Batch [95/147] train loss: 843.99, train corr: 0.01581
Epoch [19/100], Batch [96/147] train loss: 770.94, train corr: 0.00229
Epoch [19/100], Batch [97/147] train loss: 733.14, train corr: -0.01191
Epoch [19/100], Batch [98/147] train loss: 818.32, train corr: -0.01898
Epoch [19/100], Batch [99/147] train loss: 972.37, train corr: 0.00043
Epoch [19/100], Batch [100/147] train loss: 1133.75, train corr: 0.00149
Epoch [19/100], Batch [101/147] train loss: 1166.24, train corr: 0.00716
Epoch [19/100], Batch [102/147] train loss: 1116.46, train corr: 0.00415
Epoch [19/100], Batch [103/147] train loss: 1749.16, train corr: -0.00440
Epoch [19/100], Batch [104/147] train loss: 1167.38, train corr: -0.02363
Epoch [19/100], Batch [105/147] train loss: 1020.60, train corr: 0.00015
Epoch [19/100], Batch [106/147] train loss: 1185.33, train corr: 0.00908
Epoch [19/100], Batch [107/147] train loss: 1294.59, train corr: 0.01596
Epoch [19/100], Batch [108/147] train loss: 1348.12, train corr: 0.01378
Epoch [19/100], Batch [109/147] train loss: 1226.18, train corr: 0.01669
Epoch [19/100], Batch [110/147] train loss: 1330.20, train corr: 0.01777
Epoch [19/100], Batch [111/147] train loss: 1044.74, train corr: 0.01666
Epoch [19/100], Batch [112/147] train loss: 1114.31, train corr: 0.01790
Epoch [19/100], Batch [113/147] train loss: 897.26, train corr: 0.01907
Epoch [19/100], Batch [114/147] train loss: 917.20, train corr: 0.01944
Epoch [19/100], Batch [115/147] train loss: 919.69, train corr: 0.01719
Epoch [19/100], Batch [116/147] train loss: 789.07, train corr: 0.00868
Epoch [19/100], Batch [117/147] train loss: 1320.66, train corr: -0.01346
Epoch [19/100], Batch [118/147] train loss: 1290.89, train corr: 0.02341
Epoch [19/100], Batch [119/147] train loss: 1713.86, train corr: 0.02707
Epoch [19/100], Batch [120/147] train loss: 2048.76, train corr: 0.02152
Epoch [19/100], Batch [121/147] train loss: 2272.34, train corr: 0.02458
Epoch [19/100], Batch [122/147] train loss: 2315.37, train corr: 0.02829
Epoch [19/100], Batch [123/147] train loss: 2354.31, train corr: 0.02497
Epoch [19/100], Batch [124/147] train loss: 2260.23, train corr: 0.02537
Epoch [19/100], Batch [125/147] train loss: 2038.74, train corr: 0.02795
Epoch [19/100], Batch [126/147] train loss: 1983.06, train corr: 0.02511
Epoch [19/100], Batch [127/147] train loss: 1663.07, train corr: 0.02619
Epoch [19/100], Batch [128/147] train loss: 1333.92, train corr: 0.02928
Epoch [19/100], Batch [129/147] train loss: 1150.61, train corr: 0.03284
Epoch [19/100], Batch [130/147] train loss: 1673.30, train corr: 0.03052
Epoch [19/100], Batch [131/147] train loss: 940.45, train corr: 0.03317
Epoch [19/100], Batch [132/147] train loss: 1015.09, train corr: 0.02671
Epoch [19/100], Batch [133/147] train loss: 1048.34, train corr: 0.02834
Epoch [19/100], Batch [134/147] train loss: 1008.20, train corr: 0.01764
Epoch [19/100], Batch [135/147] train loss: 865.22, train corr: -0.02451
Epoch [19/100], Batch [136/147] train loss: 1541.18, train corr: -0.03189
Epoch [19/100], Batch [137/147] train loss: 1122.91, train corr: 0.00882
Epoch [19/100], Batch [138/147] train loss: 1625.53, train corr: 0.01450
Epoch [19/100], Batch [139/147] train loss: 1778.84, train corr: 0.01967
Epoch [19/100], Batch [140/147] train loss: 1898.24, train corr: 0.01685
Epoch [19/100], Batch [141/147] train loss: 1886.45, train corr: 0.01455
Epoch [19/100], Batch [142/147] train loss: 1784.76, train corr: 0.01441
Epoch [19/100], Batch [143/147] train loss: 1553.39, train corr: 0.01883
Epoch [19/100], Batch [144/147] train loss: 1395.70, train corr: 0.01438
Epoch [19/100], Batch [145/147] train loss: 1172.87, train corr: 0.01337
Epoch [19/100], Batch [146/147] train loss: 1145.39, train corr: 0.00718
Epoch [19/100], Batch [147/147] train loss: 1469.69, train corr: -0.00848
Epoch [19/100], validation loss: 896.49, validation correlation: -0.00052
Epoch [20/100], Batch [1/147] train loss: 851.17, train corr: -0.00173
Epoch [20/100], Batch [2/147] train loss: 831.38, train corr: 0.00997
Epoch [20/100], Batch [3/147] train loss: 935.96, train corr: 0.01054
Epoch [20/100], Batch [4/147] train loss: 865.82, train corr: 0.01247
Epoch [20/100], Batch [5/147] train loss: 812.76, train corr: -0.01134
Epoch [20/100], Batch [6/147] train loss: 1561.13, train corr: -0.01555
Epoch [20/100], Batch [7/147] train loss: 1615.02, train corr: 0.02550
Epoch [20/100], Batch [8/147] train loss: 2341.91, train corr: 0.02477
Epoch [20/100], Batch [9/147] train loss: 3269.95, train corr: 0.02549
Epoch [20/100], Batch [10/147] train loss: 7158.39, train corr: 0.02106
Epoch [20/100], Batch [11/147] train loss: 3352.21, train corr: 0.02397
Epoch [20/100], Batch [12/147] train loss: 3525.93, train corr: 0.02758
Epoch [20/100], Batch [13/147] train loss: 3306.99, train corr: 0.02562
Epoch [20/100], Batch [14/147] train loss: 3282.85, train corr: 0.02517
Epoch [20/100], Batch [15/147] train loss: 2874.00, train corr: 0.02536
Epoch [20/100], Batch [16/147] train loss: 2818.78, train corr: 0.02388
Epoch [20/100], Batch [17/147] train loss: 2396.98, train corr: 0.02726
Epoch [20/100], Batch [18/147] train loss: 2128.77, train corr: 0.02672
Epoch [20/100], Batch [19/147] train loss: 1680.79, train corr: 0.03074
Epoch [20/100], Batch [20/147] train loss: 1432.46, train corr: 0.03216
Epoch [20/100], Batch [21/147] train loss: 1709.54, train corr: 0.03140
Epoch [20/100], Batch [22/147] train loss: 1802.14, train corr: 0.02698
Epoch [20/100], Batch [23/147] train loss: 972.92, train corr: 0.03297
Epoch [20/100], Batch [24/147] train loss: 1067.85, train corr: 0.03299
Epoch [20/100], Batch [25/147] train loss: 1223.25, train corr: 0.02851
Epoch [20/100], Batch [26/147] train loss: 1304.36, train corr: 0.01414
Epoch [20/100], Batch [27/147] train loss: 1188.91, train corr: -0.01031
Epoch [20/100], Batch [28/147] train loss: 1063.70, train corr: -0.02668
Epoch [20/100], Batch [29/147] train loss: 1673.93, train corr: -0.02953
Epoch [20/100], Batch [30/147] train loss: 1331.51, train corr: -0.01545
Epoch [20/100], Batch [31/147] train loss: 1675.63, train corr: 0.00564
Epoch [20/100], Batch [32/147] train loss: 1832.47, train corr: 0.01040
Epoch [20/100], Batch [33/147] train loss: 2029.87, train corr: 0.01330
Epoch [20/100], Batch [34/147] train loss: 1985.58, train corr: 0.01205
Epoch [20/100], Batch [35/147] train loss: 1898.37, train corr: 0.01419
Epoch [20/100], Batch [36/147] train loss: 1700.05, train corr: 0.01151
Epoch [20/100], Batch [37/147] train loss: 1595.05, train corr: 0.00391
Epoch [20/100], Batch [38/147] train loss: 1365.14, train corr: 0.00022
Epoch [20/100], Batch [39/147] train loss: 1172.79, train corr: -0.01172
Epoch [20/100], Batch [40/147] train loss: 1316.27, train corr: -0.02087
Epoch [20/100], Batch [41/147] train loss: 926.35, train corr: -0.01682
Epoch [20/100], Batch [42/147] train loss: 971.85, train corr: -0.00893
Epoch [20/100], Batch [43/147] train loss: 1087.94, train corr: -0.00770
Epoch [20/100], Batch [44/147] train loss: 1070.66, train corr: -0.00779
Epoch [20/100], Batch [45/147] train loss: 1055.36, train corr: -0.01462
Epoch [20/100], Batch [46/147] train loss: 833.38, train corr: -0.02107
Epoch [20/100], Batch [47/147] train loss: 2059.21, train corr: -0.02972
Epoch [20/100], Batch [48/147] train loss: 1751.96, train corr: 0.01365
Epoch [20/100], Batch [49/147] train loss: 2713.88, train corr: 0.01672
Epoch [20/100], Batch [50/147] train loss: 3353.55, train corr: 0.01692
Epoch [20/100], Batch [51/147] train loss: 4013.27, train corr: 0.02197
Epoch [20/100], Batch [52/147] train loss: 4460.89, train corr: 0.02055
Epoch [20/100], Batch [53/147] train loss: 4571.19, train corr: 0.02271
Epoch [20/100], Batch [54/147] train loss: 5120.69, train corr: 0.01529
Epoch [20/100], Batch [55/147] train loss: 4649.49, train corr: 0.02121
Epoch [20/100], Batch [56/147] train loss: 4900.07, train corr: 0.01906
Epoch [20/100], Batch [57/147] train loss: 4722.38, train corr: 0.02363
Epoch [20/100], Batch [58/147] train loss: 4732.39, train corr: 0.01780
Epoch [20/100], Batch [59/147] train loss: 4272.35, train corr: 0.02323
Epoch [20/100], Batch [60/147] train loss: 4280.70, train corr: 0.01772
Epoch [20/100], Batch [61/147] train loss: 5418.51, train corr: 0.02128
Epoch [20/100], Batch [62/147] train loss: 3477.24, train corr: 0.02482
Epoch [20/100], Batch [63/147] train loss: 3008.03, train corr: 0.02487
Epoch [20/100], Batch [64/147] train loss: 2561.42, train corr: 0.02414
Epoch [20/100], Batch [65/147] train loss: 2687.45, train corr: 0.02149
Epoch [20/100], Batch [66/147] train loss: 1702.84, train corr: 0.02452
Epoch [20/100], Batch [67/147] train loss: 1377.70, train corr: 0.02833
Epoch [20/100], Batch [68/147] train loss: 2085.81, train corr: 0.02953
Epoch [20/100], Batch [69/147] train loss: 2286.29, train corr: 0.02186
Epoch [20/100], Batch [70/147] train loss: 971.23, train corr: 0.02517
Epoch [20/100], Batch [71/147] train loss: 1231.78, train corr: 0.02048
Epoch [20/100], Batch [72/147] train loss: 1369.07, train corr: 0.02484
Epoch [20/100], Batch [73/147] train loss: 1451.12, train corr: 0.01994
Epoch [20/100], Batch [74/147] train loss: 1388.90, train corr: 0.02103
Epoch [20/100], Batch [75/147] train loss: 1313.27, train corr: 0.00892
Epoch [20/100], Batch [76/147] train loss: 1132.45, train corr: -0.03194
Epoch [20/100], Batch [77/147] train loss: 1367.15, train corr: -0.02688
Epoch [20/100], Batch [78/147] train loss: 1184.42, train corr: -0.02957
Epoch [20/100], Batch [79/147] train loss: 1353.85, train corr: -0.00814
Epoch [20/100], Batch [80/147] train loss: 1450.39, train corr: 0.00959
Epoch [20/100], Batch [81/147] train loss: 1448.86, train corr: 0.00988
Epoch [20/100], Batch [82/147] train loss: 1412.73, train corr: 0.00306
Epoch [20/100], Batch [83/147] train loss: 1260.44, train corr: -0.00005
Epoch [20/100], Batch [84/147] train loss: 1097.69, train corr: -0.02226
Epoch [20/100], Batch [85/147] train loss: 908.08, train corr: -0.02660
Epoch [20/100], Batch [86/147] train loss: 1762.03, train corr: -0.02809
Epoch [20/100], Batch [87/147] train loss: 1314.94, train corr: 0.02061
Epoch [20/100], Batch [88/147] train loss: 1947.26, train corr: 0.02481
Epoch [20/100], Batch [89/147] train loss: 2316.25, train corr: 0.02571
Epoch [20/100], Batch [90/147] train loss: 2656.57, train corr: 0.02216
Epoch [20/100], Batch [91/147] train loss: 2979.25, train corr: 0.02362
Epoch [20/100], Batch [92/147] train loss: 2953.52, train corr: 0.02311
Epoch [20/100], Batch [93/147] train loss: 3117.01, train corr: 0.02040
Epoch [20/100], Batch [94/147] train loss: 2840.71, train corr: 0.02375
Epoch [20/100], Batch [95/147] train loss: 2762.77, train corr: 0.02136
Epoch [20/100], Batch [96/147] train loss: 2564.32, train corr: 0.02200
Epoch [20/100], Batch [97/147] train loss: 2344.31, train corr: 0.02190
Epoch [20/100], Batch [98/147] train loss: 5240.87, train corr: 0.02523
Epoch [20/100], Batch [99/147] train loss: 1822.18, train corr: 0.02057
Epoch [20/100], Batch [100/147] train loss: 1424.06, train corr: 0.02297
Epoch [20/100], Batch [101/147] train loss: 2800.99, train corr: 0.02680
Epoch [20/100], Batch [102/147] train loss: 1274.05, train corr: 0.02682
Epoch [20/100], Batch [103/147] train loss: 1328.52, train corr: 0.02736
Epoch [20/100], Batch [104/147] train loss: 1507.85, train corr: 0.02608
Epoch [20/100], Batch [105/147] train loss: 1572.09, train corr: 0.02572
Epoch [20/100], Batch [106/147] train loss: 1648.83, train corr: 0.02547
Epoch [20/100], Batch [107/147] train loss: 1504.49, train corr: 0.02098
Epoch [20/100], Batch [108/147] train loss: 1350.52, train corr: 0.02433
Epoch [20/100], Batch [109/147] train loss: 1125.33, train corr: 0.02080
Epoch [20/100], Batch [110/147] train loss: 941.77, train corr: 0.00689
Epoch [20/100], Batch [111/147] train loss: 1388.21, train corr: -0.00580
Epoch [20/100], Batch [112/147] train loss: 928.61, train corr: -0.00108
Epoch [20/100], Batch [113/147] train loss: 1072.84, train corr: 0.00545
Epoch [20/100], Batch [114/147] train loss: 1110.10, train corr: 0.00420
Epoch [20/100], Batch [115/147] train loss: 1183.09, train corr: 0.00454
Epoch [20/100], Batch [116/147] train loss: 1080.03, train corr: -0.00056
Epoch [20/100], Batch [117/147] train loss: 981.21, train corr: -0.00809
Epoch [20/100], Batch [118/147] train loss: 939.61, train corr: -0.01404
Epoch [20/100], Batch [119/147] train loss: 1087.97, train corr: -0.02093
Epoch [20/100], Batch [120/147] train loss: 1136.73, train corr: 0.00681
Epoch [20/100], Batch [121/147] train loss: 1454.91, train corr: 0.01532
Epoch [20/100], Batch [122/147] train loss: 1568.46, train corr: 0.02037
Epoch [20/100], Batch [123/147] train loss: 1836.73, train corr: 0.01976
Epoch [20/100], Batch [124/147] train loss: 1724.78, train corr: 0.02270
Epoch [20/100], Batch [125/147] train loss: 1680.88, train corr: 0.02245
Epoch [20/100], Batch [126/147] train loss: 1547.08, train corr: 0.02088
Epoch [20/100], Batch [127/147] train loss: 1421.39, train corr: 0.02508
Epoch [20/100], Batch [128/147] train loss: 1160.40, train corr: 0.02572
Epoch [20/100], Batch [129/147] train loss: 971.80, train corr: 0.02667
Epoch [20/100], Batch [130/147] train loss: 1198.65, train corr: 0.01094
Epoch [20/100], Batch [131/147] train loss: 1624.05, train corr: 0.00095
Epoch [20/100], Batch [132/147] train loss: 1354.36, train corr: 0.02422
Epoch [20/100], Batch [133/147] train loss: 2038.68, train corr: 0.02422
Epoch [20/100], Batch [134/147] train loss: 2663.16, train corr: 0.02264
Epoch [20/100], Batch [135/147] train loss: 3260.19, train corr: 0.01807
Epoch [20/100], Batch [136/147] train loss: 3460.07, train corr: 0.02223
Epoch [20/100], Batch [137/147] train loss: 3573.85, train corr: 0.01797
Epoch [20/100], Batch [138/147] train loss: 3785.05, train corr: 0.02135
Epoch [20/100], Batch [139/147] train loss: 3670.34, train corr: 0.02174
Epoch [20/100], Batch [140/147] train loss: 3773.12, train corr: 0.01508
Epoch [20/100], Batch [141/147] train loss: 3392.43, train corr: 0.02277
Epoch [20/100], Batch [142/147] train loss: 3389.31, train corr: 0.02080
Epoch [20/100], Batch [143/147] train loss: 3260.20, train corr: 0.01409
Epoch [20/100], Batch [144/147] train loss: 3027.88, train corr: 0.01699
Epoch [20/100], Batch [145/147] train loss: 2712.14, train corr: 0.01927
Epoch [20/100], Batch [146/147] train loss: 2566.11, train corr: 0.01914
Epoch [20/100], Batch [147/147] train loss: 2495.66, train corr: 0.01324
Epoch [20/100], validation loss: 2257.10, validation correlation: 0.01802
Epoch [21/100], Batch [1/147] train loss: 2079.23, train corr: 0.01835
Epoch [21/100], Batch [2/147] train loss: 1975.95, train corr: 0.01721
Epoch [21/100], Batch [3/147] train loss: 1754.02, train corr: 0.01524
Epoch [21/100], Batch [4/147] train loss: 1576.06, train corr: 0.01824
Epoch [21/100], Batch [5/147] train loss: 1442.80, train corr: 0.01509
Epoch [21/100], Batch [6/147] train loss: 1320.58, train corr: 0.01921
Epoch [21/100], Batch [7/147] train loss: 1405.51, train corr: 0.01172
Epoch [21/100], Batch [8/147] train loss: 1160.91, train corr: 0.01291
Epoch [21/100], Batch [9/147] train loss: 880.51, train corr: 0.00713
Epoch [21/100], Batch [10/147] train loss: 922.11, train corr: -0.00313
Epoch [21/100], Batch [11/147] train loss: 918.74, train corr: -0.01285
Epoch [21/100], Batch [12/147] train loss: 929.20, train corr: -0.01119
Epoch [21/100], Batch [13/147] train loss: 964.76, train corr: -0.00856
Epoch [21/100], Batch [14/147] train loss: 905.00, train corr: -0.01758
Epoch [21/100], Batch [15/147] train loss: 955.14, train corr: -0.01797
Epoch [21/100], Batch [16/147] train loss: 987.21, train corr: -0.00582
Epoch [21/100], Batch [17/147] train loss: 1027.29, train corr: 0.00308
Epoch [21/100], Batch [18/147] train loss: 992.43, train corr: 0.00147
Epoch [21/100], Batch [19/147] train loss: 893.82, train corr: -0.00470
Epoch [21/100], Batch [20/147] train loss: 1082.72, train corr: -0.01383
Epoch [21/100], Batch [21/147] train loss: 1086.03, train corr: 0.03423
Epoch [21/100], Batch [22/147] train loss: 1360.42, train corr: 0.03093
Epoch [21/100], Batch [23/147] train loss: 1497.46, train corr: 0.02898
Epoch [21/100], Batch [24/147] train loss: 1641.08, train corr: 0.02793
Epoch [21/100], Batch [25/147] train loss: 1582.50, train corr: 0.02890
Epoch [21/100], Batch [26/147] train loss: 1659.80, train corr: 0.02975
Epoch [21/100], Batch [27/147] train loss: 1514.26, train corr: 0.02973
Epoch [21/100], Batch [28/147] train loss: 1368.61, train corr: 0.03235
Epoch [21/100], Batch [29/147] train loss: 1242.66, train corr: 0.03131
Epoch [21/100], Batch [30/147] train loss: 1287.94, train corr: 0.03468
Epoch [21/100], Batch [31/147] train loss: 1246.40, train corr: 0.03358
Epoch [21/100], Batch [32/147] train loss: 1012.69, train corr: 0.03489
Epoch [21/100], Batch [33/147] train loss: 906.61, train corr: 0.03148
Epoch [21/100], Batch [34/147] train loss: 912.64, train corr: 0.03052
Epoch [21/100], Batch [35/147] train loss: 795.73, train corr: 0.03020
Epoch [21/100], Batch [36/147] train loss: 780.94, train corr: -0.00233
Epoch [21/100], Batch [37/147] train loss: 742.75, train corr: -0.01832
Epoch [21/100], Batch [38/147] train loss: 783.25, train corr: -0.02592
Epoch [21/100], Batch [39/147] train loss: 1117.06, train corr: 0.01492
Epoch [21/100], Batch [40/147] train loss: 1531.07, train corr: 0.01530
Epoch [21/100], Batch [41/147] train loss: 1794.57, train corr: 0.01475
Epoch [21/100], Batch [42/147] train loss: 1846.32, train corr: 0.01907
Epoch [21/100], Batch [43/147] train loss: 1897.11, train corr: 0.02347
Epoch [21/100], Batch [44/147] train loss: 1914.70, train corr: 0.01857
Epoch [21/100], Batch [45/147] train loss: 1840.37, train corr: 0.01958
Epoch [21/100], Batch [46/147] train loss: 1726.84, train corr: 0.02009
Epoch [21/100], Batch [47/147] train loss: 1538.77, train corr: 0.01325
Epoch [21/100], Batch [48/147] train loss: 1386.45, train corr: 0.01069
Epoch [21/100], Batch [49/147] train loss: 1173.07, train corr: 0.00770
Epoch [21/100], Batch [50/147] train loss: 925.12, train corr: -0.01242
Epoch [21/100], Batch [51/147] train loss: 1165.31, train corr: -0.03193
Epoch [21/100], Batch [52/147] train loss: 764.48, train corr: -0.02697
Epoch [21/100], Batch [53/147] train loss: 823.92, train corr: -0.01585
Epoch [21/100], Batch [54/147] train loss: 848.19, train corr: -0.00225
Epoch [21/100], Batch [55/147] train loss: 723.64, train corr: -0.01090
Epoch [21/100], Batch [56/147] train loss: 1045.90, train corr: -0.02490
Epoch [21/100], Batch [57/147] train loss: 1075.03, train corr: 0.01964
Epoch [21/100], Batch [58/147] train loss: 1473.65, train corr: 0.01883
Epoch [21/100], Batch [59/147] train loss: 3696.04, train corr: 0.01677
Epoch [21/100], Batch [60/147] train loss: 1794.62, train corr: 0.02434
Epoch [21/100], Batch [61/147] train loss: 1847.49, train corr: 0.01955
Epoch [21/100], Batch [62/147] train loss: 1818.12, train corr: 0.01605
Epoch [21/100], Batch [63/147] train loss: 1642.49, train corr: 0.02490
Epoch [21/100], Batch [64/147] train loss: 1587.18, train corr: 0.01827
Epoch [21/100], Batch [65/147] train loss: 1277.10, train corr: 0.02630
Epoch [21/100], Batch [66/147] train loss: 1095.09, train corr: 0.02598
Epoch [21/100], Batch [67/147] train loss: 1823.66, train corr: 0.02569
Epoch [21/100], Batch [68/147] train loss: 1037.90, train corr: 0.02728
Epoch [21/100], Batch [69/147] train loss: 799.66, train corr: 0.02428
Epoch [21/100], Batch [70/147] train loss: 838.64, train corr: 0.01736
Epoch [21/100], Batch [71/147] train loss: 869.07, train corr: 0.00635
Epoch [21/100], Batch [72/147] train loss: 794.99, train corr: -0.01481
Epoch [21/100], Batch [73/147] train loss: 862.92, train corr: -0.03013
Epoch [21/100], Batch [74/147] train loss: 916.78, train corr: -0.02225
Epoch [21/100], Batch [75/147] train loss: 1029.15, train corr: -0.01191
Epoch [21/100], Batch [76/147] train loss: 1007.98, train corr: -0.00999
Epoch [21/100], Batch [77/147] train loss: 973.59, train corr: -0.01489
Epoch [21/100], Batch [78/147] train loss: 915.82, train corr: -0.02150
Epoch [21/100], Batch [79/147] train loss: 790.47, train corr: -0.02791
Epoch [21/100], Batch [80/147] train loss: 2133.09, train corr: -0.03062
Epoch [21/100], Batch [81/147] train loss: 1290.06, train corr: 0.01113
Epoch [21/100], Batch [82/147] train loss: 2392.17, train corr: 0.01630
Epoch [21/100], Batch [83/147] train loss: 2188.91, train corr: 0.01918
Epoch [21/100], Batch [84/147] train loss: 2594.57, train corr: 0.02257
Epoch [21/100], Batch [85/147] train loss: 2827.31, train corr: 0.02298
Epoch [21/100], Batch [86/147] train loss: 2849.87, train corr: 0.02259
Epoch [21/100], Batch [87/147] train loss: 3112.13, train corr: 0.01830
Epoch [21/100], Batch [88/147] train loss: 2975.26, train corr: 0.02291
Epoch [21/100], Batch [89/147] train loss: 3008.48, train corr: 0.02061
Epoch [21/100], Batch [90/147] train loss: 2903.15, train corr: 0.02147
Epoch [21/100], Batch [91/147] train loss: 2696.90, train corr: 0.02270
Epoch [21/100], Batch [92/147] train loss: 2552.90, train corr: 0.01802
Epoch [21/100], Batch [93/147] train loss: 2344.10, train corr: 0.02224
Epoch [21/100], Batch [94/147] train loss: 2138.37, train corr: 0.02223
Epoch [21/100], Batch [95/147] train loss: 1781.10, train corr: 0.02413
Epoch [21/100], Batch [96/147] train loss: 1588.05, train corr: 0.01913
Epoch [21/100], Batch [97/147] train loss: 1424.25, train corr: 0.02511
Epoch [21/100], Batch [98/147] train loss: 1728.96, train corr: 0.02221
Epoch [21/100], Batch [99/147] train loss: 1636.86, train corr: 0.02149
Epoch [21/100], Batch [100/147] train loss: 1111.35, train corr: 0.02097
Epoch [21/100], Batch [101/147] train loss: 1221.11, train corr: 0.01947
Epoch [21/100], Batch [102/147] train loss: 1284.92, train corr: 0.01898
Epoch [21/100], Batch [103/147] train loss: 1255.10, train corr: 0.01859
Epoch [21/100], Batch [104/147] train loss: 1153.99, train corr: 0.02279
Epoch [21/100], Batch [105/147] train loss: 974.49, train corr: 0.01967
Epoch [21/100], Batch [106/147] train loss: 828.14, train corr: 0.01383
Epoch [21/100], Batch [107/147] train loss: 1025.09, train corr: -0.02862
Epoch [21/100], Batch [108/147] train loss: 794.33, train corr: -0.01262
Epoch [21/100], Batch [109/147] train loss: 809.69, train corr: 0.01652
Epoch [21/100], Batch [110/147] train loss: 898.23, train corr: 0.01728
Epoch [21/100], Batch [111/147] train loss: 902.88, train corr: 0.01753
Epoch [21/100], Batch [112/147] train loss: 820.60, train corr: 0.02052
Epoch [21/100], Batch [113/147] train loss: 731.05, train corr: 0.02035
Epoch [21/100], Batch [114/147] train loss: 718.39, train corr: 0.01029
Epoch [21/100], Batch [115/147] train loss: 664.37, train corr: 0.02118
Epoch [21/100], Batch [116/147] train loss: 664.78, train corr: 0.02247
Epoch [21/100], Batch [117/147] train loss: 662.69, train corr: 0.02273
Epoch [21/100], Batch [118/147] train loss: 649.59, train corr: 0.01653
Epoch [21/100], Batch [119/147] train loss: 860.60, train corr: 0.00410
Epoch [21/100], Batch [120/147] train loss: 1090.70, train corr: 0.02480
Epoch [21/100], Batch [121/147] train loss: 1648.76, train corr: 0.01686
Epoch [21/100], Batch [122/147] train loss: 1892.87, train corr: 0.02541
Epoch [21/100], Batch [123/147] train loss: 2227.45, train corr: 0.02248
Epoch [21/100], Batch [124/147] train loss: 2303.83, train corr: 0.02038
Epoch [21/100], Batch [125/147] train loss: 2426.74, train corr: 0.02687
Epoch [21/100], Batch [126/147] train loss: 2452.81, train corr: 0.01898
Epoch [21/100], Batch [127/147] train loss: 2339.70, train corr: 0.02319
Epoch [21/100], Batch [128/147] train loss: 2357.11, train corr: 0.02417
Epoch [21/100], Batch [129/147] train loss: 2186.77, train corr: 0.02543
Epoch [21/100], Batch [130/147] train loss: 2099.44, train corr: 0.02029
Epoch [21/100], Batch [131/147] train loss: 1818.38, train corr: 0.02269
Epoch [21/100], Batch [132/147] train loss: 1658.50, train corr: 0.02092
Epoch [21/100], Batch [133/147] train loss: 1392.53, train corr: 0.02058
Epoch [21/100], Batch [134/147] train loss: 1127.70, train corr: 0.02565
Epoch [21/100], Batch [135/147] train loss: 845.01, train corr: 0.02392
Epoch [21/100], Batch [136/147] train loss: 1489.55, train corr: -0.01578
Epoch [21/100], Batch [137/147] train loss: 1064.27, train corr: 0.02064
Epoch [21/100], Batch [138/147] train loss: 1297.28, train corr: 0.02433
Epoch [21/100], Batch [139/147] train loss: 1557.52, train corr: 0.02494
Epoch [21/100], Batch [140/147] train loss: 1717.48, train corr: 0.02644
Epoch [21/100], Batch [141/147] train loss: 1764.36, train corr: 0.02754
Epoch [21/100], Batch [142/147] train loss: 1836.24, train corr: 0.02770
Epoch [21/100], Batch [143/147] train loss: 1743.64, train corr: 0.02439
Epoch [21/100], Batch [144/147] train loss: 1558.78, train corr: 0.02616
Epoch [21/100], Batch [145/147] train loss: 1365.75, train corr: 0.02759
Epoch [21/100], Batch [146/147] train loss: 1262.41, train corr: 0.02709
Epoch [21/100], Batch [147/147] train loss: 1302.55, train corr: 0.03087
Epoch [21/100], validation loss: 1312.89, validation correlation: 0.02841
Epoch [22/100], Batch [1/147] train loss: 1243.14, train corr: 0.02732
Epoch [22/100], Batch [2/147] train loss: 966.46, train corr: 0.02627
Epoch [22/100], Batch [3/147] train loss: 990.07, train corr: 0.02733
Epoch [22/100], Batch [4/147] train loss: 900.04, train corr: 0.02648
Epoch [22/100], Batch [5/147] train loss: 882.60, train corr: 0.02363
Epoch [22/100], Batch [6/147] train loss: 861.59, train corr: 0.01797
Epoch [22/100], Batch [7/147] train loss: 786.52, train corr: 0.02253
Epoch [22/100], Batch [8/147] train loss: 743.87, train corr: 0.01413
Epoch [22/100], Batch [9/147] train loss: 685.21, train corr: 0.00286
Epoch [22/100], Batch [10/147] train loss: 802.42, train corr: -0.02243
Epoch [22/100], Batch [11/147] train loss: 974.95, train corr: 0.00565
Epoch [22/100], Batch [12/147] train loss: 1215.27, train corr: 0.01706
Epoch [22/100], Batch [13/147] train loss: 1424.67, train corr: 0.01767
Epoch [22/100], Batch [14/147] train loss: 1466.57, train corr: 0.02160
Epoch [22/100], Batch [15/147] train loss: 1531.78, train corr: 0.01961
Epoch [22/100], Batch [16/147] train loss: 1418.84, train corr: 0.01594
Epoch [22/100], Batch [17/147] train loss: 2922.19, train corr: 0.01457
Epoch [22/100], Batch [18/147] train loss: 1208.08, train corr: 0.01225
Epoch [22/100], Batch [19/147] train loss: 1922.53, train corr: 0.00237
Epoch [22/100], Batch [20/147] train loss: 795.56, train corr: -0.03455
Epoch [22/100], Batch [21/147] train loss: 2851.95, train corr: -0.03398
Epoch [22/100], Batch [22/147] train loss: 1089.36, train corr: 0.01090
Epoch [22/100], Batch [23/147] train loss: 1589.96, train corr: 0.02053
Epoch [22/100], Batch [24/147] train loss: 2006.62, train corr: 0.02262
Epoch [22/100], Batch [25/147] train loss: 2311.80, train corr: 0.02122
Epoch [22/100], Batch [26/147] train loss: 2691.54, train corr: 0.01490
Epoch [22/100], Batch [27/147] train loss: 2747.54, train corr: 0.02048
Epoch [22/100], Batch [28/147] train loss: 2844.67, train corr: 0.02440
Epoch [22/100], Batch [29/147] train loss: 2741.07, train corr: 0.02103
Epoch [22/100], Batch [30/147] train loss: 2827.04, train corr: 0.02427
Epoch [22/100], Batch [31/147] train loss: 2688.82, train corr: 0.02396
Epoch [22/100], Batch [32/147] train loss: 2562.23, train corr: 0.02143
Epoch [22/100], Batch [33/147] train loss: 2483.70, train corr: 0.02121
Epoch [22/100], Batch [34/147] train loss: 2248.69, train corr: 0.02739
Epoch [22/100], Batch [35/147] train loss: 2036.42, train corr: 0.02706
Epoch [22/100], Batch [36/147] train loss: 1849.80, train corr: 0.02480
Epoch [22/100], Batch [37/147] train loss: 1575.93, train corr: 0.02706
Epoch [22/100], Batch [38/147] train loss: 1326.58, train corr: 0.02402
Epoch [22/100], Batch [39/147] train loss: 1088.23, train corr: 0.02780
Epoch [22/100], Batch [40/147] train loss: 1777.21, train corr: 0.02841
Epoch [22/100], Batch [41/147] train loss: 1241.67, train corr: 0.02998
Epoch [22/100], Batch [42/147] train loss: 1015.00, train corr: 0.02801
Epoch [22/100], Batch [43/147] train loss: 1475.07, train corr: 0.01927
Epoch [22/100], Batch [44/147] train loss: 1244.06, train corr: 0.02318
Epoch [22/100], Batch [45/147] train loss: 1333.06, train corr: 0.02273
Epoch [22/100], Batch [46/147] train loss: 1221.39, train corr: 0.02282
Epoch [22/100], Batch [47/147] train loss: 1181.81, train corr: 0.01608
Epoch [22/100], Batch [48/147] train loss: 1049.45, train corr: 0.01532
Epoch [22/100], Batch [49/147] train loss: 871.71, train corr: -0.00622
Epoch [22/100], Batch [50/147] train loss: 1061.36, train corr: -0.03452
Epoch [22/100], Batch [51/147] train loss: 874.81, train corr: -0.03322
Epoch [22/100], Batch [52/147] train loss: 851.03, train corr: -0.02001
Epoch [22/100], Batch [53/147] train loss: 943.24, train corr: -0.01172
Epoch [22/100], Batch [54/147] train loss: 928.06, train corr: -0.00255
Epoch [22/100], Batch [55/147] train loss: 882.04, train corr: -0.01032
Epoch [22/100], Batch [56/147] train loss: 896.20, train corr: -0.02885
Epoch [22/100], Batch [57/147] train loss: 782.90, train corr: -0.03398
Epoch [22/100], Batch [58/147] train loss: 764.88, train corr: -0.02252
Epoch [22/100], Batch [59/147] train loss: 768.60, train corr: -0.01252
Epoch [22/100], Batch [60/147] train loss: 737.29, train corr: -0.00769
Epoch [22/100], Batch [61/147] train loss: 666.07, train corr: -0.01998
Epoch [22/100], Batch [62/147] train loss: 938.22, train corr: -0.03291
Epoch [22/100], Batch [63/147] train loss: 870.64, train corr: 0.01674
Epoch [22/100], Batch [64/147] train loss: 1093.13, train corr: 0.01962
Epoch [22/100], Batch [65/147] train loss: 1267.85, train corr: 0.02179
Epoch [22/100], Batch [66/147] train loss: 1399.71, train corr: 0.01894
Epoch [22/100], Batch [67/147] train loss: 1379.43, train corr: 0.02457
Epoch [22/100], Batch [68/147] train loss: 1393.09, train corr: 0.01767
Epoch [22/100], Batch [69/147] train loss: 1287.52, train corr: 0.02803
Epoch [22/100], Batch [70/147] train loss: 1188.78, train corr: 0.02649
Epoch [22/100], Batch [71/147] train loss: 1099.64, train corr: 0.02789
Epoch [22/100], Batch [72/147] train loss: 1001.47, train corr: 0.02460
Epoch [22/100], Batch [73/147] train loss: 1119.34, train corr: 0.02694
Epoch [22/100], Batch [74/147] train loss: 980.06, train corr: 0.02785
Epoch [22/100], Batch [75/147] train loss: 904.70, train corr: 0.02582
Epoch [22/100], Batch [76/147] train loss: 967.37, train corr: 0.02296
Epoch [22/100], Batch [77/147] train loss: 936.10, train corr: 0.02701
Epoch [22/100], Batch [78/147] train loss: 880.44, train corr: 0.02850
Epoch [22/100], Batch [79/147] train loss: 804.98, train corr: 0.02928
Epoch [22/100], Batch [80/147] train loss: 842.95, train corr: 0.02815
Epoch [22/100], Batch [81/147] train loss: 714.90, train corr: 0.03397
Epoch [22/100], Batch [82/147] train loss: 714.80, train corr: 0.03230
Epoch [22/100], Batch [83/147] train loss: 679.86, train corr: 0.02856
Epoch [22/100], Batch [84/147] train loss: 663.71, train corr: -0.00207
Epoch [22/100], Batch [85/147] train loss: 690.31, train corr: 0.01532
Epoch [22/100], Batch [86/147] train loss: 730.10, train corr: 0.02220
Epoch [22/100], Batch [87/147] train loss: 722.59, train corr: 0.01099
Epoch [22/100], Batch [88/147] train loss: 678.02, train corr: -0.00674
Epoch [22/100], Batch [89/147] train loss: 1032.86, train corr: -0.01377
Epoch [22/100], Batch [90/147] train loss: 1009.95, train corr: 0.02978
Epoch [22/100], Batch [91/147] train loss: 1285.02, train corr: 0.02593
Epoch [22/100], Batch [92/147] train loss: 1605.13, train corr: 0.02237
Epoch [22/100], Batch [93/147] train loss: 1731.08, train corr: 0.02686
Epoch [22/100], Batch [94/147] train loss: 1927.39, train corr: 0.02150
Epoch [22/100], Batch [95/147] train loss: 2206.31, train corr: 0.02442
Epoch [22/100], Batch [96/147] train loss: 1920.03, train corr: 0.02110
Epoch [22/100], Batch [97/147] train loss: 1908.20, train corr: 0.02374
Epoch [22/100], Batch [98/147] train loss: 1748.15, train corr: 0.02582
Epoch [22/100], Batch [99/147] train loss: 1646.33, train corr: 0.02650
Epoch [22/100], Batch [100/147] train loss: 1488.04, train corr: 0.02793
Epoch [22/100], Batch [101/147] train loss: 1378.84, train corr: 0.02712
Epoch [22/100], Batch [102/147] train loss: 1104.42, train corr: 0.02698
Epoch [22/100], Batch [103/147] train loss: 1054.54, train corr: 0.03030
Epoch [22/100], Batch [104/147] train loss: 1147.99, train corr: 0.03135
Epoch [22/100], Batch [105/147] train loss: 1034.17, train corr: 0.03371
Epoch [22/100], Batch [106/147] train loss: 796.44, train corr: 0.03326
Epoch [22/100], Batch [107/147] train loss: 744.80, train corr: 0.03086
Epoch [22/100], Batch [108/147] train loss: 717.31, train corr: 0.02040
Epoch [22/100], Batch [109/147] train loss: 674.28, train corr: -0.02135
Epoch [22/100], Batch [110/147] train loss: 1351.14, train corr: -0.02770
Epoch [22/100], Batch [111/147] train loss: 978.85, train corr: 0.01106
Epoch [22/100], Batch [112/147] train loss: 1301.10, train corr: 0.01368
Epoch [22/100], Batch [113/147] train loss: 1511.59, train corr: 0.01986
Epoch [22/100], Batch [114/147] train loss: 1684.91, train corr: 0.01668
Epoch [22/100], Batch [115/147] train loss: 1784.80, train corr: 0.01749
Epoch [22/100], Batch [116/147] train loss: 1730.69, train corr: 0.01928
Epoch [22/100], Batch [117/147] train loss: 1686.98, train corr: 0.01869
Epoch [22/100], Batch [118/147] train loss: 1670.73, train corr: 0.02026
Epoch [22/100], Batch [119/147] train loss: 1593.88, train corr: 0.01824
Epoch [22/100], Batch [120/147] train loss: 1473.20, train corr: 0.01788
Epoch [22/100], Batch [121/147] train loss: 1355.21, train corr: 0.01584
Epoch [22/100], Batch [122/147] train loss: 1206.79, train corr: 0.01455
Epoch [22/100], Batch [123/147] train loss: 1024.52, train corr: 0.01220
Epoch [22/100], Batch [124/147] train loss: 870.08, train corr: 0.00179
Epoch [22/100], Batch [125/147] train loss: 1014.55, train corr: -0.01149
Epoch [22/100], Batch [126/147] train loss: 1000.50, train corr: -0.01662
Epoch [22/100], Batch [127/147] train loss: 786.29, train corr: -0.01181
Epoch [22/100], Batch [128/147] train loss: 900.63, train corr: -0.01320
Epoch [22/100], Batch [129/147] train loss: 997.42, train corr: -0.01097
Epoch [22/100], Batch [130/147] train loss: 954.75, train corr: -0.01994
Epoch [22/100], Batch [131/147] train loss: 896.07, train corr: -0.02750
Epoch [22/100], Batch [132/147] train loss: 1047.55, train corr: -0.03175
Epoch [22/100], Batch [133/147] train loss: 1094.92, train corr: -0.00454
Epoch [22/100], Batch [134/147] train loss: 1296.40, train corr: 0.01437
Epoch [22/100], Batch [135/147] train loss: 1520.26, train corr: 0.01254
Epoch [22/100], Batch [136/147] train loss: 1579.56, train corr: 0.01769
Epoch [22/100], Batch [137/147] train loss: 2184.04, train corr: 0.01467
Epoch [22/100], Batch [138/147] train loss: 1589.42, train corr: 0.01915
Epoch [22/100], Batch [139/147] train loss: 1575.64, train corr: 0.01721
Epoch [22/100], Batch [140/147] train loss: 1493.59, train corr: 0.01253
Epoch [22/100], Batch [141/147] train loss: 1293.95, train corr: 0.02055
Epoch [22/100], Batch [142/147] train loss: 1242.82, train corr: 0.01269
Epoch [22/100], Batch [143/147] train loss: 1037.88, train corr: 0.01447
Epoch [22/100], Batch [144/147] train loss: 911.45, train corr: 0.01275
Epoch [22/100], Batch [145/147] train loss: 834.02, train corr: -0.01587
Epoch [22/100], Batch [146/147] train loss: 1478.52, train corr: -0.03430
Epoch [22/100], Batch [147/147] train loss: 973.63, train corr: 0.02245
Epoch [22/100], validation loss: 1559.25, validation correlation: 0.02290
Epoch [23/100], Batch [1/147] train loss: 1512.29, train corr: 0.01944
Epoch [23/100], Batch [2/147] train loss: 1829.58, train corr: 0.02390
Epoch [23/100], Batch [3/147] train loss: 2107.81, train corr: 0.02445
Epoch [23/100], Batch [4/147] train loss: 2218.83, train corr: 0.02306
Epoch [23/100], Batch [5/147] train loss: 2474.48, train corr: 0.01992
Epoch [23/100], Batch [6/147] train loss: 2397.83, train corr: 0.02051
Epoch [23/100], Batch [7/147] train loss: 2445.27, train corr: 0.02321
Epoch [23/100], Batch [8/147] train loss: 2255.84, train corr: 0.02643
Epoch [23/100], Batch [9/147] train loss: 2298.07, train corr: 0.02491
Epoch [23/100], Batch [10/147] train loss: 2226.17, train corr: 0.02245
Epoch [23/100], Batch [11/147] train loss: 2303.48, train corr: 0.02448
Epoch [23/100], Batch [12/147] train loss: 1917.93, train corr: 0.02475
Epoch [23/100], Batch [13/147] train loss: 1683.12, train corr: 0.02057
Epoch [23/100], Batch [14/147] train loss: 1524.32, train corr: 0.02470
Epoch [23/100], Batch [15/147] train loss: 1288.13, train corr: 0.02630
Epoch [23/100], Batch [16/147] train loss: 1226.15, train corr: 0.02487
Epoch [23/100], Batch [17/147] train loss: 1322.15, train corr: 0.02829
Epoch [23/100], Batch [18/147] train loss: 1024.37, train corr: 0.02401
Epoch [23/100], Batch [19/147] train loss: 946.46, train corr: 0.02882
Epoch [23/100], Batch [20/147] train loss: 943.70, train corr: 0.02880
Epoch [23/100], Batch [21/147] train loss: 863.78, train corr: 0.02876
Epoch [23/100], Batch [22/147] train loss: 793.69, train corr: 0.03019
Epoch [23/100], Batch [23/147] train loss: 822.71, train corr: 0.01631
Epoch [23/100], Batch [24/147] train loss: 772.24, train corr: 0.00081
Epoch [23/100], Batch [25/147] train loss: 800.74, train corr: 0.01623
Epoch [23/100], Batch [26/147] train loss: 932.23, train corr: 0.02354
Epoch [23/100], Batch [27/147] train loss: 915.93, train corr: 0.02698
Epoch [23/100], Batch [28/147] train loss: 934.47, train corr: 0.01493
Epoch [23/100], Batch [29/147] train loss: 934.69, train corr: -0.00577
Epoch [23/100], Batch [30/147] train loss: 854.53, train corr: -0.01842
Epoch [23/100], Batch [31/147] train loss: 2369.69, train corr: -0.01562
Epoch [23/100], Batch [32/147] train loss: 1469.80, train corr: 0.02788
Epoch [23/100], Batch [33/147] train loss: 2104.06, train corr: 0.02275
Epoch [23/100], Batch [34/147] train loss: 2799.83, train corr: 0.02008
Epoch [23/100], Batch [35/147] train loss: 3198.43, train corr: 0.02404
Epoch [23/100], Batch [36/147] train loss: 3468.70, train corr: 0.02337
Epoch [23/100], Batch [37/147] train loss: 3710.44, train corr: 0.02544
Epoch [23/100], Batch [38/147] train loss: 3844.29, train corr: 0.02179
Epoch [23/100], Batch [39/147] train loss: 4070.55, train corr: 0.02217
Epoch [23/100], Batch [40/147] train loss: 4183.94, train corr: 0.02207
Epoch [23/100], Batch [41/147] train loss: 4284.90, train corr: 0.02274
Epoch [23/100], Batch [42/147] train loss: 4259.73, train corr: 0.02565
Epoch [23/100], Batch [43/147] train loss: 4112.69, train corr: 0.02672
Epoch [23/100], Batch [44/147] train loss: 4013.31, train corr: 0.02470
Epoch [23/100], Batch [45/147] train loss: 10284.05, train corr: 0.02471
Epoch [23/100], Batch [46/147] train loss: 3872.92, train corr: 0.01929
Epoch [23/100], Batch [47/147] train loss: 3448.39, train corr: 0.02285
Epoch [23/100], Batch [48/147] train loss: 3236.94, train corr: 0.02446
Epoch [23/100], Batch [49/147] train loss: 3017.99, train corr: 0.02586
Epoch [23/100], Batch [50/147] train loss: 2811.78, train corr: 0.02547
Epoch [23/100], Batch [51/147] train loss: 2605.23, train corr: 0.02606
Epoch [23/100], Batch [52/147] train loss: 2290.87, train corr: 0.02551
Epoch [23/100], Batch [53/147] train loss: 2105.47, train corr: 0.02770
Epoch [23/100], Batch [54/147] train loss: 1743.49, train corr: 0.02552
Epoch [23/100], Batch [55/147] train loss: 1522.92, train corr: 0.02725
Epoch [23/100], Batch [56/147] train loss: 1299.29, train corr: 0.02733
Epoch [23/100], Batch [57/147] train loss: 1494.98, train corr: 0.02715
Epoch [23/100], Batch [58/147] train loss: 1743.24, train corr: 0.02924
Epoch [23/100], Batch [59/147] train loss: 985.77, train corr: 0.02779
Epoch [23/100], Batch [60/147] train loss: 1328.19, train corr: 0.02212
Epoch [23/100], Batch [61/147] train loss: 1089.22, train corr: 0.02173
Epoch [23/100], Batch [62/147] train loss: 1045.38, train corr: 0.02349
Epoch [23/100], Batch [63/147] train loss: 990.07, train corr: 0.01985
Epoch [23/100], Batch [64/147] train loss: 938.20, train corr: 0.01348
Epoch [23/100], Batch [65/147] train loss: 825.47, train corr: 0.00438
Epoch [23/100], Batch [66/147] train loss: 721.76, train corr: -0.02176
Epoch [23/100], Batch [67/147] train loss: 1608.96, train corr: -0.03065
Epoch [23/100], Batch [68/147] train loss: 912.28, train corr: 0.00097
Epoch [23/100], Batch [69/147] train loss: 1161.09, train corr: 0.01157
Epoch [23/100], Batch [70/147] train loss: 1389.54, train corr: 0.01138
Epoch [23/100], Batch [71/147] train loss: 1553.89, train corr: 0.01659
Epoch [23/100], Batch [72/147] train loss: 1717.39, train corr: 0.01657
Epoch [23/100], Batch [73/147] train loss: 1679.82, train corr: 0.01887
Epoch [23/100], Batch [74/147] train loss: 1743.10, train corr: 0.02234
Epoch [23/100], Batch [75/147] train loss: 1691.00, train corr: 0.01832
Epoch [23/100], Batch [76/147] train loss: 1663.46, train corr: 0.01744
Epoch [23/100], Batch [77/147] train loss: 1586.40, train corr: 0.02005
Epoch [23/100], Batch [78/147] train loss: 1455.27, train corr: 0.01725
Epoch [23/100], Batch [79/147] train loss: 1443.38, train corr: 0.01531
Epoch [23/100], Batch [80/147] train loss: 1377.17, train corr: 0.01929
Epoch [23/100], Batch [81/147] train loss: 1402.03, train corr: 0.01679
Epoch [23/100], Batch [82/147] train loss: 949.75, train corr: 0.01300
Epoch [23/100], Batch [83/147] train loss: 910.85, train corr: 0.00808
Epoch [23/100], Batch [84/147] train loss: 1028.57, train corr: -0.00109
Epoch [23/100], Batch [85/147] train loss: 806.92, train corr: -0.00259
Epoch [23/100], Batch [86/147] train loss: 730.97, train corr: -0.00648
Epoch [23/100], Batch [87/147] train loss: 740.95, train corr: -0.01439
Epoch [23/100], Batch [88/147] train loss: 748.83, train corr: -0.02332
Epoch [23/100], Batch [89/147] train loss: 879.47, train corr: -0.02275
Epoch [23/100], Batch [90/147] train loss: 961.37, train corr: 0.02463
Epoch [23/100], Batch [91/147] train loss: 1171.07, train corr: 0.02583
Epoch [23/100], Batch [92/147] train loss: 1280.54, train corr: 0.02657
Epoch [23/100], Batch [93/147] train loss: 1379.56, train corr: 0.02491
Epoch [23/100], Batch [94/147] train loss: 1406.65, train corr: 0.02269
Epoch [23/100], Batch [95/147] train loss: 1354.00, train corr: 0.02807
Epoch [23/100], Batch [96/147] train loss: 1285.78, train corr: 0.02744
Epoch [23/100], Batch [97/147] train loss: 1201.61, train corr: 0.02933
Epoch [23/100], Batch [98/147] train loss: 1122.32, train corr: 0.02964
Epoch [23/100], Batch [99/147] train loss: 1046.16, train corr: 0.02757
Epoch [23/100], Batch [100/147] train loss: 905.63, train corr: 0.03441
Epoch [23/100], Batch [101/147] train loss: 723.99, train corr: 0.02727
Epoch [23/100], Batch [102/147] train loss: 1544.23, train corr: -0.00042
Epoch [23/100], Batch [103/147] train loss: 1123.42, train corr: 0.02543
Epoch [23/100], Batch [104/147] train loss: 1531.17, train corr: 0.02165
Epoch [23/100], Batch [105/147] train loss: 1931.04, train corr: 0.02416
Epoch [23/100], Batch [106/147] train loss: 2109.66, train corr: 0.02240
Epoch [23/100], Batch [107/147] train loss: 2276.71, train corr: 0.02552
Epoch [23/100], Batch [108/147] train loss: 2473.14, train corr: 0.02524
Epoch [23/100], Batch [109/147] train loss: 2678.00, train corr: 0.02125
Epoch [23/100], Batch [110/147] train loss: 2793.52, train corr: 0.02467
Epoch [23/100], Batch [111/147] train loss: 2794.17, train corr: 0.02125
Epoch [23/100], Batch [112/147] train loss: 2705.13, train corr: 0.02344
Epoch [23/100], Batch [113/147] train loss: 2634.39, train corr: 0.02706
Epoch [23/100], Batch [114/147] train loss: 2629.43, train corr: 0.02466
Epoch [23/100], Batch [115/147] train loss: 2621.60, train corr: 0.02130
Epoch [23/100], Batch [116/147] train loss: 2473.60, train corr: 0.02335
Epoch [23/100], Batch [117/147] train loss: 2259.75, train corr: 0.02583
Epoch [23/100], Batch [118/147] train loss: 2210.29, train corr: 0.02311
Epoch [23/100], Batch [119/147] train loss: 2083.17, train corr: 0.02181
Epoch [23/100], Batch [120/147] train loss: 1854.78, train corr: 0.02537
Epoch [23/100], Batch [121/147] train loss: 1803.65, train corr: 0.02222
Epoch [23/100], Batch [122/147] train loss: 1566.60, train corr: 0.02641
Epoch [23/100], Batch [123/147] train loss: 1516.77, train corr: 0.01710
Epoch [23/100], Batch [124/147] train loss: 1314.83, train corr: 0.02191
Epoch [23/100], Batch [125/147] train loss: 1211.62, train corr: 0.02433
Epoch [23/100], Batch [126/147] train loss: 1141.55, train corr: 0.02471
Epoch [23/100], Batch [127/147] train loss: 1063.36, train corr: 0.02691
Epoch [23/100], Batch [128/147] train loss: 904.19, train corr: 0.02703
Epoch [23/100], Batch [129/147] train loss: 814.91, train corr: 0.02560
Epoch [23/100], Batch [130/147] train loss: 775.71, train corr: 0.02247
Epoch [23/100], Batch [131/147] train loss: 758.82, train corr: 0.01591
Epoch [23/100], Batch [132/147] train loss: 858.09, train corr: -0.01869
Epoch [23/100], Batch [133/147] train loss: 803.22, train corr: -0.00023
Epoch [23/100], Batch [134/147] train loss: 883.13, train corr: 0.00339
Epoch [23/100], Batch [135/147] train loss: 937.64, train corr: 0.00535
Epoch [23/100], Batch [136/147] train loss: 960.62, train corr: -0.00069
Epoch [23/100], Batch [137/147] train loss: 908.02, train corr: 0.00057
Epoch [23/100], Batch [138/147] train loss: 818.69, train corr: -0.00995
Epoch [23/100], Batch [139/147] train loss: 725.62, train corr: -0.02285
Epoch [23/100], Batch [140/147] train loss: 1385.14, train corr: -0.03005
Epoch [23/100], Batch [141/147] train loss: 863.38, train corr: 0.00316
Epoch [23/100], Batch [142/147] train loss: 1051.65, train corr: 0.01401
Epoch [23/100], Batch [143/147] train loss: 1237.53, train corr: 0.01769
Epoch [23/100], Batch [144/147] train loss: 1277.55, train corr: 0.01737
Epoch [23/100], Batch [145/147] train loss: 1345.89, train corr: 0.02208
Epoch [23/100], Batch [146/147] train loss: 1381.57, train corr: 0.02043
Epoch [23/100], Batch [147/147] train loss: 1333.82, train corr: 0.02127
Epoch [23/100], validation loss: 1408.09, validation correlation: 0.02108
Epoch [24/100], Batch [1/147] train loss: 1270.16, train corr: 0.02198
Epoch [24/100], Batch [2/147] train loss: 1229.47, train corr: 0.02373
Epoch [24/100], Batch [3/147] train loss: 1176.05, train corr: 0.02118
Epoch [24/100], Batch [4/147] train loss: 1089.98, train corr: 0.02169
Epoch [24/100], Batch [5/147] train loss: 1029.09, train corr: 0.01744
Epoch [24/100], Batch [6/147] train loss: 921.18, train corr: 0.02428
Epoch [24/100], Batch [7/147] train loss: 1077.95, train corr: 0.02161
Epoch [24/100], Batch [8/147] train loss: 792.54, train corr: 0.02418
Epoch [24/100], Batch [9/147] train loss: 769.31, train corr: 0.02253
Epoch [24/100], Batch [10/147] train loss: 803.83, train corr: 0.02422
Epoch [24/100], Batch [11/147] train loss: 799.69, train corr: 0.02338
Epoch [24/100], Batch [12/147] train loss: 774.30, train corr: 0.02091
Epoch [24/100], Batch [13/147] train loss: 704.53, train corr: 0.00575
Epoch [24/100], Batch [14/147] train loss: 863.35, train corr: -0.01881
Epoch [24/100], Batch [15/147] train loss: 844.89, train corr: 0.01152
Epoch [24/100], Batch [16/147] train loss: 991.35, train corr: 0.02076
Epoch [24/100], Batch [17/147] train loss: 1055.24, train corr: 0.01969
Epoch [24/100], Batch [18/147] train loss: 1088.31, train corr: 0.02285
Epoch [24/100], Batch [19/147] train loss: 1163.50, train corr: 0.01752
Epoch [24/100], Batch [20/147] train loss: 1081.79, train corr: 0.02054
Epoch [24/100], Batch [21/147] train loss: 1033.12, train corr: 0.02012
Epoch [24/100], Batch [22/147] train loss: 956.57, train corr: 0.01996
Epoch [24/100], Batch [23/147] train loss: 876.39, train corr: 0.01633
Epoch [24/100], Batch [24/147] train loss: 770.00, train corr: 0.01548
Epoch [24/100], Batch [25/147] train loss: 1069.17, train corr: 0.00800
Epoch [24/100], Batch [26/147] train loss: 761.79, train corr: 0.00607
Epoch [24/100], Batch [27/147] train loss: 720.53, train corr: 0.00681
Epoch [24/100], Batch [28/147] train loss: 810.03, train corr: 0.01126
Epoch [24/100], Batch [29/147] train loss: 857.23, train corr: -0.00315
Epoch [24/100], Batch [30/147] train loss: 842.43, train corr: -0.00954
Epoch [24/100], Batch [31/147] train loss: 777.26, train corr: -0.01965
Epoch [24/100], Batch [32/147] train loss: 767.00, train corr: -0.03074
Epoch [24/100], Batch [33/147] train loss: 983.67, train corr: -0.03425
Epoch [24/100], Batch [34/147] train loss: 872.38, train corr: -0.01916
Epoch [24/100], Batch [35/147] train loss: 1068.12, train corr: 0.00145
Epoch [24/100], Batch [36/147] train loss: 1110.76, train corr: 0.01037
Epoch [24/100], Batch [37/147] train loss: 1218.22, train corr: 0.00317
Epoch [24/100], Batch [38/147] train loss: 1173.53, train corr: 0.01111
Epoch [24/100], Batch [39/147] train loss: 1121.62, train corr: 0.01344
Epoch [24/100], Batch [40/147] train loss: 1051.74, train corr: 0.01651
Epoch [24/100], Batch [41/147] train loss: 1008.72, train corr: 0.01267
Epoch [24/100], Batch [42/147] train loss: 927.59, train corr: 0.00029
Epoch [24/100], Batch [43/147] train loss: 851.72, train corr: -0.00250
Epoch [24/100], Batch [44/147] train loss: 738.33, train corr: -0.02338
Epoch [24/100], Batch [45/147] train loss: 1291.89, train corr: -0.03348
Epoch [24/100], Batch [46/147] train loss: 788.60, train corr: 0.00394
Epoch [24/100], Batch [47/147] train loss: 968.90, train corr: 0.01238
Epoch [24/100], Batch [48/147] train loss: 1327.38, train corr: 0.01551
Epoch [24/100], Batch [49/147] train loss: 1190.26, train corr: 0.01900
Epoch [24/100], Batch [50/147] train loss: 1223.86, train corr: 0.01935
Epoch [24/100], Batch [51/147] train loss: 1253.84, train corr: 0.02174
Epoch [24/100], Batch [52/147] train loss: 1222.65, train corr: 0.02254
Epoch [24/100], Batch [53/147] train loss: 1157.78, train corr: 0.02088
Epoch [24/100], Batch [54/147] train loss: 1099.56, train corr: 0.02157
Epoch [24/100], Batch [55/147] train loss: 991.81, train corr: 0.02050
Epoch [24/100], Batch [56/147] train loss: 973.99, train corr: 0.01611
Epoch [24/100], Batch [57/147] train loss: 965.94, train corr: 0.01894
Epoch [24/100], Batch [58/147] train loss: 910.29, train corr: 0.01818
Epoch [24/100], Batch [59/147] train loss: 797.12, train corr: 0.01766
Epoch [24/100], Batch [60/147] train loss: 751.38, train corr: 0.01972
Epoch [24/100], Batch [61/147] train loss: 687.61, train corr: 0.02128
Epoch [24/100], Batch [62/147] train loss: 643.22, train corr: 0.02022
Epoch [24/100], Batch [63/147] train loss: 686.32, train corr: -0.01191
Epoch [24/100], Batch [64/147] train loss: 708.18, train corr: 0.02332
Epoch [24/100], Batch [65/147] train loss: 768.54, train corr: 0.03357
Epoch [24/100], Batch [66/147] train loss: 792.55, train corr: 0.03177
Epoch [24/100], Batch [67/147] train loss: 764.26, train corr: 0.03321
Epoch [24/100], Batch [68/147] train loss: 739.32, train corr: 0.01766
Epoch [24/100], Batch [69/147] train loss: 683.93, train corr: -0.00395
Epoch [24/100], Batch [70/147] train loss: 1621.75, train corr: -0.01132
Epoch [24/100], Batch [71/147] train loss: 999.84, train corr: 0.02806
Epoch [24/100], Batch [72/147] train loss: 1377.70, train corr: 0.02537
Epoch [24/100], Batch [73/147] train loss: 1638.90, train corr: 0.02440
Epoch [24/100], Batch [74/147] train loss: 1858.18, train corr: 0.02439
Epoch [24/100], Batch [75/147] train loss: 2636.11, train corr: 0.02308
Epoch [24/100], Batch [76/147] train loss: 2106.76, train corr: 0.02369
Epoch [24/100], Batch [77/147] train loss: 2134.65, train corr: 0.02663
Epoch [24/100], Batch [78/147] train loss: 2175.85, train corr: 0.02341
Epoch [24/100], Batch [79/147] train loss: 2235.90, train corr: 0.02330
Epoch [24/100], Batch [80/147] train loss: 2297.49, train corr: 0.02311
Epoch [24/100], Batch [81/147] train loss: 2138.41, train corr: 0.02374
Epoch [24/100], Batch [82/147] train loss: 2100.09, train corr: 0.02250
Epoch [24/100], Batch [83/147] train loss: 2021.80, train corr: 0.02679
Epoch [24/100], Batch [84/147] train loss: 1988.28, train corr: 0.02657
Epoch [24/100], Batch [85/147] train loss: 1880.65, train corr: 0.02364
Epoch [24/100], Batch [86/147] train loss: 1733.34, train corr: 0.02449
Epoch [24/100], Batch [87/147] train loss: 1586.19, train corr: 0.02508
Epoch [24/100], Batch [88/147] train loss: 1446.81, train corr: 0.02738
Epoch [24/100], Batch [89/147] train loss: 1350.11, train corr: 0.02356
Epoch [24/100], Batch [90/147] train loss: 1191.85, train corr: 0.02878
Epoch [24/100], Batch [91/147] train loss: 1283.50, train corr: 0.02722
Epoch [24/100], Batch [92/147] train loss: 1373.25, train corr: 0.03070
Epoch [24/100], Batch [93/147] train loss: 1118.84, train corr: 0.02365
Epoch [24/100], Batch [94/147] train loss: 974.18, train corr: 0.02342
Epoch [24/100], Batch [95/147] train loss: 1042.25, train corr: 0.02027
Epoch [24/100], Batch [96/147] train loss: 973.99, train corr: 0.02479
Epoch [24/100], Batch [97/147] train loss: 988.90, train corr: 0.02331
Epoch [24/100], Batch [98/147] train loss: 914.59, train corr: 0.01538
Epoch [24/100], Batch [99/147] train loss: 812.59, train corr: 0.01696
Epoch [24/100], Batch [100/147] train loss: 744.69, train corr: 0.00664
Epoch [24/100], Batch [101/147] train loss: 809.05, train corr: -0.02463
Epoch [24/100], Batch [102/147] train loss: 670.94, train corr: -0.01443
Epoch [24/100], Batch [103/147] train loss: 699.71, train corr: -0.01457
Epoch [24/100], Batch [104/147] train loss: 686.67, train corr: -0.01275
Epoch [24/100], Batch [105/147] train loss: 674.72, train corr: -0.01718
Epoch [24/100], Batch [106/147] train loss: 649.59, train corr: -0.02436
Epoch [24/100], Batch [107/147] train loss: 693.40, train corr: -0.02726
Epoch [24/100], Batch [108/147] train loss: 681.96, train corr: -0.01711
Epoch [24/100], Batch [109/147] train loss: 687.28, train corr: -0.01090
Epoch [24/100], Batch [110/147] train loss: 672.29, train corr: -0.01322
Epoch [24/100], Batch [111/147] train loss: 633.09, train corr: -0.01881
Epoch [24/100], Batch [112/147] train loss: 898.12, train corr: -0.02655
Epoch [24/100], Batch [113/147] train loss: 859.34, train corr: 0.01886
Epoch [24/100], Batch [114/147] train loss: 1075.18, train corr: 0.02237
Epoch [24/100], Batch [115/147] train loss: 1261.29, train corr: 0.02103
Epoch [24/100], Batch [116/147] train loss: 1399.38, train corr: 0.02289
Epoch [24/100], Batch [117/147] train loss: 1494.68, train corr: 0.02208
Epoch [24/100], Batch [118/147] train loss: 1506.88, train corr: 0.02035
Epoch [24/100], Batch [119/147] train loss: 1488.20, train corr: 0.02253
Epoch [24/100], Batch [120/147] train loss: 1512.10, train corr: 0.02338
Epoch [24/100], Batch [121/147] train loss: 1458.27, train corr: 0.01783
Epoch [24/100], Batch [122/147] train loss: 3060.16, train corr: 0.02034
Epoch [24/100], Batch [123/147] train loss: 1341.64, train corr: 0.01497
Epoch [24/100], Batch [124/147] train loss: 1192.24, train corr: 0.02177
Epoch [24/100], Batch [125/147] train loss: 1075.51, train corr: 0.02120
Epoch [24/100], Batch [126/147] train loss: 912.61, train corr: 0.02207
Epoch [24/100], Batch [127/147] train loss: 928.10, train corr: 0.02375
Epoch [24/100], Batch [128/147] train loss: 963.97, train corr: 0.02723
Epoch [24/100], Batch [129/147] train loss: 716.44, train corr: 0.02709
Epoch [24/100], Batch [130/147] train loss: 690.07, train corr: 0.02640
Epoch [24/100], Batch [131/147] train loss: 677.72, train corr: 0.03179
Epoch [24/100], Batch [132/147] train loss: 663.71, train corr: -0.00092
Epoch [24/100], Batch [133/147] train loss: 1355.47, train corr: -0.01305
Epoch [24/100], Batch [134/147] train loss: 1006.71, train corr: 0.02593
Epoch [24/100], Batch [135/147] train loss: 1320.91, train corr: 0.02524
Epoch [24/100], Batch [136/147] train loss: 1546.17, train corr: 0.02591
Epoch [24/100], Batch [137/147] train loss: 1686.19, train corr: 0.02612
Epoch [24/100], Batch [138/147] train loss: 1854.42, train corr: 0.02130
Epoch [24/100], Batch [139/147] train loss: 1871.57, train corr: 0.02631
Epoch [24/100], Batch [140/147] train loss: 1977.36, train corr: 0.02509
Epoch [24/100], Batch [141/147] train loss: 1929.03, train corr: 0.02636
Epoch [24/100], Batch [142/147] train loss: 1997.21, train corr: 0.01945
Epoch [24/100], Batch [143/147] train loss: 1802.37, train corr: 0.02333
Epoch [24/100], Batch [144/147] train loss: 1785.14, train corr: 0.02681
Epoch [24/100], Batch [145/147] train loss: 1687.97, train corr: 0.02065
Epoch [24/100], Batch [146/147] train loss: 3789.62, train corr: 0.02257
Epoch [24/100], Batch [147/147] train loss: 1487.77, train corr: 0.02772
Epoch [24/100], validation loss: 1438.98, validation correlation: 0.02571
Epoch [25/100], Batch [1/147] train loss: 1358.26, train corr: 0.02283
Epoch [25/100], Batch [2/147] train loss: 1186.91, train corr: 0.02635
Epoch [25/100], Batch [3/147] train loss: 1047.84, train corr: 0.02902
Epoch [25/100], Batch [4/147] train loss: 917.02, train corr: 0.02947
Epoch [25/100], Batch [5/147] train loss: 1111.75, train corr: 0.03048
Epoch [25/100], Batch [6/147] train loss: 1099.79, train corr: 0.03201
Epoch [25/100], Batch [7/147] train loss: 832.37, train corr: 0.02921
Epoch [25/100], Batch [8/147] train loss: 779.43, train corr: 0.02858
Epoch [25/100], Batch [9/147] train loss: 820.45, train corr: 0.02835
Epoch [25/100], Batch [10/147] train loss: 838.07, train corr: 0.02571
Epoch [25/100], Batch [11/147] train loss: 872.42, train corr: 0.02293
Epoch [25/100], Batch [12/147] train loss: 783.92, train corr: -0.01477
Epoch [25/100], Batch [13/147] train loss: 792.01, train corr: -0.02623
Epoch [25/100], Batch [14/147] train loss: 833.59, train corr: -0.03004
Epoch [25/100], Batch [15/147] train loss: 850.64, train corr: 0.00546
Epoch [25/100], Batch [16/147] train loss: 858.90, train corr: 0.00953
Epoch [25/100], Batch [17/147] train loss: 866.35, train corr: 0.00918
Epoch [25/100], Batch [18/147] train loss: 838.03, train corr: -0.00007
Epoch [25/100], Batch [19/147] train loss: 797.14, train corr: -0.01908
Epoch [25/100], Batch [20/147] train loss: 717.15, train corr: -0.02614
Epoch [25/100], Batch [21/147] train loss: 1037.23, train corr: -0.02492
Epoch [25/100], Batch [22/147] train loss: 835.61, train corr: 0.01662
Epoch [25/100], Batch [23/147] train loss: 971.11, train corr: 0.02490
Epoch [25/100], Batch [24/147] train loss: 1109.26, train corr: 0.02202
Epoch [25/100], Batch [25/147] train loss: 1184.19, train corr: 0.02730
Epoch [25/100], Batch [26/147] train loss: 1230.78, train corr: 0.02502
Epoch [25/100], Batch [27/147] train loss: 1295.16, train corr: 0.02526
Epoch [25/100], Batch [28/147] train loss: 1283.64, train corr: 0.01904
Epoch [25/100], Batch [29/147] train loss: 1229.25, train corr: 0.02106
Epoch [25/100], Batch [30/147] train loss: 1170.08, train corr: 0.02565
Epoch [25/100], Batch [31/147] train loss: 1430.56, train corr: 0.01890
Epoch [25/100], Batch [32/147] train loss: 1099.47, train corr: 0.02480
Epoch [25/100], Batch [33/147] train loss: 947.32, train corr: 0.02514
Epoch [25/100], Batch [34/147] train loss: 879.51, train corr: 0.02449
Epoch [25/100], Batch [35/147] train loss: 913.67, train corr: 0.02528
Epoch [25/100], Batch [36/147] train loss: 986.99, train corr: 0.02511
Epoch [25/100], Batch [37/147] train loss: 729.25, train corr: 0.02631
Epoch [25/100], Batch [38/147] train loss: 730.31, train corr: 0.02535
Epoch [25/100], Batch [39/147] train loss: 705.21, train corr: 0.02105
Epoch [25/100], Batch [40/147] train loss: 652.18, train corr: 0.01758
Epoch [25/100], Batch [41/147] train loss: 622.25, train corr: -0.02623
Epoch [25/100], Batch [42/147] train loss: 1620.76, train corr: -0.02499
Epoch [25/100], Batch [43/147] train loss: 932.15, train corr: 0.01765
Epoch [25/100], Batch [44/147] train loss: 1304.01, train corr: 0.02341
Epoch [25/100], Batch [45/147] train loss: 1604.29, train corr: 0.01890
Epoch [25/100], Batch [46/147] train loss: 1754.17, train corr: 0.02100
Epoch [25/100], Batch [47/147] train loss: 1946.14, train corr: 0.02088
Epoch [25/100], Batch [48/147] train loss: 2004.45, train corr: 0.02176
Epoch [25/100], Batch [49/147] train loss: 2147.25, train corr: 0.01793
Epoch [25/100], Batch [50/147] train loss: 2183.63, train corr: 0.01735
Epoch [25/100], Batch [51/147] train loss: 2063.42, train corr: 0.02154
Epoch [25/100], Batch [52/147] train loss: 1969.34, train corr: 0.02380
Epoch [25/100], Batch [53/147] train loss: 2078.94, train corr: 0.02207
Epoch [25/100], Batch [54/147] train loss: 2042.22, train corr: 0.02350
Epoch [25/100], Batch [55/147] train loss: 2587.54, train corr: 0.01714
Epoch [25/100], Batch [56/147] train loss: 1870.15, train corr: 0.02445
Epoch [25/100], Batch [57/147] train loss: 1841.31, train corr: 0.02311
Epoch [25/100], Batch [58/147] train loss: 1664.30, train corr: 0.02230
Epoch [25/100], Batch [59/147] train loss: 1570.42, train corr: 0.01908
Epoch [25/100], Batch [60/147] train loss: 1476.32, train corr: 0.01664
Epoch [25/100], Batch [61/147] train loss: 1275.75, train corr: 0.01954
Epoch [25/100], Batch [62/147] train loss: 1201.77, train corr: 0.02117
Epoch [25/100], Batch [63/147] train loss: 1182.28, train corr: 0.02410
Epoch [25/100], Batch [64/147] train loss: 1166.89, train corr: 0.02213
Epoch [25/100], Batch [65/147] train loss: 1037.90, train corr: 0.02148
Epoch [25/100], Batch [66/147] train loss: 868.84, train corr: 0.02640
Epoch [25/100], Batch [67/147] train loss: 838.46, train corr: 0.02659
Epoch [25/100], Batch [68/147] train loss: 829.71, train corr: 0.02298
Epoch [25/100], Batch [69/147] train loss: 794.09, train corr: 0.02799
Epoch [25/100], Batch [70/147] train loss: 758.91, train corr: 0.02698
Epoch [25/100], Batch [71/147] train loss: 803.85, train corr: 0.01014
Epoch [25/100], Batch [72/147] train loss: 1137.06, train corr: 0.01026
Epoch [25/100], Batch [73/147] train loss: 770.43, train corr: 0.01722
Epoch [25/100], Batch [74/147] train loss: 805.31, train corr: 0.02514
Epoch [25/100], Batch [75/147] train loss: 839.28, train corr: 0.02666
Epoch [25/100], Batch [76/147] train loss: 805.09, train corr: 0.02416
Epoch [25/100], Batch [77/147] train loss: 766.77, train corr: 0.01778
Epoch [25/100], Batch [78/147] train loss: 726.77, train corr: 0.00639
Epoch [25/100], Batch [79/147] train loss: 738.80, train corr: 0.01187
Epoch [25/100], Batch [80/147] train loss: 722.48, train corr: 0.01473
Epoch [25/100], Batch [81/147] train loss: 693.14, train corr: 0.00982
Epoch [25/100], Batch [82/147] train loss: 725.46, train corr: 0.02339
Epoch [25/100], Batch [83/147] train loss: 710.70, train corr: 0.01996
Epoch [25/100], Batch [84/147] train loss: 682.23, train corr: 0.02158
Epoch [25/100], Batch [85/147] train loss: 662.99, train corr: 0.02393
Epoch [25/100], Batch [86/147] train loss: 645.68, train corr: 0.02122
Epoch [25/100], Batch [87/147] train loss: 634.10, train corr: 0.01158
Epoch [25/100], Batch [88/147] train loss: 660.39, train corr: 0.00790
Epoch [25/100], Batch [89/147] train loss: 725.80, train corr: 0.03237
Epoch [25/100], Batch [90/147] train loss: 781.95, train corr: 0.02975
Epoch [25/100], Batch [91/147] train loss: 821.61, train corr: 0.03153
Epoch [25/100], Batch [92/147] train loss: 866.20, train corr: 0.03033
Epoch [25/100], Batch [93/147] train loss: 865.52, train corr: 0.02839
Epoch [25/100], Batch [94/147] train loss: 843.09, train corr: 0.02637
Epoch [25/100], Batch [95/147] train loss: 800.70, train corr: 0.02808
Epoch [25/100], Batch [96/147] train loss: 734.14, train corr: 0.02724
Epoch [25/100], Batch [97/147] train loss: 731.27, train corr: 0.02784
Epoch [25/100], Batch [98/147] train loss: 662.55, train corr: 0.02989
Epoch [25/100], Batch [99/147] train loss: 728.69, train corr: 0.02764
Epoch [25/100], Batch [100/147] train loss: 615.12, train corr: 0.02681
Epoch [25/100], Batch [101/147] train loss: 647.36, train corr: 0.02126
Epoch [25/100], Batch [102/147] train loss: 633.56, train corr: 0.01674
Epoch [25/100], Batch [103/147] train loss: 636.80, train corr: -0.00613
Epoch [25/100], Batch [104/147] train loss: 688.23, train corr: -0.02397
Epoch [25/100], Batch [105/147] train loss: 811.94, train corr: 0.02036
Epoch [25/100], Batch [106/147] train loss: 1064.60, train corr: 0.02303
Epoch [25/100], Batch [107/147] train loss: 1192.40, train corr: 0.01917
Epoch [25/100], Batch [108/147] train loss: 1219.26, train corr: 0.02281
Epoch [25/100], Batch [109/147] train loss: 1310.75, train corr: 0.02243
Epoch [25/100], Batch [110/147] train loss: 1323.04, train corr: 0.02177
Epoch [25/100], Batch [111/147] train loss: 1341.98, train corr: 0.01961
Epoch [25/100], Batch [112/147] train loss: 1294.94, train corr: 0.02179
Epoch [25/100], Batch [113/147] train loss: 1184.19, train corr: 0.02218
Epoch [25/100], Batch [114/147] train loss: 1106.32, train corr: 0.02230
Epoch [25/100], Batch [115/147] train loss: 1061.15, train corr: 0.02163
Epoch [25/100], Batch [116/147] train loss: 953.54, train corr: 0.02052
Epoch [25/100], Batch [117/147] train loss: 968.85, train corr: 0.02188
Epoch [25/100], Batch [118/147] train loss: 897.35, train corr: 0.02260
Epoch [25/100], Batch [119/147] train loss: 791.23, train corr: 0.01858
Epoch [25/100], Batch [120/147] train loss: 770.53, train corr: 0.02560
Epoch [25/100], Batch [121/147] train loss: 722.47, train corr: 0.02584
Epoch [25/100], Batch [122/147] train loss: 696.82, train corr: 0.02568
Epoch [25/100], Batch [123/147] train loss: 639.62, train corr: 0.02308
Epoch [25/100], Batch [124/147] train loss: 647.42, train corr: 0.00800
Epoch [25/100], Batch [125/147] train loss: 703.69, train corr: -0.00424
Epoch [25/100], Batch [126/147] train loss: 768.06, train corr: 0.02955
Epoch [25/100], Batch [127/147] train loss: 867.07, train corr: 0.02693
Epoch [25/100], Batch [128/147] train loss: 943.02, train corr: 0.02640
Epoch [25/100], Batch [129/147] train loss: 991.12, train corr: 0.02469
Epoch [25/100], Batch [130/147] train loss: 1051.36, train corr: 0.02510
Epoch [25/100], Batch [131/147] train loss: 1008.08, train corr: 0.02434
Epoch [25/100], Batch [132/147] train loss: 926.76, train corr: 0.02785
Epoch [25/100], Batch [133/147] train loss: 878.27, train corr: 0.02490
Epoch [25/100], Batch [134/147] train loss: 778.33, train corr: 0.02956
Epoch [25/100], Batch [135/147] train loss: 719.40, train corr: 0.02803
Epoch [25/100], Batch [136/147] train loss: 778.00, train corr: 0.00041
Epoch [25/100], Batch [137/147] train loss: 1054.68, train corr: 0.00239
Epoch [25/100], Batch [138/147] train loss: 686.52, train corr: 0.02609
Epoch [25/100], Batch [139/147] train loss: 701.41, train corr: 0.02583
Epoch [25/100], Batch [140/147] train loss: 715.59, train corr: 0.02249
Epoch [25/100], Batch [141/147] train loss: 701.94, train corr: 0.01402
Epoch [25/100], Batch [142/147] train loss: 687.10, train corr: 0.00454
Epoch [25/100], Batch [143/147] train loss: 663.48, train corr: -0.01291
Epoch [25/100], Batch [144/147] train loss: 819.29, train corr: -0.01987
Epoch [25/100], Batch [145/147] train loss: 763.13, train corr: 0.01415
Epoch [25/100], Batch [146/147] train loss: 938.60, train corr: 0.01722
Epoch [25/100], Batch [147/147] train loss: 1011.49, train corr: 0.02178
Epoch [25/100], validation loss: 1182.68, validation correlation: 0.02200
Epoch [26/100], Batch [1/147] train loss: 1103.84, train corr: 0.01637
Epoch [26/100], Batch [2/147] train loss: 1135.02, train corr: 0.02069
Epoch [26/100], Batch [3/147] train loss: 1207.84, train corr: 0.02027
Epoch [26/100], Batch [4/147] train loss: 1162.47, train corr: 0.01741
Epoch [26/100], Batch [5/147] train loss: 1124.91, train corr: 0.02329
Epoch [26/100], Batch [6/147] train loss: 1100.94, train corr: 0.02225
Epoch [26/100], Batch [7/147] train loss: 1075.40, train corr: 0.02283
Epoch [26/100], Batch [8/147] train loss: 1092.51, train corr: 0.01841
Epoch [26/100], Batch [9/147] train loss: 1011.98, train corr: 0.01820
Epoch [26/100], Batch [10/147] train loss: 923.39, train corr: 0.02454
Epoch [26/100], Batch [11/147] train loss: 867.48, train corr: 0.02469
Epoch [26/100], Batch [12/147] train loss: 851.09, train corr: 0.01339
Epoch [26/100], Batch [13/147] train loss: 796.02, train corr: 0.02269
Epoch [26/100], Batch [14/147] train loss: 823.18, train corr: 0.02106
Epoch [26/100], Batch [15/147] train loss: 716.56, train corr: 0.01963
Epoch [26/100], Batch [16/147] train loss: 670.47, train corr: 0.01016
Epoch [26/100], Batch [17/147] train loss: 627.46, train corr: -0.01197
Epoch [26/100], Batch [18/147] train loss: 714.69, train corr: -0.01820
Epoch [26/100], Batch [19/147] train loss: 815.24, train corr: 0.02292
Epoch [26/100], Batch [20/147] train loss: 979.05, train corr: 0.02079
Epoch [26/100], Batch [21/147] train loss: 1109.44, train corr: 0.02240
Epoch [26/100], Batch [22/147] train loss: 1206.10, train corr: 0.02279
Epoch [26/100], Batch [23/147] train loss: 1296.66, train corr: 0.02289
Epoch [26/100], Batch [24/147] train loss: 1294.33, train corr: 0.02090
Epoch [26/100], Batch [25/147] train loss: 1270.21, train corr: 0.02010
Epoch [26/100], Batch [26/147] train loss: 1261.51, train corr: 0.01771
Epoch [26/100], Batch [27/147] train loss: 1230.91, train corr: 0.01971
Epoch [26/100], Batch [28/147] train loss: 1174.99, train corr: 0.02050
Epoch [26/100], Batch [29/147] train loss: 1035.33, train corr: 0.02269
Epoch [26/100], Batch [30/147] train loss: 994.10, train corr: 0.01844
Epoch [26/100], Batch [31/147] train loss: 876.10, train corr: 0.02143
Epoch [26/100], Batch [32/147] train loss: 803.28, train corr: 0.01551
Epoch [26/100], Batch [33/147] train loss: 734.76, train corr: 0.01311
Epoch [26/100], Batch [34/147] train loss: 885.04, train corr: -0.01042
Epoch [26/100], Batch [35/147] train loss: 916.97, train corr: -0.01250
Epoch [26/100], Batch [36/147] train loss: 635.33, train corr: 0.00403
Epoch [26/100], Batch [37/147] train loss: 687.55, train corr: 0.00908
Epoch [26/100], Batch [38/147] train loss: 722.76, train corr: 0.00662
Epoch [26/100], Batch [39/147] train loss: 729.25, train corr: 0.00415
Epoch [26/100], Batch [40/147] train loss: 731.34, train corr: -0.00591
Epoch [26/100], Batch [41/147] train loss: 697.46, train corr: -0.02250
Epoch [26/100], Batch [42/147] train loss: 868.70, train corr: -0.03436
Epoch [26/100], Batch [43/147] train loss: 852.69, train corr: 0.01569
Epoch [26/100], Batch [44/147] train loss: 1062.30, train corr: 0.01976
Epoch [26/100], Batch [45/147] train loss: 1480.98, train corr: 0.02194
Epoch [26/100], Batch [46/147] train loss: 1305.80, train corr: 0.01942
Epoch [26/100], Batch [47/147] train loss: 1319.80, train corr: 0.02253
Epoch [26/100], Batch [48/147] train loss: 1455.57, train corr: 0.02215
Epoch [26/100], Batch [49/147] train loss: 1468.42, train corr: 0.01965
Epoch [26/100], Batch [50/147] train loss: 1436.06, train corr: 0.02222
Epoch [26/100], Batch [51/147] train loss: 1313.52, train corr: 0.02293
Epoch [26/100], Batch [52/147] train loss: 1282.91, train corr: 0.01981
Epoch [26/100], Batch [53/147] train loss: 1222.33, train corr: 0.02205
Epoch [26/100], Batch [54/147] train loss: 1183.39, train corr: 0.02261
Epoch [26/100], Batch [55/147] train loss: 1076.12, train corr: 0.02414
Epoch [26/100], Batch [56/147] train loss: 974.99, train corr: 0.02602
Epoch [26/100], Batch [57/147] train loss: 902.81, train corr: 0.02568
Epoch [26/100], Batch [58/147] train loss: 881.06, train corr: 0.02485
Epoch [26/100], Batch [59/147] train loss: 822.54, train corr: 0.02397
Epoch [26/100], Batch [60/147] train loss: 740.28, train corr: 0.02589
Epoch [26/100], Batch [61/147] train loss: 729.25, train corr: 0.03012
Epoch [26/100], Batch [62/147] train loss: 669.08, train corr: 0.03081
Epoch [26/100], Batch [63/147] train loss: 629.81, train corr: 0.01613
Epoch [26/100], Batch [64/147] train loss: 838.45, train corr: -0.00742
Epoch [26/100], Batch [65/147] train loss: 796.62, train corr: 0.02728
Epoch [26/100], Batch [66/147] train loss: 900.61, train corr: 0.02746
Epoch [26/100], Batch [67/147] train loss: 1060.32, train corr: 0.02459
Epoch [26/100], Batch [68/147] train loss: 1077.24, train corr: 0.02682
Epoch [26/100], Batch [69/147] train loss: 1164.66, train corr: 0.02557
Epoch [26/100], Batch [70/147] train loss: 1230.12, train corr: 0.02363
Epoch [26/100], Batch [71/147] train loss: 1224.07, train corr: 0.02495
Epoch [26/100], Batch [72/147] train loss: 1160.79, train corr: 0.02593
Epoch [26/100], Batch [73/147] train loss: 1162.84, train corr: 0.02368
Epoch [26/100], Batch [74/147] train loss: 1056.68, train corr: 0.02660
Epoch [26/100], Batch [75/147] train loss: 1016.22, train corr: 0.02686
Epoch [26/100], Batch [76/147] train loss: 946.59, train corr: 0.02807
Epoch [26/100], Batch [77/147] train loss: 904.40, train corr: 0.02720
Epoch [26/100], Batch [78/147] train loss: 816.43, train corr: 0.02527
Epoch [26/100], Batch [79/147] train loss: 724.24, train corr: 0.03019
Epoch [26/100], Batch [80/147] train loss: 848.18, train corr: 0.01617
Epoch [26/100], Batch [81/147] train loss: 1013.53, train corr: 0.00568
Epoch [26/100], Batch [82/147] train loss: 763.65, train corr: 0.03203
Epoch [26/100], Batch [83/147] train loss: 949.36, train corr: 0.02856
Epoch [26/100], Batch [84/147] train loss: 1105.05, train corr: 0.02306
Epoch [26/100], Batch [85/147] train loss: 1179.56, train corr: 0.02808
Epoch [26/100], Batch [86/147] train loss: 1628.20, train corr: 0.02239
Epoch [26/100], Batch [87/147] train loss: 1278.78, train corr: 0.02646
Epoch [26/100], Batch [88/147] train loss: 1351.78, train corr: 0.02360
Epoch [26/100], Batch [89/147] train loss: 1345.83, train corr: 0.01815
Epoch [26/100], Batch [90/147] train loss: 1306.04, train corr: 0.02555
Epoch [26/100], Batch [91/147] train loss: 1313.64, train corr: 0.02639
Epoch [26/100], Batch [92/147] train loss: 1234.58, train corr: 0.02273
Epoch [26/100], Batch [93/147] train loss: 1181.88, train corr: 0.02670
Epoch [26/100], Batch [94/147] train loss: 1187.96, train corr: 0.02382
Epoch [26/100], Batch [95/147] train loss: 1028.50, train corr: 0.02674
Epoch [26/100], Batch [96/147] train loss: 963.63, train corr: 0.02580
Epoch [26/100], Batch [97/147] train loss: 874.36, train corr: 0.02738
Epoch [26/100], Batch [98/147] train loss: 774.97, train corr: 0.02805
Epoch [26/100], Batch [99/147] train loss: 711.06, train corr: 0.02804
Epoch [26/100], Batch [100/147] train loss: 929.43, train corr: 0.00333
Epoch [26/100], Batch [101/147] train loss: 718.06, train corr: 0.02906
Epoch [26/100], Batch [102/147] train loss: 805.57, train corr: 0.02565
Epoch [26/100], Batch [103/147] train loss: 874.05, train corr: 0.02706
Epoch [26/100], Batch [104/147] train loss: 935.75, train corr: 0.02870
Epoch [26/100], Batch [105/147] train loss: 998.85, train corr: 0.02211
Epoch [26/100], Batch [106/147] train loss: 1007.22, train corr: 0.02347
Epoch [26/100], Batch [107/147] train loss: 1023.91, train corr: 0.02371
Epoch [26/100], Batch [108/147] train loss: 985.53, train corr: 0.02328
Epoch [26/100], Batch [109/147] train loss: 934.79, train corr: 0.02323
Epoch [26/100], Batch [110/147] train loss: 883.69, train corr: 0.02625
Epoch [26/100], Batch [111/147] train loss: 816.04, train corr: 0.02702
Epoch [26/100], Batch [112/147] train loss: 724.75, train corr: 0.02459
Epoch [26/100], Batch [113/147] train loss: 677.52, train corr: 0.02754
Epoch [26/100], Batch [114/147] train loss: 644.47, train corr: 0.03150
Epoch [26/100], Batch [115/147] train loss: 1180.52, train corr: -0.01298
Epoch [26/100], Batch [116/147] train loss: 810.18, train corr: 0.02509
Epoch [26/100], Batch [117/147] train loss: 1106.79, train corr: 0.01934
Epoch [26/100], Batch [118/147] train loss: 1349.61, train corr: 0.02369
Epoch [26/100], Batch [119/147] train loss: 1530.72, train corr: 0.02375
Epoch [26/100], Batch [120/147] train loss: 1716.17, train corr: 0.02309
Epoch [26/100], Batch [121/147] train loss: 1835.71, train corr: 0.02008
Epoch [26/100], Batch [122/147] train loss: 1858.00, train corr: 0.02239
Epoch [26/100], Batch [123/147] train loss: 2033.48, train corr: 0.02589
Epoch [26/100], Batch [124/147] train loss: 1991.71, train corr: 0.02434
Epoch [26/100], Batch [125/147] train loss: 2022.54, train corr: 0.01974
Epoch [26/100], Batch [126/147] train loss: 1980.38, train corr: 0.02199
Epoch [26/100], Batch [127/147] train loss: 2048.03, train corr: 0.02274
Epoch [26/100], Batch [128/147] train loss: 1972.22, train corr: 0.01913
Epoch [26/100], Batch [129/147] train loss: 1896.26, train corr: 0.02498
Epoch [26/100], Batch [130/147] train loss: 1821.84, train corr: 0.02121
Epoch [26/100], Batch [131/147] train loss: 1799.82, train corr: 0.02210
Epoch [26/100], Batch [132/147] train loss: 1741.38, train corr: 0.02170
Epoch [26/100], Batch [133/147] train loss: 1652.63, train corr: 0.02408
Epoch [26/100], Batch [134/147] train loss: 1515.60, train corr: 0.02632
Epoch [26/100], Batch [135/147] train loss: 1518.33, train corr: 0.02209
Epoch [26/100], Batch [136/147] train loss: 1389.27, train corr: 0.02027
Epoch [26/100], Batch [137/147] train loss: 1237.23, train corr: 0.02256
Epoch [26/100], Batch [138/147] train loss: 1179.23, train corr: 0.02216
Epoch [26/100], Batch [139/147] train loss: 1070.17, train corr: 0.02241
Epoch [26/100], Batch [140/147] train loss: 970.31, train corr: 0.02164
Epoch [26/100], Batch [141/147] train loss: 923.56, train corr: 0.01731
Epoch [26/100], Batch [142/147] train loss: 1609.54, train corr: 0.01693
Epoch [26/100], Batch [143/147] train loss: 761.60, train corr: 0.01940
Epoch [26/100], Batch [144/147] train loss: 677.52, train corr: 0.02798
Epoch [26/100], Batch [145/147] train loss: 881.67, train corr: 0.00630
Epoch [26/100], Batch [146/147] train loss: 724.03, train corr: 0.03304
Epoch [26/100], Batch [147/147] train loss: 920.39, train corr: 0.03138
Epoch [26/100], validation loss: 1021.90, validation correlation: 0.03123
Epoch [27/100], Batch [1/147] train loss: 969.73, train corr: 0.02941
Epoch [27/100], Batch [2/147] train loss: 1061.36, train corr: 0.03193
Epoch [27/100], Batch [3/147] train loss: 1052.06, train corr: 0.03259
Epoch [27/100], Batch [4/147] train loss: 1055.01, train corr: 0.02759
Epoch [27/100], Batch [5/147] train loss: 1068.93, train corr: 0.03223
Epoch [27/100], Batch [6/147] train loss: 988.12, train corr: 0.03316
Epoch [27/100], Batch [7/147] train loss: 995.56, train corr: 0.03318
Epoch [27/100], Batch [8/147] train loss: 959.91, train corr: 0.03254
Epoch [27/100], Batch [9/147] train loss: 914.46, train corr: 0.03314
Epoch [27/100], Batch [10/147] train loss: 817.84, train corr: 0.02639
Epoch [27/100], Batch [11/147] train loss: 742.69, train corr: 0.00566
Epoch [27/100], Batch [12/147] train loss: 944.04, train corr: -0.00767
Epoch [27/100], Batch [13/147] train loss: 1260.81, train corr: 0.01662
Epoch [27/100], Batch [14/147] train loss: 1396.89, train corr: 0.03065
Epoch [27/100], Batch [15/147] train loss: 799.49, train corr: 0.03303
Epoch [27/100], Batch [16/147] train loss: 782.98, train corr: 0.03329
Epoch [27/100], Batch [17/147] train loss: 792.13, train corr: 0.03254
Epoch [27/100], Batch [18/147] train loss: 759.19, train corr: 0.03416
Epoch [27/100], Batch [19/147] train loss: 733.27, train corr: 0.03389
Epoch [27/100], Batch [20/147] train loss: 668.16, train corr: 0.03053
Epoch [27/100], Batch [21/147] train loss: 674.43, train corr: 0.02166
Epoch [27/100], Batch [22/147] train loss: 703.70, train corr: 0.01812
Epoch [27/100], Batch [23/147] train loss: 636.44, train corr: 0.02407
Epoch [27/100], Batch [24/147] train loss: 639.72, train corr: 0.02946
Epoch [27/100], Batch [25/147] train loss: 663.35, train corr: 0.02735
Epoch [27/100], Batch [26/147] train loss: 624.55, train corr: 0.01358
Epoch [27/100], Batch [27/147] train loss: 631.77, train corr: -0.00430
Epoch [27/100], Batch [28/147] train loss: 690.04, train corr: -0.01119
Epoch [27/100], Batch [29/147] train loss: 845.40, train corr: 0.02531
Epoch [27/100], Batch [30/147] train loss: 999.24, train corr: 0.02649
Epoch [27/100], Batch [31/147] train loss: 1269.85, train corr: 0.02253
Epoch [27/100], Batch [32/147] train loss: 1305.74, train corr: 0.02342
Epoch [27/100], Batch [33/147] train loss: 1472.14, train corr: 0.02041
Epoch [27/100], Batch [34/147] train loss: 1465.88, train corr: 0.02337
Epoch [27/100], Batch [35/147] train loss: 1466.23, train corr: 0.02653
Epoch [27/100], Batch [36/147] train loss: 1508.26, train corr: 0.02590
Epoch [27/100], Batch [37/147] train loss: 1530.65, train corr: 0.02271
Epoch [27/100], Batch [38/147] train loss: 1514.65, train corr: 0.02137
Epoch [27/100], Batch [39/147] train loss: 1476.83, train corr: 0.02008
Epoch [27/100], Batch [40/147] train loss: 1423.93, train corr: 0.02488
Epoch [27/100], Batch [41/147] train loss: 1422.41, train corr: 0.02569
Epoch [27/100], Batch [42/147] train loss: 1354.13, train corr: 0.02534
Epoch [27/100], Batch [43/147] train loss: 1310.07, train corr: 0.02292
Epoch [27/100], Batch [44/147] train loss: 1309.25, train corr: 0.02494
Epoch [27/100], Batch [45/147] train loss: 1159.57, train corr: 0.02489
Epoch [27/100], Batch [46/147] train loss: 1093.85, train corr: 0.02401
Epoch [27/100], Batch [47/147] train loss: 1012.88, train corr: 0.02546
Epoch [27/100], Batch [48/147] train loss: 969.67, train corr: 0.02433
Epoch [27/100], Batch [49/147] train loss: 922.28, train corr: 0.02576
Epoch [27/100], Batch [50/147] train loss: 947.51, train corr: 0.02727
Epoch [27/100], Batch [51/147] train loss: 863.21, train corr: 0.02762
Epoch [27/100], Batch [52/147] train loss: 788.57, train corr: 0.02800
Epoch [27/100], Batch [53/147] train loss: 788.60, train corr: 0.02611
Epoch [27/100], Batch [54/147] train loss: 770.87, train corr: 0.02767
Epoch [27/100], Batch [55/147] train loss: 743.02, train corr: 0.02729
Epoch [27/100], Batch [56/147] train loss: 701.30, train corr: 0.03336
Epoch [27/100], Batch [57/147] train loss: 671.97, train corr: 0.03439
Epoch [27/100], Batch [58/147] train loss: 717.15, train corr: 0.01378
Epoch [27/100], Batch [59/147] train loss: 673.53, train corr: 0.02920
Epoch [27/100], Batch [60/147] train loss: 679.80, train corr: 0.03303
Epoch [27/100], Batch [61/147] train loss: 830.97, train corr: 0.02726
Epoch [27/100], Batch [62/147] train loss: 683.30, train corr: 0.03243
Epoch [27/100], Batch [63/147] train loss: 690.77, train corr: 0.02196
Epoch [27/100], Batch [64/147] train loss: 679.41, train corr: 0.00156
Epoch [27/100], Batch [65/147] train loss: 855.34, train corr: -0.01462
Epoch [27/100], Batch [66/147] train loss: 738.63, train corr: 0.03088
Epoch [27/100], Batch [67/147] train loss: 837.19, train corr: 0.02808
Epoch [27/100], Batch [68/147] train loss: 915.22, train corr: 0.02452
Epoch [27/100], Batch [69/147] train loss: 966.04, train corr: 0.02358
Epoch [27/100], Batch [70/147] train loss: 986.27, train corr: 0.02486
Epoch [27/100], Batch [71/147] train loss: 1005.34, train corr: 0.02485
Epoch [27/100], Batch [72/147] train loss: 1007.05, train corr: 0.02451
Epoch [27/100], Batch [73/147] train loss: 972.92, train corr: 0.02498
Epoch [27/100], Batch [74/147] train loss: 948.35, train corr: 0.02515
Epoch [27/100], Batch [75/147] train loss: 925.49, train corr: 0.02232
Epoch [27/100], Batch [76/147] train loss: 877.50, train corr: 0.02450
Epoch [27/100], Batch [77/147] train loss: 812.91, train corr: 0.02344
Epoch [27/100], Batch [78/147] train loss: 755.99, train corr: 0.02626
Epoch [27/100], Batch [79/147] train loss: 682.36, train corr: 0.02686
Epoch [27/100], Batch [80/147] train loss: 893.57, train corr: 0.02865
Epoch [27/100], Batch [81/147] train loss: 638.05, train corr: 0.02658
Epoch [27/100], Batch [82/147] train loss: 656.49, train corr: 0.02444
Epoch [27/100], Batch [83/147] train loss: 666.17, train corr: 0.02554
Epoch [27/100], Batch [84/147] train loss: 679.96, train corr: 0.01616
Epoch [27/100], Batch [85/147] train loss: 645.57, train corr: 0.00845
Epoch [27/100], Batch [86/147] train loss: 618.40, train corr: -0.02794
Epoch [27/100], Batch [87/147] train loss: 1017.57, train corr: -0.03309
Epoch [27/100], Batch [88/147] train loss: 723.76, train corr: 0.01703
Epoch [27/100], Batch [89/147] train loss: 849.72, train corr: 0.02007
Epoch [27/100], Batch [90/147] train loss: 949.37, train corr: 0.02094
Epoch [27/100], Batch [91/147] train loss: 1025.98, train corr: 0.02104
Epoch [27/100], Batch [92/147] train loss: 1095.24, train corr: 0.01876
Epoch [27/100], Batch [93/147] train loss: 1132.54, train corr: 0.02052
Epoch [27/100], Batch [94/147] train loss: 1162.12, train corr: 0.02220
Epoch [27/100], Batch [95/147] train loss: 1070.63, train corr: 0.02341
Epoch [27/100], Batch [96/147] train loss: 1092.28, train corr: 0.02307
Epoch [27/100], Batch [97/147] train loss: 1026.18, train corr: 0.02303
Epoch [27/100], Batch [98/147] train loss: 1037.61, train corr: 0.02048
Epoch [27/100], Batch [99/147] train loss: 979.41, train corr: 0.02080
Epoch [27/100], Batch [100/147] train loss: 939.23, train corr: 0.02258
Epoch [27/100], Batch [101/147] train loss: 958.13, train corr: 0.01409
Epoch [27/100], Batch [102/147] train loss: 896.66, train corr: 0.02363
Epoch [27/100], Batch [103/147] train loss: 846.24, train corr: 0.01724
Epoch [27/100], Batch [104/147] train loss: 766.02, train corr: 0.02403
Epoch [27/100], Batch [105/147] train loss: 717.65, train corr: 0.02328
Epoch [27/100], Batch [106/147] train loss: 659.73, train corr: 0.02399
Epoch [27/100], Batch [107/147] train loss: 613.95, train corr: 0.02690
Epoch [27/100], Batch [108/147] train loss: 825.64, train corr: -0.01260
Epoch [27/100], Batch [109/147] train loss: 707.97, train corr: 0.02268
Epoch [27/100], Batch [110/147] train loss: 809.77, train corr: 0.02226
Epoch [27/100], Batch [111/147] train loss: 842.98, train corr: 0.02572
Epoch [27/100], Batch [112/147] train loss: 944.80, train corr: 0.02199
Epoch [27/100], Batch [113/147] train loss: 988.24, train corr: 0.02522
Epoch [27/100], Batch [114/147] train loss: 1028.57, train corr: 0.02296
Epoch [27/100], Batch [115/147] train loss: 994.06, train corr: 0.02283
Epoch [27/100], Batch [116/147] train loss: 1014.43, train corr: 0.02340
Epoch [27/100], Batch [117/147] train loss: 940.13, train corr: 0.02335
Epoch [27/100], Batch [118/147] train loss: 942.84, train corr: 0.02106
Epoch [27/100], Batch [119/147] train loss: 915.45, train corr: 0.01752
Epoch [27/100], Batch [120/147] train loss: 813.28, train corr: 0.02706
Epoch [27/100], Batch [121/147] train loss: 777.38, train corr: 0.02298
Epoch [27/100], Batch [122/147] train loss: 711.39, train corr: 0.02390
Epoch [27/100], Batch [123/147] train loss: 649.00, train corr: 0.02972
Epoch [27/100], Batch [124/147] train loss: 784.16, train corr: 0.00107
Epoch [27/100], Batch [125/147] train loss: 700.91, train corr: 0.02775
Epoch [27/100], Batch [126/147] train loss: 706.26, train corr: 0.02212
Epoch [27/100], Batch [127/147] train loss: 686.73, train corr: 0.02718
Epoch [27/100], Batch [128/147] train loss: 715.91, train corr: 0.02600
Epoch [27/100], Batch [129/147] train loss: 717.32, train corr: 0.02792
Epoch [27/100], Batch [130/147] train loss: 685.39, train corr: 0.02795
Epoch [27/100], Batch [131/147] train loss: 683.25, train corr: 0.02685
Epoch [27/100], Batch [132/147] train loss: 649.48, train corr: 0.02907
Epoch [27/100], Batch [133/147] train loss: 613.24, train corr: 0.03096
Epoch [27/100], Batch [134/147] train loss: 888.26, train corr: 0.00300
Epoch [27/100], Batch [135/147] train loss: 892.28, train corr: 0.02439
Epoch [27/100], Batch [136/147] train loss: 1201.53, train corr: 0.02129
Epoch [27/100], Batch [137/147] train loss: 1480.59, train corr: 0.02261
Epoch [27/100], Batch [138/147] train loss: 1647.83, train corr: 0.02688
Epoch [27/100], Batch [139/147] train loss: 1769.81, train corr: 0.02614
Epoch [27/100], Batch [140/147] train loss: 1948.38, train corr: 0.02546
Epoch [27/100], Batch [141/147] train loss: 2021.60, train corr: 0.02650
Epoch [27/100], Batch [142/147] train loss: 2088.75, train corr: 0.02643
Epoch [27/100], Batch [143/147] train loss: 2091.70, train corr: 0.02509
Epoch [27/100], Batch [144/147] train loss: 2311.36, train corr: 0.02563
Epoch [27/100], Batch [145/147] train loss: 2219.82, train corr: 0.02630
Epoch [27/100], Batch [146/147] train loss: 2245.33, train corr: 0.02216
Epoch [27/100], Batch [147/147] train loss: 2255.68, train corr: 0.02660
Epoch [27/100], validation loss: 2351.02, validation correlation: 0.02438
Epoch [28/100], Batch [1/147] train loss: 2200.54, train corr: 0.02256
Epoch [28/100], Batch [2/147] train loss: 2284.69, train corr: 0.02639
Epoch [28/100], Batch [3/147] train loss: 2195.43, train corr: 0.01951
Epoch [28/100], Batch [4/147] train loss: 2129.78, train corr: 0.02074
Epoch [28/100], Batch [5/147] train loss: 2104.23, train corr: 0.02200
Epoch [28/100], Batch [6/147] train loss: 1953.79, train corr: 0.02582
Epoch [28/100], Batch [7/147] train loss: 4528.87, train corr: 0.02171
Epoch [28/100], Batch [8/147] train loss: 1764.88, train corr: 0.02602
Epoch [28/100], Batch [9/147] train loss: 1681.34, train corr: 0.02361
Epoch [28/100], Batch [10/147] train loss: 1635.41, train corr: 0.02501
Epoch [28/100], Batch [11/147] train loss: 1510.04, train corr: 0.02352
Epoch [28/100], Batch [12/147] train loss: 1433.30, train corr: 0.02276
Epoch [28/100], Batch [13/147] train loss: 1270.72, train corr: 0.02525
Epoch [28/100], Batch [14/147] train loss: 1231.20, train corr: 0.02417
Epoch [28/100], Batch [15/147] train loss: 1203.27, train corr: 0.02643
Epoch [28/100], Batch [16/147] train loss: 1208.07, train corr: 0.02283
Epoch [28/100], Batch [17/147] train loss: 1028.37, train corr: 0.02384
Epoch [28/100], Batch [18/147] train loss: 965.36, train corr: 0.02845
Epoch [28/100], Batch [19/147] train loss: 926.17, train corr: 0.02347
Epoch [28/100], Batch [20/147] train loss: 870.49, train corr: 0.02748
Epoch [28/100], Batch [21/147] train loss: 832.31, train corr: 0.03161
Epoch [28/100], Batch [22/147] train loss: 810.12, train corr: 0.02547
Epoch [28/100], Batch [23/147] train loss: 768.98, train corr: 0.03149
Epoch [28/100], Batch [24/147] train loss: 744.95, train corr: 0.02747
Epoch [28/100], Batch [25/147] train loss: 691.06, train corr: 0.03147
Epoch [28/100], Batch [26/147] train loss: 695.03, train corr: 0.03125
Epoch [28/100], Batch [27/147] train loss: 698.13, train corr: 0.02295
Epoch [28/100], Batch [28/147] train loss: 678.09, train corr: 0.01939
Epoch [28/100], Batch [29/147] train loss: 693.86, train corr: 0.01525
Epoch [28/100], Batch [30/147] train loss: 703.22, train corr: 0.00965
Epoch [28/100], Batch [31/147] train loss: 733.16, train corr: -0.00641
Epoch [28/100], Batch [32/147] train loss: 759.03, train corr: 0.02850
Epoch [28/100], Batch [33/147] train loss: 769.77, train corr: 0.02698
Epoch [28/100], Batch [34/147] train loss: 795.67, train corr: 0.02595
Epoch [28/100], Batch [35/147] train loss: 813.32, train corr: 0.02578
Epoch [28/100], Batch [36/147] train loss: 782.43, train corr: 0.02580
Epoch [28/100], Batch [37/147] train loss: 773.43, train corr: 0.02641
Epoch [28/100], Batch [38/147] train loss: 737.10, train corr: 0.02623
Epoch [28/100], Batch [39/147] train loss: 698.36, train corr: 0.02687
Epoch [28/100], Batch [40/147] train loss: 650.91, train corr: 0.02874
Epoch [28/100], Batch [41/147] train loss: 627.50, train corr: 0.02250
Epoch [28/100], Batch [42/147] train loss: 779.14, train corr: -0.00208
Epoch [28/100], Batch [43/147] train loss: 687.39, train corr: 0.03045
Epoch [28/100], Batch [44/147] train loss: 823.60, train corr: 0.02448
Epoch [28/100], Batch [45/147] train loss: 915.73, train corr: 0.02520
Epoch [28/100], Batch [46/147] train loss: 990.86, train corr: 0.02230
Epoch [28/100], Batch [47/147] train loss: 1033.25, train corr: 0.02488
Epoch [28/100], Batch [48/147] train loss: 1071.65, train corr: 0.02337
Epoch [28/100], Batch [49/147] train loss: 1099.53, train corr: 0.02058
Epoch [28/100], Batch [50/147] train loss: 1366.20, train corr: 0.02138
Epoch [28/100], Batch [51/147] train loss: 1087.63, train corr: 0.02536
Epoch [28/100], Batch [52/147] train loss: 1017.72, train corr: 0.02470
Epoch [28/100], Batch [53/147] train loss: 1023.33, train corr: 0.02230
Epoch [28/100], Batch [54/147] train loss: 972.92, train corr: 0.02130
Epoch [28/100], Batch [55/147] train loss: 953.49, train corr: 0.02434
Epoch [28/100], Batch [56/147] train loss: 916.69, train corr: 0.02048
Epoch [28/100], Batch [57/147] train loss: 822.47, train corr: 0.02274
Epoch [28/100], Batch [58/147] train loss: 798.01, train corr: 0.02280
Epoch [28/100], Batch [59/147] train loss: 792.33, train corr: 0.02041
Epoch [28/100], Batch [60/147] train loss: 741.51, train corr: 0.02240
Epoch [28/100], Batch [61/147] train loss: 681.54, train corr: 0.01627
Epoch [28/100], Batch [62/147] train loss: 653.60, train corr: 0.01072
Epoch [28/100], Batch [63/147] train loss: 619.62, train corr: -0.01526
Epoch [28/100], Batch [64/147] train loss: 905.72, train corr: -0.02756
Epoch [28/100], Batch [65/147] train loss: 713.76, train corr: 0.01423
Epoch [28/100], Batch [66/147] train loss: 850.92, train corr: 0.01948
Epoch [28/100], Batch [67/147] train loss: 920.22, train corr: 0.01966
Epoch [28/100], Batch [68/147] train loss: 989.21, train corr: 0.02393
Epoch [28/100], Batch [69/147] train loss: 1022.11, train corr: 0.02195
Epoch [28/100], Batch [70/147] train loss: 1092.87, train corr: 0.02465
Epoch [28/100], Batch [71/147] train loss: 1069.81, train corr: 0.02428
Epoch [28/100], Batch [72/147] train loss: 1084.95, train corr: 0.02222
Epoch [28/100], Batch [73/147] train loss: 1041.70, train corr: 0.02070
Epoch [28/100], Batch [74/147] train loss: 1033.94, train corr: 0.02279
Epoch [28/100], Batch [75/147] train loss: 971.38, train corr: 0.02176
Epoch [28/100], Batch [76/147] train loss: 950.59, train corr: 0.02103
Epoch [28/100], Batch [77/147] train loss: 910.21, train corr: 0.02218
Epoch [28/100], Batch [78/147] train loss: 875.26, train corr: 0.02189
Epoch [28/100], Batch [79/147] train loss: 846.45, train corr: 0.02195
Epoch [28/100], Batch [80/147] train loss: 834.34, train corr: 0.02089
Epoch [28/100], Batch [81/147] train loss: 828.95, train corr: 0.01403
Epoch [28/100], Batch [82/147] train loss: 753.19, train corr: 0.02143
Epoch [28/100], Batch [83/147] train loss: 706.05, train corr: 0.02115
Epoch [28/100], Batch [84/147] train loss: 694.29, train corr: 0.01346
Epoch [28/100], Batch [85/147] train loss: 655.13, train corr: 0.01360
Epoch [28/100], Batch [86/147] train loss: 614.75, train corr: 0.00218
Epoch [28/100], Batch [87/147] train loss: 678.60, train corr: -0.02823
Epoch [28/100], Batch [88/147] train loss: 644.79, train corr: 0.01391
Epoch [28/100], Batch [89/147] train loss: 712.27, train corr: 0.02181
Epoch [28/100], Batch [90/147] train loss: 735.17, train corr: 0.02076
Epoch [28/100], Batch [91/147] train loss: 756.61, train corr: 0.02123
Epoch [28/100], Batch [92/147] train loss: 762.13, train corr: 0.02656
Epoch [28/100], Batch [93/147] train loss: 736.01, train corr: 0.02794
Epoch [28/100], Batch [94/147] train loss: 741.75, train corr: 0.02197
Epoch [28/100], Batch [95/147] train loss: 699.47, train corr: 0.02907
Epoch [28/100], Batch [96/147] train loss: 659.45, train corr: 0.02887
Epoch [28/100], Batch [97/147] train loss: 627.89, train corr: 0.03454
Epoch [28/100], Batch [98/147] train loss: 612.01, train corr: 0.00475
Epoch [28/100], Batch [99/147] train loss: 593.81, train corr: 0.02576
Epoch [28/100], Batch [100/147] train loss: 596.82, train corr: 0.03279
Epoch [28/100], Batch [101/147] train loss: 602.58, train corr: 0.02991
Epoch [28/100], Batch [102/147] train loss: 600.74, train corr: 0.02607
Epoch [28/100], Batch [103/147] train loss: 604.08, train corr: 0.01882
Epoch [28/100], Batch [104/147] train loss: 623.38, train corr: 0.00357
Epoch [28/100], Batch [105/147] train loss: 587.98, train corr: -0.00904
Epoch [28/100], Batch [106/147] train loss: 597.57, train corr: -0.00121
Epoch [28/100], Batch [107/147] train loss: 600.14, train corr: -0.00014
Epoch [28/100], Batch [108/147] train loss: 568.77, train corr: -0.01472
Epoch [28/100], Batch [109/147] train loss: 586.01, train corr: -0.02437
Epoch [28/100], Batch [110/147] train loss: 605.03, train corr: 0.01679
Epoch [28/100], Batch [111/147] train loss: 622.74, train corr: 0.02442
Epoch [28/100], Batch [112/147] train loss: 604.52, train corr: 0.02503
Epoch [28/100], Batch [113/147] train loss: 598.79, train corr: 0.02560
Epoch [28/100], Batch [114/147] train loss: 571.36, train corr: 0.03259
Epoch [28/100], Batch [115/147] train loss: 609.41, train corr: -0.00536
Epoch [28/100], Batch [116/147] train loss: 613.08, train corr: 0.02623
Epoch [28/100], Batch [117/147] train loss: 664.66, train corr: 0.02544
Epoch [28/100], Batch [118/147] train loss: 838.46, train corr: 0.02385
Epoch [28/100], Batch [119/147] train loss: 703.42, train corr: 0.02432
Epoch [28/100], Batch [120/147] train loss: 709.27, train corr: 0.02293
Epoch [28/100], Batch [121/147] train loss: 667.45, train corr: 0.02644
Epoch [28/100], Batch [122/147] train loss: 676.85, train corr: 0.02498
Epoch [28/100], Batch [123/147] train loss: 653.09, train corr: 0.02639
Epoch [28/100], Batch [124/147] train loss: 635.33, train corr: 0.02775
Epoch [28/100], Batch [125/147] train loss: 659.81, train corr: 0.02524
Epoch [28/100], Batch [126/147] train loss: 626.28, train corr: 0.02743
Epoch [28/100], Batch [127/147] train loss: 607.52, train corr: 0.02690
Epoch [28/100], Batch [128/147] train loss: 585.84, train corr: 0.02868
Epoch [28/100], Batch [129/147] train loss: 572.85, train corr: 0.03376
Epoch [28/100], Batch [130/147] train loss: 713.03, train corr: -0.01599
Epoch [28/100], Batch [131/147] train loss: 707.19, train corr: 0.02323
Epoch [28/100], Batch [132/147] train loss: 807.12, train corr: 0.02490
Epoch [28/100], Batch [133/147] train loss: 907.76, train corr: 0.02403
Epoch [28/100], Batch [134/147] train loss: 969.27, train corr: 0.02184
Epoch [28/100], Batch [135/147] train loss: 992.67, train corr: 0.02526
Epoch [28/100], Batch [136/147] train loss: 1009.78, train corr: 0.02371
Epoch [28/100], Batch [137/147] train loss: 1009.58, train corr: 0.02833
Epoch [28/100], Batch [138/147] train loss: 980.57, train corr: 0.02514
Epoch [28/100], Batch [139/147] train loss: 1005.06, train corr: 0.02435
Epoch [28/100], Batch [140/147] train loss: 1121.30, train corr: 0.02464
Epoch [28/100], Batch [141/147] train loss: 937.58, train corr: 0.02792
Epoch [28/100], Batch [142/147] train loss: 890.74, train corr: 0.02434
Epoch [28/100], Batch [143/147] train loss: 828.99, train corr: 0.02191
Epoch [28/100], Batch [144/147] train loss: 767.82, train corr: 0.02675
Epoch [28/100], Batch [145/147] train loss: 772.30, train corr: 0.02763
Epoch [28/100], Batch [146/147] train loss: 787.20, train corr: 0.02941
Epoch [28/100], Batch [147/147] train loss: 1767.39, train corr: 0.02618
Epoch [28/100], validation loss: 688.73, validation correlation: 0.02498
Epoch [29/100], Batch [1/147] train loss: 658.64, train corr: 0.02546
Epoch [29/100], Batch [2/147] train loss: 646.58, train corr: 0.01392
Epoch [29/100], Batch [3/147] train loss: 633.89, train corr: -0.01166
Epoch [29/100], Batch [4/147] train loss: 734.34, train corr: -0.02613
Epoch [29/100], Batch [5/147] train loss: 792.50, train corr: 0.00605
Epoch [29/100], Batch [6/147] train loss: 1000.48, train corr: 0.01093
Epoch [29/100], Batch [7/147] train loss: 1098.14, train corr: 0.01511
Epoch [29/100], Batch [8/147] train loss: 1151.83, train corr: 0.01774
Epoch [29/100], Batch [9/147] train loss: 1221.62, train corr: 0.01776
Epoch [29/100], Batch [10/147] train loss: 1260.94, train corr: 0.02096
Epoch [29/100], Batch [11/147] train loss: 1349.20, train corr: 0.01566
Epoch [29/100], Batch [12/147] train loss: 1291.23, train corr: 0.01933
Epoch [29/100], Batch [13/147] train loss: 1297.17, train corr: 0.01931
Epoch [29/100], Batch [14/147] train loss: 1283.45, train corr: 0.01917
Epoch [29/100], Batch [15/147] train loss: 1287.36, train corr: 0.02073
Epoch [29/100], Batch [16/147] train loss: 1250.62, train corr: 0.02126
Epoch [29/100], Batch [17/147] train loss: 1214.82, train corr: 0.01686
Epoch [29/100], Batch [18/147] train loss: 1136.38, train corr: 0.01768
Epoch [29/100], Batch [19/147] train loss: 1091.69, train corr: 0.01708
Epoch [29/100], Batch [20/147] train loss: 1085.98, train corr: 0.01187
Epoch [29/100], Batch [21/147] train loss: 977.95, train corr: 0.01843
Epoch [29/100], Batch [22/147] train loss: 914.44, train corr: 0.01936
Epoch [29/100], Batch [23/147] train loss: 876.19, train corr: 0.00771
Epoch [29/100], Batch [24/147] train loss: 804.46, train corr: 0.00978
Epoch [29/100], Batch [25/147] train loss: 846.05, train corr: 0.00320
Epoch [29/100], Batch [26/147] train loss: 826.68, train corr: 0.00024
Epoch [29/100], Batch [27/147] train loss: 685.13, train corr: -0.00628
Epoch [29/100], Batch [28/147] train loss: 636.01, train corr: -0.01188
Epoch [29/100], Batch [29/147] train loss: 653.63, train corr: -0.02274
Epoch [29/100], Batch [30/147] train loss: 705.64, train corr: -0.02869
Epoch [29/100], Batch [31/147] train loss: 690.55, train corr: -0.02154
Epoch [29/100], Batch [32/147] train loss: 716.57, train corr: -0.01208
Epoch [29/100], Batch [33/147] train loss: 770.14, train corr: -0.01070
Epoch [29/100], Batch [34/147] train loss: 783.40, train corr: -0.00451
Epoch [29/100], Batch [35/147] train loss: 799.68, train corr: -0.00916
Epoch [29/100], Batch [36/147] train loss: 773.12, train corr: -0.00922
Epoch [29/100], Batch [37/147] train loss: 748.83, train corr: -0.01874
Epoch [29/100], Batch [38/147] train loss: 739.72, train corr: -0.02865
Epoch [29/100], Batch [39/147] train loss: 703.30, train corr: -0.03341
Epoch [29/100], Batch [40/147] train loss: 835.62, train corr: -0.03403
Epoch [29/100], Batch [41/147] train loss: 743.92, train corr: -0.01465
Epoch [29/100], Batch [42/147] train loss: 801.38, train corr: 0.00980
Epoch [29/100], Batch [43/147] train loss: 896.35, train corr: 0.01730
Epoch [29/100], Batch [44/147] train loss: 1001.73, train corr: 0.01853
Epoch [29/100], Batch [45/147] train loss: 918.77, train corr: 0.02055
Epoch [29/100], Batch [46/147] train loss: 925.25, train corr: 0.02056
Epoch [29/100], Batch [47/147] train loss: 917.12, train corr: 0.01979
Epoch [29/100], Batch [48/147] train loss: 905.21, train corr: 0.02117
Epoch [29/100], Batch [49/147] train loss: 886.31, train corr: 0.01973
Epoch [29/100], Batch [50/147] train loss: 869.89, train corr: 0.01862
Epoch [29/100], Batch [51/147] train loss: 819.50, train corr: 0.02038
Epoch [29/100], Batch [52/147] train loss: 769.82, train corr: 0.02289
Epoch [29/100], Batch [53/147] train loss: 885.39, train corr: 0.02198
Epoch [29/100], Batch [54/147] train loss: 700.53, train corr: 0.02100
Epoch [29/100], Batch [55/147] train loss: 657.48, train corr: 0.02070
Epoch [29/100], Batch [56/147] train loss: 761.78, train corr: 0.02104
Epoch [29/100], Batch [57/147] train loss: 613.10, train corr: 0.01198
Epoch [29/100], Batch [58/147] train loss: 596.47, train corr: -0.02058
Epoch [29/100], Batch [59/147] train loss: 583.54, train corr: -0.03221
Epoch [29/100], Batch [60/147] train loss: 589.78, train corr: -0.02779
Epoch [29/100], Batch [61/147] train loss: 855.84, train corr: -0.02248
Epoch [29/100], Batch [62/147] train loss: 628.67, train corr: -0.01537
Epoch [29/100], Batch [63/147] train loss: 640.01, train corr: -0.00062
Epoch [29/100], Batch [64/147] train loss: 637.51, train corr: -0.00225
Epoch [29/100], Batch [65/147] train loss: 639.70, train corr: -0.00975
Epoch [29/100], Batch [66/147] train loss: 619.85, train corr: -0.01613
Epoch [29/100], Batch [67/147] train loss: 619.76, train corr: -0.01503
Epoch [29/100], Batch [68/147] train loss: 608.61, train corr: -0.00604
Epoch [29/100], Batch [69/147] train loss: 634.05, train corr: 0.00030
Epoch [29/100], Batch [70/147] train loss: 606.84, train corr: -0.00832
Epoch [29/100], Batch [71/147] train loss: 615.86, train corr: 0.00217
Epoch [29/100], Batch [72/147] train loss: 595.64, train corr: 0.00336
Epoch [29/100], Batch [73/147] train loss: 578.30, train corr: 0.00732
Epoch [29/100], Batch [74/147] train loss: 590.85, train corr: 0.00554
Epoch [29/100], Batch [75/147] train loss: 583.44, train corr: 0.00211
Epoch [29/100], Batch [76/147] train loss: 592.03, train corr: 0.00878
Epoch [29/100], Batch [77/147] train loss: 571.21, train corr: 0.01575
Epoch [29/100], Batch [78/147] train loss: 587.64, train corr: 0.01490
Epoch [29/100], Batch [79/147] train loss: 593.68, train corr: 0.01110
Epoch [29/100], Batch [80/147] train loss: 588.47, train corr: 0.00683
Epoch [29/100], Batch [81/147] train loss: 573.97, train corr: 0.01408
Epoch [29/100], Batch [82/147] train loss: 574.37, train corr: 0.01591
Epoch [29/100], Batch [83/147] train loss: 582.72, train corr: 0.01397
Epoch [29/100], Batch [84/147] train loss: 594.35, train corr: 0.00849
Epoch [29/100], Batch [85/147] train loss: 599.66, train corr: 0.02827
Epoch [29/100], Batch [86/147] train loss: 584.33, train corr: 0.03011
Epoch [29/100], Batch [87/147] train loss: 580.12, train corr: 0.02637
Epoch [29/100], Batch [88/147] train loss: 574.41, train corr: 0.00012
Epoch [29/100], Batch [89/147] train loss: 583.45, train corr: 0.00924
Epoch [29/100], Batch [90/147] train loss: 574.16, train corr: 0.01813
Epoch [29/100], Batch [91/147] train loss: 562.66, train corr: 0.01935
Epoch [29/100], Batch [92/147] train loss: 577.44, train corr: 0.00980
Epoch [29/100], Batch [93/147] train loss: 578.32, train corr: 0.00195
Epoch [29/100], Batch [94/147] train loss: 560.29, train corr: 0.02306
Epoch [29/100], Batch [95/147] train loss: 572.91, train corr: 0.02699
Epoch [29/100], Batch [96/147] train loss: 570.60, train corr: 0.01379
Epoch [29/100], Batch [97/147] train loss: 576.52, train corr: -0.00840
Epoch [29/100], Batch [98/147] train loss: 580.65, train corr: 0.02474
Epoch [29/100], Batch [99/147] train loss: 586.26, train corr: 0.02244
Epoch [29/100], Batch [100/147] train loss: 583.77, train corr: 0.02238
Epoch [29/100], Batch [101/147] train loss: 571.25, train corr: -0.02192
Epoch [29/100], Batch [102/147] train loss: 593.09, train corr: 0.02356
Epoch [29/100], Batch [103/147] train loss: 579.23, train corr: 0.02523
Epoch [29/100], Batch [104/147] train loss: 596.05, train corr: 0.02520
Epoch [29/100], Batch [105/147] train loss: 583.99, train corr: 0.03309
Epoch [29/100], Batch [106/147] train loss: 584.17, train corr: 0.02677
Epoch [29/100], Batch [107/147] train loss: 623.59, train corr: -0.01608
Epoch [29/100], Batch [108/147] train loss: 655.40, train corr: 0.02378
Epoch [29/100], Batch [109/147] train loss: 735.46, train corr: 0.02588
Epoch [29/100], Batch [110/147] train loss: 813.48, train corr: 0.02462
Epoch [29/100], Batch [111/147] train loss: 884.87, train corr: 0.02564
Epoch [29/100], Batch [112/147] train loss: 889.98, train corr: 0.02142
Epoch [29/100], Batch [113/147] train loss: 923.86, train corr: 0.02465
Epoch [29/100], Batch [114/147] train loss: 923.35, train corr: 0.02457
Epoch [29/100], Batch [115/147] train loss: 939.92, train corr: 0.02379
Epoch [29/100], Batch [116/147] train loss: 935.87, train corr: 0.02402
Epoch [29/100], Batch [117/147] train loss: 909.43, train corr: 0.02435
Epoch [29/100], Batch [118/147] train loss: 874.82, train corr: 0.02598
Epoch [29/100], Batch [119/147] train loss: 839.59, train corr: 0.02033
Epoch [29/100], Batch [120/147] train loss: 794.01, train corr: 0.02465
Epoch [29/100], Batch [121/147] train loss: 786.87, train corr: 0.02353
Epoch [29/100], Batch [122/147] train loss: 729.11, train corr: 0.02462
Epoch [29/100], Batch [123/147] train loss: 727.98, train corr: 0.02634
Epoch [29/100], Batch [124/147] train loss: 707.49, train corr: 0.02873
Epoch [29/100], Batch [125/147] train loss: 651.53, train corr: 0.02611
Epoch [29/100], Batch [126/147] train loss: 639.47, train corr: 0.02772
Epoch [29/100], Batch [127/147] train loss: 627.58, train corr: 0.02499
Epoch [29/100], Batch [128/147] train loss: 590.01, train corr: 0.02574
Epoch [29/100], Batch [129/147] train loss: 597.55, train corr: -0.00801
Epoch [29/100], Batch [130/147] train loss: 881.57, train corr: -0.00782
Epoch [29/100], Batch [131/147] train loss: 628.07, train corr: -0.01415
Epoch [29/100], Batch [132/147] train loss: 608.93, train corr: -0.00878
Epoch [29/100], Batch [133/147] train loss: 604.71, train corr: -0.00908
Epoch [29/100], Batch [134/147] train loss: 616.76, train corr: -0.01401
Epoch [29/100], Batch [135/147] train loss: 620.81, train corr: -0.02290
Epoch [29/100], Batch [136/147] train loss: 622.13, train corr: 0.01492
Epoch [29/100], Batch [137/147] train loss: 650.96, train corr: 0.02391
Epoch [29/100], Batch [138/147] train loss: 666.23, train corr: 0.02407
Epoch [29/100], Batch [139/147] train loss: 688.08, train corr: 0.02475
Epoch [29/100], Batch [140/147] train loss: 672.98, train corr: 0.02434
Epoch [29/100], Batch [141/147] train loss: 672.67, train corr: 0.01913
Epoch [29/100], Batch [142/147] train loss: 617.41, train corr: 0.02670
Epoch [29/100], Batch [143/147] train loss: 646.02, train corr: 0.01985
Epoch [29/100], Batch [144/147] train loss: 597.74, train corr: 0.01128
Epoch [29/100], Batch [145/147] train loss: 579.51, train corr: 0.00863
Epoch [29/100], Batch [146/147] train loss: 579.29, train corr: 0.00282
Epoch [29/100], Batch [147/147] train loss: 552.90, train corr: -0.00369
Epoch [29/100], validation loss: 619.47, validation correlation: -0.00987
Epoch [30/100], Batch [1/147] train loss: 584.46, train corr: -0.00814
Epoch [30/100], Batch [2/147] train loss: 585.88, train corr: -0.00127
Epoch [30/100], Batch [3/147] train loss: 604.26, train corr: 0.00149
Epoch [30/100], Batch [4/147] train loss: 583.96, train corr: -0.00935
Epoch [30/100], Batch [5/147] train loss: 583.27, train corr: 0.00780
Epoch [30/100], Batch [6/147] train loss: 590.98, train corr: 0.01274
Epoch [30/100], Batch [7/147] train loss: 583.09, train corr: 0.00429
Epoch [30/100], Batch [8/147] train loss: 596.36, train corr: 0.00111
Epoch [30/100], Batch [9/147] train loss: 602.36, train corr: 0.02564
Epoch [30/100], Batch [10/147] train loss: 596.05, train corr: 0.02794
Epoch [30/100], Batch [11/147] train loss: 604.05, train corr: 0.02658
Epoch [30/100], Batch [12/147] train loss: 578.70, train corr: 0.02342
Epoch [30/100], Batch [13/147] train loss: 578.39, train corr: -0.01092
Epoch [30/100], Batch [14/147] train loss: 580.97, train corr: 0.01520
Epoch [30/100], Batch [15/147] train loss: 584.77, train corr: 0.02289
Epoch [30/100], Batch [16/147] train loss: 595.83, train corr: 0.02216
Epoch [30/100], Batch [17/147] train loss: 572.47, train corr: 0.00990
Epoch [30/100], Batch [18/147] train loss: 591.38, train corr: -0.01070
Epoch [30/100], Batch [19/147] train loss: 576.11, train corr: 0.02353
Epoch [30/100], Batch [20/147] train loss: 595.16, train corr: 0.02037
Epoch [30/100], Batch [21/147] train loss: 578.96, train corr: 0.02385
Epoch [30/100], Batch [22/147] train loss: 586.05, train corr: 0.02001
Epoch [30/100], Batch [23/147] train loss: 581.70, train corr: 0.00827
Epoch [30/100], Batch [24/147] train loss: 712.54, train corr: -0.02459
Epoch [30/100], Batch [25/147] train loss: 759.08, train corr: 0.02489
Epoch [30/100], Batch [26/147] train loss: 952.66, train corr: 0.02455
Epoch [30/100], Batch [27/147] train loss: 1035.03, train corr: 0.02695
Epoch [30/100], Batch [28/147] train loss: 1220.02, train corr: 0.02532
Epoch [30/100], Batch [29/147] train loss: 1319.38, train corr: 0.02710
Epoch [30/100], Batch [30/147] train loss: 1392.31, train corr: 0.02183
Epoch [30/100], Batch [31/147] train loss: 1360.76, train corr: 0.02420
Epoch [30/100], Batch [32/147] train loss: 1437.03, train corr: 0.02507
Epoch [30/100], Batch [33/147] train loss: 1548.29, train corr: 0.02289
Epoch [30/100], Batch [34/147] train loss: 1489.03, train corr: 0.02772
Epoch [30/100], Batch [35/147] train loss: 1480.11, train corr: 0.02345
Epoch [30/100], Batch [36/147] train loss: 1492.01, train corr: 0.02255
Epoch [30/100], Batch [37/147] train loss: 1401.91, train corr: 0.02551
Epoch [30/100], Batch [38/147] train loss: 1426.37, train corr: 0.02633
Epoch [30/100], Batch [39/147] train loss: 1363.61, train corr: 0.02225
Epoch [30/100], Batch [40/147] train loss: 1390.91, train corr: 0.02093
Epoch [30/100], Batch [41/147] train loss: 1325.91, train corr: 0.02351
Epoch [30/100], Batch [42/147] train loss: 1315.86, train corr: 0.02596
Epoch [30/100], Batch [43/147] train loss: 1255.07, train corr: 0.02323
Epoch [30/100], Batch [44/147] train loss: 1506.84, train corr: 0.02455
Epoch [30/100], Batch [45/147] train loss: 1126.91, train corr: 0.02390
Epoch [30/100], Batch [46/147] train loss: 1036.21, train corr: 0.02801
Epoch [30/100], Batch [47/147] train loss: 1019.19, train corr: 0.02581
Epoch [30/100], Batch [48/147] train loss: 1037.16, train corr: 0.01865
Epoch [30/100], Batch [49/147] train loss: 957.83, train corr: 0.02780
Epoch [30/100], Batch [50/147] train loss: 903.04, train corr: 0.02990
Epoch [30/100], Batch [51/147] train loss: 853.65, train corr: 0.02773
Epoch [30/100], Batch [52/147] train loss: 811.85, train corr: 0.02875
Epoch [30/100], Batch [53/147] train loss: 781.53, train corr: 0.02482
Epoch [30/100], Batch [54/147] train loss: 777.93, train corr: 0.02615
Epoch [30/100], Batch [55/147] train loss: 749.84, train corr: 0.02814
Epoch [30/100], Batch [56/147] train loss: 750.53, train corr: 0.02724
Epoch [30/100], Batch [57/147] train loss: 689.43, train corr: 0.02984
Epoch [30/100], Batch [58/147] train loss: 650.47, train corr: 0.03279
Epoch [30/100], Batch [59/147] train loss: 635.16, train corr: 0.03015
Epoch [30/100], Batch [60/147] train loss: 668.57, train corr: 0.03185
Epoch [30/100], Batch [61/147] train loss: 646.21, train corr: 0.03172
Epoch [30/100], Batch [62/147] train loss: 651.97, train corr: 0.03528
Epoch [30/100], Batch [63/147] train loss: 654.24, train corr: 0.03313
Epoch [30/100], Batch [64/147] train loss: 656.04, train corr: 0.01952
Epoch [30/100], Batch [65/147] train loss: 661.05, train corr: -0.00953
Epoch [30/100], Batch [66/147] train loss: 686.61, train corr: 0.03338
Epoch [30/100], Batch [67/147] train loss: 697.46, train corr: 0.03294
Epoch [30/100], Batch [68/147] train loss: 762.92, train corr: 0.02753
Epoch [30/100], Batch [69/147] train loss: 704.19, train corr: 0.03269
Epoch [30/100], Batch [70/147] train loss: 699.11, train corr: 0.03221
Epoch [30/100], Batch [71/147] train loss: 690.13, train corr: 0.03094
Epoch [30/100], Batch [72/147] train loss: 668.55, train corr: 0.03417
Epoch [30/100], Batch [73/147] train loss: 629.14, train corr: 0.01172
Epoch [30/100], Batch [74/147] train loss: 862.98, train corr: -0.01074
Epoch [30/100], Batch [75/147] train loss: 708.66, train corr: 0.02944
Epoch [30/100], Batch [76/147] train loss: 747.65, train corr: 0.02872
Epoch [30/100], Batch [77/147] train loss: 824.19, train corr: 0.02718
Epoch [30/100], Batch [78/147] train loss: 827.22, train corr: 0.02886
Epoch [30/100], Batch [79/147] train loss: 930.90, train corr: 0.02837
Epoch [30/100], Batch [80/147] train loss: 891.15, train corr: 0.02503
Epoch [30/100], Batch [81/147] train loss: 942.25, train corr: 0.02271
Epoch [30/100], Batch [82/147] train loss: 881.79, train corr: 0.02554
Epoch [30/100], Batch [83/147] train loss: 1032.39, train corr: 0.02164
Epoch [30/100], Batch [84/147] train loss: 876.68, train corr: 0.02796
Epoch [30/100], Batch [85/147] train loss: 846.20, train corr: 0.02653
Epoch [30/100], Batch [86/147] train loss: 865.82, train corr: 0.02289
Epoch [30/100], Batch [87/147] train loss: 816.71, train corr: 0.02297
Epoch [30/100], Batch [88/147] train loss: 828.52, train corr: 0.02436
Epoch [30/100], Batch [89/147] train loss: 765.80, train corr: 0.02567
Epoch [30/100], Batch [90/147] train loss: 715.33, train corr: 0.02838
Epoch [30/100], Batch [91/147] train loss: 750.24, train corr: 0.02378
Epoch [30/100], Batch [92/147] train loss: 698.60, train corr: 0.02851
Epoch [30/100], Batch [93/147] train loss: 703.41, train corr: 0.02524
Epoch [30/100], Batch [94/147] train loss: 672.78, train corr: 0.02599
Epoch [30/100], Batch [95/147] train loss: 654.37, train corr: 0.03078
Epoch [30/100], Batch [96/147] train loss: 636.32, train corr: 0.02781
Epoch [30/100], Batch [97/147] train loss: 594.48, train corr: 0.02835
Epoch [30/100], Batch [98/147] train loss: 596.83, train corr: 0.02331
Epoch [30/100], Batch [99/147] train loss: 698.77, train corr: -0.01414
Epoch [30/100], Batch [100/147] train loss: 644.20, train corr: 0.02544
Epoch [30/100], Batch [101/147] train loss: 1195.55, train corr: 0.02253
Epoch [30/100], Batch [102/147] train loss: 753.52, train corr: 0.02578
Epoch [30/100], Batch [103/147] train loss: 813.19, train corr: 0.02207
Epoch [30/100], Batch [104/147] train loss: 806.19, train corr: 0.02340
Epoch [30/100], Batch [105/147] train loss: 787.53, train corr: 0.02498
Epoch [30/100], Batch [106/147] train loss: 792.32, train corr: 0.02057
Epoch [30/100], Batch [107/147] train loss: 768.71, train corr: 0.02721
Epoch [30/100], Batch [108/147] train loss: 729.90, train corr: 0.02582
Epoch [30/100], Batch [109/147] train loss: 1377.51, train corr: 0.01836
Epoch [30/100], Batch [110/147] train loss: 665.67, train corr: 0.02155
Epoch [30/100], Batch [111/147] train loss: 635.24, train corr: 0.02125
Epoch [30/100], Batch [112/147] train loss: 663.06, train corr: -0.02804
Epoch [30/100], Batch [113/147] train loss: 585.86, train corr: 0.02227
Epoch [30/100], Batch [114/147] train loss: 618.21, train corr: 0.02363
Epoch [30/100], Batch [115/147] train loss: 639.15, train corr: 0.02467
Epoch [30/100], Batch [116/147] train loss: 641.66, train corr: 0.01816
Epoch [30/100], Batch [117/147] train loss: 627.50, train corr: 0.02338
Epoch [30/100], Batch [118/147] train loss: 618.26, train corr: 0.02552
Epoch [30/100], Batch [119/147] train loss: 622.28, train corr: 0.02060
Epoch [30/100], Batch [120/147] train loss: 606.25, train corr: 0.02128
Epoch [30/100], Batch [121/147] train loss: 802.37, train corr: -0.01992
Epoch [30/100], Batch [122/147] train loss: 780.21, train corr: 0.02597
Epoch [30/100], Batch [123/147] train loss: 968.77, train corr: 0.02384
Epoch [30/100], Batch [124/147] train loss: 1129.06, train corr: 0.02652
Epoch [30/100], Batch [125/147] train loss: 1257.91, train corr: 0.02581
Epoch [30/100], Batch [126/147] train loss: 1329.42, train corr: 0.02344
Epoch [30/100], Batch [127/147] train loss: 1520.78, train corr: 0.01753
Epoch [30/100], Batch [128/147] train loss: 1471.31, train corr: 0.02578
Epoch [30/100], Batch [129/147] train loss: 1526.18, train corr: 0.02519
Epoch [30/100], Batch [130/147] train loss: 1545.51, train corr: 0.02123
Epoch [30/100], Batch [131/147] train loss: 1532.50, train corr: 0.02669
Epoch [30/100], Batch [132/147] train loss: 1586.08, train corr: 0.02311
Epoch [30/100], Batch [133/147] train loss: 1571.70, train corr: 0.02510
Epoch [30/100], Batch [134/147] train loss: 1664.47, train corr: 0.01756
Epoch [30/100], Batch [135/147] train loss: 1510.50, train corr: 0.02424
Epoch [30/100], Batch [136/147] train loss: 1494.76, train corr: 0.02397
Epoch [30/100], Batch [137/147] train loss: 1513.37, train corr: 0.02048
Epoch [30/100], Batch [138/147] train loss: 1456.39, train corr: 0.02675
Epoch [30/100], Batch [139/147] train loss: 1344.28, train corr: 0.02781
Epoch [30/100], Batch [140/147] train loss: 1318.29, train corr: 0.02533
Epoch [30/100], Batch [141/147] train loss: 1267.31, train corr: 0.02512
Epoch [30/100], Batch [142/147] train loss: 1230.17, train corr: 0.02658
Epoch [30/100], Batch [143/147] train loss: 1204.98, train corr: 0.02234
Epoch [30/100], Batch [144/147] train loss: 1173.72, train corr: 0.02361
Epoch [30/100], Batch [145/147] train loss: 1085.26, train corr: 0.02490
Epoch [30/100], Batch [146/147] train loss: 999.28, train corr: 0.02388
Epoch [30/100], Batch [147/147] train loss: 938.70, train corr: 0.02690
Epoch [30/100], validation loss: 986.89, validation correlation: 0.02597
Epoch [31/100], Batch [1/147] train loss: 1810.92, train corr: 0.02277
Epoch [31/100], Batch [2/147] train loss: 926.70, train corr: 0.02259
Epoch [31/100], Batch [3/147] train loss: 881.63, train corr: 0.02478
Epoch [31/100], Batch [4/147] train loss: 797.75, train corr: 0.02219
Epoch [31/100], Batch [5/147] train loss: 747.00, train corr: 0.02498
Epoch [31/100], Batch [6/147] train loss: 733.26, train corr: 0.02684
Epoch [31/100], Batch [7/147] train loss: 692.15, train corr: 0.02693
Epoch [31/100], Batch [8/147] train loss: 713.66, train corr: 0.02638
Epoch [31/100], Batch [9/147] train loss: 628.71, train corr: 0.02975
Epoch [31/100], Batch [10/147] train loss: 670.45, train corr: 0.03392
Epoch [31/100], Batch [11/147] train loss: 654.19, train corr: 0.03026
Epoch [31/100], Batch [12/147] train loss: 661.34, train corr: 0.03177
Epoch [31/100], Batch [13/147] train loss: 674.34, train corr: 0.03226
Epoch [31/100], Batch [14/147] train loss: 714.29, train corr: 0.02993
Epoch [31/100], Batch [15/147] train loss: 718.25, train corr: 0.02839
Epoch [31/100], Batch [16/147] train loss: 745.63, train corr: 0.02886
Epoch [31/100], Batch [17/147] train loss: 690.60, train corr: 0.03258
Epoch [31/100], Batch [18/147] train loss: 672.88, train corr: 0.03558
Epoch [31/100], Batch [19/147] train loss: 663.94, train corr: 0.02897
Epoch [31/100], Batch [20/147] train loss: 716.54, train corr: 0.01039
Epoch [31/100], Batch [21/147] train loss: 656.84, train corr: 0.03183
Epoch [31/100], Batch [22/147] train loss: 736.78, train corr: 0.03035
Epoch [31/100], Batch [23/147] train loss: 738.30, train corr: 0.02951
Epoch [31/100], Batch [24/147] train loss: 791.26, train corr: 0.02921
Epoch [31/100], Batch [25/147] train loss: 783.93, train corr: 0.02797
Epoch [31/100], Batch [26/147] train loss: 806.50, train corr: 0.03003
Epoch [31/100], Batch [27/147] train loss: 808.81, train corr: 0.02894
Epoch [31/100], Batch [28/147] train loss: 783.31, train corr: 0.02717
Epoch [31/100], Batch [29/147] train loss: 765.07, train corr: 0.02686
Epoch [31/100], Batch [30/147] train loss: 763.11, train corr: 0.02840
Epoch [31/100], Batch [31/147] train loss: 738.60, train corr: 0.02943
Epoch [31/100], Batch [32/147] train loss: 739.53, train corr: 0.02698
Epoch [31/100], Batch [33/147] train loss: 726.04, train corr: 0.02749
Epoch [31/100], Batch [34/147] train loss: 743.42, train corr: 0.02619
Epoch [31/100], Batch [35/147] train loss: 693.57, train corr: 0.02692
Epoch [31/100], Batch [36/147] train loss: 691.02, train corr: 0.02317
Epoch [31/100], Batch [37/147] train loss: 657.71, train corr: 0.02703
Epoch [31/100], Batch [38/147] train loss: 667.28, train corr: 0.02752
Epoch [31/100], Batch [39/147] train loss: 639.67, train corr: 0.02781
Epoch [31/100], Batch [40/147] train loss: 604.88, train corr: 0.02744
Epoch [31/100], Batch [41/147] train loss: 585.84, train corr: 0.00994
Epoch [31/100], Batch [42/147] train loss: 702.22, train corr: -0.01289
Epoch [31/100], Batch [43/147] train loss: 662.01, train corr: 0.02447
Epoch [31/100], Batch [44/147] train loss: 718.53, train corr: 0.02729
Epoch [31/100], Batch [45/147] train loss: 820.73, train corr: 0.02425
Epoch [31/100], Batch [46/147] train loss: 877.27, train corr: 0.02423
Epoch [31/100], Batch [47/147] train loss: 898.09, train corr: 0.02518
Epoch [31/100], Batch [48/147] train loss: 926.69, train corr: 0.02691
Epoch [31/100], Batch [49/147] train loss: 930.56, train corr: 0.02191
Epoch [31/100], Batch [50/147] train loss: 913.04, train corr: 0.02589
Epoch [31/100], Batch [51/147] train loss: 1111.40, train corr: 0.02326
Epoch [31/100], Batch [52/147] train loss: 923.98, train corr: 0.02398
Epoch [31/100], Batch [53/147] train loss: 874.52, train corr: 0.02377
Epoch [31/100], Batch [54/147] train loss: 829.59, train corr: 0.02385
Epoch [31/100], Batch [55/147] train loss: 779.77, train corr: 0.02634
Epoch [31/100], Batch [56/147] train loss: 765.80, train corr: 0.02441
Epoch [31/100], Batch [57/147] train loss: 1279.69, train corr: 0.02278
Epoch [31/100], Batch [58/147] train loss: 685.74, train corr: 0.02777
Epoch [31/100], Batch [59/147] train loss: 687.51, train corr: 0.02495
Epoch [31/100], Batch [60/147] train loss: 655.33, train corr: 0.02574
Epoch [31/100], Batch [61/147] train loss: 608.08, train corr: 0.02312
Epoch [31/100], Batch [62/147] train loss: 714.73, train corr: -0.02370
Epoch [31/100], Batch [63/147] train loss: 725.69, train corr: 0.02547
Epoch [31/100], Batch [64/147] train loss: 883.88, train corr: 0.02401
Epoch [31/100], Batch [65/147] train loss: 1036.84, train corr: 0.02585
Epoch [31/100], Batch [66/147] train loss: 1116.93, train corr: 0.02562
Epoch [31/100], Batch [67/147] train loss: 1196.41, train corr: 0.02620
Epoch [31/100], Batch [68/147] train loss: 1321.73, train corr: 0.02142
Epoch [31/100], Batch [69/147] train loss: 1388.69, train corr: 0.02384
Epoch [31/100], Batch [70/147] train loss: 1330.37, train corr: 0.02571
Epoch [31/100], Batch [71/147] train loss: 1415.19, train corr: 0.01982
Epoch [31/100], Batch [72/147] train loss: 1363.35, train corr: 0.02463
Epoch [31/100], Batch [73/147] train loss: 1370.13, train corr: 0.02488
Epoch [31/100], Batch [74/147] train loss: 1438.23, train corr: 0.02673
Epoch [31/100], Batch [75/147] train loss: 1342.13, train corr: 0.02519
Epoch [31/100], Batch [76/147] train loss: 1334.01, train corr: 0.02391
Epoch [31/100], Batch [77/147] train loss: 1315.31, train corr: 0.02712
Epoch [31/100], Batch [78/147] train loss: 1338.02, train corr: 0.02002
Epoch [31/100], Batch [79/147] train loss: 1289.63, train corr: 0.01990
Epoch [31/100], Batch [80/147] train loss: 1387.05, train corr: 0.02146
Epoch [31/100], Batch [81/147] train loss: 1187.28, train corr: 0.02578
Epoch [31/100], Batch [82/147] train loss: 1169.18, train corr: 0.01705
Epoch [31/100], Batch [83/147] train loss: 1080.82, train corr: 0.02499
Epoch [31/100], Batch [84/147] train loss: 1010.08, train corr: 0.02697
Epoch [31/100], Batch [85/147] train loss: 969.67, train corr: 0.02625
Epoch [31/100], Batch [86/147] train loss: 934.42, train corr: 0.02619
Epoch [31/100], Batch [87/147] train loss: 858.49, train corr: 0.02720
Epoch [31/100], Batch [88/147] train loss: 832.57, train corr: 0.02652
Epoch [31/100], Batch [89/147] train loss: 752.49, train corr: 0.02618
Epoch [31/100], Batch [90/147] train loss: 731.40, train corr: 0.02244
Epoch [31/100], Batch [91/147] train loss: 721.60, train corr: 0.02715
Epoch [31/100], Batch [92/147] train loss: 692.80, train corr: 0.02613
Epoch [31/100], Batch [93/147] train loss: 628.40, train corr: 0.02777
Epoch [31/100], Batch [94/147] train loss: 610.98, train corr: 0.03014
Epoch [31/100], Batch [95/147] train loss: 686.77, train corr: 0.01136
Epoch [31/100], Batch [96/147] train loss: 642.47, train corr: 0.02688
Epoch [31/100], Batch [97/147] train loss: 726.83, train corr: 0.02588
Epoch [31/100], Batch [98/147] train loss: 755.59, train corr: 0.02668
Epoch [31/100], Batch [99/147] train loss: 804.60, train corr: 0.02584
Epoch [31/100], Batch [100/147] train loss: 858.56, train corr: 0.02206
Epoch [31/100], Batch [101/147] train loss: 827.18, train corr: 0.02467
Epoch [31/100], Batch [102/147] train loss: 819.20, train corr: 0.02398
Epoch [31/100], Batch [103/147] train loss: 794.30, train corr: 0.02524
Epoch [31/100], Batch [104/147] train loss: 810.82, train corr: 0.02238
Epoch [31/100], Batch [105/147] train loss: 785.05, train corr: 0.01867
Epoch [31/100], Batch [106/147] train loss: 736.89, train corr: 0.02168
Epoch [31/100], Batch [107/147] train loss: 708.08, train corr: 0.02523
Epoch [31/100], Batch [108/147] train loss: 669.75, train corr: 0.02170
Epoch [31/100], Batch [109/147] train loss: 638.57, train corr: 0.01490
Epoch [31/100], Batch [110/147] train loss: 597.36, train corr: 0.00401
Epoch [31/100], Batch [111/147] train loss: 873.65, train corr: -0.01380
Epoch [31/100], Batch [112/147] train loss: 633.07, train corr: 0.01586
Epoch [31/100], Batch [113/147] train loss: 666.47, train corr: 0.02443
Epoch [31/100], Batch [114/147] train loss: 756.43, train corr: 0.02272
Epoch [31/100], Batch [115/147] train loss: 776.20, train corr: 0.02269
Epoch [31/100], Batch [116/147] train loss: 808.77, train corr: 0.02381
Epoch [31/100], Batch [117/147] train loss: 819.57, train corr: 0.02121
Epoch [31/100], Batch [118/147] train loss: 824.82, train corr: 0.02025
Epoch [31/100], Batch [119/147] train loss: 822.26, train corr: 0.02235
Epoch [31/100], Batch [120/147] train loss: 833.49, train corr: 0.02637
Epoch [31/100], Batch [121/147] train loss: 791.95, train corr: 0.02576
Epoch [31/100], Batch [122/147] train loss: 798.64, train corr: 0.02728
Epoch [31/100], Batch [123/147] train loss: 789.65, train corr: 0.02036
Epoch [31/100], Batch [124/147] train loss: 751.74, train corr: 0.02435
Epoch [31/100], Batch [125/147] train loss: 763.05, train corr: 0.01973
Epoch [31/100], Batch [126/147] train loss: 737.66, train corr: 0.02179
Epoch [31/100], Batch [127/147] train loss: 680.50, train corr: 0.02005
Epoch [31/100], Batch [128/147] train loss: 645.75, train corr: 0.02791
Epoch [31/100], Batch [129/147] train loss: 608.53, train corr: 0.02710
Epoch [31/100], Batch [130/147] train loss: 620.38, train corr: 0.02403
Epoch [31/100], Batch [131/147] train loss: 592.05, train corr: 0.02229
Epoch [31/100], Batch [132/147] train loss: 776.96, train corr: -0.01543
Epoch [31/100], Batch [133/147] train loss: 681.43, train corr: 0.02624
Epoch [31/100], Batch [134/147] train loss: 792.09, train corr: 0.02625
Epoch [31/100], Batch [135/147] train loss: 920.33, train corr: 0.02447
Epoch [31/100], Batch [136/147] train loss: 1021.06, train corr: 0.02268
Epoch [31/100], Batch [137/147] train loss: 1347.43, train corr: 0.02066
Epoch [31/100], Batch [138/147] train loss: 1118.30, train corr: 0.02562
Epoch [31/100], Batch [139/147] train loss: 1144.37, train corr: 0.02463
Epoch [31/100], Batch [140/147] train loss: 1191.15, train corr: 0.02422
Epoch [31/100], Batch [141/147] train loss: 1215.66, train corr: 0.02445
Epoch [31/100], Batch [142/147] train loss: 1232.06, train corr: 0.02496
Epoch [31/100], Batch [143/147] train loss: 1176.26, train corr: 0.02640
Epoch [31/100], Batch [144/147] train loss: 1245.86, train corr: 0.01855
Epoch [31/100], Batch [145/147] train loss: 1132.79, train corr: 0.02208
Epoch [31/100], Batch [146/147] train loss: 1117.49, train corr: 0.02274
Epoch [31/100], Batch [147/147] train loss: 1117.27, train corr: 0.02069
Epoch [31/100], validation loss: 1183.19, validation correlation: 0.02520
Epoch [32/100], Batch [1/147] train loss: 1112.84, train corr: 0.02479
Epoch [32/100], Batch [2/147] train loss: 1100.42, train corr: 0.02359
Epoch [32/100], Batch [3/147] train loss: 1054.79, train corr: 0.02575
Epoch [32/100], Batch [4/147] train loss: 996.27, train corr: 0.02722
Epoch [32/100], Batch [5/147] train loss: 1969.35, train corr: 0.01885
Epoch [32/100], Batch [6/147] train loss: 925.48, train corr: 0.02715
Epoch [32/100], Batch [7/147] train loss: 916.49, train corr: 0.02507
Epoch [32/100], Batch [8/147] train loss: 820.68, train corr: 0.02545
Epoch [32/100], Batch [9/147] train loss: 783.29, train corr: 0.02768
Epoch [32/100], Batch [10/147] train loss: 760.81, train corr: 0.02665
Epoch [32/100], Batch [11/147] train loss: 779.03, train corr: 0.02833
Epoch [32/100], Batch [12/147] train loss: 730.96, train corr: 0.02511
Epoch [32/100], Batch [13/147] train loss: 700.22, train corr: 0.02444
Epoch [32/100], Batch [14/147] train loss: 670.10, train corr: 0.02720
Epoch [32/100], Batch [15/147] train loss: 656.43, train corr: 0.02415
Epoch [32/100], Batch [16/147] train loss: 643.62, train corr: 0.02787
Epoch [32/100], Batch [17/147] train loss: 622.25, train corr: 0.02655
Epoch [32/100], Batch [18/147] train loss: 715.08, train corr: 0.00171
Epoch [32/100], Batch [19/147] train loss: 632.52, train corr: 0.02502
Epoch [32/100], Batch [20/147] train loss: 662.91, train corr: 0.02685
Epoch [32/100], Batch [21/147] train loss: 691.94, train corr: 0.02551
Epoch [32/100], Batch [22/147] train loss: 730.27, train corr: 0.02367
Epoch [32/100], Batch [23/147] train loss: 707.73, train corr: 0.02457
Epoch [32/100], Batch [24/147] train loss: 729.03, train corr: 0.02359
Epoch [32/100], Batch [25/147] train loss: 706.33, train corr: 0.02512
Epoch [32/100], Batch [26/147] train loss: 690.22, train corr: 0.02466
Epoch [32/100], Batch [27/147] train loss: 662.59, train corr: 0.02471
Epoch [32/100], Batch [28/147] train loss: 651.90, train corr: 0.02382
Epoch [32/100], Batch [29/147] train loss: 614.20, train corr: 0.02030
Epoch [32/100], Batch [30/147] train loss: 611.73, train corr: 0.00188
Epoch [32/100], Batch [31/147] train loss: 703.84, train corr: -0.01209
Epoch [32/100], Batch [32/147] train loss: 622.94, train corr: 0.02191
Epoch [32/100], Batch [33/147] train loss: 678.04, train corr: 0.02353
Epoch [32/100], Batch [34/147] train loss: 708.31, train corr: 0.02647
Epoch [32/100], Batch [35/147] train loss: 734.51, train corr: 0.02513
Epoch [32/100], Batch [36/147] train loss: 788.29, train corr: 0.01980
Epoch [32/100], Batch [37/147] train loss: 757.33, train corr: 0.02619
Epoch [32/100], Batch [38/147] train loss: 768.40, train corr: 0.02576
Epoch [32/100], Batch [39/147] train loss: 780.23, train corr: 0.02347
Epoch [32/100], Batch [40/147] train loss: 766.47, train corr: 0.02285
Epoch [32/100], Batch [41/147] train loss: 771.55, train corr: 0.02460
Epoch [32/100], Batch [42/147] train loss: 769.79, train corr: 0.02707
Epoch [32/100], Batch [43/147] train loss: 737.68, train corr: 0.02823
Epoch [32/100], Batch [44/147] train loss: 731.78, train corr: 0.02217
Epoch [32/100], Batch [45/147] train loss: 716.45, train corr: 0.02463
Epoch [32/100], Batch [46/147] train loss: 701.66, train corr: 0.02629
Epoch [32/100], Batch [47/147] train loss: 651.57, train corr: 0.02786
Epoch [32/100], Batch [48/147] train loss: 658.20, train corr: 0.02490
Epoch [32/100], Batch [49/147] train loss: 648.49, train corr: 0.02547
Epoch [32/100], Batch [50/147] train loss: 643.86, train corr: 0.02309
Epoch [32/100], Batch [51/147] train loss: 629.26, train corr: 0.02845
Epoch [32/100], Batch [52/147] train loss: 584.90, train corr: 0.02983
Epoch [32/100], Batch [53/147] train loss: 649.67, train corr: -0.00112
Epoch [32/100], Batch [54/147] train loss: 622.25, train corr: 0.03036
Epoch [32/100], Batch [55/147] train loss: 636.21, train corr: 0.02792
Epoch [32/100], Batch [56/147] train loss: 654.90, train corr: 0.02710
Epoch [32/100], Batch [57/147] train loss: 682.13, train corr: 0.02706
Epoch [32/100], Batch [58/147] train loss: 677.32, train corr: 0.02633
Epoch [32/100], Batch [59/147] train loss: 650.63, train corr: 0.02584
Epoch [32/100], Batch [60/147] train loss: 1089.27, train corr: 0.02155
Epoch [32/100], Batch [61/147] train loss: 627.11, train corr: 0.02769
Epoch [32/100], Batch [62/147] train loss: 598.39, train corr: 0.02680
Epoch [32/100], Batch [63/147] train loss: 597.01, train corr: -0.01453
Epoch [32/100], Batch [64/147] train loss: 813.32, train corr: -0.02234
Epoch [32/100], Batch [65/147] train loss: 652.99, train corr: 0.02554
Epoch [32/100], Batch [66/147] train loss: 770.88, train corr: 0.02197
Epoch [32/100], Batch [67/147] train loss: 837.60, train corr: 0.02684
Epoch [32/100], Batch [68/147] train loss: 887.04, train corr: 0.02585
Epoch [32/100], Batch [69/147] train loss: 960.39, train corr: 0.02636
Epoch [32/100], Batch [70/147] train loss: 980.27, train corr: 0.02322
Epoch [32/100], Batch [71/147] train loss: 1010.41, train corr: 0.02510
Epoch [32/100], Batch [72/147] train loss: 1025.51, train corr: 0.02358
Epoch [32/100], Batch [73/147] train loss: 1094.80, train corr: 0.02083
Epoch [32/100], Batch [74/147] train loss: 1160.94, train corr: 0.02603
Epoch [32/100], Batch [75/147] train loss: 1015.14, train corr: 0.02670
Epoch [32/100], Batch [76/147] train loss: 1066.13, train corr: 0.02539
Epoch [32/100], Batch [77/147] train loss: 1034.77, train corr: 0.02198
Epoch [32/100], Batch [78/147] train loss: 999.31, train corr: 0.02297
Epoch [32/100], Batch [79/147] train loss: 943.80, train corr: 0.02704
Epoch [32/100], Batch [80/147] train loss: 925.91, train corr: 0.02825
Epoch [32/100], Batch [81/147] train loss: 917.39, train corr: 0.02705
Epoch [32/100], Batch [82/147] train loss: 888.94, train corr: 0.02706
Epoch [32/100], Batch [83/147] train loss: 895.32, train corr: 0.02587
Epoch [32/100], Batch [84/147] train loss: 893.00, train corr: 0.02998
Epoch [32/100], Batch [85/147] train loss: 838.28, train corr: 0.02408
Epoch [32/100], Batch [86/147] train loss: 826.28, train corr: 0.02447
Epoch [32/100], Batch [87/147] train loss: 803.88, train corr: 0.02058
Epoch [32/100], Batch [88/147] train loss: 746.41, train corr: 0.02768
Epoch [32/100], Batch [89/147] train loss: 725.61, train corr: 0.02656
Epoch [32/100], Batch [90/147] train loss: 857.21, train corr: 0.02188
Epoch [32/100], Batch [91/147] train loss: 689.15, train corr: 0.02755
Epoch [32/100], Batch [92/147] train loss: 681.07, train corr: 0.02761
Epoch [32/100], Batch [93/147] train loss: 638.88, train corr: 0.03034
Epoch [32/100], Batch [94/147] train loss: 732.54, train corr: 0.02756
Epoch [32/100], Batch [95/147] train loss: 610.41, train corr: 0.03102
Epoch [32/100], Batch [96/147] train loss: 616.88, train corr: 0.02940
Epoch [32/100], Batch [97/147] train loss: 624.54, train corr: 0.01111
Epoch [32/100], Batch [98/147] train loss: 616.11, train corr: 0.03289
Epoch [32/100], Batch [99/147] train loss: 646.56, train corr: 0.03009
Epoch [32/100], Batch [100/147] train loss: 691.72, train corr: 0.03039
Epoch [32/100], Batch [101/147] train loss: 696.13, train corr: 0.02804
Epoch [32/100], Batch [102/147] train loss: 737.47, train corr: 0.02424
Epoch [32/100], Batch [103/147] train loss: 689.93, train corr: 0.02901
Epoch [32/100], Batch [104/147] train loss: 714.10, train corr: 0.02598
Epoch [32/100], Batch [105/147] train loss: 664.96, train corr: 0.02806
Epoch [32/100], Batch [106/147] train loss: 637.57, train corr: 0.03041
Epoch [32/100], Batch [107/147] train loss: 639.04, train corr: 0.02872
Epoch [32/100], Batch [108/147] train loss: 610.67, train corr: 0.02463
Epoch [32/100], Batch [109/147] train loss: 689.84, train corr: -0.00845
Epoch [32/100], Batch [110/147] train loss: 648.75, train corr: 0.02668
Epoch [32/100], Batch [111/147] train loss: 714.41, train corr: 0.01832
Epoch [32/100], Batch [112/147] train loss: 743.64, train corr: 0.02542
Epoch [32/100], Batch [113/147] train loss: 741.07, train corr: 0.02783
Epoch [32/100], Batch [114/147] train loss: 777.83, train corr: 0.02274
Epoch [32/100], Batch [115/147] train loss: 779.23, train corr: 0.02831
Epoch [32/100], Batch [116/147] train loss: 765.07, train corr: 0.02837
Epoch [32/100], Batch [117/147] train loss: 784.98, train corr: 0.03010
Epoch [32/100], Batch [118/147] train loss: 770.45, train corr: 0.02621
Epoch [32/100], Batch [119/147] train loss: 778.72, train corr: 0.02586
Epoch [32/100], Batch [120/147] train loss: 758.43, train corr: 0.02563
Epoch [32/100], Batch [121/147] train loss: 763.58, train corr: 0.02358
Epoch [32/100], Batch [122/147] train loss: 712.11, train corr: 0.02632
Epoch [32/100], Batch [123/147] train loss: 715.63, train corr: 0.02522
Epoch [32/100], Batch [124/147] train loss: 701.22, train corr: 0.02582
Epoch [32/100], Batch [125/147] train loss: 693.21, train corr: 0.02916
Epoch [32/100], Batch [126/147] train loss: 668.85, train corr: 0.02724
Epoch [32/100], Batch [127/147] train loss: 662.35, train corr: 0.02821
Epoch [32/100], Batch [128/147] train loss: 642.99, train corr: 0.02690
Epoch [32/100], Batch [129/147] train loss: 607.52, train corr: 0.02860
Epoch [32/100], Batch [130/147] train loss: 605.66, train corr: 0.02749
Epoch [32/100], Batch [131/147] train loss: 577.13, train corr: 0.01888
Epoch [32/100], Batch [132/147] train loss: 826.46, train corr: -0.01528
Epoch [32/100], Batch [133/147] train loss: 701.15, train corr: 0.02297
Epoch [32/100], Batch [134/147] train loss: 814.58, train corr: 0.02575
Epoch [32/100], Batch [135/147] train loss: 921.62, train corr: 0.02139
Epoch [32/100], Batch [136/147] train loss: 967.92, train corr: 0.02491
Epoch [32/100], Batch [137/147] train loss: 1091.89, train corr: 0.02222
Epoch [32/100], Batch [138/147] train loss: 1135.16, train corr: 0.02510
Epoch [32/100], Batch [139/147] train loss: 1162.44, train corr: 0.02388
Epoch [32/100], Batch [140/147] train loss: 1152.55, train corr: 0.02582
Epoch [32/100], Batch [141/147] train loss: 1164.14, train corr: 0.02016
Epoch [32/100], Batch [142/147] train loss: 1168.27, train corr: 0.02765
Epoch [32/100], Batch [143/147] train loss: 1194.68, train corr: 0.02516
Epoch [32/100], Batch [144/147] train loss: 1141.60, train corr: 0.02713
Epoch [32/100], Batch [145/147] train loss: 1093.87, train corr: 0.02597
Epoch [32/100], Batch [146/147] train loss: 1127.29, train corr: 0.02553
Epoch [32/100], Batch [147/147] train loss: 1168.93, train corr: 0.02238
Epoch [32/100], validation loss: 1174.85, validation correlation: 0.02567
Epoch [33/100], Batch [1/147] train loss: 1088.92, train corr: 0.02336
Epoch [33/100], Batch [2/147] train loss: 1122.16, train corr: 0.02258
Epoch [33/100], Batch [3/147] train loss: 1071.57, train corr: 0.02021
Epoch [33/100], Batch [4/147] train loss: 1009.75, train corr: 0.02655
Epoch [33/100], Batch [5/147] train loss: 1006.94, train corr: 0.02190
Epoch [33/100], Batch [6/147] train loss: 976.23, train corr: 0.02545
Epoch [33/100], Batch [7/147] train loss: 927.63, train corr: 0.02538
Epoch [33/100], Batch [8/147] train loss: 914.77, train corr: 0.02557
Epoch [33/100], Batch [9/147] train loss: 866.88, train corr: 0.02944
Epoch [33/100], Batch [10/147] train loss: 864.31, train corr: 0.02752
Epoch [33/100], Batch [11/147] train loss: 811.32, train corr: 0.02676
Epoch [33/100], Batch [12/147] train loss: 793.63, train corr: 0.02671
Epoch [33/100], Batch [13/147] train loss: 746.43, train corr: 0.02900
Epoch [33/100], Batch [14/147] train loss: 747.28, train corr: 0.02754
Epoch [33/100], Batch [15/147] train loss: 722.45, train corr: 0.02786
Epoch [33/100], Batch [16/147] train loss: 742.09, train corr: 0.02486
Epoch [33/100], Batch [17/147] train loss: 697.05, train corr: 0.02639
Epoch [33/100], Batch [18/147] train loss: 653.57, train corr: 0.02876
Epoch [33/100], Batch [19/147] train loss: 656.46, train corr: 0.02728
Epoch [33/100], Batch [20/147] train loss: 660.55, train corr: 0.02948
Epoch [33/100], Batch [21/147] train loss: 652.50, train corr: 0.03124
Epoch [33/100], Batch [22/147] train loss: 622.67, train corr: 0.03321
Epoch [33/100], Batch [23/147] train loss: 600.45, train corr: 0.03361
Epoch [33/100], Batch [24/147] train loss: 613.03, train corr: 0.03213
Epoch [33/100], Batch [25/147] train loss: 659.59, train corr: 0.03099
Epoch [33/100], Batch [26/147] train loss: 629.13, train corr: 0.02706
Epoch [33/100], Batch [27/147] train loss: 627.53, train corr: 0.03036
Epoch [33/100], Batch [28/147] train loss: 624.89, train corr: 0.02875
Epoch [33/100], Batch [29/147] train loss: 636.90, train corr: 0.02871
Epoch [33/100], Batch [30/147] train loss: 639.87, train corr: 0.02924
Epoch [33/100], Batch [31/147] train loss: 621.43, train corr: 0.03038
Epoch [33/100], Batch [32/147] train loss: 614.53, train corr: 0.02936
Epoch [33/100], Batch [33/147] train loss: 599.23, train corr: 0.02976
Epoch [33/100], Batch [34/147] train loss: 611.23, train corr: 0.03314
Epoch [33/100], Batch [35/147] train loss: 601.16, train corr: 0.03401
Epoch [33/100], Batch [36/147] train loss: 724.21, train corr: 0.02611
Epoch [33/100], Batch [37/147] train loss: 574.63, train corr: 0.03292
Epoch [33/100], Batch [38/147] train loss: 592.71, train corr: 0.03171
Epoch [33/100], Batch [39/147] train loss: 576.96, train corr: 0.03166
Epoch [33/100], Batch [40/147] train loss: 641.26, train corr: 0.02991
Epoch [33/100], Batch [41/147] train loss: 568.26, train corr: 0.03001
Epoch [33/100], Batch [42/147] train loss: 566.22, train corr: 0.03040
Epoch [33/100], Batch [43/147] train loss: 589.36, train corr: 0.02619
Epoch [33/100], Batch [44/147] train loss: 593.93, train corr: 0.02501
Epoch [33/100], Batch [45/147] train loss: 870.93, train corr: 0.01961
Epoch [33/100], Batch [46/147] train loss: 583.42, train corr: 0.02361
Epoch [33/100], Batch [47/147] train loss: 570.05, train corr: 0.02469
Epoch [33/100], Batch [48/147] train loss: 582.66, train corr: 0.02667
Epoch [33/100], Batch [49/147] train loss: 591.15, train corr: 0.02651
Epoch [33/100], Batch [50/147] train loss: 585.01, train corr: 0.02720
Epoch [33/100], Batch [51/147] train loss: 577.40, train corr: 0.02121
Epoch [33/100], Batch [52/147] train loss: 573.62, train corr: 0.02224
Epoch [33/100], Batch [53/147] train loss: 572.54, train corr: 0.02423
Epoch [33/100], Batch [54/147] train loss: 571.11, train corr: 0.01633
Epoch [33/100], Batch [55/147] train loss: 574.15, train corr: 0.01583
Epoch [33/100], Batch [56/147] train loss: 581.56, train corr: -0.01151
Epoch [33/100], Batch [57/147] train loss: 559.54, train corr: -0.00428
Epoch [33/100], Batch [58/147] train loss: 595.98, train corr: 0.01681
Epoch [33/100], Batch [59/147] train loss: 584.44, train corr: 0.01843
Epoch [33/100], Batch [60/147] train loss: 578.23, train corr: 0.02128
Epoch [33/100], Batch [61/147] train loss: 570.72, train corr: 0.02279
Epoch [33/100], Batch [62/147] train loss: 575.48, train corr: 0.03304
Epoch [33/100], Batch [63/147] train loss: 568.14, train corr: 0.03186
Epoch [33/100], Batch [64/147] train loss: 582.99, train corr: 0.03278
Epoch [33/100], Batch [65/147] train loss: 572.31, train corr: 0.03391
Epoch [33/100], Batch [66/147] train loss: 545.36, train corr: 0.03306
Epoch [33/100], Batch [67/147] train loss: 578.27, train corr: 0.03338
Epoch [33/100], Batch [68/147] train loss: 577.73, train corr: 0.03222
Epoch [33/100], Batch [69/147] train loss: 565.57, train corr: 0.02553
Epoch [33/100], Batch [70/147] train loss: 567.24, train corr: -0.00333
Epoch [33/100], Batch [71/147] train loss: 570.89, train corr: -0.01581
Epoch [33/100], Batch [72/147] train loss: 557.74, train corr: -0.01749
Epoch [33/100], Batch [73/147] train loss: 560.13, train corr: -0.01320
Epoch [33/100], Batch [74/147] train loss: 562.56, train corr: -0.02110
Epoch [33/100], Batch [75/147] train loss: 568.35, train corr: -0.01938
Epoch [33/100], Batch [76/147] train loss: 578.62, train corr: -0.00414
Epoch [33/100], Batch [77/147] train loss: 577.55, train corr: 0.01270
Epoch [33/100], Batch [78/147] train loss: 574.49, train corr: -0.00134
Epoch [33/100], Batch [79/147] train loss: 564.71, train corr: 0.00191
Epoch [33/100], Batch [80/147] train loss: 581.73, train corr: 0.03021
Epoch [33/100], Batch [81/147] train loss: 574.73, train corr: 0.02978
Epoch [33/100], Batch [82/147] train loss: 577.78, train corr: 0.01739
Epoch [33/100], Batch [83/147] train loss: 576.90, train corr: 0.00878
Epoch [33/100], Batch [84/147] train loss: 749.63, train corr: 0.01131
Epoch [33/100], Batch [85/147] train loss: 595.14, train corr: -0.02482
Epoch [33/100], Batch [86/147] train loss: 614.40, train corr: 0.02637
Epoch [33/100], Batch [87/147] train loss: 663.35, train corr: 0.02626
Epoch [33/100], Batch [88/147] train loss: 700.76, train corr: 0.02621
Epoch [33/100], Batch [89/147] train loss: 748.98, train corr: 0.02145
Epoch [33/100], Batch [90/147] train loss: 921.81, train corr: 0.02051
Epoch [33/100], Batch [91/147] train loss: 787.51, train corr: 0.02627
Epoch [33/100], Batch [92/147] train loss: 756.71, train corr: 0.02599
Epoch [33/100], Batch [93/147] train loss: 762.43, train corr: 0.02611
Epoch [33/100], Batch [94/147] train loss: 751.10, train corr: 0.02703
Epoch [33/100], Batch [95/147] train loss: 752.01, train corr: 0.02740
Epoch [33/100], Batch [96/147] train loss: 723.08, train corr: 0.02584
Epoch [33/100], Batch [97/147] train loss: 726.55, train corr: 0.02477
Epoch [33/100], Batch [98/147] train loss: 707.56, train corr: 0.02670
Epoch [33/100], Batch [99/147] train loss: 717.69, train corr: 0.02563
Epoch [33/100], Batch [100/147] train loss: 700.31, train corr: 0.02521
Epoch [33/100], Batch [101/147] train loss: 668.22, train corr: 0.02384
Epoch [33/100], Batch [102/147] train loss: 657.87, train corr: 0.02854
Epoch [33/100], Batch [103/147] train loss: 629.89, train corr: 0.02728
Epoch [33/100], Batch [104/147] train loss: 632.94, train corr: 0.02371
Epoch [33/100], Batch [105/147] train loss: 618.63, train corr: 0.02745
Epoch [33/100], Batch [106/147] train loss: 612.46, train corr: 0.02886
Epoch [33/100], Batch [107/147] train loss: 584.17, train corr: 0.02424
Epoch [33/100], Batch [108/147] train loss: 784.71, train corr: -0.01507
Epoch [33/100], Batch [109/147] train loss: 644.66, train corr: 0.02197
Epoch [33/100], Batch [110/147] train loss: 687.54, train corr: 0.02833
Epoch [33/100], Batch [111/147] train loss: 751.83, train corr: 0.02699
Epoch [33/100], Batch [112/147] train loss: 783.43, train corr: 0.02606
Epoch [33/100], Batch [113/147] train loss: 808.72, train corr: 0.02574
Epoch [33/100], Batch [114/147] train loss: 841.85, train corr: 0.02842
Epoch [33/100], Batch [115/147] train loss: 837.69, train corr: 0.02710
Epoch [33/100], Batch [116/147] train loss: 830.92, train corr: 0.02536
Epoch [33/100], Batch [117/147] train loss: 863.04, train corr: 0.02487
Epoch [33/100], Batch [118/147] train loss: 844.74, train corr: 0.02745
Epoch [33/100], Batch [119/147] train loss: 846.81, train corr: 0.02082
Epoch [33/100], Batch [120/147] train loss: 833.48, train corr: 0.02578
Epoch [33/100], Batch [121/147] train loss: 791.07, train corr: 0.02614
Epoch [33/100], Batch [122/147] train loss: 776.08, train corr: 0.02333
Epoch [33/100], Batch [123/147] train loss: 747.67, train corr: 0.02947
Epoch [33/100], Batch [124/147] train loss: 735.76, train corr: 0.02621
Epoch [33/100], Batch [125/147] train loss: 736.99, train corr: 0.02648
Epoch [33/100], Batch [126/147] train loss: 697.14, train corr: 0.02838
Epoch [33/100], Batch [127/147] train loss: 688.01, train corr: 0.02849
Epoch [33/100], Batch [128/147] train loss: 650.21, train corr: 0.02472
Epoch [33/100], Batch [129/147] train loss: 629.59, train corr: 0.02872
Epoch [33/100], Batch [130/147] train loss: 636.07, train corr: 0.02713
Epoch [33/100], Batch [131/147] train loss: 625.87, train corr: 0.02605
Epoch [33/100], Batch [132/147] train loss: 598.06, train corr: 0.03010
Epoch [33/100], Batch [133/147] train loss: 593.43, train corr: 0.02839
Epoch [33/100], Batch [134/147] train loss: 700.56, train corr: -0.02032
Epoch [33/100], Batch [135/147] train loss: 652.88, train corr: 0.02594
Epoch [33/100], Batch [136/147] train loss: 746.35, train corr: 0.02555
Epoch [33/100], Batch [137/147] train loss: 825.79, train corr: 0.02513
Epoch [33/100], Batch [138/147] train loss: 894.23, train corr: 0.02464
Epoch [33/100], Batch [139/147] train loss: 948.75, train corr: 0.02292
Epoch [33/100], Batch [140/147] train loss: 978.99, train corr: 0.02496
Epoch [33/100], Batch [141/147] train loss: 988.07, train corr: 0.02712
Epoch [33/100], Batch [142/147] train loss: 999.97, train corr: 0.02690
Epoch [33/100], Batch [143/147] train loss: 1005.93, train corr: 0.02580
Epoch [33/100], Batch [144/147] train loss: 979.79, train corr: 0.02768
Epoch [33/100], Batch [145/147] train loss: 978.74, train corr: 0.02610
Epoch [33/100], Batch [146/147] train loss: 1001.22, train corr: 0.02408
Epoch [33/100], Batch [147/147] train loss: 981.81, train corr: 0.02353
Epoch [33/100], validation loss: 996.17, validation correlation: 0.02555
Epoch [34/100], Batch [1/147] train loss: 922.71, train corr: 0.02586
Epoch [34/100], Batch [2/147] train loss: 926.64, train corr: 0.02509
Epoch [34/100], Batch [3/147] train loss: 911.66, train corr: 0.02589
Epoch [34/100], Batch [4/147] train loss: 848.79, train corr: 0.02669
Epoch [34/100], Batch [5/147] train loss: 884.58, train corr: 0.02525
Epoch [34/100], Batch [6/147] train loss: 839.91, train corr: 0.02451
Epoch [34/100], Batch [7/147] train loss: 799.76, train corr: 0.02696
Epoch [34/100], Batch [8/147] train loss: 800.21, train corr: 0.02360
Epoch [34/100], Batch [9/147] train loss: 746.00, train corr: 0.02535
Epoch [34/100], Batch [10/147] train loss: 742.23, train corr: 0.02426
Epoch [34/100], Batch [11/147] train loss: 712.50, train corr: 0.02596
Epoch [34/100], Batch [12/147] train loss: 700.77, train corr: 0.02251
Epoch [34/100], Batch [13/147] train loss: 1118.07, train corr: 0.02181
Epoch [34/100], Batch [14/147] train loss: 632.62, train corr: 0.02822
Epoch [34/100], Batch [15/147] train loss: 626.81, train corr: 0.02606
Epoch [34/100], Batch [16/147] train loss: 599.88, train corr: 0.02782
Epoch [34/100], Batch [17/147] train loss: 809.94, train corr: -0.01244
Epoch [34/100], Batch [18/147] train loss: 614.30, train corr: 0.02257
Epoch [34/100], Batch [19/147] train loss: 656.90, train corr: 0.02789
Epoch [34/100], Batch [20/147] train loss: 711.76, train corr: 0.02175
Epoch [34/100], Batch [21/147] train loss: 705.74, train corr: 0.02902
Epoch [34/100], Batch [22/147] train loss: 726.99, train corr: 0.02723
Epoch [34/100], Batch [23/147] train loss: 750.10, train corr: 0.02418
Epoch [34/100], Batch [24/147] train loss: 757.18, train corr: 0.02782
Epoch [34/100], Batch [25/147] train loss: 876.08, train corr: 0.02141
Epoch [34/100], Batch [26/147] train loss: 719.05, train corr: 0.02629
Epoch [34/100], Batch [27/147] train loss: 725.43, train corr: 0.02615
Epoch [34/100], Batch [28/147] train loss: 685.07, train corr: 0.02439
Epoch [34/100], Batch [29/147] train loss: 644.89, train corr: 0.02697
Epoch [34/100], Batch [30/147] train loss: 635.37, train corr: 0.02946
Epoch [34/100], Batch [31/147] train loss: 643.43, train corr: 0.02381
Epoch [34/100], Batch [32/147] train loss: 594.30, train corr: 0.03093
Epoch [34/100], Batch [33/147] train loss: 632.40, train corr: 0.00530
Epoch [34/100], Batch [34/147] train loss: 598.56, train corr: -0.00738
Epoch [34/100], Batch [35/147] train loss: 585.35, train corr: 0.00057
Epoch [34/100], Batch [36/147] train loss: 602.49, train corr: 0.00100
Epoch [34/100], Batch [37/147] train loss: 837.47, train corr: -0.00114
Epoch [34/100], Batch [38/147] train loss: 613.92, train corr: -0.01230
Epoch [34/100], Batch [39/147] train loss: 621.04, train corr: -0.01420
Epoch [34/100], Batch [40/147] train loss: 612.28, train corr: 0.01383
Epoch [34/100], Batch [41/147] train loss: 659.99, train corr: 0.02224
Epoch [34/100], Batch [42/147] train loss: 690.72, train corr: 0.02406
Epoch [34/100], Batch [43/147] train loss: 698.20, train corr: 0.02422
Epoch [34/100], Batch [44/147] train loss: 712.03, train corr: 0.02214
Epoch [34/100], Batch [45/147] train loss: 697.11, train corr: 0.02506
Epoch [34/100], Batch [46/147] train loss: 687.89, train corr: 0.02518
Epoch [34/100], Batch [47/147] train loss: 680.97, train corr: 0.02395
Epoch [34/100], Batch [48/147] train loss: 689.67, train corr: 0.02360
Epoch [34/100], Batch [49/147] train loss: 646.73, train corr: 0.02714
Epoch [34/100], Batch [50/147] train loss: 657.56, train corr: 0.02266
Epoch [34/100], Batch [51/147] train loss: 646.16, train corr: 0.02533
Epoch [34/100], Batch [52/147] train loss: 613.32, train corr: 0.02835
Epoch [34/100], Batch [53/147] train loss: 610.42, train corr: 0.02465
Epoch [34/100], Batch [54/147] train loss: 583.46, train corr: 0.02774
Epoch [34/100], Batch [55/147] train loss: 585.22, train corr: 0.02807
Epoch [34/100], Batch [56/147] train loss: 567.81, train corr: -0.01285
Epoch [34/100], Batch [57/147] train loss: 601.71, train corr: -0.01317
Epoch [34/100], Batch [58/147] train loss: 597.06, train corr: 0.02880
Epoch [34/100], Batch [59/147] train loss: 601.59, train corr: 0.02887
Epoch [34/100], Batch [60/147] train loss: 611.76, train corr: 0.02904
Epoch [34/100], Batch [61/147] train loss: 611.58, train corr: 0.02577
Epoch [34/100], Batch [62/147] train loss: 615.89, train corr: 0.02334
Epoch [34/100], Batch [63/147] train loss: 621.00, train corr: 0.02005
Epoch [34/100], Batch [64/147] train loss: 588.41, train corr: 0.01523
Epoch [34/100], Batch [65/147] train loss: 599.70, train corr: -0.01205
Epoch [34/100], Batch [66/147] train loss: 671.96, train corr: -0.02166
Epoch [34/100], Batch [67/147] train loss: 669.59, train corr: 0.02455
Epoch [34/100], Batch [68/147] train loss: 761.43, train corr: 0.02427
Epoch [34/100], Batch [69/147] train loss: 830.81, train corr: 0.02346
Epoch [34/100], Batch [70/147] train loss: 898.95, train corr: 0.02508
Epoch [34/100], Batch [71/147] train loss: 952.69, train corr: 0.02206
Epoch [34/100], Batch [72/147] train loss: 976.92, train corr: 0.02040
Epoch [34/100], Batch [73/147] train loss: 996.71, train corr: 0.02063
Epoch [34/100], Batch [74/147] train loss: 970.97, train corr: 0.02675
Epoch [34/100], Batch [75/147] train loss: 1020.36, train corr: 0.02554
Epoch [34/100], Batch [76/147] train loss: 1017.88, train corr: 0.02188
Epoch [34/100], Batch [77/147] train loss: 989.60, train corr: 0.02619
Epoch [34/100], Batch [78/147] train loss: 984.90, train corr: 0.02742
Epoch [34/100], Batch [79/147] train loss: 983.85, train corr: 0.02675
Epoch [34/100], Batch [80/147] train loss: 975.78, train corr: 0.02473
Epoch [34/100], Batch [81/147] train loss: 954.33, train corr: 0.02761
Epoch [34/100], Batch [82/147] train loss: 927.33, train corr: 0.02760
Epoch [34/100], Batch [83/147] train loss: 889.59, train corr: 0.02683
Epoch [34/100], Batch [84/147] train loss: 875.08, train corr: 0.02710
Epoch [34/100], Batch [85/147] train loss: 900.70, train corr: 0.02843
Epoch [34/100], Batch [86/147] train loss: 838.01, train corr: 0.02839
Epoch [34/100], Batch [87/147] train loss: 829.21, train corr: 0.02046
Epoch [34/100], Batch [88/147] train loss: 829.06, train corr: 0.02794
Epoch [34/100], Batch [89/147] train loss: 821.55, train corr: 0.02755
Epoch [34/100], Batch [90/147] train loss: 776.31, train corr: 0.02465
Epoch [34/100], Batch [91/147] train loss: 747.51, train corr: 0.02502
Epoch [34/100], Batch [92/147] train loss: 712.15, train corr: 0.02740
Epoch [34/100], Batch [93/147] train loss: 713.30, train corr: 0.02607
Epoch [34/100], Batch [94/147] train loss: 703.39, train corr: 0.02518
Epoch [34/100], Batch [95/147] train loss: 668.54, train corr: 0.02896
Epoch [34/100], Batch [96/147] train loss: 641.39, train corr: 0.02822
Epoch [34/100], Batch [97/147] train loss: 620.36, train corr: 0.02894
Epoch [34/100], Batch [98/147] train loss: 619.33, train corr: 0.02930
Epoch [34/100], Batch [99/147] train loss: 609.88, train corr: 0.02552
Epoch [34/100], Batch [100/147] train loss: 646.86, train corr: 0.03127
Epoch [34/100], Batch [101/147] train loss: 597.19, train corr: 0.02956
Epoch [34/100], Batch [102/147] train loss: 597.99, train corr: 0.02720
Epoch [34/100], Batch [103/147] train loss: 615.66, train corr: 0.02622
Epoch [34/100], Batch [104/147] train loss: 614.42, train corr: 0.02676
Epoch [34/100], Batch [105/147] train loss: 607.83, train corr: 0.02843
Epoch [34/100], Batch [106/147] train loss: 619.76, train corr: 0.02899
Epoch [34/100], Batch [107/147] train loss: 638.84, train corr: -0.01622
Epoch [34/100], Batch [108/147] train loss: 618.76, train corr: 0.02780
Epoch [34/100], Batch [109/147] train loss: 643.03, train corr: 0.02649
Epoch [34/100], Batch [110/147] train loss: 665.09, train corr: 0.02457
Epoch [34/100], Batch [111/147] train loss: 666.30, train corr: 0.02156
Epoch [34/100], Batch [112/147] train loss: 680.03, train corr: 0.02332
Epoch [34/100], Batch [113/147] train loss: 676.12, train corr: 0.02466
Epoch [34/100], Batch [114/147] train loss: 673.47, train corr: 0.02757
Epoch [34/100], Batch [115/147] train loss: 639.37, train corr: 0.02557
Epoch [34/100], Batch [116/147] train loss: 635.18, train corr: 0.02458
Epoch [34/100], Batch [117/147] train loss: 625.94, train corr: 0.02837
Epoch [34/100], Batch [118/147] train loss: 604.09, train corr: 0.02656
Epoch [34/100], Batch [119/147] train loss: 584.08, train corr: 0.02474
Epoch [34/100], Batch [120/147] train loss: 580.04, train corr: 0.02770
Epoch [34/100], Batch [121/147] train loss: 596.16, train corr: 0.02663
Epoch [34/100], Batch [122/147] train loss: 595.60, train corr: 0.00882
Epoch [34/100], Batch [123/147] train loss: 599.84, train corr: -0.00048
Epoch [34/100], Batch [124/147] train loss: 555.05, train corr: 0.00612
Epoch [34/100], Batch [125/147] train loss: 585.28, train corr: 0.00456
Epoch [34/100], Batch [126/147] train loss: 587.12, train corr: -0.01030
Epoch [34/100], Batch [127/147] train loss: 590.89, train corr: -0.02078
Epoch [34/100], Batch [128/147] train loss: 592.35, train corr: -0.02234
Epoch [34/100], Batch [129/147] train loss: 578.64, train corr: -0.01278
Epoch [34/100], Batch [130/147] train loss: 595.19, train corr: -0.00546
Epoch [34/100], Batch [131/147] train loss: 603.62, train corr: -0.01032
Epoch [34/100], Batch [132/147] train loss: 677.76, train corr: -0.01670
Epoch [34/100], Batch [133/147] train loss: 581.81, train corr: -0.00490
Epoch [34/100], Batch [134/147] train loss: 587.39, train corr: 0.00493
Epoch [34/100], Batch [135/147] train loss: 588.58, train corr: 0.00582
Epoch [34/100], Batch [136/147] train loss: 572.40, train corr: -0.00442
Epoch [34/100], Batch [137/147] train loss: 584.68, train corr: -0.01464
Epoch [34/100], Batch [138/147] train loss: 573.99, train corr: 0.00365
Epoch [34/100], Batch [139/147] train loss: 618.36, train corr: 0.01719
Epoch [34/100], Batch [140/147] train loss: 562.24, train corr: 0.01526
Epoch [34/100], Batch [141/147] train loss: 581.57, train corr: -0.00895
Epoch [34/100], Batch [142/147] train loss: 558.21, train corr: -0.02391
Epoch [34/100], Batch [143/147] train loss: 575.44, train corr: -0.00116
Epoch [34/100], Batch [144/147] train loss: 570.64, train corr: 0.02498
Epoch [34/100], Batch [145/147] train loss: 577.71, train corr: 0.02692
Epoch [34/100], Batch [146/147] train loss: 581.14, train corr: 0.02860
Epoch [34/100], Batch [147/147] train loss: 588.05, train corr: -0.01350
Epoch [34/100], validation loss: 602.89, validation correlation: -0.02060
Epoch [35/100], Batch [1/147] train loss: 558.05, train corr: -0.01975
Epoch [35/100], Batch [2/147] train loss: 587.38, train corr: 0.03112
Epoch [35/100], Batch [3/147] train loss: 567.17, train corr: 0.02663
Epoch [35/100], Batch [4/147] train loss: 585.86, train corr: 0.02995
Epoch [35/100], Batch [5/147] train loss: 569.12, train corr: -0.00525
Epoch [35/100], Batch [6/147] train loss: 584.94, train corr: -0.01454
Epoch [35/100], Batch [7/147] train loss: 571.57, train corr: 0.03056
Epoch [35/100], Batch [8/147] train loss: 599.27, train corr: 0.02377
Epoch [35/100], Batch [9/147] train loss: 603.31, train corr: 0.02469
Epoch [35/100], Batch [10/147] train loss: 624.35, train corr: 0.02736
Epoch [35/100], Batch [11/147] train loss: 618.74, train corr: 0.02561
Epoch [35/100], Batch [12/147] train loss: 611.17, train corr: 0.02464
Epoch [35/100], Batch [13/147] train loss: 602.85, train corr: 0.02892
Epoch [35/100], Batch [14/147] train loss: 587.46, train corr: 0.02808
Epoch [35/100], Batch [15/147] train loss: 578.21, train corr: 0.02941
Epoch [35/100], Batch [16/147] train loss: 583.94, train corr: 0.02901
Epoch [35/100], Batch [17/147] train loss: 565.22, train corr: 0.03257
Epoch [35/100], Batch [18/147] train loss: 581.67, train corr: 0.00604
Epoch [35/100], Batch [19/147] train loss: 571.72, train corr: 0.02827
Epoch [35/100], Batch [20/147] train loss: 583.12, train corr: 0.02390
Epoch [35/100], Batch [21/147] train loss: 567.08, train corr: 0.01809
Epoch [35/100], Batch [22/147] train loss: 578.35, train corr: -0.01642
Epoch [35/100], Batch [23/147] train loss: 588.47, train corr: -0.02808
Epoch [35/100], Batch [24/147] train loss: 595.10, train corr: -0.02740
Epoch [35/100], Batch [25/147] train loss: 606.97, train corr: 0.01682
Epoch [35/100], Batch [26/147] train loss: 619.26, train corr: 0.02330
Epoch [35/100], Batch [27/147] train loss: 613.93, train corr: 0.02502
Epoch [35/100], Batch [28/147] train loss: 627.92, train corr: 0.02242
Epoch [35/100], Batch [29/147] train loss: 635.65, train corr: 0.02394
Epoch [35/100], Batch [30/147] train loss: 608.34, train corr: 0.02467
Epoch [35/100], Batch [31/147] train loss: 587.61, train corr: 0.02276
Epoch [35/100], Batch [32/147] train loss: 568.69, train corr: 0.02464
Epoch [35/100], Batch [33/147] train loss: 608.22, train corr: -0.02499
Epoch [35/100], Batch [34/147] train loss: 575.20, train corr: 0.02342
Epoch [35/100], Batch [35/147] train loss: 569.93, train corr: 0.02641
Epoch [35/100], Batch [36/147] train loss: 570.08, train corr: 0.02704
Epoch [35/100], Batch [37/147] train loss: 583.39, train corr: 0.02821
Epoch [35/100], Batch [38/147] train loss: 605.60, train corr: 0.02194
Epoch [35/100], Batch [39/147] train loss: 580.03, train corr: 0.02687
Epoch [35/100], Batch [40/147] train loss: 581.82, train corr: 0.02599
Epoch [35/100], Batch [41/147] train loss: 579.36, train corr: 0.02860
Epoch [35/100], Batch [42/147] train loss: 576.77, train corr: -0.01931
Epoch [35/100], Batch [43/147] train loss: 579.81, train corr: 0.02614
Epoch [35/100], Batch [44/147] train loss: 579.39, train corr: 0.02620
Epoch [35/100], Batch [45/147] train loss: 891.27, train corr: 0.02234
Epoch [35/100], Batch [46/147] train loss: 565.83, train corr: 0.02707
Epoch [35/100], Batch [47/147] train loss: 586.25, train corr: -0.01524
Epoch [35/100], Batch [48/147] train loss: 637.23, train corr: -0.02457
Epoch [35/100], Batch [49/147] train loss: 638.48, train corr: 0.02737
Epoch [35/100], Batch [50/147] train loss: 709.53, train corr: 0.02697
Epoch [35/100], Batch [51/147] train loss: 811.91, train corr: 0.02263
Epoch [35/100], Batch [52/147] train loss: 826.84, train corr: 0.02823
Epoch [35/100], Batch [53/147] train loss: 853.75, train corr: 0.02446
Epoch [35/100], Batch [54/147] train loss: 880.56, train corr: 0.02437
Epoch [35/100], Batch [55/147] train loss: 909.80, train corr: 0.02326
Epoch [35/100], Batch [56/147] train loss: 967.41, train corr: 0.02428
Epoch [35/100], Batch [57/147] train loss: 966.80, train corr: 0.02503
Epoch [35/100], Batch [58/147] train loss: 917.50, train corr: 0.02500
Epoch [35/100], Batch [59/147] train loss: 943.31, train corr: 0.02664
Epoch [35/100], Batch [60/147] train loss: 888.87, train corr: 0.02312
Epoch [35/100], Batch [61/147] train loss: 881.61, train corr: 0.02628
Epoch [35/100], Batch [62/147] train loss: 887.27, train corr: 0.02320
Epoch [35/100], Batch [63/147] train loss: 853.78, train corr: 0.02640
Epoch [35/100], Batch [64/147] train loss: 849.59, train corr: 0.02699
Epoch [35/100], Batch [65/147] train loss: 857.64, train corr: 0.02301
Epoch [35/100], Batch [66/147] train loss: 804.34, train corr: 0.02730
Epoch [35/100], Batch [67/147] train loss: 800.11, train corr: 0.02762
Epoch [35/100], Batch [68/147] train loss: 776.11, train corr: 0.02553
Epoch [35/100], Batch [69/147] train loss: 737.04, train corr: 0.02787
Epoch [35/100], Batch [70/147] train loss: 748.43, train corr: 0.02645
Epoch [35/100], Batch [71/147] train loss: 734.95, train corr: 0.02705
Epoch [35/100], Batch [72/147] train loss: 739.36, train corr: 0.03030
Epoch [35/100], Batch [73/147] train loss: 691.72, train corr: 0.02776
Epoch [35/100], Batch [74/147] train loss: 717.26, train corr: 0.02495
Epoch [35/100], Batch [75/147] train loss: 671.93, train corr: 0.02729
Epoch [35/100], Batch [76/147] train loss: 658.64, train corr: 0.02772
Epoch [35/100], Batch [77/147] train loss: 633.29, train corr: 0.02778
Epoch [35/100], Batch [78/147] train loss: 623.05, train corr: 0.03050
Epoch [35/100], Batch [79/147] train loss: 618.32, train corr: 0.03130
Epoch [35/100], Batch [80/147] train loss: 618.66, train corr: 0.03257
Epoch [35/100], Batch [81/147] train loss: 586.21, train corr: 0.03179
Epoch [35/100], Batch [82/147] train loss: 601.61, train corr: 0.03105
Epoch [35/100], Batch [83/147] train loss: 614.67, train corr: 0.03395
Epoch [35/100], Batch [84/147] train loss: 592.10, train corr: 0.03266
Epoch [35/100], Batch [85/147] train loss: 594.84, train corr: 0.02418
Epoch [35/100], Batch [86/147] train loss: 620.54, train corr: -0.00777
Epoch [35/100], Batch [87/147] train loss: 606.01, train corr: 0.00537
Epoch [35/100], Batch [88/147] train loss: 604.19, train corr: 0.01952
Epoch [35/100], Batch [89/147] train loss: 622.16, train corr: 0.01563
Epoch [35/100], Batch [90/147] train loss: 608.11, train corr: -0.00504
Epoch [35/100], Batch [91/147] train loss: 612.03, train corr: -0.00742
Epoch [35/100], Batch [92/147] train loss: 599.41, train corr: 0.03034
Epoch [35/100], Batch [93/147] train loss: 585.02, train corr: 0.03213
Epoch [35/100], Batch [94/147] train loss: 644.72, train corr: 0.02898
Epoch [35/100], Batch [95/147] train loss: 579.74, train corr: 0.03401
Epoch [35/100], Batch [96/147] train loss: 586.42, train corr: 0.03166
Epoch [35/100], Batch [97/147] train loss: 574.99, train corr: 0.02546
Epoch [35/100], Batch [98/147] train loss: 577.62, train corr: 0.02598
Epoch [35/100], Batch [99/147] train loss: 651.13, train corr: 0.02496
Epoch [35/100], Batch [100/147] train loss: 587.82, train corr: 0.03158
Epoch [35/100], Batch [101/147] train loss: 583.25, train corr: 0.03443
Epoch [35/100], Batch [102/147] train loss: 572.67, train corr: 0.03154
Epoch [35/100], Batch [103/147] train loss: 564.54, train corr: 0.01510
Epoch [35/100], Batch [104/147] train loss: 575.17, train corr: 0.01887
Epoch [35/100], Batch [105/147] train loss: 581.38, train corr: 0.02885
Epoch [35/100], Batch [106/147] train loss: 571.75, train corr: 0.02982
Epoch [35/100], Batch [107/147] train loss: 564.75, train corr: 0.02838
Epoch [35/100], Batch [108/147] train loss: 564.29, train corr: 0.01601
Epoch [35/100], Batch [109/147] train loss: 585.22, train corr: 0.03213
Epoch [35/100], Batch [110/147] train loss: 585.78, train corr: 0.03051
Epoch [35/100], Batch [111/147] train loss: 555.66, train corr: 0.02811
Epoch [35/100], Batch [112/147] train loss: 644.07, train corr: 0.02572
Epoch [35/100], Batch [113/147] train loss: 583.17, train corr: 0.01887
Epoch [35/100], Batch [114/147] train loss: 580.51, train corr: -0.02144
Epoch [35/100], Batch [115/147] train loss: 585.42, train corr: -0.02641
Epoch [35/100], Batch [116/147] train loss: 568.51, train corr: -0.03243
Epoch [35/100], Batch [117/147] train loss: 562.85, train corr: -0.03144
Epoch [35/100], Batch [118/147] train loss: 581.39, train corr: -0.03063
Epoch [35/100], Batch [119/147] train loss: 567.67, train corr: -0.03386
Epoch [35/100], Batch [120/147] train loss: 565.39, train corr: -0.03103
Epoch [35/100], Batch [121/147] train loss: 560.95, train corr: -0.03182
Epoch [35/100], Batch [122/147] train loss: 562.25, train corr: -0.02905
Epoch [35/100], Batch [123/147] train loss: 573.66, train corr: -0.03173
Epoch [35/100], Batch [124/147] train loss: 566.26, train corr: -0.03182
Epoch [35/100], Batch [125/147] train loss: 565.74, train corr: -0.03258
Epoch [35/100], Batch [126/147] train loss: 560.52, train corr: -0.02967
Epoch [35/100], Batch [127/147] train loss: 562.76, train corr: -0.02785
Epoch [35/100], Batch [128/147] train loss: 568.71, train corr: -0.00225
Epoch [35/100], Batch [129/147] train loss: 554.81, train corr: 0.02642
Epoch [35/100], Batch [130/147] train loss: 574.48, train corr: 0.01584
Epoch [35/100], Batch [131/147] train loss: 564.65, train corr: 0.01414
Epoch [35/100], Batch [132/147] train loss: 583.42, train corr: 0.01196
Epoch [35/100], Batch [133/147] train loss: 567.02, train corr: 0.00138
Epoch [35/100], Batch [134/147] train loss: 563.55, train corr: -0.00653
Epoch [35/100], Batch [135/147] train loss: 582.06, train corr: -0.00367
Epoch [35/100], Batch [136/147] train loss: 561.88, train corr: -0.01389
Epoch [35/100], Batch [137/147] train loss: 585.38, train corr: -0.00659
Epoch [35/100], Batch [138/147] train loss: 564.34, train corr: -0.00993
Epoch [35/100], Batch [139/147] train loss: 579.14, train corr: -0.00708
Epoch [35/100], Batch [140/147] train loss: 556.14, train corr: -0.00972
Epoch [35/100], Batch [141/147] train loss: 743.92, train corr: -0.00286
Epoch [35/100], Batch [142/147] train loss: 583.14, train corr: -0.02052
Epoch [35/100], Batch [143/147] train loss: 598.97, train corr: 0.02760
Epoch [35/100], Batch [144/147] train loss: 628.65, train corr: 0.02472
Epoch [35/100], Batch [145/147] train loss: 665.53, train corr: 0.02747
Epoch [35/100], Batch [146/147] train loss: 685.78, train corr: 0.02727
Epoch [35/100], Batch [147/147] train loss: 682.89, train corr: 0.02828
Epoch [35/100], validation loss: 729.42, validation correlation: 0.02653
Epoch [36/100], Batch [1/147] train loss: 666.11, train corr: 0.02850
Epoch [36/100], Batch [2/147] train loss: 695.80, train corr: 0.02635
Epoch [36/100], Batch [3/147] train loss: 657.28, train corr: 0.02745
Epoch [36/100], Batch [4/147] train loss: 683.96, train corr: 0.02424
Epoch [36/100], Batch [5/147] train loss: 667.67, train corr: 0.02310
Epoch [36/100], Batch [6/147] train loss: 727.82, train corr: 0.02508
Epoch [36/100], Batch [7/147] train loss: 656.07, train corr: 0.02755
Epoch [36/100], Batch [8/147] train loss: 647.60, train corr: 0.02647
Epoch [36/100], Batch [9/147] train loss: 631.08, train corr: 0.02726
Epoch [36/100], Batch [10/147] train loss: 629.86, train corr: 0.03133
Epoch [36/100], Batch [11/147] train loss: 613.46, train corr: 0.02351
Epoch [36/100], Batch [12/147] train loss: 604.81, train corr: 0.02876
Epoch [36/100], Batch [13/147] train loss: 575.39, train corr: 0.02714
Epoch [36/100], Batch [14/147] train loss: 575.81, train corr: 0.00035
Epoch [36/100], Batch [15/147] train loss: 678.84, train corr: -0.01857
Epoch [36/100], Batch [16/147] train loss: 630.51, train corr: 0.02637
Epoch [36/100], Batch [17/147] train loss: 687.96, train corr: 0.02692
Epoch [36/100], Batch [18/147] train loss: 728.95, train corr: 0.02562
Epoch [36/100], Batch [19/147] train loss: 783.46, train corr: 0.02502
Epoch [36/100], Batch [20/147] train loss: 788.34, train corr: 0.02370
Epoch [36/100], Batch [21/147] train loss: 806.69, train corr: 0.02702
Epoch [36/100], Batch [22/147] train loss: 803.48, train corr: 0.02721
Epoch [36/100], Batch [23/147] train loss: 841.64, train corr: 0.02615
Epoch [36/100], Batch [24/147] train loss: 798.42, train corr: 0.02810
Epoch [36/100], Batch [25/147] train loss: 791.26, train corr: 0.02739
Epoch [36/100], Batch [26/147] train loss: 806.29, train corr: 0.02335
Epoch [36/100], Batch [27/147] train loss: 780.30, train corr: 0.02082
Epoch [36/100], Batch [28/147] train loss: 747.78, train corr: 0.02712
Epoch [36/100], Batch [29/147] train loss: 738.47, train corr: 0.02654
Epoch [36/100], Batch [30/147] train loss: 722.17, train corr: 0.02493
Epoch [36/100], Batch [31/147] train loss: 741.70, train corr: 0.02539
Epoch [36/100], Batch [32/147] train loss: 723.82, train corr: 0.02523
Epoch [36/100], Batch [33/147] train loss: 691.64, train corr: 0.02713
Epoch [36/100], Batch [34/147] train loss: 681.67, train corr: 0.02751
Epoch [36/100], Batch [35/147] train loss: 630.08, train corr: 0.02693
Epoch [36/100], Batch [36/147] train loss: 622.09, train corr: 0.02642
Epoch [36/100], Batch [37/147] train loss: 628.69, train corr: 0.02617
Epoch [36/100], Batch [38/147] train loss: 613.20, train corr: 0.02683
Epoch [36/100], Batch [39/147] train loss: 598.98, train corr: 0.02819
Epoch [36/100], Batch [40/147] train loss: 600.54, train corr: 0.02842
Epoch [36/100], Batch [41/147] train loss: 594.62, train corr: -0.02139
Epoch [36/100], Batch [42/147] train loss: 604.93, train corr: 0.02416
Epoch [36/100], Batch [43/147] train loss: 614.43, train corr: 0.02483
Epoch [36/100], Batch [44/147] train loss: 613.11, train corr: 0.02828
Epoch [36/100], Batch [45/147] train loss: 630.79, train corr: 0.02709
Epoch [36/100], Batch [46/147] train loss: 617.81, train corr: 0.02703
Epoch [36/100], Batch [47/147] train loss: 598.52, train corr: 0.02673
Epoch [36/100], Batch [48/147] train loss: 591.46, train corr: 0.02809
Epoch [36/100], Batch [49/147] train loss: 580.31, train corr: 0.02746
Epoch [36/100], Batch [50/147] train loss: 581.48, train corr: 0.02553
Epoch [36/100], Batch [51/147] train loss: 670.48, train corr: -0.01964
Epoch [36/100], Batch [52/147] train loss: 598.86, train corr: 0.02727
Epoch [36/100], Batch [53/147] train loss: 643.30, train corr: 0.02484
Epoch [36/100], Batch [54/147] train loss: 697.36, train corr: 0.02335
Epoch [36/100], Batch [55/147] train loss: 748.39, train corr: 0.01967
Epoch [36/100], Batch [56/147] train loss: 750.06, train corr: 0.02256
Epoch [36/100], Batch [57/147] train loss: 760.38, train corr: 0.02073
Epoch [36/100], Batch [58/147] train loss: 742.30, train corr: 0.02311
Epoch [36/100], Batch [59/147] train loss: 756.47, train corr: 0.02647
Epoch [36/100], Batch [60/147] train loss: 727.40, train corr: 0.02591
Epoch [36/100], Batch [61/147] train loss: 758.81, train corr: 0.02650
Epoch [36/100], Batch [62/147] train loss: 732.51, train corr: 0.02458
Epoch [36/100], Batch [63/147] train loss: 738.93, train corr: 0.02683
Epoch [36/100], Batch [64/147] train loss: 718.45, train corr: 0.02725
Epoch [36/100], Batch [65/147] train loss: 712.56, train corr: 0.02512
Epoch [36/100], Batch [66/147] train loss: 698.31, train corr: 0.02570
Epoch [36/100], Batch [67/147] train loss: 689.14, train corr: 0.02692
Epoch [36/100], Batch [68/147] train loss: 676.07, train corr: 0.02810
Epoch [36/100], Batch [69/147] train loss: 665.13, train corr: 0.02646
Epoch [36/100], Batch [70/147] train loss: 644.48, train corr: 0.02502
Epoch [36/100], Batch [71/147] train loss: 666.54, train corr: 0.02219
Epoch [36/100], Batch [72/147] train loss: 621.52, train corr: 0.02817
Epoch [36/100], Batch [73/147] train loss: 939.41, train corr: 0.02498
Epoch [36/100], Batch [74/147] train loss: 582.49, train corr: 0.02964
Epoch [36/100], Batch [75/147] train loss: 714.09, train corr: -0.00483
Epoch [36/100], Batch [76/147] train loss: 663.21, train corr: 0.03011
Epoch [36/100], Batch [77/147] train loss: 742.43, train corr: 0.02598
Epoch [36/100], Batch [78/147] train loss: 870.83, train corr: 0.02140
Epoch [36/100], Batch [79/147] train loss: 916.70, train corr: 0.02620
Epoch [36/100], Batch [80/147] train loss: 928.11, train corr: 0.02827
Epoch [36/100], Batch [81/147] train loss: 984.92, train corr: 0.02839
Epoch [36/100], Batch [82/147] train loss: 1010.50, train corr: 0.02827
Epoch [36/100], Batch [83/147] train loss: 1078.37, train corr: 0.02803
Epoch [36/100], Batch [84/147] train loss: 1041.06, train corr: 0.02524
Epoch [36/100], Batch [85/147] train loss: 1055.22, train corr: 0.02713
Epoch [36/100], Batch [86/147] train loss: 1029.35, train corr: 0.02405
Epoch [36/100], Batch [87/147] train loss: 1057.51, train corr: 0.02568
Epoch [36/100], Batch [88/147] train loss: 980.87, train corr: 0.02852
Epoch [36/100], Batch [89/147] train loss: 987.23, train corr: 0.02780
Epoch [36/100], Batch [90/147] train loss: 988.74, train corr: 0.02726
Epoch [36/100], Batch [91/147] train loss: 976.00, train corr: 0.02362
Epoch [36/100], Batch [92/147] train loss: 954.57, train corr: 0.02741
Epoch [36/100], Batch [93/147] train loss: 965.12, train corr: 0.02533
Epoch [36/100], Batch [94/147] train loss: 938.30, train corr: 0.02277
Epoch [36/100], Batch [95/147] train loss: 927.23, train corr: 0.02211
Epoch [36/100], Batch [96/147] train loss: 862.47, train corr: 0.02659
Epoch [36/100], Batch [97/147] train loss: 843.80, train corr: 0.02784
Epoch [36/100], Batch [98/147] train loss: 804.27, train corr: 0.02896
Epoch [36/100], Batch [99/147] train loss: 941.38, train corr: 0.02647
Epoch [36/100], Batch [100/147] train loss: 767.33, train corr: 0.02773
Epoch [36/100], Batch [101/147] train loss: 777.97, train corr: 0.02922
Epoch [36/100], Batch [102/147] train loss: 779.67, train corr: 0.02330
Epoch [36/100], Batch [103/147] train loss: 730.49, train corr: 0.02710
Epoch [36/100], Batch [104/147] train loss: 706.17, train corr: 0.02576
Epoch [36/100], Batch [105/147] train loss: 686.30, train corr: 0.02863
Epoch [36/100], Batch [106/147] train loss: 672.52, train corr: 0.02793
Epoch [36/100], Batch [107/147] train loss: 652.13, train corr: 0.02697
Epoch [36/100], Batch [108/147] train loss: 637.97, train corr: 0.02815
Epoch [36/100], Batch [109/147] train loss: 658.45, train corr: 0.02625
Epoch [36/100], Batch [110/147] train loss: 608.78, train corr: 0.02787
Epoch [36/100], Batch [111/147] train loss: 614.21, train corr: 0.02928
Epoch [36/100], Batch [112/147] train loss: 616.57, train corr: 0.03027
Epoch [36/100], Batch [113/147] train loss: 608.55, train corr: 0.02610
Epoch [36/100], Batch [114/147] train loss: 617.79, train corr: 0.02821
Epoch [36/100], Batch [115/147] train loss: 611.16, train corr: 0.02980
Epoch [36/100], Batch [116/147] train loss: 605.60, train corr: 0.03118
Epoch [36/100], Batch [117/147] train loss: 588.73, train corr: 0.03494
Epoch [36/100], Batch [118/147] train loss: 629.06, train corr: 0.02765
Epoch [36/100], Batch [119/147] train loss: 613.80, train corr: 0.02809
Epoch [36/100], Batch [120/147] train loss: 616.74, train corr: 0.02780
Epoch [36/100], Batch [121/147] train loss: 604.76, train corr: 0.02687
Epoch [36/100], Batch [122/147] train loss: 582.13, train corr: 0.03227
Epoch [36/100], Batch [123/147] train loss: 592.15, train corr: 0.02999
Epoch [36/100], Batch [124/147] train loss: 588.48, train corr: 0.03330
Epoch [36/100], Batch [125/147] train loss: 602.52, train corr: 0.02706
Epoch [36/100], Batch [126/147] train loss: 574.64, train corr: 0.02998
Epoch [36/100], Batch [127/147] train loss: 662.66, train corr: 0.02647
Epoch [36/100], Batch [128/147] train loss: 583.00, train corr: 0.02935
Epoch [36/100], Batch [129/147] train loss: 580.67, train corr: 0.03050
Epoch [36/100], Batch [130/147] train loss: 591.57, train corr: 0.02956
Epoch [36/100], Batch [131/147] train loss: 572.07, train corr: 0.03009
Epoch [36/100], Batch [132/147] train loss: 591.21, train corr: 0.02910
Epoch [36/100], Batch [133/147] train loss: 590.69, train corr: 0.02754
Epoch [36/100], Batch [134/147] train loss: 572.67, train corr: 0.02916
Epoch [36/100], Batch [135/147] train loss: 568.20, train corr: 0.02915
Epoch [36/100], Batch [136/147] train loss: 770.81, train corr: 0.02580
Epoch [36/100], Batch [137/147] train loss: 583.90, train corr: 0.03217
Epoch [36/100], Batch [138/147] train loss: 579.16, train corr: 0.02804
Epoch [36/100], Batch [139/147] train loss: 578.13, train corr: 0.02945
Epoch [36/100], Batch [140/147] train loss: 568.35, train corr: 0.02897
Epoch [36/100], Batch [141/147] train loss: 593.03, train corr: 0.02464
Epoch [36/100], Batch [142/147] train loss: 568.59, train corr: 0.02778
Epoch [36/100], Batch [143/147] train loss: 582.57, train corr: 0.02647
Epoch [36/100], Batch [144/147] train loss: 594.39, train corr: -0.00342
Epoch [36/100], Batch [145/147] train loss: 579.95, train corr: 0.02844
Epoch [36/100], Batch [146/147] train loss: 602.32, train corr: 0.02463
Epoch [36/100], Batch [147/147] train loss: 617.50, train corr: 0.02045
Epoch [36/100], validation loss: 636.89, validation correlation: 0.02680
Epoch [37/100], Batch [1/147] train loss: 597.81, train corr: 0.02693
Epoch [37/100], Batch [2/147] train loss: 583.74, train corr: 0.02664
Epoch [37/100], Batch [3/147] train loss: 602.38, train corr: 0.02637
Epoch [37/100], Batch [4/147] train loss: 592.57, train corr: 0.03008
Epoch [37/100], Batch [5/147] train loss: 584.95, train corr: 0.02658
Epoch [37/100], Batch [6/147] train loss: 612.83, train corr: 0.02555
Epoch [37/100], Batch [7/147] train loss: 578.17, train corr: 0.03239
Epoch [37/100], Batch [8/147] train loss: 570.94, train corr: 0.00250
Epoch [37/100], Batch [9/147] train loss: 591.43, train corr: 0.02611
Epoch [37/100], Batch [10/147] train loss: 618.38, train corr: 0.02313
Epoch [37/100], Batch [11/147] train loss: 573.70, train corr: 0.02720
Epoch [37/100], Batch [12/147] train loss: 586.59, train corr: -0.02473
Epoch [37/100], Batch [13/147] train loss: 594.15, train corr: -0.02539
Epoch [37/100], Batch [14/147] train loss: 566.17, train corr: 0.00070
Epoch [37/100], Batch [15/147] train loss: 605.27, train corr: 0.02487
Epoch [37/100], Batch [16/147] train loss: 594.94, train corr: 0.02188
Epoch [37/100], Batch [17/147] train loss: 594.13, train corr: 0.02352
Epoch [37/100], Batch [18/147] train loss: 568.48, train corr: -0.03119
Epoch [37/100], Batch [19/147] train loss: 603.08, train corr: -0.01885
Epoch [37/100], Batch [20/147] train loss: 595.87, train corr: 0.02862
Epoch [37/100], Batch [21/147] train loss: 601.81, train corr: 0.02586
Epoch [37/100], Batch [22/147] train loss: 614.22, train corr: 0.02759
Epoch [37/100], Batch [23/147] train loss: 629.13, train corr: 0.02352
Epoch [37/100], Batch [24/147] train loss: 652.42, train corr: 0.02584
Epoch [37/100], Batch [25/147] train loss: 640.42, train corr: 0.02763
Epoch [37/100], Batch [26/147] train loss: 618.68, train corr: 0.02575
Epoch [37/100], Batch [27/147] train loss: 649.12, train corr: 0.02226
Epoch [37/100], Batch [28/147] train loss: 625.65, train corr: 0.02548
Epoch [37/100], Batch [29/147] train loss: 633.76, train corr: 0.02707
Epoch [37/100], Batch [30/147] train loss: 611.34, train corr: 0.02618
Epoch [37/100], Batch [31/147] train loss: 629.53, train corr: 0.02403
Epoch [37/100], Batch [32/147] train loss: 594.93, train corr: 0.02957
Epoch [37/100], Batch [33/147] train loss: 584.29, train corr: 0.02650
Epoch [37/100], Batch [34/147] train loss: 589.71, train corr: 0.03071
Epoch [37/100], Batch [35/147] train loss: 575.73, train corr: 0.03189
Epoch [37/100], Batch [36/147] train loss: 596.88, train corr: -0.01987
Epoch [37/100], Batch [37/147] train loss: 589.60, train corr: 0.02531
Epoch [37/100], Batch [38/147] train loss: 625.15, train corr: 0.02553
Epoch [37/100], Batch [39/147] train loss: 644.56, train corr: 0.02485
Epoch [37/100], Batch [40/147] train loss: 638.15, train corr: 0.02727
Epoch [37/100], Batch [41/147] train loss: 635.63, train corr: 0.02603
Epoch [37/100], Batch [42/147] train loss: 631.48, train corr: 0.02784
Epoch [37/100], Batch [43/147] train loss: 642.43, train corr: 0.02438
Epoch [37/100], Batch [44/147] train loss: 634.65, train corr: 0.02692
Epoch [37/100], Batch [45/147] train loss: 614.06, train corr: 0.02737
Epoch [37/100], Batch [46/147] train loss: 588.97, train corr: 0.02764
Epoch [37/100], Batch [47/147] train loss: 576.14, train corr: 0.02996
Epoch [37/100], Batch [48/147] train loss: 594.71, train corr: 0.03546
Epoch [37/100], Batch [49/147] train loss: 629.93, train corr: -0.00261
Epoch [37/100], Batch [50/147] train loss: 583.46, train corr: 0.02969
Epoch [37/100], Batch [51/147] train loss: 613.31, train corr: 0.02770
Epoch [37/100], Batch [52/147] train loss: 626.60, train corr: 0.02842
Epoch [37/100], Batch [53/147] train loss: 653.28, train corr: 0.02801
Epoch [37/100], Batch [54/147] train loss: 636.13, train corr: 0.02731
Epoch [37/100], Batch [55/147] train loss: 1112.88, train corr: 0.02205
Epoch [37/100], Batch [56/147] train loss: 644.30, train corr: 0.02703
Epoch [37/100], Batch [57/147] train loss: 628.95, train corr: 0.02661
Epoch [37/100], Batch [58/147] train loss: 799.45, train corr: 0.02151
Epoch [37/100], Batch [59/147] train loss: 608.95, train corr: 0.02615
Epoch [37/100], Batch [60/147] train loss: 581.80, train corr: 0.02762
Epoch [37/100], Batch [61/147] train loss: 606.51, train corr: 0.03236
Epoch [37/100], Batch [62/147] train loss: 607.16, train corr: 0.00068
Epoch [37/100], Batch [63/147] train loss: 572.71, train corr: 0.02640
Epoch [37/100], Batch [64/147] train loss: 596.64, train corr: 0.02710
Epoch [37/100], Batch [65/147] train loss: 595.12, train corr: 0.02617
Epoch [37/100], Batch [66/147] train loss: 619.07, train corr: 0.02514
Epoch [37/100], Batch [67/147] train loss: 615.19, train corr: 0.02474
Epoch [37/100], Batch [68/147] train loss: 624.17, train corr: 0.02460
Epoch [37/100], Batch [69/147] train loss: 605.15, train corr: 0.02234
Epoch [37/100], Batch [70/147] train loss: 582.97, train corr: 0.02279
Epoch [37/100], Batch [71/147] train loss: 582.30, train corr: -0.02991
Epoch [37/100], Batch [72/147] train loss: 588.28, train corr: -0.03016
Epoch [37/100], Batch [73/147] train loss: 574.76, train corr: 0.01671
Epoch [37/100], Batch [74/147] train loss: 601.31, train corr: 0.02341
Epoch [37/100], Batch [75/147] train loss: 616.16, train corr: 0.02439
Epoch [37/100], Batch [76/147] train loss: 624.36, train corr: 0.02127
Epoch [37/100], Batch [77/147] train loss: 604.65, train corr: 0.02258
Epoch [37/100], Batch [78/147] train loss: 607.15, train corr: 0.02398
Epoch [37/100], Batch [79/147] train loss: 620.61, train corr: 0.02287
Epoch [37/100], Batch [80/147] train loss: 600.59, train corr: 0.02184
Epoch [37/100], Batch [81/147] train loss: 584.99, train corr: 0.02611
Epoch [37/100], Batch [82/147] train loss: 561.88, train corr: 0.01991
Epoch [37/100], Batch [83/147] train loss: 628.59, train corr: -0.02635
Epoch [37/100], Batch [84/147] train loss: 610.80, train corr: 0.02235
Epoch [37/100], Batch [85/147] train loss: 645.50, train corr: 0.02677
Epoch [37/100], Batch [86/147] train loss: 675.48, train corr: 0.02554
Epoch [37/100], Batch [87/147] train loss: 701.65, train corr: 0.02755
Epoch [37/100], Batch [88/147] train loss: 751.25, train corr: 0.02794
Epoch [37/100], Batch [89/147] train loss: 769.44, train corr: 0.02400
Epoch [37/100], Batch [90/147] train loss: 751.74, train corr: 0.02666
Epoch [37/100], Batch [91/147] train loss: 764.53, train corr: 0.02557
Epoch [37/100], Batch [92/147] train loss: 787.87, train corr: 0.02334
Epoch [37/100], Batch [93/147] train loss: 740.91, train corr: 0.02566
Epoch [37/100], Batch [94/147] train loss: 742.13, train corr: 0.02711
Epoch [37/100], Batch [95/147] train loss: 737.24, train corr: 0.02351
Epoch [37/100], Batch [96/147] train loss: 719.41, train corr: 0.02860
Epoch [37/100], Batch [97/147] train loss: 684.12, train corr: 0.02774
Epoch [37/100], Batch [98/147] train loss: 703.94, train corr: 0.02437
Epoch [37/100], Batch [99/147] train loss: 677.70, train corr: 0.02586
Epoch [37/100], Batch [100/147] train loss: 694.12, train corr: 0.02253
Epoch [37/100], Batch [101/147] train loss: 653.40, train corr: 0.02689
Epoch [37/100], Batch [102/147] train loss: 648.15, train corr: 0.02583
Epoch [37/100], Batch [103/147] train loss: 622.37, train corr: 0.02694
Epoch [37/100], Batch [104/147] train loss: 622.17, train corr: 0.02894
Epoch [37/100], Batch [105/147] train loss: 602.89, train corr: 0.02918
Epoch [37/100], Batch [106/147] train loss: 592.34, train corr: 0.02934
Epoch [37/100], Batch [107/147] train loss: 573.21, train corr: 0.03019
Epoch [37/100], Batch [108/147] train loss: 767.73, train corr: -0.01359
Epoch [37/100], Batch [109/147] train loss: 637.88, train corr: 0.02571
Epoch [37/100], Batch [110/147] train loss: 686.22, train corr: 0.02736
Epoch [37/100], Batch [111/147] train loss: 724.73, train corr: 0.02782
Epoch [37/100], Batch [112/147] train loss: 766.02, train corr: 0.02855
Epoch [37/100], Batch [113/147] train loss: 839.22, train corr: 0.02215
Epoch [37/100], Batch [114/147] train loss: 853.96, train corr: 0.02389
Epoch [37/100], Batch [115/147] train loss: 844.01, train corr: 0.02595
Epoch [37/100], Batch [116/147] train loss: 838.60, train corr: 0.02698
Epoch [37/100], Batch [117/147] train loss: 872.92, train corr: 0.02761
Epoch [37/100], Batch [118/147] train loss: 863.26, train corr: 0.02651
Epoch [37/100], Batch [119/147] train loss: 876.33, train corr: 0.02743
Epoch [37/100], Batch [120/147] train loss: 855.85, train corr: 0.02619
Epoch [37/100], Batch [121/147] train loss: 842.71, train corr: 0.02620
Epoch [37/100], Batch [122/147] train loss: 828.79, train corr: 0.02525
Epoch [37/100], Batch [123/147] train loss: 831.64, train corr: 0.02427
Epoch [37/100], Batch [124/147] train loss: 798.10, train corr: 0.02585
Epoch [37/100], Batch [125/147] train loss: 763.32, train corr: 0.02577
Epoch [37/100], Batch [126/147] train loss: 764.80, train corr: 0.02701
Epoch [37/100], Batch [127/147] train loss: 758.04, train corr: 0.02238
Epoch [37/100], Batch [128/147] train loss: 705.35, train corr: 0.02833
Epoch [37/100], Batch [129/147] train loss: 714.10, train corr: 0.02549
Epoch [37/100], Batch [130/147] train loss: 732.03, train corr: 0.02293
Epoch [37/100], Batch [131/147] train loss: 687.90, train corr: 0.02792
Epoch [37/100], Batch [132/147] train loss: 669.39, train corr: 0.02836
Epoch [37/100], Batch [133/147] train loss: 982.41, train corr: 0.02743
Epoch [37/100], Batch [134/147] train loss: 626.04, train corr: 0.03062
Epoch [37/100], Batch [135/147] train loss: 617.26, train corr: 0.02889
Epoch [37/100], Batch [136/147] train loss: 619.58, train corr: 0.02468
Epoch [37/100], Batch [137/147] train loss: 581.65, train corr: 0.03085
Epoch [37/100], Batch [138/147] train loss: 680.24, train corr: -0.01296
Epoch [37/100], Batch [139/147] train loss: 610.94, train corr: 0.02731
Epoch [37/100], Batch [140/147] train loss: 673.09, train corr: 0.01954
Epoch [37/100], Batch [141/147] train loss: 700.71, train corr: 0.02741
Epoch [37/100], Batch [142/147] train loss: 748.03, train corr: 0.02149
Epoch [37/100], Batch [143/147] train loss: 771.52, train corr: 0.02534
Epoch [37/100], Batch [144/147] train loss: 778.08, train corr: 0.02459
Epoch [37/100], Batch [145/147] train loss: 815.68, train corr: 0.02401
Epoch [37/100], Batch [146/147] train loss: 746.13, train corr: 0.02728
Epoch [37/100], Batch [147/147] train loss: 767.74, train corr: 0.02699
Epoch [37/100], validation loss: 810.83, validation correlation: 0.02649
Epoch [38/100], Batch [1/147] train loss: 764.59, train corr: 0.02440
Epoch [38/100], Batch [2/147] train loss: 725.76, train corr: 0.02526
Epoch [38/100], Batch [3/147] train loss: 744.26, train corr: 0.02669
Epoch [38/100], Batch [4/147] train loss: 706.79, train corr: 0.02642
Epoch [38/100], Batch [5/147] train loss: 733.93, train corr: 0.02411
Epoch [38/100], Batch [6/147] train loss: 702.31, train corr: 0.03026
Epoch [38/100], Batch [7/147] train loss: 696.80, train corr: 0.02701
Epoch [38/100], Batch [8/147] train loss: 690.22, train corr: 0.02252
Epoch [38/100], Batch [9/147] train loss: 668.74, train corr: 0.02412
Epoch [38/100], Batch [10/147] train loss: 647.80, train corr: 0.01941
Epoch [38/100], Batch [11/147] train loss: 645.22, train corr: 0.02575
Epoch [38/100], Batch [12/147] train loss: 649.08, train corr: 0.02525
Epoch [38/100], Batch [13/147] train loss: 625.27, train corr: 0.02688
Epoch [38/100], Batch [14/147] train loss: 586.02, train corr: 0.03000
Epoch [38/100], Batch [15/147] train loss: 588.10, train corr: 0.02564
Epoch [38/100], Batch [16/147] train loss: 582.39, train corr: -0.00981
Epoch [38/100], Batch [17/147] train loss: 603.19, train corr: -0.01769
Epoch [38/100], Batch [18/147] train loss: 584.37, train corr: 0.02765
Epoch [38/100], Batch [19/147] train loss: 598.10, train corr: 0.02589
Epoch [38/100], Batch [20/147] train loss: 627.70, train corr: 0.02179
Epoch [38/100], Batch [21/147] train loss: 631.09, train corr: 0.02420
Epoch [38/100], Batch [22/147] train loss: 639.69, train corr: 0.02397
Epoch [38/100], Batch [23/147] train loss: 633.29, train corr: 0.02314
Epoch [38/100], Batch [24/147] train loss: 632.05, train corr: 0.02250
Epoch [38/100], Batch [25/147] train loss: 623.59, train corr: 0.02231
Epoch [38/100], Batch [26/147] train loss: 605.32, train corr: 0.02651
Epoch [38/100], Batch [27/147] train loss: 589.49, train corr: 0.02204
Epoch [38/100], Batch [28/147] train loss: 612.27, train corr: -0.02379
Epoch [38/100], Batch [29/147] train loss: 607.44, train corr: -0.02577
Epoch [38/100], Batch [30/147] train loss: 592.99, train corr: 0.02711
Epoch [38/100], Batch [31/147] train loss: 636.35, train corr: 0.02460
Epoch [38/100], Batch [32/147] train loss: 649.91, train corr: 0.02148
Epoch [38/100], Batch [33/147] train loss: 658.88, train corr: 0.02652
Epoch [38/100], Batch [34/147] train loss: 651.13, train corr: 0.02692
Epoch [38/100], Batch [35/147] train loss: 668.08, train corr: 0.02615
Epoch [38/100], Batch [36/147] train loss: 740.87, train corr: 0.02597
Epoch [38/100], Batch [37/147] train loss: 633.16, train corr: 0.02720
Epoch [38/100], Batch [38/147] train loss: 651.04, train corr: 0.02587
Epoch [38/100], Batch [39/147] train loss: 642.05, train corr: 0.02457
Epoch [38/100], Batch [40/147] train loss: 629.51, train corr: 0.02774
Epoch [38/100], Batch [41/147] train loss: 634.34, train corr: 0.02486
Epoch [38/100], Batch [42/147] train loss: 609.98, train corr: 0.02813
Epoch [38/100], Batch [43/147] train loss: 611.97, train corr: 0.02472
Epoch [38/100], Batch [44/147] train loss: 590.47, train corr: 0.02578
Epoch [38/100], Batch [45/147] train loss: 578.45, train corr: 0.02894
Epoch [38/100], Batch [46/147] train loss: 574.69, train corr: 0.03126
Epoch [38/100], Batch [47/147] train loss: 606.84, train corr: -0.01744
Epoch [38/100], Batch [48/147] train loss: 587.65, train corr: 0.03216
Epoch [38/100], Batch [49/147] train loss: 593.44, train corr: 0.02919
Epoch [38/100], Batch [50/147] train loss: 581.33, train corr: 0.02954
Epoch [38/100], Batch [51/147] train loss: 600.68, train corr: 0.02786
Epoch [38/100], Batch [52/147] train loss: 605.38, train corr: 0.02809
Epoch [38/100], Batch [53/147] train loss: 585.78, train corr: -0.00584
Epoch [38/100], Batch [54/147] train loss: 580.36, train corr: -0.02352
Epoch [38/100], Batch [55/147] train loss: 598.41, train corr: -0.02680
Epoch [38/100], Batch [56/147] train loss: 601.62, train corr: 0.02810
Epoch [38/100], Batch [57/147] train loss: 626.17, train corr: 0.02740
Epoch [38/100], Batch [58/147] train loss: 643.49, train corr: 0.02709
Epoch [38/100], Batch [59/147] train loss: 661.66, train corr: 0.02605
Epoch [38/100], Batch [60/147] train loss: 653.17, train corr: 0.02736
Epoch [38/100], Batch [61/147] train loss: 686.89, train corr: 0.02373
Epoch [38/100], Batch [62/147] train loss: 668.49, train corr: 0.02818
Epoch [38/100], Batch [63/147] train loss: 690.09, train corr: 0.02506
Epoch [38/100], Batch [64/147] train loss: 675.27, train corr: 0.02813
Epoch [38/100], Batch [65/147] train loss: 676.41, train corr: 0.02150
Epoch [38/100], Batch [66/147] train loss: 642.49, train corr: 0.03035
Epoch [38/100], Batch [67/147] train loss: 649.13, train corr: 0.02950
Epoch [38/100], Batch [68/147] train loss: 670.31, train corr: 0.02611
Epoch [38/100], Batch [69/147] train loss: 946.26, train corr: 0.02576
Epoch [38/100], Batch [70/147] train loss: 639.95, train corr: 0.02806
Epoch [38/100], Batch [71/147] train loss: 616.20, train corr: 0.02383
Epoch [38/100], Batch [72/147] train loss: 625.58, train corr: 0.02286
Epoch [38/100], Batch [73/147] train loss: 573.34, train corr: 0.03060
Epoch [38/100], Batch [74/147] train loss: 573.30, train corr: 0.03367
Epoch [38/100], Batch [75/147] train loss: 650.19, train corr: -0.02273
Epoch [38/100], Batch [76/147] train loss: 629.50, train corr: 0.02577
Epoch [38/100], Batch [77/147] train loss: 675.34, train corr: 0.02073
Epoch [38/100], Batch [78/147] train loss: 688.23, train corr: 0.02688
Epoch [38/100], Batch [79/147] train loss: 725.92, train corr: 0.02585
Epoch [38/100], Batch [80/147] train loss: 741.93, train corr: 0.02882
Epoch [38/100], Batch [81/147] train loss: 739.12, train corr: 0.02518
Epoch [38/100], Batch [82/147] train loss: 756.45, train corr: 0.02332
Epoch [38/100], Batch [83/147] train loss: 750.96, train corr: 0.02668
Epoch [38/100], Batch [84/147] train loss: 766.39, train corr: 0.02268
Epoch [38/100], Batch [85/147] train loss: 732.41, train corr: 0.02773
Epoch [38/100], Batch [86/147] train loss: 734.17, train corr: 0.02551
Epoch [38/100], Batch [87/147] train loss: 704.79, train corr: 0.02920
Epoch [38/100], Batch [88/147] train loss: 714.29, train corr: 0.02287
Epoch [38/100], Batch [89/147] train loss: 691.13, train corr: 0.02161
Epoch [38/100], Batch [90/147] train loss: 656.24, train corr: 0.02851
Epoch [38/100], Batch [91/147] train loss: 683.86, train corr: 0.02408
Epoch [38/100], Batch [92/147] train loss: 645.26, train corr: 0.02921
Epoch [38/100], Batch [93/147] train loss: 631.13, train corr: 0.02519
Epoch [38/100], Batch [94/147] train loss: 620.35, train corr: 0.02930
Epoch [38/100], Batch [95/147] train loss: 619.28, train corr: 0.02698
Epoch [38/100], Batch [96/147] train loss: 603.02, train corr: 0.02677
Epoch [38/100], Batch [97/147] train loss: 577.07, train corr: 0.02788
Epoch [38/100], Batch [98/147] train loss: 572.67, train corr: 0.01814
Epoch [38/100], Batch [99/147] train loss: 700.34, train corr: -0.02218
Epoch [38/100], Batch [100/147] train loss: 631.41, train corr: 0.02668
Epoch [38/100], Batch [101/147] train loss: 732.28, train corr: 0.02484
Epoch [38/100], Batch [102/147] train loss: 821.80, train corr: 0.02625
Epoch [38/100], Batch [103/147] train loss: 875.50, train corr: 0.02579
Epoch [38/100], Batch [104/147] train loss: 891.61, train corr: 0.02466
Epoch [38/100], Batch [105/147] train loss: 938.78, train corr: 0.02501
Epoch [38/100], Batch [106/147] train loss: 942.79, train corr: 0.02792
Epoch [38/100], Batch [107/147] train loss: 981.09, train corr: 0.02492
Epoch [38/100], Batch [108/147] train loss: 996.80, train corr: 0.02268
Epoch [38/100], Batch [109/147] train loss: 974.87, train corr: 0.02724
Epoch [38/100], Batch [110/147] train loss: 1024.50, train corr: 0.02437
Epoch [38/100], Batch [111/147] train loss: 975.01, train corr: 0.02546
Epoch [38/100], Batch [112/147] train loss: 957.66, train corr: 0.02514
Epoch [38/100], Batch [113/147] train loss: 952.89, train corr: 0.02858
Epoch [38/100], Batch [114/147] train loss: 963.71, train corr: 0.02564
Epoch [38/100], Batch [115/147] train loss: 939.73, train corr: 0.02891
Epoch [38/100], Batch [116/147] train loss: 928.13, train corr: 0.02707
Epoch [38/100], Batch [117/147] train loss: 951.93, train corr: 0.02219
Epoch [38/100], Batch [118/147] train loss: 908.76, train corr: 0.02565
Epoch [38/100], Batch [119/147] train loss: 901.34, train corr: 0.02421
Epoch [38/100], Batch [120/147] train loss: 870.77, train corr: 0.02916
Epoch [38/100], Batch [121/147] train loss: 864.04, train corr: 0.02381
Epoch [38/100], Batch [122/147] train loss: 813.51, train corr: 0.02526
Epoch [38/100], Batch [123/147] train loss: 805.02, train corr: 0.02580
Epoch [38/100], Batch [124/147] train loss: 792.10, train corr: 0.02276
Epoch [38/100], Batch [125/147] train loss: 761.79, train corr: 0.02727
Epoch [38/100], Batch [126/147] train loss: 747.82, train corr: 0.02672
Epoch [38/100], Batch [127/147] train loss: 722.61, train corr: 0.02559
Epoch [38/100], Batch [128/147] train loss: 726.53, train corr: 0.02196
Epoch [38/100], Batch [129/147] train loss: 704.70, train corr: 0.02766
Epoch [38/100], Batch [130/147] train loss: 684.98, train corr: 0.03023
Epoch [38/100], Batch [131/147] train loss: 666.13, train corr: 0.02825
Epoch [38/100], Batch [132/147] train loss: 650.10, train corr: 0.02937
Epoch [38/100], Batch [133/147] train loss: 728.59, train corr: 0.02565
Epoch [38/100], Batch [134/147] train loss: 647.09, train corr: 0.02764
Epoch [38/100], Batch [135/147] train loss: 975.04, train corr: 0.02358
Epoch [38/100], Batch [136/147] train loss: 614.78, train corr: 0.02882
Epoch [38/100], Batch [137/147] train loss: 619.50, train corr: 0.03227
Epoch [38/100], Batch [138/147] train loss: 613.78, train corr: 0.02955
Epoch [38/100], Batch [139/147] train loss: 626.60, train corr: 0.02993
Epoch [38/100], Batch [140/147] train loss: 613.18, train corr: 0.02961
Epoch [38/100], Batch [141/147] train loss: 708.77, train corr: 0.02266
Epoch [38/100], Batch [142/147] train loss: 617.62, train corr: 0.03095
Epoch [38/100], Batch [143/147] train loss: 613.10, train corr: 0.02503
Epoch [38/100], Batch [144/147] train loss: 588.46, train corr: 0.02850
Epoch [38/100], Batch [145/147] train loss: 615.87, train corr: 0.02742
Epoch [38/100], Batch [146/147] train loss: 586.54, train corr: 0.02782
Epoch [38/100], Batch [147/147] train loss: 600.08, train corr: 0.02951
Epoch [38/100], validation loss: 657.71, validation correlation: 0.02684
Epoch [39/100], Batch [1/147] train loss: 625.56, train corr: 0.02124
Epoch [39/100], Batch [2/147] train loss: 608.11, train corr: 0.02744
Epoch [39/100], Batch [3/147] train loss: 620.89, train corr: 0.02493
Epoch [39/100], Batch [4/147] train loss: 893.69, train corr: 0.02132
Epoch [39/100], Batch [5/147] train loss: 592.21, train corr: 0.02822
Epoch [39/100], Batch [6/147] train loss: 574.29, train corr: 0.02747
Epoch [39/100], Batch [7/147] train loss: 588.87, train corr: 0.02469
Epoch [39/100], Batch [8/147] train loss: 587.11, train corr: 0.02844
Epoch [39/100], Batch [9/147] train loss: 601.34, train corr: 0.02437
Epoch [39/100], Batch [10/147] train loss: 578.14, train corr: 0.02948
Epoch [39/100], Batch [11/147] train loss: 593.27, train corr: 0.02731
Epoch [39/100], Batch [12/147] train loss: 598.78, train corr: 0.02820
Epoch [39/100], Batch [13/147] train loss: 590.57, train corr: 0.02823
Epoch [39/100], Batch [14/147] train loss: 586.71, train corr: 0.03022
Epoch [39/100], Batch [15/147] train loss: 582.70, train corr: 0.03050
Epoch [39/100], Batch [16/147] train loss: 575.38, train corr: 0.03254
Epoch [39/100], Batch [17/147] train loss: 574.68, train corr: 0.03396
Epoch [39/100], Batch [18/147] train loss: 822.89, train corr: 0.00661
Epoch [39/100], Batch [19/147] train loss: 570.80, train corr: 0.03416
Epoch [39/100], Batch [20/147] train loss: 573.92, train corr: 0.03307
Epoch [39/100], Batch [21/147] train loss: 566.80, train corr: 0.02851
Epoch [39/100], Batch [22/147] train loss: 579.90, train corr: 0.02665
Epoch [39/100], Batch [23/147] train loss: 592.98, train corr: 0.02151
Epoch [39/100], Batch [24/147] train loss: 595.42, train corr: -0.02790
Epoch [39/100], Batch [25/147] train loss: 577.91, train corr: -0.03195
Epoch [39/100], Batch [26/147] train loss: 589.38, train corr: 0.01489
Epoch [39/100], Batch [27/147] train loss: 594.94, train corr: 0.02023
Epoch [39/100], Batch [28/147] train loss: 594.51, train corr: 0.02241
Epoch [39/100], Batch [29/147] train loss: 588.11, train corr: 0.02170
Epoch [39/100], Batch [30/147] train loss: 570.49, train corr: -0.00301
Epoch [39/100], Batch [31/147] train loss: 572.78, train corr: -0.00238
Epoch [39/100], Batch [32/147] train loss: 568.79, train corr: 0.02725
Epoch [39/100], Batch [33/147] train loss: 579.95, train corr: 0.02492
Epoch [39/100], Batch [34/147] train loss: 568.96, train corr: 0.02931
Epoch [39/100], Batch [35/147] train loss: 564.14, train corr: 0.02825
Epoch [39/100], Batch [36/147] train loss: 572.90, train corr: 0.03470
Epoch [39/100], Batch [37/147] train loss: 562.57, train corr: 0.03027
Epoch [39/100], Batch [38/147] train loss: 553.76, train corr: 0.03049
Epoch [39/100], Batch [39/147] train loss: 659.20, train corr: 0.02590
Epoch [39/100], Batch [40/147] train loss: 590.45, train corr: 0.02950
Epoch [39/100], Batch [41/147] train loss: 570.94, train corr: 0.03233
Epoch [39/100], Batch [42/147] train loss: 575.95, train corr: 0.03238
Epoch [39/100], Batch [43/147] train loss: 567.01, train corr: -0.01428
Epoch [39/100], Batch [44/147] train loss: 559.53, train corr: -0.01945
Epoch [39/100], Batch [45/147] train loss: 585.66, train corr: -0.00857
Epoch [39/100], Batch [46/147] train loss: 571.15, train corr: 0.02950
Epoch [39/100], Batch [47/147] train loss: 569.31, train corr: 0.01986
Epoch [39/100], Batch [48/147] train loss: 552.48, train corr: -0.02735
Epoch [39/100], Batch [49/147] train loss: 553.25, train corr: -0.02987
Epoch [39/100], Batch [50/147] train loss: 564.72, train corr: -0.02348
Epoch [39/100], Batch [51/147] train loss: 575.43, train corr: -0.01634
Epoch [39/100], Batch [52/147] train loss: 572.11, train corr: -0.00762
Epoch [39/100], Batch [53/147] train loss: 570.50, train corr: -0.01719
Epoch [39/100], Batch [54/147] train loss: 547.27, train corr: -0.02143
Epoch [39/100], Batch [55/147] train loss: 574.47, train corr: -0.01800
Epoch [39/100], Batch [56/147] train loss: 563.07, train corr: -0.01113
Epoch [39/100], Batch [57/147] train loss: 580.91, train corr: 0.00290
Epoch [39/100], Batch [58/147] train loss: 568.77, train corr: -0.00137
Epoch [39/100], Batch [59/147] train loss: 571.60, train corr: -0.01169
Epoch [39/100], Batch [60/147] train loss: 563.84, train corr: -0.01189
Epoch [39/100], Batch [61/147] train loss: 572.22, train corr: -0.00820
Epoch [39/100], Batch [62/147] train loss: 559.93, train corr: -0.00097
Epoch [39/100], Batch [63/147] train loss: 565.34, train corr: 0.00220
Epoch [39/100], Batch [64/147] train loss: 560.88, train corr: -0.00627
Epoch [39/100], Batch [65/147] train loss: 561.17, train corr: -0.01372
Epoch [39/100], Batch [66/147] train loss: 566.23, train corr: -0.01551
Epoch [39/100], Batch [67/147] train loss: 568.48, train corr: -0.01312
Epoch [39/100], Batch [68/147] train loss: 569.11, train corr: -0.01210
Epoch [39/100], Batch [69/147] train loss: 576.68, train corr: -0.01210
Epoch [39/100], Batch [70/147] train loss: 577.48, train corr: -0.01506
Epoch [39/100], Batch [71/147] train loss: 561.86, train corr: -0.01925
Epoch [39/100], Batch [72/147] train loss: 557.27, train corr: -0.01788
Epoch [39/100], Batch [73/147] train loss: 569.31, train corr: -0.01564
Epoch [39/100], Batch [74/147] train loss: 567.96, train corr: -0.01607
Epoch [39/100], Batch [75/147] train loss: 557.41, train corr: -0.01898
Epoch [39/100], Batch [76/147] train loss: 583.82, train corr: -0.01632
Epoch [39/100], Batch [77/147] train loss: 621.67, train corr: -0.01397
Epoch [39/100], Batch [78/147] train loss: 564.91, train corr: -0.01158
Epoch [39/100], Batch [79/147] train loss: 578.99, train corr: -0.01133
Epoch [39/100], Batch [80/147] train loss: 566.56, train corr: -0.01836
Epoch [39/100], Batch [81/147] train loss: 555.49, train corr: -0.01551
Epoch [39/100], Batch [82/147] train loss: 573.69, train corr: -0.01178
Epoch [39/100], Batch [83/147] train loss: 569.09, train corr: -0.00432
Epoch [39/100], Batch [84/147] train loss: 571.55, train corr: -0.00923
Epoch [39/100], Batch [85/147] train loss: 566.62, train corr: -0.01694
Epoch [39/100], Batch [86/147] train loss: 579.86, train corr: -0.01459
Epoch [39/100], Batch [87/147] train loss: 574.80, train corr: -0.01250
Epoch [39/100], Batch [88/147] train loss: 563.15, train corr: -0.00872
Epoch [39/100], Batch [89/147] train loss: 573.85, train corr: -0.00429
Epoch [39/100], Batch [90/147] train loss: 576.34, train corr: -0.01456
Epoch [39/100], Batch [91/147] train loss: 560.46, train corr: -0.01548
Epoch [39/100], Batch [92/147] train loss: 582.44, train corr: -0.01343
Epoch [39/100], Batch [93/147] train loss: 557.25, train corr: -0.01310
Epoch [39/100], Batch [94/147] train loss: 564.84, train corr: -0.01365
Epoch [39/100], Batch [95/147] train loss: 573.26, train corr: -0.01528
Epoch [39/100], Batch [96/147] train loss: 565.87, train corr: -0.01803
Epoch [39/100], Batch [97/147] train loss: 572.29, train corr: -0.01621
Epoch [39/100], Batch [98/147] train loss: 580.96, train corr: -0.01363
Epoch [39/100], Batch [99/147] train loss: 593.88, train corr: -0.01435
Epoch [39/100], Batch [100/147] train loss: 573.56, train corr: -0.01764
Epoch [39/100], Batch [101/147] train loss: 555.26, train corr: -0.02094
Epoch [39/100], Batch [102/147] train loss: 572.82, train corr: -0.01739
Epoch [39/100], Batch [103/147] train loss: 585.99, train corr: -0.01636
Epoch [39/100], Batch [104/147] train loss: 560.90, train corr: -0.01641
Epoch [39/100], Batch [105/147] train loss: 582.99, train corr: -0.01609
Epoch [39/100], Batch [106/147] train loss: 571.09, train corr: -0.01479
Epoch [39/100], Batch [107/147] train loss: 568.69, train corr: -0.01707
Epoch [39/100], Batch [108/147] train loss: 562.95, train corr: -0.01342
Epoch [39/100], Batch [109/147] train loss: 568.15, train corr: -0.01709
Epoch [39/100], Batch [110/147] train loss: 559.09, train corr: -0.01470
Epoch [39/100], Batch [111/147] train loss: 567.36, train corr: -0.01380
Epoch [39/100], Batch [112/147] train loss: 564.44, train corr: -0.01336
Epoch [39/100], Batch [113/147] train loss: 618.85, train corr: -0.01482
Epoch [39/100], Batch [114/147] train loss: 578.22, train corr: -0.01204
Epoch [39/100], Batch [115/147] train loss: 558.44, train corr: -0.01833
Epoch [39/100], Batch [116/147] train loss: 574.51, train corr: -0.01812
Epoch [39/100], Batch [117/147] train loss: 573.21, train corr: -0.01510
Epoch [39/100], Batch [118/147] train loss: 582.36, train corr: -0.01466
Epoch [39/100], Batch [119/147] train loss: 558.18, train corr: -0.01987
Epoch [39/100], Batch [120/147] train loss: 577.49, train corr: -0.00817
Epoch [39/100], Batch [121/147] train loss: 557.19, train corr: -0.01818
Epoch [39/100], Batch [122/147] train loss: 549.61, train corr: -0.02141
Epoch [39/100], Batch [123/147] train loss: 573.04, train corr: -0.02094
Epoch [39/100], Batch [124/147] train loss: 558.22, train corr: -0.01723
Epoch [39/100], Batch [125/147] train loss: 558.96, train corr: -0.01616
Epoch [39/100], Batch [126/147] train loss: 567.10, train corr: -0.01922
Epoch [39/100], Batch [127/147] train loss: 558.59, train corr: -0.02114
Epoch [39/100], Batch [128/147] train loss: 588.63, train corr: -0.01427
Epoch [39/100], Batch [129/147] train loss: 595.97, train corr: -0.00702
Epoch [39/100], Batch [130/147] train loss: 561.95, train corr: -0.01232
Epoch [39/100], Batch [131/147] train loss: 559.62, train corr: -0.01606
Epoch [39/100], Batch [132/147] train loss: 555.84, train corr: -0.01286
Epoch [39/100], Batch [133/147] train loss: 562.33, train corr: -0.01548
Epoch [39/100], Batch [134/147] train loss: 566.14, train corr: -0.01048
Epoch [39/100], Batch [135/147] train loss: 567.63, train corr: -0.01645
Epoch [39/100], Batch [136/147] train loss: 565.28, train corr: -0.01243
Epoch [39/100], Batch [137/147] train loss: 572.27, train corr: -0.01429
Epoch [39/100], Batch [138/147] train loss: 572.90, train corr: -0.01209
Epoch [39/100], Batch [139/147] train loss: 555.25, train corr: -0.01735
Epoch [39/100], Batch [140/147] train loss: 580.93, train corr: -0.01387
Epoch [39/100], Batch [141/147] train loss: 561.68, train corr: -0.01682
Epoch [39/100], Batch [142/147] train loss: 572.12, train corr: -0.01655
Epoch [39/100], Batch [143/147] train loss: 586.03, train corr: -0.01261
Epoch [39/100], Batch [144/147] train loss: 581.09, train corr: -0.01747
Epoch [39/100], Batch [145/147] train loss: 565.68, train corr: -0.01861
Epoch [39/100], Batch [146/147] train loss: 555.19, train corr: -0.01943
Epoch [39/100], Batch [147/147] train loss: 582.26, train corr: -0.01606
Epoch [39/100], validation loss: 597.78, validation correlation: -0.01747
Epoch [40/100], Batch [1/147] train loss: 566.95, train corr: -0.01826
Epoch [40/100], Batch [2/147] train loss: 570.40, train corr: -0.01357
Epoch [40/100], Batch [3/147] train loss: 571.04, train corr: -0.01344
Epoch [40/100], Batch [4/147] train loss: 573.87, train corr: -0.01614
Epoch [40/100], Batch [5/147] train loss: 566.23, train corr: -0.01588
Epoch [40/100], Batch [6/147] train loss: 569.58, train corr: -0.01279
Epoch [40/100], Batch [7/147] train loss: 574.22, train corr: -0.01308
Epoch [40/100], Batch [8/147] train loss: 578.87, train corr: -0.01433
Epoch [40/100], Batch [9/147] train loss: 568.10, train corr: -0.01444
Epoch [40/100], Batch [10/147] train loss: 567.21, train corr: -0.01456
Epoch [40/100], Batch [11/147] train loss: 560.67, train corr: -0.01639
Epoch [40/100], Batch [12/147] train loss: 560.77, train corr: -0.01847
Epoch [40/100], Batch [13/147] train loss: 579.57, train corr: -0.01573
Epoch [40/100], Batch [14/147] train loss: 575.22, train corr: -0.01836
Epoch [40/100], Batch [15/147] train loss: 565.00, train corr: -0.01835
Epoch [40/100], Batch [16/147] train loss: 556.48, train corr: -0.01853
Epoch [40/100], Batch [17/147] train loss: 570.69, train corr: -0.01712
Epoch [40/100], Batch [18/147] train loss: 562.94, train corr: -0.01205
Epoch [40/100], Batch [19/147] train loss: 582.35, train corr: -0.01388
Epoch [40/100], Batch [20/147] train loss: 554.36, train corr: -0.01775
Epoch [40/100], Batch [21/147] train loss: 560.95, train corr: -0.01590
Epoch [40/100], Batch [22/147] train loss: 561.43, train corr: -0.01537
Epoch [40/100], Batch [23/147] train loss: 570.14, train corr: -0.01882
Epoch [40/100], Batch [24/147] train loss: 564.92, train corr: -0.01935
Epoch [40/100], Batch [25/147] train loss: 578.34, train corr: -0.01350
Epoch [40/100], Batch [26/147] train loss: 561.69, train corr: -0.01565
Epoch [40/100], Batch [27/147] train loss: 550.32, train corr: -0.01664
Epoch [40/100], Batch [28/147] train loss: 569.08, train corr: -0.00962
Epoch [40/100], Batch [29/147] train loss: 551.42, train corr: -0.01941
Epoch [40/100], Batch [30/147] train loss: 563.48, train corr: -0.01908
Epoch [40/100], Batch [31/147] train loss: 557.05, train corr: -0.02170
Epoch [40/100], Batch [32/147] train loss: 567.08, train corr: -0.01810
Epoch [40/100], Batch [33/147] train loss: 575.68, train corr: -0.01593
Epoch [40/100], Batch [34/147] train loss: 574.17, train corr: -0.01440
Epoch [40/100], Batch [35/147] train loss: 569.27, train corr: -0.01740
Epoch [40/100], Batch [36/147] train loss: 568.87, train corr: -0.01900
Epoch [40/100], Batch [37/147] train loss: 572.97, train corr: -0.01206
Epoch [40/100], Batch [38/147] train loss: 566.67, train corr: -0.01919
Epoch [40/100], Batch [39/147] train loss: 566.55, train corr: -0.01660
Epoch [40/100], Batch [40/147] train loss: 567.85, train corr: -0.01275
Epoch [40/100], Batch [41/147] train loss: 566.84, train corr: -0.01027
Epoch [40/100], Batch [42/147] train loss: 568.59, train corr: -0.01566
Epoch [40/100], Batch [43/147] train loss: 645.27, train corr: -0.01678
Epoch [40/100], Batch [44/147] train loss: 571.51, train corr: -0.00865
Epoch [40/100], Batch [45/147] train loss: 562.34, train corr: -0.01115
Epoch [40/100], Batch [46/147] train loss: 549.34, train corr: -0.02084
Epoch [40/100], Batch [47/147] train loss: 562.68, train corr: -0.02206
Epoch [40/100], Batch [48/147] train loss: 567.38, train corr: -0.01806
Epoch [40/100], Batch [49/147] train loss: 566.71, train corr: -0.01535
Epoch [40/100], Batch [50/147] train loss: 571.02, train corr: -0.01400
Epoch [40/100], Batch [51/147] train loss: 569.66, train corr: -0.01718
Epoch [40/100], Batch [52/147] train loss: 567.68, train corr: -0.01607
Epoch [40/100], Batch [53/147] train loss: 586.83, train corr: -0.01469
Epoch [40/100], Batch [54/147] train loss: 562.45, train corr: -0.01081
Epoch [40/100], Batch [55/147] train loss: 572.75, train corr: -0.01358
Epoch [40/100], Batch [56/147] train loss: 579.59, train corr: -0.01314
Epoch [40/100], Batch [57/147] train loss: 636.86, train corr: -0.01783
Epoch [40/100], Batch [58/147] train loss: 581.24, train corr: -0.01141
Epoch [40/100], Batch [59/147] train loss: 560.14, train corr: -0.00701
Epoch [40/100], Batch [60/147] train loss: 622.69, train corr: -0.01336
Epoch [40/100], Batch [61/147] train loss: 585.02, train corr: -0.01809
Epoch [40/100], Batch [62/147] train loss: 574.94, train corr: -0.01925
Epoch [40/100], Batch [63/147] train loss: 583.14, train corr: -0.00529
Epoch [40/100], Batch [64/147] train loss: 574.22, train corr: -0.01124
Epoch [40/100], Batch [65/147] train loss: 566.22, train corr: -0.01749
Epoch [40/100], Batch [66/147] train loss: 560.86, train corr: -0.01488
Epoch [40/100], Batch [67/147] train loss: 579.17, train corr: -0.01758
Epoch [40/100], Batch [68/147] train loss: 564.19, train corr: -0.00705
Epoch [40/100], Batch [69/147] train loss: 582.72, train corr: -0.01418
Epoch [40/100], Batch [70/147] train loss: 580.00, train corr: -0.01688
Epoch [40/100], Batch [71/147] train loss: 560.10, train corr: -0.01483
Epoch [40/100], Batch [72/147] train loss: 554.63, train corr: -0.02063
Epoch [40/100], Batch [73/147] train loss: 577.49, train corr: -0.01065
Epoch [40/100], Batch [74/147] train loss: 832.48, train corr: -0.01569
Epoch [40/100], Batch [75/147] train loss: 566.78, train corr: -0.02543
Epoch [40/100], Batch [76/147] train loss: 560.05, train corr: 0.02999
Epoch [40/100], Batch [77/147] train loss: 561.25, train corr: 0.02739
Epoch [40/100], Batch [78/147] train loss: 582.81, train corr: 0.02556
Epoch [40/100], Batch [79/147] train loss: 578.39, train corr: 0.02819
Epoch [40/100], Batch [80/147] train loss: 579.90, train corr: 0.02655
Epoch [40/100], Batch [81/147] train loss: 571.31, train corr: 0.02788
Epoch [40/100], Batch [82/147] train loss: 586.45, train corr: 0.02635
Epoch [40/100], Batch [83/147] train loss: 557.04, train corr: -0.01324
Epoch [40/100], Batch [84/147] train loss: 556.41, train corr: -0.00758
Epoch [40/100], Batch [85/147] train loss: 560.03, train corr: 0.02129
Epoch [40/100], Batch [86/147] train loss: 545.69, train corr: 0.01791
Epoch [40/100], Batch [87/147] train loss: 581.35, train corr: -0.01208
Epoch [40/100], Batch [88/147] train loss: 577.86, train corr: -0.02384
Epoch [40/100], Batch [89/147] train loss: 557.39, train corr: -0.02611
Epoch [40/100], Batch [90/147] train loss: 550.30, train corr: -0.02711
Epoch [40/100], Batch [91/147] train loss: 558.61, train corr: 0.01298
Epoch [40/100], Batch [92/147] train loss: 578.72, train corr: 0.00689
Epoch [40/100], Batch [93/147] train loss: 578.33, train corr: -0.03281
Epoch [40/100], Batch [94/147] train loss: 571.13, train corr: -0.03353
Epoch [40/100], Batch [95/147] train loss: 573.69, train corr: 0.00218
Epoch [40/100], Batch [96/147] train loss: 567.58, train corr: 0.02639
Epoch [40/100], Batch [97/147] train loss: 569.45, train corr: 0.03152
Epoch [40/100], Batch [98/147] train loss: 576.65, train corr: 0.00287
Epoch [40/100], Batch [99/147] train loss: 581.41, train corr: -0.01694
Epoch [40/100], Batch [100/147] train loss: 566.36, train corr: -0.00870
Epoch [40/100], Batch [101/147] train loss: 571.72, train corr: 0.01354
Epoch [40/100], Batch [102/147] train loss: 566.65, train corr: 0.01759
Epoch [40/100], Batch [103/147] train loss: 564.35, train corr: 0.00701
Epoch [40/100], Batch [104/147] train loss: 561.11, train corr: -0.01270
Epoch [40/100], Batch [105/147] train loss: 579.15, train corr: -0.01123
Epoch [40/100], Batch [106/147] train loss: 577.56, train corr: 0.01625
Epoch [40/100], Batch [107/147] train loss: 573.59, train corr: 0.03036
Epoch [40/100], Batch [108/147] train loss: 556.99, train corr: -0.00772
Epoch [40/100], Batch [109/147] train loss: 554.18, train corr: -0.02497
Epoch [40/100], Batch [110/147] train loss: 553.26, train corr: -0.02672
Epoch [40/100], Batch [111/147] train loss: 560.43, train corr: -0.02262
Epoch [40/100], Batch [112/147] train loss: 577.20, train corr: -0.01690
Epoch [40/100], Batch [113/147] train loss: 583.72, train corr: -0.02030
Epoch [40/100], Batch [114/147] train loss: 556.71, train corr: -0.02448
Epoch [40/100], Batch [115/147] train loss: 583.05, train corr: -0.01223
Epoch [40/100], Batch [116/147] train loss: 560.07, train corr: -0.01768
Epoch [40/100], Batch [117/147] train loss: 557.95, train corr: -0.01321
Epoch [40/100], Batch [118/147] train loss: 557.79, train corr: -0.01833
Epoch [40/100], Batch [119/147] train loss: 567.15, train corr: -0.01511
Epoch [40/100], Batch [120/147] train loss: 583.58, train corr: -0.01474
Epoch [40/100], Batch [121/147] train loss: 564.54, train corr: -0.00625
Epoch [40/100], Batch [122/147] train loss: 579.65, train corr: -0.00504
Epoch [40/100], Batch [123/147] train loss: 555.53, train corr: -0.01384
Epoch [40/100], Batch [124/147] train loss: 580.76, train corr: -0.01397
Epoch [40/100], Batch [125/147] train loss: 583.38, train corr: -0.00752
Epoch [40/100], Batch [126/147] train loss: 586.72, train corr: -0.00843
Epoch [40/100], Batch [127/147] train loss: 570.32, train corr: -0.01513
Epoch [40/100], Batch [128/147] train loss: 564.28, train corr: -0.01817
Epoch [40/100], Batch [129/147] train loss: 573.63, train corr: -0.01413
Epoch [40/100], Batch [130/147] train loss: 569.91, train corr: -0.01625
Epoch [40/100], Batch [131/147] train loss: 568.46, train corr: -0.01468
Epoch [40/100], Batch [132/147] train loss: 565.18, train corr: -0.01724
Epoch [40/100], Batch [133/147] train loss: 551.09, train corr: -0.02372
Epoch [40/100], Batch [134/147] train loss: 578.27, train corr: -0.01722
Epoch [40/100], Batch [135/147] train loss: 551.44, train corr: -0.01985
Epoch [40/100], Batch [136/147] train loss: 570.76, train corr: -0.01789
Epoch [40/100], Batch [137/147] train loss: 580.12, train corr: -0.01909
Epoch [40/100], Batch [138/147] train loss: 559.50, train corr: -0.01758
Epoch [40/100], Batch [139/147] train loss: 550.79, train corr: -0.01896
Epoch [40/100], Batch [140/147] train loss: 746.28, train corr: -0.01331
Epoch [40/100], Batch [141/147] train loss: 578.80, train corr: -0.02459
Epoch [40/100], Batch [142/147] train loss: 587.51, train corr: 0.02720
Epoch [40/100], Batch [143/147] train loss: 597.64, train corr: 0.02638
Epoch [40/100], Batch [144/147] train loss: 639.38, train corr: 0.02073
Epoch [40/100], Batch [145/147] train loss: 647.10, train corr: 0.02285
Epoch [40/100], Batch [146/147] train loss: 643.41, train corr: 0.02507
Epoch [40/100], Batch [147/147] train loss: 621.40, train corr: 0.02372
Epoch [40/100], validation loss: 667.52, validation correlation: 0.02669
Epoch [41/100], Batch [1/147] train loss: 628.92, train corr: 0.02514
Epoch [41/100], Batch [2/147] train loss: 639.06, train corr: 0.02753
Epoch [41/100], Batch [3/147] train loss: 1289.18, train corr: 0.02023
Epoch [41/100], Batch [4/147] train loss: 603.85, train corr: 0.02926
Epoch [41/100], Batch [5/147] train loss: 611.15, train corr: 0.02780
Epoch [41/100], Batch [6/147] train loss: 576.13, train corr: 0.03200
Epoch [41/100], Batch [7/147] train loss: 575.02, train corr: 0.02642
Epoch [41/100], Batch [8/147] train loss: 684.46, train corr: -0.01400
Epoch [41/100], Batch [9/147] train loss: 640.34, train corr: 0.02739
Epoch [41/100], Batch [10/147] train loss: 716.23, train corr: 0.02500
Epoch [41/100], Batch [11/147] train loss: 798.83, train corr: 0.02455
Epoch [41/100], Batch [12/147] train loss: 840.59, train corr: 0.02564
Epoch [41/100], Batch [13/147] train loss: 878.66, train corr: 0.02090
Epoch [41/100], Batch [14/147] train loss: 1161.24, train corr: 0.02054
Epoch [41/100], Batch [15/147] train loss: 974.77, train corr: 0.02085
Epoch [41/100], Batch [16/147] train loss: 964.38, train corr: 0.02363
Epoch [41/100], Batch [17/147] train loss: 970.79, train corr: 0.02604
Epoch [41/100], Batch [18/147] train loss: 978.24, train corr: 0.02395
Epoch [41/100], Batch [19/147] train loss: 960.43, train corr: 0.02714
Epoch [41/100], Batch [20/147] train loss: 918.56, train corr: 0.02529
Epoch [41/100], Batch [21/147] train loss: 907.55, train corr: 0.02390
Epoch [41/100], Batch [22/147] train loss: 887.67, train corr: 0.02582
Epoch [41/100], Batch [23/147] train loss: 917.03, train corr: 0.02175
Epoch [41/100], Batch [24/147] train loss: 908.46, train corr: 0.02794
Epoch [41/100], Batch [25/147] train loss: 872.11, train corr: 0.02385
Epoch [41/100], Batch [26/147] train loss: 867.54, train corr: 0.02527
Epoch [41/100], Batch [27/147] train loss: 833.14, train corr: 0.02654
Epoch [41/100], Batch [28/147] train loss: 833.75, train corr: 0.02632
Epoch [41/100], Batch [29/147] train loss: 823.37, train corr: 0.02839
Epoch [41/100], Batch [30/147] train loss: 784.38, train corr: 0.02679
Epoch [41/100], Batch [31/147] train loss: 781.05, train corr: 0.02741
Epoch [41/100], Batch [32/147] train loss: 763.00, train corr: 0.02663
Epoch [41/100], Batch [33/147] train loss: 740.63, train corr: 0.02831
Epoch [41/100], Batch [34/147] train loss: 736.75, train corr: 0.02427
Epoch [41/100], Batch [35/147] train loss: 719.96, train corr: 0.02571
Epoch [41/100], Batch [36/147] train loss: 707.31, train corr: 0.02424
Epoch [41/100], Batch [37/147] train loss: 692.18, train corr: 0.02598
Epoch [41/100], Batch [38/147] train loss: 662.28, train corr: 0.02743
Epoch [41/100], Batch [39/147] train loss: 651.32, train corr: 0.02486
Epoch [41/100], Batch [40/147] train loss: 648.01, train corr: 0.02434
Epoch [41/100], Batch [41/147] train loss: 633.20, train corr: 0.02709
Epoch [41/100], Batch [42/147] train loss: 599.85, train corr: 0.02802
Epoch [41/100], Batch [43/147] train loss: 599.87, train corr: 0.02889
Epoch [41/100], Batch [44/147] train loss: 623.15, train corr: 0.03163
Epoch [41/100], Batch [45/147] train loss: 595.83, train corr: 0.02984
Epoch [41/100], Batch [46/147] train loss: 608.20, train corr: 0.02678
Epoch [41/100], Batch [47/147] train loss: 616.06, train corr: 0.02888
Epoch [41/100], Batch [48/147] train loss: 611.42, train corr: 0.02950
Epoch [41/100], Batch [49/147] train loss: 608.34, train corr: 0.02984
Epoch [41/100], Batch [50/147] train loss: 613.93, train corr: 0.03073
Epoch [41/100], Batch [51/147] train loss: 595.27, train corr: 0.03120
Epoch [41/100], Batch [52/147] train loss: 590.06, train corr: 0.03109
Epoch [41/100], Batch [53/147] train loss: 627.40, train corr: 0.02034
Epoch [41/100], Batch [54/147] train loss: 605.29, train corr: 0.02863
Epoch [41/100], Batch [55/147] train loss: 645.82, train corr: 0.02582
Epoch [41/100], Batch [56/147] train loss: 676.34, train corr: 0.02267
Epoch [41/100], Batch [57/147] train loss: 669.05, train corr: 0.02752
Epoch [41/100], Batch [58/147] train loss: 672.97, train corr: 0.02669
Epoch [41/100], Batch [59/147] train loss: 667.51, train corr: 0.02960
Epoch [41/100], Batch [60/147] train loss: 694.03, train corr: 0.02527
Epoch [41/100], Batch [61/147] train loss: 672.73, train corr: 0.02626
Epoch [41/100], Batch [62/147] train loss: 673.14, train corr: 0.02892
Epoch [41/100], Batch [63/147] train loss: 648.48, train corr: 0.02570
Epoch [41/100], Batch [64/147] train loss: 680.96, train corr: 0.02838
Epoch [41/100], Batch [65/147] train loss: 640.31, train corr: 0.02747
Epoch [41/100], Batch [66/147] train loss: 658.41, train corr: 0.02783
Epoch [41/100], Batch [67/147] train loss: 642.47, train corr: 0.02822
Epoch [41/100], Batch [68/147] train loss: 629.04, train corr: 0.02557
Epoch [41/100], Batch [69/147] train loss: 628.01, train corr: 0.02662
Epoch [41/100], Batch [70/147] train loss: 610.70, train corr: 0.02814
Epoch [41/100], Batch [71/147] train loss: 625.19, train corr: 0.02602
Epoch [41/100], Batch [72/147] train loss: 597.46, train corr: 0.02679
Epoch [41/100], Batch [73/147] train loss: 633.93, train corr: 0.02681
Epoch [41/100], Batch [74/147] train loss: 570.44, train corr: 0.03136
Epoch [41/100], Batch [75/147] train loss: 752.80, train corr: -0.02290
Epoch [41/100], Batch [76/147] train loss: 637.98, train corr: 0.02493
Epoch [41/100], Batch [77/147] train loss: 717.73, train corr: 0.02521
Epoch [41/100], Batch [78/147] train loss: 781.54, train corr: 0.02679
Epoch [41/100], Batch [79/147] train loss: 824.57, train corr: 0.02623
Epoch [41/100], Batch [80/147] train loss: 893.96, train corr: 0.02006
Epoch [41/100], Batch [81/147] train loss: 910.17, train corr: 0.02606
Epoch [41/100], Batch [82/147] train loss: 952.85, train corr: 0.02199
Epoch [41/100], Batch [83/147] train loss: 912.03, train corr: 0.02849
Epoch [41/100], Batch [84/147] train loss: 933.94, train corr: 0.02214
Epoch [41/100], Batch [85/147] train loss: 911.11, train corr: 0.02588
Epoch [41/100], Batch [86/147] train loss: 902.38, train corr: 0.02484
Epoch [41/100], Batch [87/147] train loss: 927.82, train corr: 0.02631
Epoch [41/100], Batch [88/147] train loss: 912.43, train corr: 0.02530
Epoch [41/100], Batch [89/147] train loss: 894.60, train corr: 0.02519
Epoch [41/100], Batch [90/147] train loss: 882.69, train corr: 0.02660
Epoch [41/100], Batch [91/147] train loss: 898.21, train corr: 0.02556
Epoch [41/100], Batch [92/147] train loss: 879.13, train corr: 0.02748
Epoch [41/100], Batch [93/147] train loss: 864.02, train corr: 0.02753
Epoch [41/100], Batch [94/147] train loss: 875.04, train corr: 0.02712
Epoch [41/100], Batch [95/147] train loss: 854.78, train corr: 0.02638
Epoch [41/100], Batch [96/147] train loss: 845.77, train corr: 0.02505
Epoch [41/100], Batch [97/147] train loss: 829.96, train corr: 0.02203
Epoch [41/100], Batch [98/147] train loss: 794.22, train corr: 0.02631
Epoch [41/100], Batch [99/147] train loss: 787.46, train corr: 0.02587
Epoch [41/100], Batch [100/147] train loss: 800.22, train corr: 0.02605
Epoch [41/100], Batch [101/147] train loss: 770.65, train corr: 0.02642
Epoch [41/100], Batch [102/147] train loss: 769.71, train corr: 0.02550
Epoch [41/100], Batch [103/147] train loss: 732.08, train corr: 0.02784
Epoch [41/100], Batch [104/147] train loss: 712.94, train corr: 0.02747
Epoch [41/100], Batch [105/147] train loss: 726.40, train corr: 0.02481
Epoch [41/100], Batch [106/147] train loss: 707.45, train corr: 0.02333
Epoch [41/100], Batch [107/147] train loss: 676.09, train corr: 0.02845
Epoch [41/100], Batch [108/147] train loss: 661.50, train corr: 0.02720
Epoch [41/100], Batch [109/147] train loss: 687.57, train corr: 0.02316
Epoch [41/100], Batch [110/147] train loss: 641.62, train corr: 0.02819
Epoch [41/100], Batch [111/147] train loss: 618.55, train corr: 0.02853
Epoch [41/100], Batch [112/147] train loss: 603.88, train corr: 0.02938
Epoch [41/100], Batch [113/147] train loss: 618.07, train corr: 0.02560
Epoch [41/100], Batch [114/147] train loss: 589.76, train corr: 0.03055
Epoch [41/100], Batch [115/147] train loss: 614.02, train corr: 0.02450
Epoch [41/100], Batch [116/147] train loss: 605.38, train corr: 0.02585
Epoch [41/100], Batch [117/147] train loss: 606.44, train corr: 0.02860
Epoch [41/100], Batch [118/147] train loss: 592.35, train corr: 0.02691
Epoch [41/100], Batch [119/147] train loss: 601.74, train corr: 0.02793
Epoch [41/100], Batch [120/147] train loss: 588.98, train corr: 0.02823
Epoch [41/100], Batch [121/147] train loss: 598.13, train corr: 0.02719
Epoch [41/100], Batch [122/147] train loss: 596.40, train corr: 0.02832
Epoch [41/100], Batch [123/147] train loss: 617.96, train corr: 0.02355
Epoch [41/100], Batch [124/147] train loss: 592.61, train corr: 0.02538
Epoch [41/100], Batch [125/147] train loss: 592.84, train corr: 0.02542
Epoch [41/100], Batch [126/147] train loss: 577.44, train corr: 0.02863
Epoch [41/100], Batch [127/147] train loss: 578.85, train corr: 0.02690
Epoch [41/100], Batch [128/147] train loss: 573.95, train corr: 0.02759
Epoch [41/100], Batch [129/147] train loss: 585.18, train corr: 0.02550
Epoch [41/100], Batch [130/147] train loss: 583.16, train corr: 0.02039
Epoch [41/100], Batch [131/147] train loss: 569.60, train corr: 0.02543
Epoch [41/100], Batch [132/147] train loss: 564.82, train corr: 0.02736
Epoch [41/100], Batch [133/147] train loss: 578.95, train corr: 0.02629
Epoch [41/100], Batch [134/147] train loss: 578.50, train corr: 0.02463
Epoch [41/100], Batch [135/147] train loss: 582.96, train corr: 0.02650
Epoch [41/100], Batch [136/147] train loss: 569.14, train corr: 0.02601
Epoch [41/100], Batch [137/147] train loss: 578.89, train corr: 0.02882
Epoch [41/100], Batch [138/147] train loss: 643.70, train corr: 0.02178
Epoch [41/100], Batch [139/147] train loss: 576.93, train corr: 0.02664
Epoch [41/100], Batch [140/147] train loss: 558.00, train corr: 0.02964
Epoch [41/100], Batch [141/147] train loss: 572.44, train corr: 0.02771
Epoch [41/100], Batch [142/147] train loss: 577.87, train corr: 0.02707
Epoch [41/100], Batch [143/147] train loss: 580.19, train corr: 0.02888
Epoch [41/100], Batch [144/147] train loss: 578.42, train corr: 0.02832
Epoch [41/100], Batch [145/147] train loss: 577.44, train corr: 0.03038
Epoch [41/100], Batch [146/147] train loss: 569.64, train corr: 0.02667
Epoch [41/100], Batch [147/147] train loss: 571.24, train corr: 0.02760
Epoch [41/100], validation loss: 600.43, validation correlation: 0.02800
Epoch [42/100], Batch [1/147] train loss: 563.81, train corr: 0.02744
Epoch [42/100], Batch [2/147] train loss: 565.02, train corr: 0.02740
Epoch [42/100], Batch [3/147] train loss: 574.45, train corr: 0.02865
Epoch [42/100], Batch [4/147] train loss: 583.99, train corr: 0.02882
Epoch [42/100], Batch [5/147] train loss: 576.24, train corr: 0.02970
Epoch [42/100], Batch [6/147] train loss: 567.76, train corr: 0.02141
Epoch [42/100], Batch [7/147] train loss: 839.64, train corr: 0.00949
Epoch [42/100], Batch [8/147] train loss: 562.31, train corr: -0.02066
Epoch [42/100], Batch [9/147] train loss: 569.95, train corr: -0.01842
Epoch [42/100], Batch [10/147] train loss: 563.02, train corr: 0.02488
Epoch [42/100], Batch [11/147] train loss: 558.93, train corr: 0.03366
Epoch [42/100], Batch [12/147] train loss: 573.89, train corr: 0.03058
Epoch [42/100], Batch [13/147] train loss: 560.71, train corr: -0.01556
Epoch [42/100], Batch [14/147] train loss: 569.50, train corr: -0.02096
Epoch [42/100], Batch [15/147] train loss: 582.92, train corr: 0.00223
Epoch [42/100], Batch [16/147] train loss: 578.55, train corr: 0.02680
Epoch [42/100], Batch [17/147] train loss: 578.58, train corr: 0.01861
Epoch [42/100], Batch [18/147] train loss: 655.94, train corr: -0.01712
Epoch [42/100], Batch [19/147] train loss: 559.98, train corr: -0.02364
Epoch [42/100], Batch [20/147] train loss: 582.50, train corr: -0.02102
Epoch [42/100], Batch [21/147] train loss: 566.92, train corr: -0.00912
Epoch [42/100], Batch [22/147] train loss: 559.12, train corr: 0.01044
Epoch [42/100], Batch [23/147] train loss: 574.55, train corr: -0.01590
Epoch [42/100], Batch [24/147] train loss: 575.45, train corr: -0.01656
Epoch [42/100], Batch [25/147] train loss: 579.33, train corr: -0.01784
Epoch [42/100], Batch [26/147] train loss: 547.99, train corr: -0.01593
Epoch [42/100], Batch [27/147] train loss: 562.90, train corr: 0.00436
Epoch [42/100], Batch [28/147] train loss: 562.07, train corr: -0.00408
Epoch [42/100], Batch [29/147] train loss: 583.30, train corr: -0.01420
Epoch [42/100], Batch [30/147] train loss: 568.92, train corr: -0.02072
Epoch [42/100], Batch [31/147] train loss: 574.51, train corr: -0.01895
Epoch [42/100], Batch [32/147] train loss: 555.53, train corr: -0.01652
Epoch [42/100], Batch [33/147] train loss: 566.27, train corr: -0.01391
Epoch [42/100], Batch [34/147] train loss: 561.22, train corr: -0.02028
Epoch [42/100], Batch [35/147] train loss: 557.59, train corr: -0.02160
Epoch [42/100], Batch [36/147] train loss: 567.86, train corr: -0.01916
Epoch [42/100], Batch [37/147] train loss: 563.74, train corr: -0.01469
Epoch [42/100], Batch [38/147] train loss: 731.36, train corr: -0.01247
Epoch [42/100], Batch [39/147] train loss: 573.73, train corr: -0.02122
Epoch [42/100], Batch [40/147] train loss: 581.06, train corr: 0.02380
Epoch [42/100], Batch [41/147] train loss: 580.85, train corr: 0.02834
Epoch [42/100], Batch [42/147] train loss: 582.26, train corr: 0.02647
Epoch [42/100], Batch [43/147] train loss: 579.39, train corr: 0.02567
Epoch [42/100], Batch [44/147] train loss: 600.97, train corr: 0.02449
Epoch [42/100], Batch [45/147] train loss: 573.56, train corr: 0.02888
Epoch [42/100], Batch [46/147] train loss: 563.64, train corr: 0.02824
Epoch [42/100], Batch [47/147] train loss: 567.92, train corr: 0.03298
Epoch [42/100], Batch [48/147] train loss: 603.41, train corr: -0.01910
Epoch [42/100], Batch [49/147] train loss: 579.64, train corr: 0.02297
Epoch [42/100], Batch [50/147] train loss: 567.63, train corr: 0.02634
Epoch [42/100], Batch [51/147] train loss: 584.94, train corr: 0.02661
Epoch [42/100], Batch [52/147] train loss: 591.05, train corr: 0.02587
Epoch [42/100], Batch [53/147] train loss: 597.22, train corr: 0.02635
Epoch [42/100], Batch [54/147] train loss: 589.05, train corr: 0.02482
Epoch [42/100], Batch [55/147] train loss: 599.55, train corr: 0.02591
Epoch [42/100], Batch [56/147] train loss: 563.77, train corr: 0.02920
Epoch [42/100], Batch [57/147] train loss: 563.70, train corr: 0.03110
Epoch [42/100], Batch [58/147] train loss: 574.95, train corr: 0.03207
Epoch [42/100], Batch [59/147] train loss: 598.75, train corr: -0.01644
Epoch [42/100], Batch [60/147] train loss: 577.04, train corr: 0.02470
Epoch [42/100], Batch [61/147] train loss: 584.97, train corr: 0.02566
Epoch [42/100], Batch [62/147] train loss: 599.83, train corr: 0.02611
Epoch [42/100], Batch [63/147] train loss: 604.03, train corr: 0.02507
Epoch [42/100], Batch [64/147] train loss: 610.22, train corr: 0.02681
Epoch [42/100], Batch [65/147] train loss: 634.88, train corr: 0.02134
Epoch [42/100], Batch [66/147] train loss: 606.35, train corr: 0.02254
Epoch [42/100], Batch [67/147] train loss: 594.65, train corr: 0.02732
Epoch [42/100], Batch [68/147] train loss: 603.84, train corr: 0.02215
Epoch [42/100], Batch [69/147] train loss: 574.63, train corr: 0.02901
Epoch [42/100], Batch [70/147] train loss: 577.76, train corr: 0.02895
Epoch [42/100], Batch [71/147] train loss: 599.58, train corr: 0.02710
Epoch [42/100], Batch [72/147] train loss: 596.28, train corr: 0.02719
Epoch [42/100], Batch [73/147] train loss: 596.98, train corr: -0.03000
Epoch [42/100], Batch [74/147] train loss: 587.86, train corr: 0.01981
Epoch [42/100], Batch [75/147] train loss: 611.63, train corr: 0.02172
Epoch [42/100], Batch [76/147] train loss: 712.33, train corr: 0.02211
Epoch [42/100], Batch [77/147] train loss: 628.00, train corr: 0.02388
Epoch [42/100], Batch [78/147] train loss: 638.87, train corr: 0.02327
Epoch [42/100], Batch [79/147] train loss: 637.05, train corr: 0.02441
Epoch [42/100], Batch [80/147] train loss: 631.63, train corr: 0.02372
Epoch [42/100], Batch [81/147] train loss: 625.31, train corr: 0.02331
Epoch [42/100], Batch [82/147] train loss: 614.62, train corr: 0.02467
Epoch [42/100], Batch [83/147] train loss: 590.60, train corr: 0.02578
Epoch [42/100], Batch [84/147] train loss: 586.19, train corr: 0.02640
Epoch [42/100], Batch [85/147] train loss: 575.94, train corr: 0.02678
Epoch [42/100], Batch [86/147] train loss: 587.05, train corr: 0.02563
Epoch [42/100], Batch [87/147] train loss: 611.40, train corr: -0.02024
Epoch [42/100], Batch [88/147] train loss: 580.43, train corr: 0.02575
Epoch [42/100], Batch [89/147] train loss: 610.28, train corr: 0.02224
Epoch [42/100], Batch [90/147] train loss: 617.97, train corr: 0.02606
Epoch [42/100], Batch [91/147] train loss: 625.30, train corr: 0.02465
Epoch [42/100], Batch [92/147] train loss: 624.86, train corr: 0.02667
Epoch [42/100], Batch [93/147] train loss: 647.49, train corr: 0.02285
Epoch [42/100], Batch [94/147] train loss: 640.77, train corr: 0.02612
Epoch [42/100], Batch [95/147] train loss: 635.46, train corr: 0.02479
Epoch [42/100], Batch [96/147] train loss: 631.93, train corr: 0.02725
Epoch [42/100], Batch [97/147] train loss: 622.97, train corr: 0.02816
Epoch [42/100], Batch [98/147] train loss: 614.20, train corr: 0.02622
Epoch [42/100], Batch [99/147] train loss: 622.59, train corr: 0.02712
Epoch [42/100], Batch [100/147] train loss: 591.90, train corr: 0.02797
Epoch [42/100], Batch [101/147] train loss: 591.27, train corr: 0.02594
Epoch [42/100], Batch [102/147] train loss: 585.45, train corr: 0.02197
Epoch [42/100], Batch [103/147] train loss: 590.01, train corr: 0.01145
Epoch [42/100], Batch [104/147] train loss: 609.70, train corr: -0.02978
Epoch [42/100], Batch [105/147] train loss: 602.81, train corr: 0.02351
Epoch [42/100], Batch [106/147] train loss: 661.06, train corr: 0.02399
Epoch [42/100], Batch [107/147] train loss: 710.99, train corr: 0.02425
Epoch [42/100], Batch [108/147] train loss: 738.01, train corr: 0.02404
Epoch [42/100], Batch [109/147] train loss: 756.25, train corr: 0.02580
Epoch [42/100], Batch [110/147] train loss: 777.64, train corr: 0.02791
Epoch [42/100], Batch [111/147] train loss: 778.28, train corr: 0.02515
Epoch [42/100], Batch [112/147] train loss: 776.87, train corr: 0.02717
Epoch [42/100], Batch [113/147] train loss: 755.17, train corr: 0.02904
Epoch [42/100], Batch [114/147] train loss: 763.23, train corr: 0.02593
Epoch [42/100], Batch [115/147] train loss: 838.65, train corr: 0.02014
Epoch [42/100], Batch [116/147] train loss: 759.46, train corr: 0.02734
Epoch [42/100], Batch [117/147] train loss: 738.85, train corr: 0.02339
Epoch [42/100], Batch [118/147] train loss: 727.10, train corr: 0.02497
Epoch [42/100], Batch [119/147] train loss: 735.45, train corr: 0.02420
Epoch [42/100], Batch [120/147] train loss: 719.72, train corr: 0.02554
Epoch [42/100], Batch [121/147] train loss: 692.53, train corr: 0.02715
Epoch [42/100], Batch [122/147] train loss: 717.44, train corr: 0.01937
Epoch [42/100], Batch [123/147] train loss: 680.16, train corr: 0.02594
Epoch [42/100], Batch [124/147] train loss: 651.77, train corr: 0.02971
Epoch [42/100], Batch [125/147] train loss: 644.62, train corr: 0.02636
Epoch [42/100], Batch [126/147] train loss: 663.02, train corr: 0.02601
Epoch [42/100], Batch [127/147] train loss: 630.32, train corr: 0.02801
Epoch [42/100], Batch [128/147] train loss: 631.52, train corr: 0.02728
Epoch [42/100], Batch [129/147] train loss: 608.04, train corr: 0.02980
Epoch [42/100], Batch [130/147] train loss: 597.65, train corr: 0.02710
Epoch [42/100], Batch [131/147] train loss: 587.45, train corr: 0.02715
Epoch [42/100], Batch [132/147] train loss: 577.70, train corr: 0.03234
Epoch [42/100], Batch [133/147] train loss: 572.96, train corr: 0.02967
Epoch [42/100], Batch [134/147] train loss: 601.73, train corr: 0.02316
Epoch [42/100], Batch [135/147] train loss: 618.91, train corr: 0.02755
Epoch [42/100], Batch [136/147] train loss: 606.97, train corr: 0.02136
Epoch [42/100], Batch [137/147] train loss: 594.78, train corr: 0.02302
Epoch [42/100], Batch [138/147] train loss: 591.46, train corr: 0.02408
Epoch [42/100], Batch [139/147] train loss: 595.04, train corr: 0.02260
Epoch [42/100], Batch [140/147] train loss: 572.68, train corr: 0.02741
Epoch [42/100], Batch [141/147] train loss: 568.68, train corr: 0.02890
Epoch [42/100], Batch [142/147] train loss: 583.40, train corr: 0.02994
Epoch [42/100], Batch [143/147] train loss: 583.31, train corr: 0.02582
Epoch [42/100], Batch [144/147] train loss: 593.68, train corr: 0.02762
Epoch [42/100], Batch [145/147] train loss: 591.50, train corr: 0.02991
Epoch [42/100], Batch [146/147] train loss: 584.59, train corr: 0.02800
Epoch [42/100], Batch [147/147] train loss: 588.35, train corr: 0.02843
Epoch [42/100], validation loss: 615.82, validation correlation: 0.02897
Epoch [43/100], Batch [1/147] train loss: 594.29, train corr: 0.02732
Epoch [43/100], Batch [2/147] train loss: 571.82, train corr: 0.03152
Epoch [43/100], Batch [3/147] train loss: 567.10, train corr: 0.03091
Epoch [43/100], Batch [4/147] train loss: 578.59, train corr: 0.03180
Epoch [43/100], Batch [5/147] train loss: 575.51, train corr: 0.03164
Epoch [43/100], Batch [6/147] train loss: 584.45, train corr: 0.02625
Epoch [43/100], Batch [7/147] train loss: 572.45, train corr: 0.02794
Epoch [43/100], Batch [8/147] train loss: 582.75, train corr: 0.02600
Epoch [43/100], Batch [9/147] train loss: 591.19, train corr: 0.02486
Epoch [43/100], Batch [10/147] train loss: 598.04, train corr: 0.02233
Epoch [43/100], Batch [11/147] train loss: 573.49, train corr: 0.02322
Epoch [43/100], Batch [12/147] train loss: 569.90, train corr: 0.00518
Epoch [43/100], Batch [13/147] train loss: 575.21, train corr: 0.01110
Epoch [43/100], Batch [14/147] train loss: 572.69, train corr: 0.02768
Epoch [43/100], Batch [15/147] train loss: 577.77, train corr: 0.02746
Epoch [43/100], Batch [16/147] train loss: 557.33, train corr: 0.02711
Epoch [43/100], Batch [17/147] train loss: 569.10, train corr: 0.02705
Epoch [43/100], Batch [18/147] train loss: 557.75, train corr: 0.02995
Epoch [43/100], Batch [19/147] train loss: 565.77, train corr: 0.03303
Epoch [43/100], Batch [20/147] train loss: 567.96, train corr: 0.00292
Epoch [43/100], Batch [21/147] train loss: 557.11, train corr: 0.02661
Epoch [43/100], Batch [22/147] train loss: 596.50, train corr: 0.02395
Epoch [43/100], Batch [23/147] train loss: 577.47, train corr: 0.01892
Epoch [43/100], Batch [24/147] train loss: 563.86, train corr: 0.02234
Epoch [43/100], Batch [25/147] train loss: 760.11, train corr: -0.02178
Epoch [43/100], Batch [26/147] train loss: 622.51, train corr: -0.02154
Epoch [43/100], Batch [27/147] train loss: 601.53, train corr: 0.02365
Epoch [43/100], Batch [28/147] train loss: 627.37, train corr: 0.02707
Epoch [43/100], Batch [29/147] train loss: 711.22, train corr: 0.02779
Epoch [43/100], Batch [30/147] train loss: 791.29, train corr: 0.02206
Epoch [43/100], Batch [31/147] train loss: 704.53, train corr: 0.02546
Epoch [43/100], Batch [32/147] train loss: 709.05, train corr: 0.02440
Epoch [43/100], Batch [33/147] train loss: 708.10, train corr: 0.02991
Epoch [43/100], Batch [34/147] train loss: 699.35, train corr: 0.02636
Epoch [43/100], Batch [35/147] train loss: 716.32, train corr: 0.01929
Epoch [43/100], Batch [36/147] train loss: 693.66, train corr: 0.02737
Epoch [43/100], Batch [37/147] train loss: 684.74, train corr: 0.02549
Epoch [43/100], Batch [38/147] train loss: 684.23, train corr: 0.02289
Epoch [43/100], Batch [39/147] train loss: 678.57, train corr: 0.02513
Epoch [43/100], Batch [40/147] train loss: 679.99, train corr: 0.02729
Epoch [43/100], Batch [41/147] train loss: 673.47, train corr: 0.02762
Epoch [43/100], Batch [42/147] train loss: 663.94, train corr: 0.02793
Epoch [43/100], Batch [43/147] train loss: 652.45, train corr: 0.02744
Epoch [43/100], Batch [44/147] train loss: 648.25, train corr: 0.02818
Epoch [43/100], Batch [45/147] train loss: 640.69, train corr: 0.02701
Epoch [43/100], Batch [46/147] train loss: 648.82, train corr: 0.02999
Epoch [43/100], Batch [47/147] train loss: 619.85, train corr: 0.02873
Epoch [43/100], Batch [48/147] train loss: 618.83, train corr: 0.02587
Epoch [43/100], Batch [49/147] train loss: 610.19, train corr: 0.02528
Epoch [43/100], Batch [50/147] train loss: 584.01, train corr: 0.03012
Epoch [43/100], Batch [51/147] train loss: 563.93, train corr: 0.03280
Epoch [43/100], Batch [52/147] train loss: 579.43, train corr: 0.03435
Epoch [43/100], Batch [53/147] train loss: 595.95, train corr: 0.02918
Epoch [43/100], Batch [54/147] train loss: 566.16, train corr: 0.03074
Epoch [43/100], Batch [55/147] train loss: 576.52, train corr: 0.03009
Epoch [43/100], Batch [56/147] train loss: 574.76, train corr: 0.03109
Epoch [43/100], Batch [57/147] train loss: 568.07, train corr: 0.03103
Epoch [43/100], Batch [58/147] train loss: 571.54, train corr: 0.03204
Epoch [43/100], Batch [59/147] train loss: 576.49, train corr: 0.03029
Epoch [43/100], Batch [60/147] train loss: 582.60, train corr: 0.01158
Epoch [43/100], Batch [61/147] train loss: 589.22, train corr: 0.02787
Epoch [43/100], Batch [62/147] train loss: 571.41, train corr: 0.03145
Epoch [43/100], Batch [63/147] train loss: 576.71, train corr: 0.02673
Epoch [43/100], Batch [64/147] train loss: 581.60, train corr: 0.02720
Epoch [43/100], Batch [65/147] train loss: 596.00, train corr: 0.01741
Epoch [43/100], Batch [66/147] train loss: 560.68, train corr: 0.03012
Epoch [43/100], Batch [67/147] train loss: 587.12, train corr: 0.02819
Epoch [43/100], Batch [68/147] train loss: 585.28, train corr: 0.02952
Epoch [43/100], Batch [69/147] train loss: 579.67, train corr: 0.03179
Epoch [43/100], Batch [70/147] train loss: 567.71, train corr: 0.01518
Epoch [43/100], Batch [71/147] train loss: 583.31, train corr: 0.00538
Epoch [43/100], Batch [72/147] train loss: 578.43, train corr: 0.01502
Epoch [43/100], Batch [73/147] train loss: 570.95, train corr: 0.00413
Epoch [43/100], Batch [74/147] train loss: 565.95, train corr: -0.01977
Epoch [43/100], Batch [75/147] train loss: 560.32, train corr: -0.02232
Epoch [43/100], Batch [76/147] train loss: 556.49, train corr: -0.02535
Epoch [43/100], Batch [77/147] train loss: 553.17, train corr: -0.02455
Epoch [43/100], Batch [78/147] train loss: 552.36, train corr: -0.02252
Epoch [43/100], Batch [79/147] train loss: 576.12, train corr: -0.02248
Epoch [43/100], Batch [80/147] train loss: 560.24, train corr: -0.02465
Epoch [43/100], Batch [81/147] train loss: 565.27, train corr: -0.02689
Epoch [43/100], Batch [82/147] train loss: 566.02, train corr: -0.01543
Epoch [43/100], Batch [83/147] train loss: 571.05, train corr: 0.02755
Epoch [43/100], Batch [84/147] train loss: 575.67, train corr: 0.02640
Epoch [43/100], Batch [85/147] train loss: 551.49, train corr: 0.03015
Epoch [43/100], Batch [86/147] train loss: 569.59, train corr: 0.02021
Epoch [43/100], Batch [87/147] train loss: 557.22, train corr: -0.00023
Epoch [43/100], Batch [88/147] train loss: 580.13, train corr: 0.01824
Epoch [43/100], Batch [89/147] train loss: 569.57, train corr: 0.02429
Epoch [43/100], Batch [90/147] train loss: 584.16, train corr: -0.00229
Epoch [43/100], Batch [91/147] train loss: 558.24, train corr: -0.02279
Epoch [43/100], Batch [92/147] train loss: 566.86, train corr: -0.02337
Epoch [43/100], Batch [93/147] train loss: 563.47, train corr: -0.02493
Epoch [43/100], Batch [94/147] train loss: 559.56, train corr: -0.02474
Epoch [43/100], Batch [95/147] train loss: 559.11, train corr: -0.02490
Epoch [43/100], Batch [96/147] train loss: 559.46, train corr: -0.02384
Epoch [43/100], Batch [97/147] train loss: 819.03, train corr: -0.02129
Epoch [43/100], Batch [98/147] train loss: 576.85, train corr: -0.01841
Epoch [43/100], Batch [99/147] train loss: 572.20, train corr: -0.01659
Epoch [43/100], Batch [100/147] train loss: 628.09, train corr: 0.02688
Epoch [43/100], Batch [101/147] train loss: 566.11, train corr: 0.03124
Epoch [43/100], Batch [102/147] train loss: 558.84, train corr: 0.03097
Epoch [43/100], Batch [103/147] train loss: 581.19, train corr: 0.01994
Epoch [43/100], Batch [104/147] train loss: 592.95, train corr: 0.00691
Epoch [43/100], Batch [105/147] train loss: 581.32, train corr: 0.02455
Epoch [43/100], Batch [106/147] train loss: 561.80, train corr: 0.03078
Epoch [43/100], Batch [107/147] train loss: 569.07, train corr: 0.02690
Epoch [43/100], Batch [108/147] train loss: 582.37, train corr: -0.00555
Epoch [43/100], Batch [109/147] train loss: 570.82, train corr: -0.01969
Epoch [43/100], Batch [110/147] train loss: 571.29, train corr: -0.01856
Epoch [43/100], Batch [111/147] train loss: 589.50, train corr: -0.01164
Epoch [43/100], Batch [112/147] train loss: 595.61, train corr: -0.00873
Epoch [43/100], Batch [113/147] train loss: 585.64, train corr: -0.01564
Epoch [43/100], Batch [114/147] train loss: 568.56, train corr: -0.02232
Epoch [43/100], Batch [115/147] train loss: 556.82, train corr: -0.02084
Epoch [43/100], Batch [116/147] train loss: 560.33, train corr: -0.01615
Epoch [43/100], Batch [117/147] train loss: 566.34, train corr: -0.00737
Epoch [43/100], Batch [118/147] train loss: 560.74, train corr: -0.00284
Epoch [43/100], Batch [119/147] train loss: 575.94, train corr: -0.00036
Epoch [43/100], Batch [120/147] train loss: 562.73, train corr: -0.01358
Epoch [43/100], Batch [121/147] train loss: 573.58, train corr: -0.01405
Epoch [43/100], Batch [122/147] train loss: 562.43, train corr: -0.01287
Epoch [43/100], Batch [123/147] train loss: 566.47, train corr: -0.01279
Epoch [43/100], Batch [124/147] train loss: 565.44, train corr: -0.01309
Epoch [43/100], Batch [125/147] train loss: 569.42, train corr: -0.01837
Epoch [43/100], Batch [126/147] train loss: 549.06, train corr: -0.02264
Epoch [43/100], Batch [127/147] train loss: 571.80, train corr: -0.02396
Epoch [43/100], Batch [128/147] train loss: 575.06, train corr: -0.01588
Epoch [43/100], Batch [129/147] train loss: 574.58, train corr: -0.01580
Epoch [43/100], Batch [130/147] train loss: 544.14, train corr: -0.01884
Epoch [43/100], Batch [131/147] train loss: 569.67, train corr: -0.01878
Epoch [43/100], Batch [132/147] train loss: 564.06, train corr: -0.01943
Epoch [43/100], Batch [133/147] train loss: 560.63, train corr: -0.01638
Epoch [43/100], Batch [134/147] train loss: 562.19, train corr: -0.01672
Epoch [43/100], Batch [135/147] train loss: 572.81, train corr: -0.01488
Epoch [43/100], Batch [136/147] train loss: 574.77, train corr: -0.01913
Epoch [43/100], Batch [137/147] train loss: 555.31, train corr: -0.01954
Epoch [43/100], Batch [138/147] train loss: 553.52, train corr: -0.01768
Epoch [43/100], Batch [139/147] train loss: 576.74, train corr: -0.01325
Epoch [43/100], Batch [140/147] train loss: 580.02, train corr: -0.01448
Epoch [43/100], Batch [141/147] train loss: 569.94, train corr: -0.01397
Epoch [43/100], Batch [142/147] train loss: 567.22, train corr: -0.01915
Epoch [43/100], Batch [143/147] train loss: 567.42, train corr: -0.01914
Epoch [43/100], Batch [144/147] train loss: 573.14, train corr: -0.01698
Epoch [43/100], Batch [145/147] train loss: 594.88, train corr: -0.01284
Epoch [43/100], Batch [146/147] train loss: 569.62, train corr: -0.01691
Epoch [43/100], Batch [147/147] train loss: 573.88, train corr: -0.01470
Epoch [43/100], validation loss: 597.27, validation correlation: -0.01941
Epoch [44/100], Batch [1/147] train loss: 554.58, train corr: -0.02003
Epoch [44/100], Batch [2/147] train loss: 566.31, train corr: -0.02047
Epoch [44/100], Batch [3/147] train loss: 579.29, train corr: -0.01477
Epoch [44/100], Batch [4/147] train loss: 561.13, train corr: -0.01609
Epoch [44/100], Batch [5/147] train loss: 570.45, train corr: -0.01767
Epoch [44/100], Batch [6/147] train loss: 761.69, train corr: -0.01656
Epoch [44/100], Batch [7/147] train loss: 570.15, train corr: -0.02313
Epoch [44/100], Batch [8/147] train loss: 569.28, train corr: 0.02976
Epoch [44/100], Batch [9/147] train loss: 574.23, train corr: 0.02714
Epoch [44/100], Batch [10/147] train loss: 577.94, train corr: 0.02928
Epoch [44/100], Batch [11/147] train loss: 580.11, train corr: 0.02954
Epoch [44/100], Batch [12/147] train loss: 575.26, train corr: 0.02740
Epoch [44/100], Batch [13/147] train loss: 572.83, train corr: 0.02763
Epoch [44/100], Batch [14/147] train loss: 562.32, train corr: 0.03050
Epoch [44/100], Batch [15/147] train loss: 581.13, train corr: 0.02799
Epoch [44/100], Batch [16/147] train loss: 595.69, train corr: -0.01345
Epoch [44/100], Batch [17/147] train loss: 562.42, train corr: -0.01587
Epoch [44/100], Batch [18/147] train loss: 566.29, train corr: 0.03300
Epoch [44/100], Batch [19/147] train loss: 582.30, train corr: 0.02833
Epoch [44/100], Batch [20/147] train loss: 592.58, train corr: 0.02961
Epoch [44/100], Batch [21/147] train loss: 588.34, train corr: 0.00281
Epoch [44/100], Batch [22/147] train loss: 572.83, train corr: -0.02409
Epoch [44/100], Batch [23/147] train loss: 566.28, train corr: -0.02484
Epoch [44/100], Batch [24/147] train loss: 589.55, train corr: -0.00859
Epoch [44/100], Batch [25/147] train loss: 570.88, train corr: 0.03335
Epoch [44/100], Batch [26/147] train loss: 575.87, train corr: 0.03125
Epoch [44/100], Batch [27/147] train loss: 575.80, train corr: 0.00636
Epoch [44/100], Batch [28/147] train loss: 558.93, train corr: -0.02301
Epoch [44/100], Batch [29/147] train loss: 581.28, train corr: -0.01160
Epoch [44/100], Batch [30/147] train loss: 594.30, train corr: 0.02970
Epoch [44/100], Batch [31/147] train loss: 557.35, train corr: 0.03221
Epoch [44/100], Batch [32/147] train loss: 563.54, train corr: 0.03013
Epoch [44/100], Batch [33/147] train loss: 566.69, train corr: 0.03434
Epoch [44/100], Batch [34/147] train loss: 565.61, train corr: -0.01860
Epoch [44/100], Batch [35/147] train loss: 548.42, train corr: -0.02247
Epoch [44/100], Batch [36/147] train loss: 559.27, train corr: -0.01400
Epoch [44/100], Batch [37/147] train loss: 576.04, train corr: 0.01714
Epoch [44/100], Batch [38/147] train loss: 568.61, train corr: -0.00930
Epoch [44/100], Batch [39/147] train loss: 572.15, train corr: -0.01815
Epoch [44/100], Batch [40/147] train loss: 578.27, train corr: -0.01992
Epoch [44/100], Batch [41/147] train loss: 544.68, train corr: -0.02248
Epoch [44/100], Batch [42/147] train loss: 586.17, train corr: -0.00080
Epoch [44/100], Batch [43/147] train loss: 558.89, train corr: -0.00378
Epoch [44/100], Batch [44/147] train loss: 567.27, train corr: -0.01565
Epoch [44/100], Batch [45/147] train loss: 572.53, train corr: -0.02436
Epoch [44/100], Batch [46/147] train loss: 660.99, train corr: -0.01454
Epoch [44/100], Batch [47/147] train loss: 551.58, train corr: 0.02168
Epoch [44/100], Batch [48/147] train loss: 559.16, train corr: 0.03315
Epoch [44/100], Batch [49/147] train loss: 576.54, train corr: 0.00712
Epoch [44/100], Batch [50/147] train loss: 560.99, train corr: -0.02176
Epoch [44/100], Batch [51/147] train loss: 568.49, train corr: -0.01811
Epoch [44/100], Batch [52/147] train loss: 569.28, train corr: -0.01889
Epoch [44/100], Batch [53/147] train loss: 575.81, train corr: 0.00262
Epoch [44/100], Batch [54/147] train loss: 555.02, train corr: -0.00690
Epoch [44/100], Batch [55/147] train loss: 573.14, train corr: -0.02035
Epoch [44/100], Batch [56/147] train loss: 561.90, train corr: -0.02093
Epoch [44/100], Batch [57/147] train loss: 551.39, train corr: -0.02451
Epoch [44/100], Batch [58/147] train loss: 578.35, train corr: -0.00822
Epoch [44/100], Batch [59/147] train loss: 565.16, train corr: -0.00541
Epoch [44/100], Batch [60/147] train loss: 573.52, train corr: -0.01373
Epoch [44/100], Batch [61/147] train loss: 564.22, train corr: -0.02362
Epoch [44/100], Batch [62/147] train loss: 562.27, train corr: -0.02459
Epoch [44/100], Batch [63/147] train loss: 559.10, train corr: -0.01910
Epoch [44/100], Batch [64/147] train loss: 570.57, train corr: -0.01089
Epoch [44/100], Batch [65/147] train loss: 570.58, train corr: -0.01260
Epoch [44/100], Batch [66/147] train loss: 560.99, train corr: -0.01982
Epoch [44/100], Batch [67/147] train loss: 562.87, train corr: -0.02155
Epoch [44/100], Batch [68/147] train loss: 559.27, train corr: -0.01967
Epoch [44/100], Batch [69/147] train loss: 556.56, train corr: -0.01755
Epoch [44/100], Batch [70/147] train loss: 564.52, train corr: -0.01347
Epoch [44/100], Batch [71/147] train loss: 579.35, train corr: -0.01696
Epoch [44/100], Batch [72/147] train loss: 570.82, train corr: -0.02107
Epoch [44/100], Batch [73/147] train loss: 564.29, train corr: -0.02047
Epoch [44/100], Batch [74/147] train loss: 567.70, train corr: -0.01649
Epoch [44/100], Batch [75/147] train loss: 568.02, train corr: -0.01423
Epoch [44/100], Batch [76/147] train loss: 564.24, train corr: -0.01892
Epoch [44/100], Batch [77/147] train loss: 564.82, train corr: -0.02023
Epoch [44/100], Batch [78/147] train loss: 555.17, train corr: -0.02161
Epoch [44/100], Batch [79/147] train loss: 585.71, train corr: -0.01156
Epoch [44/100], Batch [80/147] train loss: 561.28, train corr: -0.01674
Epoch [44/100], Batch [81/147] train loss: 560.26, train corr: -0.01439
Epoch [44/100], Batch [82/147] train loss: 563.85, train corr: -0.02039
Epoch [44/100], Batch [83/147] train loss: 593.43, train corr: -0.01357
Epoch [44/100], Batch [84/147] train loss: 566.27, train corr: -0.01974
Epoch [44/100], Batch [85/147] train loss: 555.17, train corr: -0.01845
Epoch [44/100], Batch [86/147] train loss: 561.31, train corr: -0.01987
Epoch [44/100], Batch [87/147] train loss: 572.37, train corr: -0.01519
Epoch [44/100], Batch [88/147] train loss: 559.10, train corr: -0.02006
Epoch [44/100], Batch [89/147] train loss: 571.74, train corr: -0.01371
Epoch [44/100], Batch [90/147] train loss: 570.53, train corr: -0.01604
Epoch [44/100], Batch [91/147] train loss: 588.59, train corr: -0.01280
Epoch [44/100], Batch [92/147] train loss: 575.81, train corr: -0.01391
Epoch [44/100], Batch [93/147] train loss: 578.56, train corr: -0.01498
Epoch [44/100], Batch [94/147] train loss: 570.33, train corr: -0.01653
Epoch [44/100], Batch [95/147] train loss: 568.04, train corr: -0.01621
Epoch [44/100], Batch [96/147] train loss: 566.59, train corr: -0.01802
Epoch [44/100], Batch [97/147] train loss: 574.07, train corr: -0.01504
Epoch [44/100], Batch [98/147] train loss: 568.21, train corr: -0.01744
Epoch [44/100], Batch [99/147] train loss: 573.00, train corr: -0.01798
Epoch [44/100], Batch [100/147] train loss: 558.33, train corr: -0.02161
Epoch [44/100], Batch [101/147] train loss: 557.89, train corr: -0.01912
Epoch [44/100], Batch [102/147] train loss: 585.49, train corr: -0.01483
Epoch [44/100], Batch [103/147] train loss: 560.96, train corr: -0.02129
Epoch [44/100], Batch [104/147] train loss: 565.71, train corr: -0.01857
Epoch [44/100], Batch [105/147] train loss: 553.30, train corr: -0.02038
Epoch [44/100], Batch [106/147] train loss: 564.18, train corr: -0.01949
Epoch [44/100], Batch [107/147] train loss: 561.25, train corr: -0.01894
Epoch [44/100], Batch [108/147] train loss: 564.46, train corr: -0.01687
Epoch [44/100], Batch [109/147] train loss: 576.56, train corr: -0.01485
Epoch [44/100], Batch [110/147] train loss: 577.15, train corr: -0.01535
Epoch [44/100], Batch [111/147] train loss: 557.30, train corr: -0.02070
Epoch [44/100], Batch [112/147] train loss: 581.96, train corr: -0.01573
Epoch [44/100], Batch [113/147] train loss: 556.39, train corr: -0.02130
Epoch [44/100], Batch [114/147] train loss: 557.86, train corr: -0.01998
Epoch [44/100], Batch [115/147] train loss: 561.52, train corr: -0.02012
Epoch [44/100], Batch [116/147] train loss: 559.12, train corr: -0.01425
Epoch [44/100], Batch [117/147] train loss: 570.92, train corr: -0.01848
Epoch [44/100], Batch [118/147] train loss: 560.68, train corr: -0.01924
Epoch [44/100], Batch [119/147] train loss: 566.19, train corr: -0.01794
Epoch [44/100], Batch [120/147] train loss: 549.83, train corr: -0.01807
Epoch [44/100], Batch [121/147] train loss: 575.36, train corr: -0.01555
Epoch [44/100], Batch [122/147] train loss: 561.77, train corr: -0.01494
Epoch [44/100], Batch [123/147] train loss: 554.07, train corr: -0.01859
Epoch [44/100], Batch [124/147] train loss: 573.92, train corr: -0.01492
Epoch [44/100], Batch [125/147] train loss: 568.60, train corr: -0.01795
Epoch [44/100], Batch [126/147] train loss: 562.97, train corr: -0.01938
Epoch [44/100], Batch [127/147] train loss: 549.92, train corr: -0.02013
Epoch [44/100], Batch [128/147] train loss: 569.21, train corr: -0.01831
Epoch [44/100], Batch [129/147] train loss: 558.28, train corr: -0.02148
Epoch [44/100], Batch [130/147] train loss: 554.50, train corr: -0.02103
Epoch [44/100], Batch [131/147] train loss: 578.80, train corr: -0.01498
Epoch [44/100], Batch [132/147] train loss: 818.06, train corr: -0.01591
Epoch [44/100], Batch [133/147] train loss: 580.92, train corr: -0.02107
Epoch [44/100], Batch [134/147] train loss: 553.76, train corr: 0.03207
Epoch [44/100], Batch [135/147] train loss: 577.82, train corr: 0.02475
Epoch [44/100], Batch [136/147] train loss: 578.12, train corr: 0.02750
Epoch [44/100], Batch [137/147] train loss: 581.74, train corr: 0.03015
Epoch [44/100], Batch [138/147] train loss: 566.81, train corr: -0.00100
Epoch [44/100], Batch [139/147] train loss: 580.62, train corr: -0.01976
Epoch [44/100], Batch [140/147] train loss: 571.22, train corr: 0.03091
Epoch [44/100], Batch [141/147] train loss: 562.67, train corr: 0.02974
Epoch [44/100], Batch [142/147] train loss: 579.37, train corr: 0.02726
Epoch [44/100], Batch [143/147] train loss: 554.57, train corr: 0.02792
Epoch [44/100], Batch [144/147] train loss: 555.53, train corr: 0.03056
Epoch [44/100], Batch [145/147] train loss: 700.76, train corr: -0.01036
Epoch [44/100], Batch [146/147] train loss: 565.69, train corr: -0.02525
Epoch [44/100], Batch [147/147] train loss: 602.15, train corr: 0.02854
Epoch [44/100], validation loss: 602.26, validation correlation: 0.02833
Epoch [45/100], Batch [1/147] train loss: 579.78, train corr: 0.02407
Epoch [45/100], Batch [2/147] train loss: 580.25, train corr: 0.02875
Epoch [45/100], Batch [3/147] train loss: 577.04, train corr: 0.02679
Epoch [45/100], Batch [4/147] train loss: 577.48, train corr: 0.02846
Epoch [45/100], Batch [5/147] train loss: 568.71, train corr: -0.02085
Epoch [45/100], Batch [6/147] train loss: 580.42, train corr: -0.02141
Epoch [45/100], Batch [7/147] train loss: 557.97, train corr: 0.02999
Epoch [45/100], Batch [8/147] train loss: 571.74, train corr: 0.02349
Epoch [45/100], Batch [9/147] train loss: 572.05, train corr: 0.02842
Epoch [45/100], Batch [10/147] train loss: 558.56, train corr: 0.02935
Epoch [45/100], Batch [11/147] train loss: 572.55, train corr: 0.03171
Epoch [45/100], Batch [12/147] train loss: 565.78, train corr: -0.02305
Epoch [45/100], Batch [13/147] train loss: 570.95, train corr: -0.01398
Epoch [45/100], Batch [14/147] train loss: 563.23, train corr: 0.03227
Epoch [45/100], Batch [15/147] train loss: 561.91, train corr: 0.03120
Epoch [45/100], Batch [16/147] train loss: 555.83, train corr: 0.03312
Epoch [45/100], Batch [17/147] train loss: 553.13, train corr: -0.01705
Epoch [45/100], Batch [18/147] train loss: 558.38, train corr: -0.01900
Epoch [45/100], Batch [19/147] train loss: 568.30, train corr: -0.01262
Epoch [45/100], Batch [20/147] train loss: 556.55, train corr: 0.03302
Epoch [45/100], Batch [21/147] train loss: 561.33, train corr: 0.03215
Epoch [45/100], Batch [22/147] train loss: 558.75, train corr: -0.00427
Epoch [45/100], Batch [23/147] train loss: 559.48, train corr: -0.02434
Epoch [45/100], Batch [24/147] train loss: 567.63, train corr: -0.01732
Epoch [45/100], Batch [25/147] train loss: 807.93, train corr: 0.00422
Epoch [45/100], Batch [26/147] train loss: 580.02, train corr: -0.01776
Epoch [45/100], Batch [27/147] train loss: 562.36, train corr: -0.00884
Epoch [45/100], Batch [28/147] train loss: 567.47, train corr: 0.03289
Epoch [45/100], Batch [29/147] train loss: 575.87, train corr: 0.03150
Epoch [45/100], Batch [30/147] train loss: 562.65, train corr: 0.00040
Epoch [45/100], Batch [31/147] train loss: 584.02, train corr: -0.02249
Epoch [45/100], Batch [32/147] train loss: 575.99, train corr: -0.01604
Epoch [45/100], Batch [33/147] train loss: 563.60, train corr: 0.02058
Epoch [45/100], Batch [34/147] train loss: 585.59, train corr: 0.02937
Epoch [45/100], Batch [35/147] train loss: 570.25, train corr: -0.01297
Epoch [45/100], Batch [36/147] train loss: 578.52, train corr: -0.01794
Epoch [45/100], Batch [37/147] train loss: 564.73, train corr: -0.02021
Epoch [45/100], Batch [38/147] train loss: 567.41, train corr: -0.01259
Epoch [45/100], Batch [39/147] train loss: 561.83, train corr: 0.01876
Epoch [45/100], Batch [40/147] train loss: 574.95, train corr: 0.00004
Epoch [45/100], Batch [41/147] train loss: 567.09, train corr: -0.01942
Epoch [45/100], Batch [42/147] train loss: 558.66, train corr: -0.02195
Epoch [45/100], Batch [43/147] train loss: 572.82, train corr: -0.01205
Epoch [45/100], Batch [44/147] train loss: 551.67, train corr: 0.00093
Epoch [45/100], Batch [45/147] train loss: 562.08, train corr: 0.00944
Epoch [45/100], Batch [46/147] train loss: 597.89, train corr: -0.01266
Epoch [45/100], Batch [47/147] train loss: 576.17, train corr: -0.02082
Epoch [45/100], Batch [48/147] train loss: 565.12, train corr: -0.02040
Epoch [45/100], Batch [49/147] train loss: 569.62, train corr: -0.01229
Epoch [45/100], Batch [50/147] train loss: 566.26, train corr: -0.01122
Epoch [45/100], Batch [51/147] train loss: 582.52, train corr: -0.01645
Epoch [45/100], Batch [52/147] train loss: 564.17, train corr: -0.01942
Epoch [45/100], Batch [53/147] train loss: 564.62, train corr: -0.02093
Epoch [45/100], Batch [54/147] train loss: 573.83, train corr: -0.01223
Epoch [45/100], Batch [55/147] train loss: 565.93, train corr: -0.01588
Epoch [45/100], Batch [56/147] train loss: 557.83, train corr: -0.02060
Epoch [45/100], Batch [57/147] train loss: 565.54, train corr: -0.02128
Epoch [45/100], Batch [58/147] train loss: 637.01, train corr: -0.01898
Epoch [45/100], Batch [59/147] train loss: 550.58, train corr: -0.01576
Epoch [45/100], Batch [60/147] train loss: 571.46, train corr: -0.00217
Epoch [45/100], Batch [61/147] train loss: 565.22, train corr: -0.01886
Epoch [45/100], Batch [62/147] train loss: 563.38, train corr: -0.01979
Epoch [45/100], Batch [63/147] train loss: 569.70, train corr: -0.02256
Epoch [45/100], Batch [64/147] train loss: 565.47, train corr: -0.01794
Epoch [45/100], Batch [65/147] train loss: 564.56, train corr: -0.00999
Epoch [45/100], Batch [66/147] train loss: 574.37, train corr: -0.01607
Epoch [45/100], Batch [67/147] train loss: 575.56, train corr: -0.01940
Epoch [45/100], Batch [68/147] train loss: 567.89, train corr: -0.02152
Epoch [45/100], Batch [69/147] train loss: 562.27, train corr: -0.01694
Epoch [45/100], Batch [70/147] train loss: 571.00, train corr: -0.01157
Epoch [45/100], Batch [71/147] train loss: 553.82, train corr: -0.01790
Epoch [45/100], Batch [72/147] train loss: 589.67, train corr: -0.01738
Epoch [45/100], Batch [73/147] train loss: 579.45, train corr: -0.01365
Epoch [45/100], Batch [74/147] train loss: 578.62, train corr: -0.01697
Epoch [45/100], Batch [75/147] train loss: 571.73, train corr: -0.01532
Epoch [45/100], Batch [76/147] train loss: 554.26, train corr: -0.01784
Epoch [45/100], Batch [77/147] train loss: 579.59, train corr: -0.01836
Epoch [45/100], Batch [78/147] train loss: 557.24, train corr: -0.01871
Epoch [45/100], Batch [79/147] train loss: 568.08, train corr: -0.01973
Epoch [45/100], Batch [80/147] train loss: 574.96, train corr: -0.01385
Epoch [45/100], Batch [81/147] train loss: 569.03, train corr: -0.02198
Epoch [45/100], Batch [82/147] train loss: 581.38, train corr: -0.02038
Epoch [45/100], Batch [83/147] train loss: 561.93, train corr: -0.02050
Epoch [45/100], Batch [84/147] train loss: 556.09, train corr: -0.02040
Epoch [45/100], Batch [85/147] train loss: 566.17, train corr: -0.01288
Epoch [45/100], Batch [86/147] train loss: 554.39, train corr: -0.01957
Epoch [45/100], Batch [87/147] train loss: 589.87, train corr: -0.01721
Epoch [45/100], Batch [88/147] train loss: 578.06, train corr: -0.01708
Epoch [45/100], Batch [89/147] train loss: 568.17, train corr: -0.01846
Epoch [45/100], Batch [90/147] train loss: 561.85, train corr: -0.01613
Epoch [45/100], Batch [91/147] train loss: 571.06, train corr: -0.01614
Epoch [45/100], Batch [92/147] train loss: 576.23, train corr: -0.01693
Epoch [45/100], Batch [93/147] train loss: 575.97, train corr: -0.01721
Epoch [45/100], Batch [94/147] train loss: 558.81, train corr: -0.01909
Epoch [45/100], Batch [95/147] train loss: 569.67, train corr: -0.01736
Epoch [45/100], Batch [96/147] train loss: 575.03, train corr: -0.01542
Epoch [45/100], Batch [97/147] train loss: 554.44, train corr: -0.02094
Epoch [45/100], Batch [98/147] train loss: 559.02, train corr: -0.01970
Epoch [45/100], Batch [99/147] train loss: 553.97, train corr: -0.01963
Epoch [45/100], Batch [100/147] train loss: 571.72, train corr: -0.01997
Epoch [45/100], Batch [101/147] train loss: 561.05, train corr: -0.02091
Epoch [45/100], Batch [102/147] train loss: 573.22, train corr: -0.01731
Epoch [45/100], Batch [103/147] train loss: 581.34, train corr: -0.01787
Epoch [45/100], Batch [104/147] train loss: 589.62, train corr: -0.01315
Epoch [45/100], Batch [105/147] train loss: 557.80, train corr: -0.01938
Epoch [45/100], Batch [106/147] train loss: 563.85, train corr: -0.02002
Epoch [45/100], Batch [107/147] train loss: 562.81, train corr: -0.01880
Epoch [45/100], Batch [108/147] train loss: 559.07, train corr: -0.01876
Epoch [45/100], Batch [109/147] train loss: 569.13, train corr: -0.01719
Epoch [45/100], Batch [110/147] train loss: 618.15, train corr: -0.01765
Epoch [45/100], Batch [111/147] train loss: 574.20, train corr: -0.01684
Epoch [45/100], Batch [112/147] train loss: 557.63, train corr: -0.01796
Epoch [45/100], Batch [113/147] train loss: 553.92, train corr: -0.01875
Epoch [45/100], Batch [114/147] train loss: 570.22, train corr: -0.01769
Epoch [45/100], Batch [115/147] train loss: 561.22, train corr: -0.01863
Epoch [45/100], Batch [116/147] train loss: 585.43, train corr: -0.00614
Epoch [45/100], Batch [117/147] train loss: 570.19, train corr: -0.01760
Epoch [45/100], Batch [118/147] train loss: 556.09, train corr: -0.02030
Epoch [45/100], Batch [119/147] train loss: 569.04, train corr: -0.01523
Epoch [45/100], Batch [120/147] train loss: 574.65, train corr: -0.01756
Epoch [45/100], Batch [121/147] train loss: 570.86, train corr: -0.01609
Epoch [45/100], Batch [122/147] train loss: 735.99, train corr: -0.01800
Epoch [45/100], Batch [123/147] train loss: 592.43, train corr: -0.02133
Epoch [45/100], Batch [124/147] train loss: 577.61, train corr: 0.02751
Epoch [45/100], Batch [125/147] train loss: 571.42, train corr: 0.02913
Epoch [45/100], Batch [126/147] train loss: 583.97, train corr: 0.02778
Epoch [45/100], Batch [127/147] train loss: 679.61, train corr: 0.02280
Epoch [45/100], Batch [128/147] train loss: 609.52, train corr: 0.02610
Epoch [45/100], Batch [129/147] train loss: 604.44, train corr: 0.02450
Epoch [45/100], Batch [130/147] train loss: 603.39, train corr: 0.02722
Epoch [45/100], Batch [131/147] train loss: 606.31, train corr: 0.02837
Epoch [45/100], Batch [132/147] train loss: 579.47, train corr: 0.02939
Epoch [45/100], Batch [133/147] train loss: 606.39, train corr: 0.02279
Epoch [45/100], Batch [134/147] train loss: 590.77, train corr: 0.02388
Epoch [45/100], Batch [135/147] train loss: 589.70, train corr: 0.02816
Epoch [45/100], Batch [136/147] train loss: 574.29, train corr: 0.02780
Epoch [45/100], Batch [137/147] train loss: 568.90, train corr: -0.00814
Epoch [45/100], Batch [138/147] train loss: 583.27, train corr: -0.01966
Epoch [45/100], Batch [139/147] train loss: 581.02, train corr: 0.02884
Epoch [45/100], Batch [140/147] train loss: 592.14, train corr: 0.02540
Epoch [45/100], Batch [141/147] train loss: 622.54, train corr: 0.02547
Epoch [45/100], Batch [142/147] train loss: 616.01, train corr: 0.02750
Epoch [45/100], Batch [143/147] train loss: 623.24, train corr: 0.02942
Epoch [45/100], Batch [144/147] train loss: 622.79, train corr: 0.02584
Epoch [45/100], Batch [145/147] train loss: 603.92, train corr: 0.02754
Epoch [45/100], Batch [146/147] train loss: 593.55, train corr: 0.02809
Epoch [45/100], Batch [147/147] train loss: 583.84, train corr: 0.02851
Epoch [45/100], validation loss: 609.88, validation correlation: 0.02946
Epoch [46/100], Batch [1/147] train loss: 568.71, train corr: 0.02976
Epoch [46/100], Batch [2/147] train loss: 590.15, train corr: 0.02031
Epoch [46/100], Batch [3/147] train loss: 598.57, train corr: -0.01448
Epoch [46/100], Batch [4/147] train loss: 587.16, train corr: 0.02662
Epoch [46/100], Batch [5/147] train loss: 611.99, train corr: 0.02888
Epoch [46/100], Batch [6/147] train loss: 638.33, train corr: 0.02721
Epoch [46/100], Batch [7/147] train loss: 661.97, train corr: 0.02356
Epoch [46/100], Batch [8/147] train loss: 696.30, train corr: 0.02224
Epoch [46/100], Batch [9/147] train loss: 1160.45, train corr: 0.02265
Epoch [46/100], Batch [10/147] train loss: 711.01, train corr: 0.02527
Epoch [46/100], Batch [11/147] train loss: 658.09, train corr: 0.02843
Epoch [46/100], Batch [12/147] train loss: 650.42, train corr: 0.02420
Epoch [46/100], Batch [13/147] train loss: 639.02, train corr: 0.02793
Epoch [46/100], Batch [14/147] train loss: 644.00, train corr: 0.02470
Epoch [46/100], Batch [15/147] train loss: 633.81, train corr: 0.02718
Epoch [46/100], Batch [16/147] train loss: 646.10, train corr: 0.02573
Epoch [46/100], Batch [17/147] train loss: 604.39, train corr: 0.02783
Epoch [46/100], Batch [18/147] train loss: 607.87, train corr: 0.02739
Epoch [46/100], Batch [19/147] train loss: 579.58, train corr: 0.02854
Epoch [46/100], Batch [20/147] train loss: 588.47, train corr: 0.02612
Epoch [46/100], Batch [21/147] train loss: 589.89, train corr: -0.00294
Epoch [46/100], Batch [22/147] train loss: 797.39, train corr: -0.02260
Epoch [46/100], Batch [23/147] train loss: 629.72, train corr: 0.02805
Epoch [46/100], Batch [24/147] train loss: 712.10, train corr: 0.02726
Epoch [46/100], Batch [25/147] train loss: 780.28, train corr: 0.02644
Epoch [46/100], Batch [26/147] train loss: 850.07, train corr: 0.02067
Epoch [46/100], Batch [27/147] train loss: 866.36, train corr: 0.02761
Epoch [46/100], Batch [28/147] train loss: 932.38, train corr: 0.02539
Epoch [46/100], Batch [29/147] train loss: 953.69, train corr: 0.02136
Epoch [46/100], Batch [30/147] train loss: 925.65, train corr: 0.03021
Epoch [46/100], Batch [31/147] train loss: 924.99, train corr: 0.02605
Epoch [46/100], Batch [32/147] train loss: 963.06, train corr: 0.02211
Epoch [46/100], Batch [33/147] train loss: 952.51, train corr: 0.02824
Epoch [46/100], Batch [34/147] train loss: 957.98, train corr: 0.02944
Epoch [46/100], Batch [35/147] train loss: 945.50, train corr: 0.02734
Epoch [46/100], Batch [36/147] train loss: 927.00, train corr: 0.02755
Epoch [46/100], Batch [37/147] train loss: 947.40, train corr: 0.01909
Epoch [46/100], Batch [38/147] train loss: 921.89, train corr: 0.02407
Epoch [46/100], Batch [39/147] train loss: 885.46, train corr: 0.02842
Epoch [46/100], Batch [40/147] train loss: 896.97, train corr: 0.02765
Epoch [46/100], Batch [41/147] train loss: 878.63, train corr: 0.02544
Epoch [46/100], Batch [42/147] train loss: 847.69, train corr: 0.02957
Epoch [46/100], Batch [43/147] train loss: 863.26, train corr: 0.02587
Epoch [46/100], Batch [44/147] train loss: 840.61, train corr: 0.02080
Epoch [46/100], Batch [45/147] train loss: 772.02, train corr: 0.02692
Epoch [46/100], Batch [46/147] train loss: 780.60, train corr: 0.02950
Epoch [46/100], Batch [47/147] train loss: 787.51, train corr: 0.02528
Epoch [46/100], Batch [48/147] train loss: 774.18, train corr: 0.02634
Epoch [46/100], Batch [49/147] train loss: 758.38, train corr: 0.02753
Epoch [46/100], Batch [50/147] train loss: 732.19, train corr: 0.02632
Epoch [46/100], Batch [51/147] train loss: 753.84, train corr: 0.02285
Epoch [46/100], Batch [52/147] train loss: 694.64, train corr: 0.02780
Epoch [46/100], Batch [53/147] train loss: 711.79, train corr: 0.02672
Epoch [46/100], Batch [54/147] train loss: 724.02, train corr: 0.02474
Epoch [46/100], Batch [55/147] train loss: 1051.52, train corr: 0.02779
Epoch [46/100], Batch [56/147] train loss: 663.78, train corr: 0.02736
Epoch [46/100], Batch [57/147] train loss: 634.67, train corr: 0.02762
Epoch [46/100], Batch [58/147] train loss: 634.05, train corr: 0.02741
Epoch [46/100], Batch [59/147] train loss: 631.46, train corr: 0.02674
Epoch [46/100], Batch [60/147] train loss: 605.96, train corr: 0.02855
Epoch [46/100], Batch [61/147] train loss: 607.33, train corr: 0.02871
Epoch [46/100], Batch [62/147] train loss: 608.67, train corr: 0.02651
Epoch [46/100], Batch [63/147] train loss: 781.05, train corr: 0.02667
Epoch [46/100], Batch [64/147] train loss: 677.65, train corr: 0.02694
Epoch [46/100], Batch [65/147] train loss: 799.04, train corr: 0.02655
Epoch [46/100], Batch [66/147] train loss: 871.74, train corr: 0.02776
Epoch [46/100], Batch [67/147] train loss: 960.12, train corr: 0.02175
Epoch [46/100], Batch [68/147] train loss: 951.88, train corr: 0.02680
Epoch [46/100], Batch [69/147] train loss: 981.13, train corr: 0.02664
Epoch [46/100], Batch [70/147] train loss: 1018.58, train corr: 0.02559
Epoch [46/100], Batch [71/147] train loss: 953.94, train corr: 0.02789
Epoch [46/100], Batch [72/147] train loss: 956.76, train corr: 0.02703
Epoch [46/100], Batch [73/147] train loss: 972.79, train corr: 0.02752
Epoch [46/100], Batch [74/147] train loss: 930.03, train corr: 0.02784
Epoch [46/100], Batch [75/147] train loss: 932.25, train corr: 0.02763
Epoch [46/100], Batch [76/147] train loss: 915.88, train corr: 0.02939
Epoch [46/100], Batch [77/147] train loss: 954.67, train corr: 0.02591
Epoch [46/100], Batch [78/147] train loss: 955.80, train corr: 0.02749
Epoch [46/100], Batch [79/147] train loss: 972.62, train corr: 0.02620
Epoch [46/100], Batch [80/147] train loss: 961.22, train corr: 0.02449
Epoch [46/100], Batch [81/147] train loss: 908.24, train corr: 0.02639
Epoch [46/100], Batch [82/147] train loss: 921.13, train corr: 0.02822
Epoch [46/100], Batch [83/147] train loss: 1088.11, train corr: 0.02476
Epoch [46/100], Batch [84/147] train loss: 1012.47, train corr: 0.02530
Epoch [46/100], Batch [85/147] train loss: 929.70, train corr: 0.02486
Epoch [46/100], Batch [86/147] train loss: 900.35, train corr: 0.02461
Epoch [46/100], Batch [87/147] train loss: 857.26, train corr: 0.02450
Epoch [46/100], Batch [88/147] train loss: 841.91, train corr: 0.02656
Epoch [46/100], Batch [89/147] train loss: 866.78, train corr: 0.02866
Epoch [46/100], Batch [90/147] train loss: 847.61, train corr: 0.02752
Epoch [46/100], Batch [91/147] train loss: 835.35, train corr: 0.02500
Epoch [46/100], Batch [92/147] train loss: 859.71, train corr: 0.02453
Epoch [46/100], Batch [93/147] train loss: 835.86, train corr: 0.02523
Epoch [46/100], Batch [94/147] train loss: 809.56, train corr: 0.02634
Epoch [46/100], Batch [95/147] train loss: 843.95, train corr: 0.02527
Epoch [46/100], Batch [96/147] train loss: 785.14, train corr: 0.02881
Epoch [46/100], Batch [97/147] train loss: 780.30, train corr: 0.02522
Epoch [46/100], Batch [98/147] train loss: 739.10, train corr: 0.02651
Epoch [46/100], Batch [99/147] train loss: 744.65, train corr: 0.02368
Epoch [46/100], Batch [100/147] train loss: 711.74, train corr: 0.02494
Epoch [46/100], Batch [101/147] train loss: 700.03, train corr: 0.02683
Epoch [46/100], Batch [102/147] train loss: 665.25, train corr: 0.02948
Epoch [46/100], Batch [103/147] train loss: 692.96, train corr: 0.02611
Epoch [46/100], Batch [104/147] train loss: 666.98, train corr: 0.02819
Epoch [46/100], Batch [105/147] train loss: 648.85, train corr: 0.03045
Epoch [46/100], Batch [106/147] train loss: 646.38, train corr: 0.02753
Epoch [46/100], Batch [107/147] train loss: 653.18, train corr: 0.02739
Epoch [46/100], Batch [108/147] train loss: 629.02, train corr: 0.02878
Epoch [46/100], Batch [109/147] train loss: 625.88, train corr: 0.02707
Epoch [46/100], Batch [110/147] train loss: 614.76, train corr: 0.02967
Epoch [46/100], Batch [111/147] train loss: 608.19, train corr: 0.02934
Epoch [46/100], Batch [112/147] train loss: 603.65, train corr: 0.02951
Epoch [46/100], Batch [113/147] train loss: 637.76, train corr: 0.02855
Epoch [46/100], Batch [114/147] train loss: 603.51, train corr: 0.02630
Epoch [46/100], Batch [115/147] train loss: 573.77, train corr: 0.02946
Epoch [46/100], Batch [116/147] train loss: 591.64, train corr: 0.02645
Epoch [46/100], Batch [117/147] train loss: 552.16, train corr: 0.02977
Epoch [46/100], Batch [118/147] train loss: 569.18, train corr: 0.02598
Epoch [46/100], Batch [119/147] train loss: 560.70, train corr: -0.01331
Epoch [46/100], Batch [120/147] train loss: 570.81, train corr: -0.02538
Epoch [46/100], Batch [121/147] train loss: 575.06, train corr: 0.02538
Epoch [46/100], Batch [122/147] train loss: 563.93, train corr: 0.02560
Epoch [46/100], Batch [123/147] train loss: 582.60, train corr: 0.01768
Epoch [46/100], Batch [124/147] train loss: 565.36, train corr: -0.00780
Epoch [46/100], Batch [125/147] train loss: 572.33, train corr: -0.03344
Epoch [46/100], Batch [126/147] train loss: 575.91, train corr: 0.01039
Epoch [46/100], Batch [127/147] train loss: 565.61, train corr: 0.02219
Epoch [46/100], Batch [128/147] train loss: 571.92, train corr: 0.02132
Epoch [46/100], Batch [129/147] train loss: 583.45, train corr: 0.01058
Epoch [46/100], Batch [130/147] train loss: 552.35, train corr: -0.03345
Epoch [46/100], Batch [131/147] train loss: 576.97, train corr: -0.02720
Epoch [46/100], Batch [132/147] train loss: 574.67, train corr: 0.02730
Epoch [46/100], Batch [133/147] train loss: 563.95, train corr: 0.02874
Epoch [46/100], Batch [134/147] train loss: 572.77, train corr: 0.02349
Epoch [46/100], Batch [135/147] train loss: 575.52, train corr: 0.02381
Epoch [46/100], Batch [136/147] train loss: 565.76, train corr: 0.02843
Epoch [46/100], Batch [137/147] train loss: 568.50, train corr: 0.02996
Epoch [46/100], Batch [138/147] train loss: 575.69, train corr: -0.02104
Epoch [46/100], Batch [139/147] train loss: 590.78, train corr: 0.02980
Epoch [46/100], Batch [140/147] train loss: 573.69, train corr: 0.02905
Epoch [46/100], Batch [141/147] train loss: 581.68, train corr: 0.03058
Epoch [46/100], Batch [142/147] train loss: 599.34, train corr: 0.02901
Epoch [46/100], Batch [143/147] train loss: 599.10, train corr: 0.02798
Epoch [46/100], Batch [144/147] train loss: 595.26, train corr: 0.02515
Epoch [46/100], Batch [145/147] train loss: 583.47, train corr: 0.02497
Epoch [46/100], Batch [146/147] train loss: 576.83, train corr: 0.02680
Epoch [46/100], Batch [147/147] train loss: 561.02, train corr: 0.02894
Epoch [46/100], validation loss: 611.00, validation correlation: 0.02845
Epoch [47/100], Batch [1/147] train loss: 583.29, train corr: 0.02983
Epoch [47/100], Batch [2/147] train loss: 564.33, train corr: 0.03279
Epoch [47/100], Batch [3/147] train loss: 586.91, train corr: 0.02796
Epoch [47/100], Batch [4/147] train loss: 572.84, train corr: -0.02181
Epoch [47/100], Batch [5/147] train loss: 564.78, train corr: 0.03234
Epoch [47/100], Batch [6/147] train loss: 569.06, train corr: 0.02896
Epoch [47/100], Batch [7/147] train loss: 599.58, train corr: 0.02659
Epoch [47/100], Batch [8/147] train loss: 598.78, train corr: 0.02612
Epoch [47/100], Batch [9/147] train loss: 587.48, train corr: 0.02890
Epoch [47/100], Batch [10/147] train loss: 601.62, train corr: 0.02612
Epoch [47/100], Batch [11/147] train loss: 613.42, train corr: 0.02416
Epoch [47/100], Batch [12/147] train loss: 580.91, train corr: 0.02657
Epoch [47/100], Batch [13/147] train loss: 581.37, train corr: 0.02331
Epoch [47/100], Batch [14/147] train loss: 583.85, train corr: 0.02224
Epoch [47/100], Batch [15/147] train loss: 576.53, train corr: 0.02656
Epoch [47/100], Batch [16/147] train loss: 572.56, train corr: 0.01810
Epoch [47/100], Batch [17/147] train loss: 599.33, train corr: -0.00774
Epoch [47/100], Batch [18/147] train loss: 565.54, train corr: 0.01539
Epoch [47/100], Batch [19/147] train loss: 589.01, train corr: 0.03300
Epoch [47/100], Batch [20/147] train loss: 586.10, train corr: 0.03472
Epoch [47/100], Batch [21/147] train loss: 553.49, train corr: 0.03402
Epoch [47/100], Batch [22/147] train loss: 591.99, train corr: 0.02757
Epoch [47/100], Batch [23/147] train loss: 569.91, train corr: 0.02652
Epoch [47/100], Batch [24/147] train loss: 565.26, train corr: -0.00482
Epoch [47/100], Batch [25/147] train loss: 570.77, train corr: -0.01644
Epoch [47/100], Batch [26/147] train loss: 590.08, train corr: 0.02747
Epoch [47/100], Batch [27/147] train loss: 574.14, train corr: 0.02968
Epoch [47/100], Batch [28/147] train loss: 564.79, train corr: 0.02808
Epoch [47/100], Batch [29/147] train loss: 585.03, train corr: 0.02234
Epoch [47/100], Batch [30/147] train loss: 569.10, train corr: 0.02671
Epoch [47/100], Batch [31/147] train loss: 561.41, train corr: 0.02598
Epoch [47/100], Batch [32/147] train loss: 583.72, train corr: 0.02789
Epoch [47/100], Batch [33/147] train loss: 566.50, train corr: 0.02800
Epoch [47/100], Batch [34/147] train loss: 616.73, train corr: 0.02676
Epoch [47/100], Batch [35/147] train loss: 590.37, train corr: 0.02614
Epoch [47/100], Batch [36/147] train loss: 565.90, train corr: -0.01351
Epoch [47/100], Batch [37/147] train loss: 585.65, train corr: -0.01847
Epoch [47/100], Batch [38/147] train loss: 572.70, train corr: 0.03142
Epoch [47/100], Batch [39/147] train loss: 590.20, train corr: 0.02737
Epoch [47/100], Batch [40/147] train loss: 573.54, train corr: 0.03208
Epoch [47/100], Batch [41/147] train loss: 565.05, train corr: 0.03033
Epoch [47/100], Batch [42/147] train loss: 588.84, train corr: 0.02575
Epoch [47/100], Batch [43/147] train loss: 577.85, train corr: -0.02896
Epoch [47/100], Batch [44/147] train loss: 570.23, train corr: -0.02860
Epoch [47/100], Batch [45/147] train loss: 568.27, train corr: 0.02070
Epoch [47/100], Batch [46/147] train loss: 571.70, train corr: 0.02369
Epoch [47/100], Batch [47/147] train loss: 550.15, train corr: 0.02873
Epoch [47/100], Batch [48/147] train loss: 591.07, train corr: 0.02301
Epoch [47/100], Batch [49/147] train loss: 591.59, train corr: 0.02608
Epoch [47/100], Batch [50/147] train loss: 552.47, train corr: 0.03163
Epoch [47/100], Batch [51/147] train loss: 591.91, train corr: 0.02304
Epoch [47/100], Batch [52/147] train loss: 560.97, train corr: -0.01641
Epoch [47/100], Batch [53/147] train loss: 565.82, train corr: -0.00110
Epoch [47/100], Batch [54/147] train loss: 573.02, train corr: 0.03486
Epoch [47/100], Batch [55/147] train loss: 560.82, train corr: 0.03385
Epoch [47/100], Batch [56/147] train loss: 589.29, train corr: 0.03058
Epoch [47/100], Batch [57/147] train loss: 570.62, train corr: 0.00966
Epoch [47/100], Batch [58/147] train loss: 571.41, train corr: -0.02039
Epoch [47/100], Batch [59/147] train loss: 594.97, train corr: -0.02342
Epoch [47/100], Batch [60/147] train loss: 564.53, train corr: -0.01873
Epoch [47/100], Batch [61/147] train loss: 586.88, train corr: 0.02635
Epoch [47/100], Batch [62/147] train loss: 566.37, train corr: 0.02435
Epoch [47/100], Batch [63/147] train loss: 639.89, train corr: 0.02687
Epoch [47/100], Batch [64/147] train loss: 555.25, train corr: -0.02713
Epoch [47/100], Batch [65/147] train loss: 575.11, train corr: -0.02419
Epoch [47/100], Batch [66/147] train loss: 558.08, train corr: 0.00770
Epoch [47/100], Batch [67/147] train loss: 587.11, train corr: 0.02960
Epoch [47/100], Batch [68/147] train loss: 569.01, train corr: 0.02931
Epoch [47/100], Batch [69/147] train loss: 579.26, train corr: 0.03176
Epoch [47/100], Batch [70/147] train loss: 565.27, train corr: 0.03280
Epoch [47/100], Batch [71/147] train loss: 579.88, train corr: 0.03067
Epoch [47/100], Batch [72/147] train loss: 546.64, train corr: 0.01996
Epoch [47/100], Batch [73/147] train loss: 558.73, train corr: -0.00504
Epoch [47/100], Batch [74/147] train loss: 560.54, train corr: -0.01491
Epoch [47/100], Batch [75/147] train loss: 567.18, train corr: -0.01690
Epoch [47/100], Batch [76/147] train loss: 559.82, train corr: -0.02101
Epoch [47/100], Batch [77/147] train loss: 565.74, train corr: -0.02535
Epoch [47/100], Batch [78/147] train loss: 742.27, train corr: -0.02446
Epoch [47/100], Batch [79/147] train loss: 563.69, train corr: -0.02784
Epoch [47/100], Batch [80/147] train loss: 568.06, train corr: 0.02235
Epoch [47/100], Batch [81/147] train loss: 584.03, train corr: 0.02324
Epoch [47/100], Batch [82/147] train loss: 560.75, train corr: 0.02869
Epoch [47/100], Batch [83/147] train loss: 575.61, train corr: 0.02489
Epoch [47/100], Batch [84/147] train loss: 576.31, train corr: 0.02559
Epoch [47/100], Batch [85/147] train loss: 563.87, train corr: 0.02980
Epoch [47/100], Batch [86/147] train loss: 577.58, train corr: 0.01575
Epoch [47/100], Batch [87/147] train loss: 586.96, train corr: -0.01996
Epoch [47/100], Batch [88/147] train loss: 572.46, train corr: 0.00120
Epoch [47/100], Batch [89/147] train loss: 577.96, train corr: 0.03281
Epoch [47/100], Batch [90/147] train loss: 559.46, train corr: 0.03284
Epoch [47/100], Batch [91/147] train loss: 549.51, train corr: 0.03456
Epoch [47/100], Batch [92/147] train loss: 581.51, train corr: 0.01302
Epoch [47/100], Batch [93/147] train loss: 560.93, train corr: -0.02113
Epoch [47/100], Batch [94/147] train loss: 562.92, train corr: -0.02279
Epoch [47/100], Batch [95/147] train loss: 548.67, train corr: 0.02203
Epoch [47/100], Batch [96/147] train loss: 578.63, train corr: 0.02557
Epoch [47/100], Batch [97/147] train loss: 574.48, train corr: 0.02621
Epoch [47/100], Batch [98/147] train loss: 573.32, train corr: 0.02724
Epoch [47/100], Batch [99/147] train loss: 560.67, train corr: -0.01293
Epoch [47/100], Batch [100/147] train loss: 572.55, train corr: -0.01917
Epoch [47/100], Batch [101/147] train loss: 562.19, train corr: -0.02056
Epoch [47/100], Batch [102/147] train loss: 570.83, train corr: 0.01658
Epoch [47/100], Batch [103/147] train loss: 595.88, train corr: 0.03303
Epoch [47/100], Batch [104/147] train loss: 564.95, train corr: 0.03246
Epoch [47/100], Batch [105/147] train loss: 568.29, train corr: 0.00337
Epoch [47/100], Batch [106/147] train loss: 556.45, train corr: -0.01777
Epoch [47/100], Batch [107/147] train loss: 560.27, train corr: -0.02284
Epoch [47/100], Batch [108/147] train loss: 566.65, train corr: -0.01747
Epoch [47/100], Batch [109/147] train loss: 565.84, train corr: 0.02721
Epoch [47/100], Batch [110/147] train loss: 552.83, train corr: 0.03179
Epoch [47/100], Batch [111/147] train loss: 561.03, train corr: 0.02100
Epoch [47/100], Batch [112/147] train loss: 578.44, train corr: -0.01529
Epoch [47/100], Batch [113/147] train loss: 559.90, train corr: -0.01708
Epoch [47/100], Batch [114/147] train loss: 568.51, train corr: -0.01956
Epoch [47/100], Batch [115/147] train loss: 579.27, train corr: -0.00823
Epoch [47/100], Batch [116/147] train loss: 556.78, train corr: 0.00927
Epoch [47/100], Batch [117/147] train loss: 577.25, train corr: 0.01297
Epoch [47/100], Batch [118/147] train loss: 564.40, train corr: -0.00747
Epoch [47/100], Batch [119/147] train loss: 628.04, train corr: -0.01915
Epoch [47/100], Batch [120/147] train loss: 572.86, train corr: -0.01723
Epoch [47/100], Batch [121/147] train loss: 559.73, train corr: -0.01363
Epoch [47/100], Batch [122/147] train loss: 573.64, train corr: 0.00102
Epoch [47/100], Batch [123/147] train loss: 589.11, train corr: -0.00348
Epoch [47/100], Batch [124/147] train loss: 562.53, train corr: -0.01896
Epoch [47/100], Batch [125/147] train loss: 555.18, train corr: -0.02118
Epoch [47/100], Batch [126/147] train loss: 555.81, train corr: -0.01690
Epoch [47/100], Batch [127/147] train loss: 562.44, train corr: -0.01163
Epoch [47/100], Batch [128/147] train loss: 563.06, train corr: -0.00293
Epoch [47/100], Batch [129/147] train loss: 560.46, train corr: -0.00829
Epoch [47/100], Batch [130/147] train loss: 560.25, train corr: -0.01278
Epoch [47/100], Batch [131/147] train loss: 564.98, train corr: -0.01601
Epoch [47/100], Batch [132/147] train loss: 555.61, train corr: -0.01678
Epoch [47/100], Batch [133/147] train loss: 576.79, train corr: -0.00865
Epoch [47/100], Batch [134/147] train loss: 560.21, train corr: 0.00319
Epoch [47/100], Batch [135/147] train loss: 568.63, train corr: 0.00216
Epoch [47/100], Batch [136/147] train loss: 548.25, train corr: -0.00844
Epoch [47/100], Batch [137/147] train loss: 563.73, train corr: -0.01472
Epoch [47/100], Batch [138/147] train loss: 569.10, train corr: -0.01506
Epoch [47/100], Batch [139/147] train loss: 566.15, train corr: -0.02075
Epoch [47/100], Batch [140/147] train loss: 821.34, train corr: -0.01191
Epoch [47/100], Batch [141/147] train loss: 559.13, train corr: -0.02407
Epoch [47/100], Batch [142/147] train loss: 568.32, train corr: -0.01852
Epoch [47/100], Batch [143/147] train loss: 568.70, train corr: 0.03088
Epoch [47/100], Batch [144/147] train loss: 559.75, train corr: 0.03296
Epoch [47/100], Batch [145/147] train loss: 565.93, train corr: 0.03162
Epoch [47/100], Batch [146/147] train loss: 565.09, train corr: 0.03102
Epoch [47/100], Batch [147/147] train loss: 567.75, train corr: -0.01139
Epoch [47/100], validation loss: 599.60, validation correlation: -0.01719
Epoch [48/100], Batch [1/147] train loss: 558.53, train corr: -0.01967
Epoch [48/100], Batch [2/147] train loss: 577.47, train corr: 0.00473
Epoch [48/100], Batch [3/147] train loss: 741.42, train corr: 0.03101
Epoch [48/100], Batch [4/147] train loss: 566.62, train corr: -0.01866
Epoch [48/100], Batch [5/147] train loss: 558.10, train corr: -0.02108
Epoch [48/100], Batch [6/147] train loss: 570.69, train corr: 0.03096
Epoch [48/100], Batch [7/147] train loss: 561.86, train corr: 0.02850
Epoch [48/100], Batch [8/147] train loss: 576.07, train corr: 0.02752
Epoch [48/100], Batch [9/147] train loss: 580.95, train corr: 0.02923
Epoch [48/100], Batch [10/147] train loss: 562.45, train corr: 0.03452
Epoch [48/100], Batch [11/147] train loss: 570.18, train corr: -0.02120
Epoch [48/100], Batch [12/147] train loss: 574.79, train corr: -0.02711
Epoch [48/100], Batch [13/147] train loss: 558.99, train corr: -0.01167
Epoch [48/100], Batch [14/147] train loss: 566.45, train corr: 0.03001
Epoch [48/100], Batch [15/147] train loss: 574.21, train corr: 0.02949
Epoch [48/100], Batch [16/147] train loss: 564.89, train corr: 0.03018
Epoch [48/100], Batch [17/147] train loss: 568.01, train corr: -0.02151
Epoch [48/100], Batch [18/147] train loss: 567.17, train corr: -0.02501
Epoch [48/100], Batch [19/147] train loss: 646.94, train corr: -0.01923
Epoch [48/100], Batch [20/147] train loss: 565.91, train corr: -0.00517
Epoch [48/100], Batch [21/147] train loss: 583.98, train corr: 0.02201
Epoch [48/100], Batch [22/147] train loss: 562.49, train corr: 0.02600
Epoch [48/100], Batch [23/147] train loss: 575.78, train corr: 0.02311
Epoch [48/100], Batch [24/147] train loss: 561.15, train corr: 0.02620
Epoch [48/100], Batch [25/147] train loss: 574.68, train corr: -0.00080
Epoch [48/100], Batch [26/147] train loss: 576.87, train corr: 0.03220
Epoch [48/100], Batch [27/147] train loss: 558.52, train corr: 0.03231
Epoch [48/100], Batch [28/147] train loss: 553.97, train corr: 0.03132
Epoch [48/100], Batch [29/147] train loss: 555.62, train corr: 0.03325
Epoch [48/100], Batch [30/147] train loss: 566.59, train corr: 0.01255
Epoch [48/100], Batch [31/147] train loss: 564.87, train corr: -0.02145
Epoch [48/100], Batch [32/147] train loss: 563.32, train corr: -0.02162
Epoch [48/100], Batch [33/147] train loss: 561.80, train corr: -0.01335
Epoch [48/100], Batch [34/147] train loss: 577.59, train corr: 0.02653
Epoch [48/100], Batch [35/147] train loss: 565.97, train corr: 0.02400
Epoch [48/100], Batch [36/147] train loss: 563.97, train corr: 0.01169
Epoch [48/100], Batch [37/147] train loss: 551.54, train corr: -0.02685
Epoch [48/100], Batch [38/147] train loss: 578.15, train corr: -0.02511
Epoch [48/100], Batch [39/147] train loss: 570.07, train corr: -0.01236
Epoch [48/100], Batch [40/147] train loss: 564.92, train corr: 0.02597
Epoch [48/100], Batch [41/147] train loss: 614.46, train corr: 0.02968
Epoch [48/100], Batch [42/147] train loss: 556.26, train corr: 0.01154
Epoch [48/100], Batch [43/147] train loss: 622.75, train corr: -0.02019
Epoch [48/100], Batch [44/147] train loss: 583.49, train corr: -0.01442
Epoch [48/100], Batch [45/147] train loss: 567.25, train corr: -0.01518
Epoch [48/100], Batch [46/147] train loss: 563.60, train corr: 0.01062
Epoch [48/100], Batch [47/147] train loss: 570.54, train corr: 0.02734
Epoch [48/100], Batch [48/147] train loss: 580.89, train corr: -0.00363
Epoch [48/100], Batch [49/147] train loss: 567.32, train corr: -0.01769
Epoch [48/100], Batch [50/147] train loss: 572.39, train corr: -0.02369
Epoch [48/100], Batch [51/147] train loss: 582.69, train corr: -0.01514
Epoch [48/100], Batch [52/147] train loss: 548.60, train corr: -0.00034
Epoch [48/100], Batch [53/147] train loss: 570.22, train corr: 0.01315
Epoch [48/100], Batch [54/147] train loss: 578.38, train corr: -0.00898
Epoch [48/100], Batch [55/147] train loss: 560.12, train corr: -0.02012
Epoch [48/100], Batch [56/147] train loss: 580.79, train corr: -0.01992
Epoch [48/100], Batch [57/147] train loss: 577.72, train corr: -0.01118
Epoch [48/100], Batch [58/147] train loss: 573.14, train corr: 0.00274
Epoch [48/100], Batch [59/147] train loss: 593.83, train corr: 0.02068
Epoch [48/100], Batch [60/147] train loss: 575.17, train corr: -0.00705
Epoch [48/100], Batch [61/147] train loss: 558.83, train corr: -0.01946
Epoch [48/100], Batch [62/147] train loss: 560.32, train corr: -0.01691
Epoch [48/100], Batch [63/147] train loss: 571.75, train corr: -0.02021
Epoch [48/100], Batch [64/147] train loss: 567.78, train corr: -0.01073
Epoch [48/100], Batch [65/147] train loss: 551.04, train corr: -0.00814
Epoch [48/100], Batch [66/147] train loss: 567.20, train corr: -0.01309
Epoch [48/100], Batch [67/147] train loss: 554.66, train corr: -0.01902
Epoch [48/100], Batch [68/147] train loss: 568.76, train corr: -0.01613
Epoch [48/100], Batch [69/147] train loss: 554.59, train corr: -0.01820
Epoch [48/100], Batch [70/147] train loss: 576.05, train corr: -0.01072
Epoch [48/100], Batch [71/147] train loss: 571.84, train corr: -0.00800
Epoch [48/100], Batch [72/147] train loss: 577.13, train corr: -0.01220
Epoch [48/100], Batch [73/147] train loss: 568.47, train corr: -0.01502
Epoch [48/100], Batch [74/147] train loss: 548.52, train corr: -0.01744
Epoch [48/100], Batch [75/147] train loss: 555.29, train corr: -0.02059
Epoch [48/100], Batch [76/147] train loss: 566.57, train corr: -0.01461
Epoch [48/100], Batch [77/147] train loss: 572.13, train corr: -0.01490
Epoch [48/100], Batch [78/147] train loss: 556.63, train corr: -0.01872
Epoch [48/100], Batch [79/147] train loss: 568.15, train corr: -0.01912
Epoch [48/100], Batch [80/147] train loss: 567.15, train corr: -0.01825
Epoch [48/100], Batch [81/147] train loss: 573.35, train corr: -0.01749
Epoch [48/100], Batch [82/147] train loss: 582.78, train corr: -0.01478
Epoch [48/100], Batch [83/147] train loss: 564.26, train corr: -0.01398
Epoch [48/100], Batch [84/147] train loss: 562.30, train corr: -0.01653
Epoch [48/100], Batch [85/147] train loss: 564.13, train corr: -0.02345
Epoch [48/100], Batch [86/147] train loss: 567.80, train corr: -0.01835
Epoch [48/100], Batch [87/147] train loss: 563.43, train corr: -0.01567
Epoch [48/100], Batch [88/147] train loss: 573.08, train corr: -0.01008
Epoch [48/100], Batch [89/147] train loss: 566.62, train corr: -0.01420
Epoch [48/100], Batch [90/147] train loss: 582.20, train corr: -0.01241
Epoch [48/100], Batch [91/147] train loss: 574.55, train corr: -0.01539
Epoch [48/100], Batch [92/147] train loss: 574.10, train corr: -0.01750
Epoch [48/100], Batch [93/147] train loss: 561.08, train corr: -0.01567
Epoch [48/100], Batch [94/147] train loss: 576.41, train corr: -0.01282
Epoch [48/100], Batch [95/147] train loss: 594.03, train corr: -0.01024
Epoch [48/100], Batch [96/147] train loss: 555.35, train corr: -0.01855
Epoch [48/100], Batch [97/147] train loss: 560.51, train corr: -0.01595
Epoch [48/100], Batch [98/147] train loss: 563.86, train corr: -0.01523
Epoch [48/100], Batch [99/147] train loss: 590.89, train corr: -0.00999
Epoch [48/100], Batch [100/147] train loss: 579.13, train corr: -0.01463
Epoch [48/100], Batch [101/147] train loss: 578.81, train corr: -0.01017
Epoch [48/100], Batch [102/147] train loss: 563.38, train corr: -0.01597
Epoch [48/100], Batch [103/147] train loss: 556.61, train corr: -0.01769
Epoch [48/100], Batch [104/147] train loss: 563.76, train corr: -0.01639
Epoch [48/100], Batch [105/147] train loss: 572.12, train corr: -0.01040
Epoch [48/100], Batch [106/147] train loss: 579.45, train corr: -0.01210
Epoch [48/100], Batch [107/147] train loss: 593.40, train corr: -0.00753
Epoch [48/100], Batch [108/147] train loss: 560.74, train corr: -0.01836
Epoch [48/100], Batch [109/147] train loss: 567.66, train corr: -0.01792
Epoch [48/100], Batch [110/147] train loss: 554.50, train corr: -0.01718
Epoch [48/100], Batch [111/147] train loss: 561.36, train corr: -0.01767
Epoch [48/100], Batch [112/147] train loss: 562.45, train corr: -0.01863
Epoch [48/100], Batch [113/147] train loss: 565.29, train corr: -0.01799
Epoch [48/100], Batch [114/147] train loss: 563.11, train corr: -0.01575
Epoch [48/100], Batch [115/147] train loss: 559.65, train corr: -0.01666
Epoch [48/100], Batch [116/147] train loss: 580.54, train corr: -0.01173
Epoch [48/100], Batch [117/147] train loss: 559.37, train corr: -0.01946
Epoch [48/100], Batch [118/147] train loss: 557.18, train corr: -0.01795
Epoch [48/100], Batch [119/147] train loss: 552.89, train corr: -0.01900
Epoch [48/100], Batch [120/147] train loss: 570.74, train corr: -0.01565
Epoch [48/100], Batch [121/147] train loss: 572.89, train corr: -0.01400
Epoch [48/100], Batch [122/147] train loss: 564.85, train corr: -0.01583
Epoch [48/100], Batch [123/147] train loss: 562.76, train corr: -0.01630
Epoch [48/100], Batch [124/147] train loss: 564.95, train corr: -0.01639
Epoch [48/100], Batch [125/147] train loss: 556.93, train corr: -0.01922
Epoch [48/100], Batch [126/147] train loss: 587.83, train corr: -0.01299
Epoch [48/100], Batch [127/147] train loss: 561.51, train corr: -0.01347
Epoch [48/100], Batch [128/147] train loss: 581.92, train corr: -0.00405
Epoch [48/100], Batch [129/147] train loss: 573.45, train corr: -0.01357
Epoch [48/100], Batch [130/147] train loss: 556.59, train corr: -0.01646
Epoch [48/100], Batch [131/147] train loss: 565.13, train corr: -0.01376
Epoch [48/100], Batch [132/147] train loss: 577.54, train corr: -0.00927
Epoch [48/100], Batch [133/147] train loss: 562.88, train corr: -0.01321
Epoch [48/100], Batch [134/147] train loss: 562.77, train corr: -0.00909
Epoch [48/100], Batch [135/147] train loss: 549.54, train corr: -0.01944
Epoch [48/100], Batch [136/147] train loss: 566.96, train corr: -0.01634
Epoch [48/100], Batch [137/147] train loss: 565.66, train corr: -0.01942
Epoch [48/100], Batch [138/147] train loss: 584.61, train corr: -0.01501
Epoch [48/100], Batch [139/147] train loss: 559.47, train corr: -0.01972
Epoch [48/100], Batch [140/147] train loss: 561.68, train corr: -0.01679
Epoch [48/100], Batch [141/147] train loss: 551.30, train corr: -0.01950
Epoch [48/100], Batch [142/147] train loss: 571.16, train corr: -0.01198
Epoch [48/100], Batch [143/147] train loss: 573.82, train corr: -0.01486
Epoch [48/100], Batch [144/147] train loss: 576.56, train corr: -0.01305
Epoch [48/100], Batch [145/147] train loss: 563.50, train corr: -0.01528
Epoch [48/100], Batch [146/147] train loss: 819.85, train corr: -0.01260
Epoch [48/100], Batch [147/147] train loss: 560.80, train corr: -0.02351
Epoch [48/100], validation loss: 597.42, validation correlation: 0.00973
Epoch [49/100], Batch [1/147] train loss: 563.82, train corr: 0.01009
Epoch [49/100], Batch [2/147] train loss: 543.59, train corr: 0.03212
Epoch [49/100], Batch [3/147] train loss: 555.86, train corr: 0.03007
Epoch [49/100], Batch [4/147] train loss: 554.89, train corr: 0.03160
Epoch [49/100], Batch [5/147] train loss: 568.48, train corr: 0.03260
Epoch [49/100], Batch [6/147] train loss: 563.47, train corr: -0.01875
Epoch [49/100], Batch [7/147] train loss: 568.36, train corr: -0.01852
Epoch [49/100], Batch [8/147] train loss: 569.53, train corr: 0.02488
Epoch [49/100], Batch [9/147] train loss: 576.38, train corr: 0.03346
Epoch [49/100], Batch [10/147] train loss: 568.74, train corr: 0.03340
Epoch [49/100], Batch [11/147] train loss: 574.96, train corr: 0.01298
Epoch [49/100], Batch [12/147] train loss: 577.14, train corr: -0.01932
Epoch [49/100], Batch [13/147] train loss: 558.75, train corr: -0.02476
Epoch [49/100], Batch [14/147] train loss: 578.42, train corr: -0.01875
Epoch [49/100], Batch [15/147] train loss: 554.18, train corr: 0.02865
Epoch [49/100], Batch [16/147] train loss: 570.56, train corr: 0.02839
Epoch [49/100], Batch [17/147] train loss: 579.14, train corr: 0.02606
Epoch [49/100], Batch [18/147] train loss: 574.03, train corr: -0.02081
Epoch [49/100], Batch [19/147] train loss: 568.33, train corr: -0.02707
Epoch [49/100], Batch [20/147] train loss: 550.98, train corr: -0.02220
Epoch [49/100], Batch [21/147] train loss: 569.49, train corr: 0.01363
Epoch [49/100], Batch [22/147] train loss: 563.83, train corr: 0.02729
Epoch [49/100], Batch [23/147] train loss: 558.56, train corr: -0.00117
Epoch [49/100], Batch [24/147] train loss: 564.17, train corr: -0.02207
Epoch [49/100], Batch [25/147] train loss: 570.30, train corr: -0.01886
Epoch [49/100], Batch [26/147] train loss: 555.38, train corr: -0.01525
Epoch [49/100], Batch [27/147] train loss: 551.85, train corr: 0.02298
Epoch [49/100], Batch [28/147] train loss: 582.78, train corr: 0.03187
Epoch [49/100], Batch [29/147] train loss: 568.14, train corr: 0.01579
Epoch [49/100], Batch [30/147] train loss: 579.02, train corr: -0.01377
Epoch [49/100], Batch [31/147] train loss: 565.17, train corr: -0.01774
Epoch [49/100], Batch [32/147] train loss: 561.97, train corr: -0.01857
Epoch [49/100], Batch [33/147] train loss: 572.26, train corr: -0.00618
Epoch [49/100], Batch [34/147] train loss: 555.70, train corr: 0.00334
Epoch [49/100], Batch [35/147] train loss: 577.50, train corr: -0.01114
Epoch [49/100], Batch [36/147] train loss: 556.41, train corr: -0.02155
Epoch [49/100], Batch [37/147] train loss: 571.22, train corr: -0.01759
Epoch [49/100], Batch [38/147] train loss: 566.46, train corr: -0.01474
Epoch [49/100], Batch [39/147] train loss: 558.66, train corr: -0.00266
Epoch [49/100], Batch [40/147] train loss: 574.28, train corr: 0.01572
Epoch [49/100], Batch [41/147] train loss: 568.32, train corr: -0.00671
Epoch [49/100], Batch [42/147] train loss: 568.82, train corr: -0.01496
Epoch [49/100], Batch [43/147] train loss: 557.11, train corr: -0.02240
Epoch [49/100], Batch [44/147] train loss: 555.56, train corr: -0.01800
Epoch [49/100], Batch [45/147] train loss: 568.59, train corr: -0.01431
Epoch [49/100], Batch [46/147] train loss: 578.73, train corr: -0.01029
Epoch [49/100], Batch [47/147] train loss: 561.73, train corr: -0.01563
Epoch [49/100], Batch [48/147] train loss: 597.32, train corr: -0.01029
Epoch [49/100], Batch [49/147] train loss: 579.54, train corr: -0.01916
Epoch [49/100], Batch [50/147] train loss: 563.45, train corr: -0.01785
Epoch [49/100], Batch [51/147] train loss: 562.30, train corr: -0.01361
Epoch [49/100], Batch [52/147] train loss: 548.12, train corr: -0.01373
Epoch [49/100], Batch [53/147] train loss: 564.34, train corr: -0.01731
Epoch [49/100], Batch [54/147] train loss: 577.45, train corr: -0.01880
Epoch [49/100], Batch [55/147] train loss: 571.19, train corr: -0.01787
Epoch [49/100], Batch [56/147] train loss: 554.88, train corr: -0.01735
Epoch [49/100], Batch [57/147] train loss: 565.92, train corr: -0.01697
Epoch [49/100], Batch [58/147] train loss: 582.98, train corr: -0.00709
Epoch [49/100], Batch [59/147] train loss: 576.98, train corr: -0.01301
Epoch [49/100], Batch [60/147] train loss: 580.89, train corr: -0.01566
Epoch [49/100], Batch [61/147] train loss: 572.76, train corr: -0.01653
Epoch [49/100], Batch [62/147] train loss: 568.37, train corr: -0.01407
Epoch [49/100], Batch [63/147] train loss: 551.37, train corr: -0.01242
Epoch [49/100], Batch [64/147] train loss: 558.24, train corr: -0.01286
Epoch [49/100], Batch [65/147] train loss: 548.68, train corr: -0.01720
Epoch [49/100], Batch [66/147] train loss: 565.54, train corr: -0.01590
Epoch [49/100], Batch [67/147] train loss: 807.47, train corr: -0.01332
Epoch [49/100], Batch [68/147] train loss: 573.00, train corr: -0.02260
Epoch [49/100], Batch [69/147] train loss: 564.44, train corr: 0.03086
Epoch [49/100], Batch [70/147] train loss: 586.18, train corr: 0.02925
Epoch [49/100], Batch [71/147] train loss: 575.60, train corr: 0.02802
Epoch [49/100], Batch [72/147] train loss: 564.35, train corr: 0.03311
Epoch [49/100], Batch [73/147] train loss: 579.35, train corr: 0.02510
Epoch [49/100], Batch [74/147] train loss: 571.64, train corr: -0.02054
Epoch [49/100], Batch [75/147] train loss: 555.94, train corr: -0.00697
Epoch [49/100], Batch [76/147] train loss: 575.23, train corr: 0.03188
Epoch [49/100], Batch [77/147] train loss: 577.51, train corr: 0.03164
Epoch [49/100], Batch [78/147] train loss: 579.83, train corr: 0.03295
Epoch [49/100], Batch [79/147] train loss: 584.67, train corr: -0.01646
Epoch [49/100], Batch [80/147] train loss: 555.40, train corr: -0.02350
Epoch [49/100], Batch [81/147] train loss: 560.04, train corr: -0.02501
Epoch [49/100], Batch [82/147] train loss: 592.23, train corr: 0.02429
Epoch [49/100], Batch [83/147] train loss: 565.67, train corr: 0.02695
Epoch [49/100], Batch [84/147] train loss: 572.40, train corr: 0.02405
Epoch [49/100], Batch [85/147] train loss: 561.76, train corr: -0.02866
Epoch [49/100], Batch [86/147] train loss: 568.93, train corr: -0.02310
Epoch [49/100], Batch [87/147] train loss: 566.44, train corr: -0.02603
Epoch [49/100], Batch [88/147] train loss: 560.35, train corr: -0.00013
Epoch [49/100], Batch [89/147] train loss: 559.55, train corr: 0.02995
Epoch [49/100], Batch [90/147] train loss: 570.92, train corr: 0.01312
Epoch [49/100], Batch [91/147] train loss: 568.16, train corr: -0.01519
Epoch [49/100], Batch [92/147] train loss: 570.88, train corr: -0.01750
Epoch [49/100], Batch [93/147] train loss: 556.65, train corr: -0.01796
Epoch [49/100], Batch [94/147] train loss: 574.63, train corr: 0.00758
Epoch [49/100], Batch [95/147] train loss: 558.89, train corr: 0.02750
Epoch [49/100], Batch [96/147] train loss: 630.07, train corr: 0.00647
Epoch [49/100], Batch [97/147] train loss: 745.19, train corr: -0.01817
Epoch [49/100], Batch [98/147] train loss: 561.71, train corr: -0.02583
Epoch [49/100], Batch [99/147] train loss: 568.31, train corr: 0.02687
Epoch [49/100], Batch [100/147] train loss: 581.46, train corr: 0.02480
Epoch [49/100], Batch [101/147] train loss: 569.42, train corr: 0.02765
Epoch [49/100], Batch [102/147] train loss: 605.72, train corr: 0.02489
Epoch [49/100], Batch [103/147] train loss: 582.61, train corr: 0.02421
Epoch [49/100], Batch [104/147] train loss: 595.68, train corr: 0.02432
Epoch [49/100], Batch [105/147] train loss: 572.07, train corr: 0.02647
Epoch [49/100], Batch [106/147] train loss: 574.47, train corr: 0.02600
Epoch [49/100], Batch [107/147] train loss: 581.87, train corr: 0.03256
Epoch [49/100], Batch [108/147] train loss: 578.76, train corr: -0.02108
Epoch [49/100], Batch [109/147] train loss: 563.38, train corr: 0.03397
Epoch [49/100], Batch [110/147] train loss: 575.23, train corr: 0.03239
Epoch [49/100], Batch [111/147] train loss: 581.93, train corr: 0.02959
Epoch [49/100], Batch [112/147] train loss: 593.89, train corr: 0.02616
Epoch [49/100], Batch [113/147] train loss: 558.19, train corr: 0.03018
Epoch [49/100], Batch [114/147] train loss: 639.61, train corr: 0.02390
Epoch [49/100], Batch [115/147] train loss: 574.84, train corr: -0.00758
Epoch [49/100], Batch [116/147] train loss: 585.17, train corr: -0.02543
Epoch [49/100], Batch [117/147] train loss: 565.34, train corr: 0.02697
Epoch [49/100], Batch [118/147] train loss: 569.81, train corr: 0.02913
Epoch [49/100], Batch [119/147] train loss: 597.62, train corr: 0.02415
Epoch [49/100], Batch [120/147] train loss: 604.13, train corr: 0.02735
Epoch [49/100], Batch [121/147] train loss: 594.55, train corr: 0.02658
Epoch [49/100], Batch [122/147] train loss: 593.90, train corr: 0.02733
Epoch [49/100], Batch [123/147] train loss: 598.63, train corr: 0.02770
Epoch [49/100], Batch [124/147] train loss: 591.83, train corr: 0.02796
Epoch [49/100], Batch [125/147] train loss: 591.10, train corr: 0.02803
Epoch [49/100], Batch [126/147] train loss: 581.99, train corr: 0.02963
Epoch [49/100], Batch [127/147] train loss: 593.02, train corr: 0.02593
Epoch [49/100], Batch [128/147] train loss: 587.46, train corr: 0.02764
Epoch [49/100], Batch [129/147] train loss: 590.56, train corr: 0.02607
Epoch [49/100], Batch [130/147] train loss: 573.38, train corr: 0.03428
Epoch [49/100], Batch [131/147] train loss: 582.66, train corr: -0.01494
Epoch [49/100], Batch [132/147] train loss: 560.12, train corr: 0.02531
Epoch [49/100], Batch [133/147] train loss: 565.15, train corr: 0.03393
Epoch [49/100], Batch [134/147] train loss: 577.43, train corr: 0.03088
Epoch [49/100], Batch [135/147] train loss: 600.81, train corr: 0.02711
Epoch [49/100], Batch [136/147] train loss: 676.97, train corr: 0.02572
Epoch [49/100], Batch [137/147] train loss: 561.90, train corr: 0.02890
Epoch [49/100], Batch [138/147] train loss: 595.44, train corr: -0.02668
Epoch [49/100], Batch [139/147] train loss: 581.67, train corr: 0.02445
Epoch [49/100], Batch [140/147] train loss: 596.19, train corr: 0.02248
Epoch [49/100], Batch [141/147] train loss: 597.76, train corr: 0.02640
Epoch [49/100], Batch [142/147] train loss: 600.28, train corr: 0.02567
Epoch [49/100], Batch [143/147] train loss: 614.30, train corr: 0.02694
Epoch [49/100], Batch [144/147] train loss: 600.77, train corr: 0.02603
Epoch [49/100], Batch [145/147] train loss: 615.61, train corr: 0.02399
Epoch [49/100], Batch [146/147] train loss: 610.16, train corr: 0.02770
Epoch [49/100], Batch [147/147] train loss: 618.20, train corr: 0.02487
Epoch [49/100], validation loss: 636.55, validation correlation: 0.02699
Epoch [50/100], Batch [1/147] train loss: 618.89, train corr: 0.02457
Epoch [50/100], Batch [2/147] train loss: 616.22, train corr: 0.02722
Epoch [50/100], Batch [3/147] train loss: 580.68, train corr: 0.02897
Epoch [50/100], Batch [4/147] train loss: 586.24, train corr: 0.02839
Epoch [50/100], Batch [5/147] train loss: 585.40, train corr: 0.02724
Epoch [50/100], Batch [6/147] train loss: 591.12, train corr: 0.03137
Epoch [50/100], Batch [7/147] train loss: 557.44, train corr: 0.03395
Epoch [50/100], Batch [8/147] train loss: 587.17, train corr: -0.01648
Epoch [50/100], Batch [9/147] train loss: 567.69, train corr: 0.03357
Epoch [50/100], Batch [10/147] train loss: 561.60, train corr: 0.03056
Epoch [50/100], Batch [11/147] train loss: 571.44, train corr: 0.02893
Epoch [50/100], Batch [12/147] train loss: 574.52, train corr: 0.02991
Epoch [50/100], Batch [13/147] train loss: 581.00, train corr: 0.02766
Epoch [50/100], Batch [14/147] train loss: 572.53, train corr: 0.02295
Epoch [50/100], Batch [15/147] train loss: 573.10, train corr: 0.02358
Epoch [50/100], Batch [16/147] train loss: 579.69, train corr: -0.02637
Epoch [50/100], Batch [17/147] train loss: 565.94, train corr: 0.02181
Epoch [50/100], Batch [18/147] train loss: 556.65, train corr: 0.02721
Epoch [50/100], Batch [19/147] train loss: 570.86, train corr: 0.02237
Epoch [50/100], Batch [20/147] train loss: 571.22, train corr: 0.03105
Epoch [50/100], Batch [21/147] train loss: 556.89, train corr: 0.03204
Epoch [50/100], Batch [22/147] train loss: 633.99, train corr: 0.02537
Epoch [50/100], Batch [23/147] train loss: 565.01, train corr: -0.01582
Epoch [50/100], Batch [24/147] train loss: 579.71, train corr: -0.01466
Epoch [50/100], Batch [25/147] train loss: 626.63, train corr: 0.02416
Epoch [50/100], Batch [26/147] train loss: 568.39, train corr: 0.02726
Epoch [50/100], Batch [27/147] train loss: 820.81, train corr: 0.02329
Epoch [50/100], Batch [28/147] train loss: 582.69, train corr: 0.00344
Epoch [50/100], Batch [29/147] train loss: 582.56, train corr: -0.01895
Epoch [50/100], Batch [30/147] train loss: 566.03, train corr: 0.02902
Epoch [50/100], Batch [31/147] train loss: 577.46, train corr: 0.02592
Epoch [50/100], Batch [32/147] train loss: 580.01, train corr: 0.02812
Epoch [50/100], Batch [33/147] train loss: 587.35, train corr: 0.02795
Epoch [50/100], Batch [34/147] train loss: 585.84, train corr: 0.02873
Epoch [50/100], Batch [35/147] train loss: 580.10, train corr: 0.02641
Epoch [50/100], Batch [36/147] train loss: 557.17, train corr: 0.02740
Epoch [50/100], Batch [37/147] train loss: 587.15, train corr: 0.02692
Epoch [50/100], Batch [38/147] train loss: 573.78, train corr: -0.01906
Epoch [50/100], Batch [39/147] train loss: 586.71, train corr: -0.01151
Epoch [50/100], Batch [40/147] train loss: 550.79, train corr: 0.03344
Epoch [50/100], Batch [41/147] train loss: 571.91, train corr: 0.03228
Epoch [50/100], Batch [42/147] train loss: 552.79, train corr: 0.03345
Epoch [50/100], Batch [43/147] train loss: 572.74, train corr: 0.01962
Epoch [50/100], Batch [44/147] train loss: 569.14, train corr: -0.02132
Epoch [50/100], Batch [45/147] train loss: 580.60, train corr: -0.02044
Epoch [50/100], Batch [46/147] train loss: 589.74, train corr: 0.01480
Epoch [50/100], Batch [47/147] train loss: 559.74, train corr: 0.03009
Epoch [50/100], Batch [48/147] train loss: 564.21, train corr: 0.02584
Epoch [50/100], Batch [49/147] train loss: 574.83, train corr: 0.02744
Epoch [50/100], Batch [50/147] train loss: 562.10, train corr: 0.02759
Epoch [50/100], Batch [51/147] train loss: 566.05, train corr: -0.01633
Epoch [50/100], Batch [52/147] train loss: 567.65, train corr: 0.00108
Epoch [50/100], Batch [53/147] train loss: 579.46, train corr: 0.03100
Epoch [50/100], Batch [54/147] train loss: 565.28, train corr: 0.03309
Epoch [50/100], Batch [55/147] train loss: 564.70, train corr: 0.02621
Epoch [50/100], Batch [56/147] train loss: 561.81, train corr: -0.01556
Epoch [50/100], Batch [57/147] train loss: 571.59, train corr: -0.02169
Epoch [50/100], Batch [58/147] train loss: 559.52, train corr: -0.02246
Epoch [50/100], Batch [59/147] train loss: 575.04, train corr: -0.00724
Epoch [50/100], Batch [60/147] train loss: 582.93, train corr: 0.02613
Epoch [50/100], Batch [61/147] train loss: 555.71, train corr: 0.03173
Epoch [50/100], Batch [62/147] train loss: 571.56, train corr: 0.00910
Epoch [50/100], Batch [63/147] train loss: 567.72, train corr: -0.01122
Epoch [50/100], Batch [64/147] train loss: 564.82, train corr: 0.00944
Epoch [50/100], Batch [65/147] train loss: 558.31, train corr: 0.03358
Epoch [50/100], Batch [66/147] train loss: 561.77, train corr: 0.03413
Epoch [50/100], Batch [67/147] train loss: 575.26, train corr: 0.02869
Epoch [50/100], Batch [68/147] train loss: 571.28, train corr: -0.00824
Epoch [50/100], Batch [69/147] train loss: 575.11, train corr: -0.01648
Epoch [50/100], Batch [70/147] train loss: 555.42, train corr: -0.02124
Epoch [50/100], Batch [71/147] train loss: 566.92, train corr: -0.01683
Epoch [50/100], Batch [72/147] train loss: 557.55, train corr: -0.01022
Epoch [50/100], Batch [73/147] train loss: 568.89, train corr: -0.01011
Epoch [50/100], Batch [74/147] train loss: 553.79, train corr: -0.02238
Epoch [50/100], Batch [75/147] train loss: 567.69, train corr: -0.02210
Epoch [50/100], Batch [76/147] train loss: 574.38, train corr: -0.02116
Epoch [50/100], Batch [77/147] train loss: 576.96, train corr: 0.01294
Epoch [50/100], Batch [78/147] train loss: 565.31, train corr: 0.03220
Epoch [50/100], Batch [79/147] train loss: 572.29, train corr: 0.03129
Epoch [50/100], Batch [80/147] train loss: 574.58, train corr: -0.01101
Epoch [50/100], Batch [81/147] train loss: 562.27, train corr: -0.01490
Epoch [50/100], Batch [82/147] train loss: 561.33, train corr: -0.01872
Epoch [50/100], Batch [83/147] train loss: 581.01, train corr: -0.01038
Epoch [50/100], Batch [84/147] train loss: 567.34, train corr: -0.00943
Epoch [50/100], Batch [85/147] train loss: 561.13, train corr: -0.00513
Epoch [50/100], Batch [86/147] train loss: 570.64, train corr: -0.01397
Epoch [50/100], Batch [87/147] train loss: 560.67, train corr: -0.02152
Epoch [50/100], Batch [88/147] train loss: 567.20, train corr: -0.01740
Epoch [50/100], Batch [89/147] train loss: 559.30, train corr: -0.01248
Epoch [50/100], Batch [90/147] train loss: 570.87, train corr: -0.00072
Epoch [50/100], Batch [91/147] train loss: 570.33, train corr: 0.00014
Epoch [50/100], Batch [92/147] train loss: 577.87, train corr: -0.00913
Epoch [50/100], Batch [93/147] train loss: 572.82, train corr: -0.01702
Epoch [50/100], Batch [94/147] train loss: 554.66, train corr: -0.01620
Epoch [50/100], Batch [95/147] train loss: 578.94, train corr: -0.01042
Epoch [50/100], Batch [96/147] train loss: 570.39, train corr: -0.00797
Epoch [50/100], Batch [97/147] train loss: 536.70, train corr: -0.01662
Epoch [50/100], Batch [98/147] train loss: 568.57, train corr: -0.01353
Epoch [50/100], Batch [99/147] train loss: 558.98, train corr: -0.01381
Epoch [50/100], Batch [100/147] train loss: 569.78, train corr: -0.01232
Epoch [50/100], Batch [101/147] train loss: 557.61, train corr: -0.01219
Epoch [50/100], Batch [102/147] train loss: 581.84, train corr: -0.01040
Epoch [50/100], Batch [103/147] train loss: 619.60, train corr: -0.01581
Epoch [50/100], Batch [104/147] train loss: 565.99, train corr: -0.02096
Epoch [50/100], Batch [105/147] train loss: 547.51, train corr: -0.01757
Epoch [50/100], Batch [106/147] train loss: 571.12, train corr: -0.01535
Epoch [50/100], Batch [107/147] train loss: 559.14, train corr: -0.01718
Epoch [50/100], Batch [108/147] train loss: 564.02, train corr: -0.01907
Epoch [50/100], Batch [109/147] train loss: 566.07, train corr: -0.01425
Epoch [50/100], Batch [110/147] train loss: 567.19, train corr: -0.01465
Epoch [50/100], Batch [111/147] train loss: 558.86, train corr: -0.01891
Epoch [50/100], Batch [112/147] train loss: 574.29, train corr: -0.01761
Epoch [50/100], Batch [113/147] train loss: 567.72, train corr: -0.01743
Epoch [50/100], Batch [114/147] train loss: 570.16, train corr: -0.01637
Epoch [50/100], Batch [115/147] train loss: 574.55, train corr: -0.01072
Epoch [50/100], Batch [116/147] train loss: 565.45, train corr: -0.01308
Epoch [50/100], Batch [117/147] train loss: 578.41, train corr: -0.01156
Epoch [50/100], Batch [118/147] train loss: 582.00, train corr: -0.01511
Epoch [50/100], Batch [119/147] train loss: 575.09, train corr: -0.01261
Epoch [50/100], Batch [120/147] train loss: 569.44, train corr: -0.01433
Epoch [50/100], Batch [121/147] train loss: 567.95, train corr: -0.01011
Epoch [50/100], Batch [122/147] train loss: 566.20, train corr: -0.01462
Epoch [50/100], Batch [123/147] train loss: 601.97, train corr: -0.00404
Epoch [50/100], Batch [124/147] train loss: 567.26, train corr: -0.01198
Epoch [50/100], Batch [125/147] train loss: 553.08, train corr: -0.01440
Epoch [50/100], Batch [126/147] train loss: 570.53, train corr: -0.00998
Epoch [50/100], Batch [127/147] train loss: 573.59, train corr: -0.00896
Epoch [50/100], Batch [128/147] train loss: 567.13, train corr: -0.01694
Epoch [50/100], Batch [129/147] train loss: 583.17, train corr: -0.01136
Epoch [50/100], Batch [130/147] train loss: 561.23, train corr: -0.01973
Epoch [50/100], Batch [131/147] train loss: 560.21, train corr: -0.01779
Epoch [50/100], Batch [132/147] train loss: 569.13, train corr: -0.01787
Epoch [50/100], Batch [133/147] train loss: 553.69, train corr: -0.01911
Epoch [50/100], Batch [134/147] train loss: 550.45, train corr: -0.02020
Epoch [50/100], Batch [135/147] train loss: 553.70, train corr: -0.01988
Epoch [50/100], Batch [136/147] train loss: 584.49, train corr: -0.00995
Epoch [50/100], Batch [137/147] train loss: 574.25, train corr: -0.01065
Epoch [50/100], Batch [138/147] train loss: 552.62, train corr: -0.01767
Epoch [50/100], Batch [139/147] train loss: 559.73, train corr: -0.01430
Epoch [50/100], Batch [140/147] train loss: 583.86, train corr: -0.01135
Epoch [50/100], Batch [141/147] train loss: 579.32, train corr: -0.01242
Epoch [50/100], Batch [142/147] train loss: 740.92, train corr: -0.01764
Epoch [50/100], Batch [143/147] train loss: 575.91, train corr: -0.02508
Epoch [50/100], Batch [144/147] train loss: 574.74, train corr: 0.03010
Epoch [50/100], Batch [145/147] train loss: 585.42, train corr: 0.02568
Epoch [50/100], Batch [146/147] train loss: 575.09, train corr: 0.02370
Epoch [50/100], Batch [147/147] train loss: 567.60, train corr: 0.02684
Epoch [50/100], validation loss: 605.47, validation correlation: 0.02783
Epoch [51/100], Batch [1/147] train loss: 576.97, train corr: 0.02655
Epoch [51/100], Batch [2/147] train loss: 585.31, train corr: 0.02501
Epoch [51/100], Batch [3/147] train loss: 578.75, train corr: 0.02763
Epoch [51/100], Batch [4/147] train loss: 586.04, train corr: 0.00512
Epoch [51/100], Batch [5/147] train loss: 568.04, train corr: -0.02396
Epoch [51/100], Batch [6/147] train loss: 588.62, train corr: 0.02945
Epoch [51/100], Batch [7/147] train loss: 558.11, train corr: 0.03002
Epoch [51/100], Batch [8/147] train loss: 568.51, train corr: 0.02864
Epoch [51/100], Batch [9/147] train loss: 574.21, train corr: 0.02595
Epoch [51/100], Batch [10/147] train loss: 560.55, train corr: 0.02809
Epoch [51/100], Batch [11/147] train loss: 564.05, train corr: 0.02961
Epoch [51/100], Batch [12/147] train loss: 563.47, train corr: 0.03045
Epoch [51/100], Batch [13/147] train loss: 579.35, train corr: -0.02745
Epoch [51/100], Batch [14/147] train loss: 582.49, train corr: 0.02891
Epoch [51/100], Batch [15/147] train loss: 582.64, train corr: 0.02514
Epoch [51/100], Batch [16/147] train loss: 641.96, train corr: 0.02522
Epoch [51/100], Batch [17/147] train loss: 588.91, train corr: 0.02523
Epoch [51/100], Batch [18/147] train loss: 591.85, train corr: 0.01996
Epoch [51/100], Batch [19/147] train loss: 566.26, train corr: 0.02831
Epoch [51/100], Batch [20/147] train loss: 579.73, train corr: 0.02732
Epoch [51/100], Batch [21/147] train loss: 564.92, train corr: 0.02798
Epoch [51/100], Batch [22/147] train loss: 577.18, train corr: 0.02814
Epoch [51/100], Batch [23/147] train loss: 577.40, train corr: 0.03373
Epoch [51/100], Batch [24/147] train loss: 568.51, train corr: -0.02130
Epoch [51/100], Batch [25/147] train loss: 582.90, train corr: 0.03219
Epoch [51/100], Batch [26/147] train loss: 573.45, train corr: 0.02598
Epoch [51/100], Batch [27/147] train loss: 585.08, train corr: 0.02978
Epoch [51/100], Batch [28/147] train loss: 579.51, train corr: 0.03002
Epoch [51/100], Batch [29/147] train loss: 577.31, train corr: 0.02799
Epoch [51/100], Batch [30/147] train loss: 580.48, train corr: 0.03045
Epoch [51/100], Batch [31/147] train loss: 577.25, train corr: -0.02004
Epoch [51/100], Batch [32/147] train loss: 578.74, train corr: -0.02582
Epoch [51/100], Batch [33/147] train loss: 581.94, train corr: 0.02496
Epoch [51/100], Batch [34/147] train loss: 577.65, train corr: 0.02798
Epoch [51/100], Batch [35/147] train loss: 614.94, train corr: 0.02743
Epoch [51/100], Batch [36/147] train loss: 593.42, train corr: 0.02621
Epoch [51/100], Batch [37/147] train loss: 618.26, train corr: 0.02669
Epoch [51/100], Batch [38/147] train loss: 611.12, train corr: 0.03106
Epoch [51/100], Batch [39/147] train loss: 624.30, train corr: 0.02571
Epoch [51/100], Batch [40/147] train loss: 608.40, train corr: 0.02311
Epoch [51/100], Batch [41/147] train loss: 582.40, train corr: 0.02917
Epoch [51/100], Batch [42/147] train loss: 603.72, train corr: 0.02269
Epoch [51/100], Batch [43/147] train loss: 597.59, train corr: 0.02662
Epoch [51/100], Batch [44/147] train loss: 588.30, train corr: 0.02347
Epoch [51/100], Batch [45/147] train loss: 603.01, train corr: 0.02274
Epoch [51/100], Batch [46/147] train loss: 665.90, train corr: 0.02680
Epoch [51/100], Batch [47/147] train loss: 589.78, train corr: 0.02991
Epoch [51/100], Batch [48/147] train loss: 588.56, train corr: -0.00401
Epoch [51/100], Batch [49/147] train loss: 591.94, train corr: -0.01373
Epoch [51/100], Batch [50/147] train loss: 596.81, train corr: 0.02975
Epoch [51/100], Batch [51/147] train loss: 602.85, train corr: 0.02644
Epoch [51/100], Batch [52/147] train loss: 606.07, train corr: 0.02755
Epoch [51/100], Batch [53/147] train loss: 597.72, train corr: 0.02868
Epoch [51/100], Batch [54/147] train loss: 612.21, train corr: 0.02508
Epoch [51/100], Batch [55/147] train loss: 620.76, train corr: 0.02476
Epoch [51/100], Batch [56/147] train loss: 591.74, train corr: 0.02784
Epoch [51/100], Batch [57/147] train loss: 599.80, train corr: 0.02595
Epoch [51/100], Batch [58/147] train loss: 566.82, train corr: 0.02852
Epoch [51/100], Batch [59/147] train loss: 607.85, train corr: 0.02768
Epoch [51/100], Batch [60/147] train loss: 591.40, train corr: 0.02939
Epoch [51/100], Batch [61/147] train loss: 577.68, train corr: 0.02679
Epoch [51/100], Batch [62/147] train loss: 828.59, train corr: 0.02685
Epoch [51/100], Batch [63/147] train loss: 570.03, train corr: 0.00977
Epoch [51/100], Batch [64/147] train loss: 630.34, train corr: -0.02119
Epoch [51/100], Batch [65/147] train loss: 601.29, train corr: 0.02777
Epoch [51/100], Batch [66/147] train loss: 645.98, train corr: 0.02634
Epoch [51/100], Batch [67/147] train loss: 681.13, train corr: 0.02330
Epoch [51/100], Batch [68/147] train loss: 672.72, train corr: 0.03023
Epoch [51/100], Batch [69/147] train loss: 704.29, train corr: 0.02476
Epoch [51/100], Batch [70/147] train loss: 711.71, train corr: 0.02659
Epoch [51/100], Batch [71/147] train loss: 722.83, train corr: 0.02537
Epoch [51/100], Batch [72/147] train loss: 703.05, train corr: 0.02788
Epoch [51/100], Batch [73/147] train loss: 728.46, train corr: 0.02353
Epoch [51/100], Batch [74/147] train loss: 703.35, train corr: 0.02809
Epoch [51/100], Batch [75/147] train loss: 666.61, train corr: 0.02844
Epoch [51/100], Batch [76/147] train loss: 662.59, train corr: 0.02969
Epoch [51/100], Batch [77/147] train loss: 705.11, train corr: 0.02420
Epoch [51/100], Batch [78/147] train loss: 699.78, train corr: 0.02032
Epoch [51/100], Batch [79/147] train loss: 688.44, train corr: 0.02414
Epoch [51/100], Batch [80/147] train loss: 675.15, train corr: 0.02318
Epoch [51/100], Batch [81/147] train loss: 672.54, train corr: 0.02461
Epoch [51/100], Batch [82/147] train loss: 664.66, train corr: 0.02803
Epoch [51/100], Batch [83/147] train loss: 649.82, train corr: 0.02944
Epoch [51/100], Batch [84/147] train loss: 665.05, train corr: 0.02344
Epoch [51/100], Batch [85/147] train loss: 650.52, train corr: 0.02783
Epoch [51/100], Batch [86/147] train loss: 618.07, train corr: 0.02849
Epoch [51/100], Batch [87/147] train loss: 608.96, train corr: 0.02951
Epoch [51/100], Batch [88/147] train loss: 601.75, train corr: 0.02878
Epoch [51/100], Batch [89/147] train loss: 584.81, train corr: 0.03229
Epoch [51/100], Batch [90/147] train loss: 590.77, train corr: 0.03145
Epoch [51/100], Batch [91/147] train loss: 583.12, train corr: 0.03110
Epoch [51/100], Batch [92/147] train loss: 554.20, train corr: -0.00232
Epoch [51/100], Batch [93/147] train loss: 665.67, train corr: -0.02825
Epoch [51/100], Batch [94/147] train loss: 634.14, train corr: 0.02326
Epoch [51/100], Batch [95/147] train loss: 698.75, train corr: 0.02646
Epoch [51/100], Batch [96/147] train loss: 734.81, train corr: 0.02453
Epoch [51/100], Batch [97/147] train loss: 740.41, train corr: 0.02639
Epoch [51/100], Batch [98/147] train loss: 807.99, train corr: 0.02553
Epoch [51/100], Batch [99/147] train loss: 789.71, train corr: 0.02791
Epoch [51/100], Batch [100/147] train loss: 827.66, train corr: 0.02834
Epoch [51/100], Batch [101/147] train loss: 809.24, train corr: 0.02620
Epoch [51/100], Batch [102/147] train loss: 792.16, train corr: 0.02811
Epoch [51/100], Batch [103/147] train loss: 790.82, train corr: 0.03053
Epoch [51/100], Batch [104/147] train loss: 770.56, train corr: 0.02598
Epoch [51/100], Batch [105/147] train loss: 765.50, train corr: 0.02571
Epoch [51/100], Batch [106/147] train loss: 779.24, train corr: 0.02644
Epoch [51/100], Batch [107/147] train loss: 761.14, train corr: 0.02501
Epoch [51/100], Batch [108/147] train loss: 766.02, train corr: 0.02946
Epoch [51/100], Batch [109/147] train loss: 747.95, train corr: 0.02736
Epoch [51/100], Batch [110/147] train loss: 749.16, train corr: 0.02641
Epoch [51/100], Batch [111/147] train loss: 753.71, train corr: 0.02732
Epoch [51/100], Batch [112/147] train loss: 732.90, train corr: 0.02819
Epoch [51/100], Batch [113/147] train loss: 731.54, train corr: 0.02552
Epoch [51/100], Batch [114/147] train loss: 802.02, train corr: 0.02532
Epoch [51/100], Batch [115/147] train loss: 695.10, train corr: 0.02797
Epoch [51/100], Batch [116/147] train loss: 705.59, train corr: 0.02375
Epoch [51/100], Batch [117/147] train loss: 681.97, train corr: 0.02882
Epoch [51/100], Batch [118/147] train loss: 673.31, train corr: 0.02657
Epoch [51/100], Batch [119/147] train loss: 682.04, train corr: 0.02600
Epoch [51/100], Batch [120/147] train loss: 679.57, train corr: 0.02253
Epoch [51/100], Batch [121/147] train loss: 639.84, train corr: 0.02939
Epoch [51/100], Batch [122/147] train loss: 651.35, train corr: 0.02690
Epoch [51/100], Batch [123/147] train loss: 632.31, train corr: 0.02905
Epoch [51/100], Batch [124/147] train loss: 625.57, train corr: 0.02718
Epoch [51/100], Batch [125/147] train loss: 614.76, train corr: 0.02666
Epoch [51/100], Batch [126/147] train loss: 604.36, train corr: 0.02658
Epoch [51/100], Batch [127/147] train loss: 617.23, train corr: 0.02500
Epoch [51/100], Batch [128/147] train loss: 611.00, train corr: 0.02055
Epoch [51/100], Batch [129/147] train loss: 592.41, train corr: 0.02640
Epoch [51/100], Batch [130/147] train loss: 570.40, train corr: 0.02760
Epoch [51/100], Batch [131/147] train loss: 582.59, train corr: 0.02374
Epoch [51/100], Batch [132/147] train loss: 778.54, train corr: 0.00878
Epoch [51/100], Batch [133/147] train loss: 591.87, train corr: -0.03157
Epoch [51/100], Batch [134/147] train loss: 566.22, train corr: 0.01166
Epoch [51/100], Batch [135/147] train loss: 569.56, train corr: 0.01924
Epoch [51/100], Batch [136/147] train loss: 606.38, train corr: 0.01757
Epoch [51/100], Batch [137/147] train loss: 587.09, train corr: 0.02460
Epoch [51/100], Batch [138/147] train loss: 597.74, train corr: 0.02695
Epoch [51/100], Batch [139/147] train loss: 603.16, train corr: 0.02674
Epoch [51/100], Batch [140/147] train loss: 571.30, train corr: 0.02679
Epoch [51/100], Batch [141/147] train loss: 579.82, train corr: 0.02555
Epoch [51/100], Batch [142/147] train loss: 577.82, train corr: 0.02736
Epoch [51/100], Batch [143/147] train loss: 590.96, train corr: 0.02649
Epoch [51/100], Batch [144/147] train loss: 580.51, train corr: 0.02907
Epoch [51/100], Batch [145/147] train loss: 577.29, train corr: 0.02606
Epoch [51/100], Batch [146/147] train loss: 575.87, train corr: 0.02412
Epoch [51/100], Batch [147/147] train loss: 577.18, train corr: 0.02164
Epoch [51/100], validation loss: 603.49, validation correlation: 0.02020
Epoch [52/100], Batch [1/147] train loss: 582.31, train corr: 0.01903
Epoch [52/100], Batch [2/147] train loss: 559.64, train corr: 0.01599
Epoch [52/100], Batch [3/147] train loss: 573.76, train corr: -0.00131
Epoch [52/100], Batch [4/147] train loss: 585.74, train corr: -0.02531
Epoch [52/100], Batch [5/147] train loss: 572.60, train corr: -0.03099
Epoch [52/100], Batch [6/147] train loss: 572.55, train corr: -0.02898
Epoch [52/100], Batch [7/147] train loss: 581.64, train corr: -0.02740
Epoch [52/100], Batch [8/147] train loss: 570.77, train corr: -0.00874
Epoch [52/100], Batch [9/147] train loss: 588.55, train corr: 0.01452
Epoch [52/100], Batch [10/147] train loss: 557.80, train corr: 0.02503
Epoch [52/100], Batch [11/147] train loss: 571.66, train corr: 0.02186
Epoch [52/100], Batch [12/147] train loss: 591.61, train corr: 0.02517
Epoch [52/100], Batch [13/147] train loss: 562.45, train corr: 0.02722
Epoch [52/100], Batch [14/147] train loss: 565.65, train corr: 0.03089
Epoch [52/100], Batch [15/147] train loss: 578.50, train corr: 0.03168
Epoch [52/100], Batch [16/147] train loss: 643.99, train corr: 0.01363
Epoch [52/100], Batch [17/147] train loss: 562.13, train corr: -0.01634
Epoch [52/100], Batch [18/147] train loss: 576.02, train corr: -0.01757
Epoch [52/100], Batch [19/147] train loss: 577.35, train corr: 0.02957
Epoch [52/100], Batch [20/147] train loss: 558.40, train corr: 0.03286
Epoch [52/100], Batch [21/147] train loss: 550.06, train corr: 0.03069
Epoch [52/100], Batch [22/147] train loss: 569.78, train corr: 0.02644
Epoch [52/100], Batch [23/147] train loss: 564.17, train corr: -0.00636
Epoch [52/100], Batch [24/147] train loss: 571.47, train corr: -0.01357
Epoch [52/100], Batch [25/147] train loss: 557.50, train corr: 0.00635
Epoch [52/100], Batch [26/147] train loss: 568.02, train corr: 0.03090
Epoch [52/100], Batch [27/147] train loss: 563.61, train corr: 0.03101
Epoch [52/100], Batch [28/147] train loss: 566.43, train corr: 0.03033
Epoch [52/100], Batch [29/147] train loss: 575.79, train corr: 0.03167
Epoch [52/100], Batch [30/147] train loss: 571.31, train corr: 0.02854
Epoch [52/100], Batch [31/147] train loss: 571.55, train corr: -0.01008
Epoch [52/100], Batch [32/147] train loss: 551.15, train corr: -0.01932
Epoch [52/100], Batch [33/147] train loss: 578.08, train corr: 0.03178
Epoch [52/100], Batch [34/147] train loss: 579.02, train corr: 0.02420
Epoch [52/100], Batch [35/147] train loss: 554.20, train corr: 0.01930
Epoch [52/100], Batch [36/147] train loss: 566.02, train corr: 0.00817
Epoch [52/100], Batch [37/147] train loss: 582.62, train corr: -0.02417
Epoch [52/100], Batch [38/147] train loss: 573.55, train corr: -0.02948
Epoch [52/100], Batch [39/147] train loss: 571.36, train corr: -0.02443
Epoch [52/100], Batch [40/147] train loss: 580.32, train corr: -0.02279
Epoch [52/100], Batch [41/147] train loss: 568.63, train corr: -0.00039
Epoch [52/100], Batch [42/147] train loss: 572.47, train corr: 0.01166
Epoch [52/100], Batch [43/147] train loss: 567.10, train corr: 0.01433
Epoch [52/100], Batch [44/147] train loss: 563.40, train corr: -0.01423
Epoch [52/100], Batch [45/147] train loss: 559.57, train corr: -0.02154
Epoch [52/100], Batch [46/147] train loss: 572.71, train corr: -0.01415
Epoch [52/100], Batch [47/147] train loss: 559.99, train corr: 0.02682
Epoch [52/100], Batch [48/147] train loss: 570.56, train corr: 0.03204
Epoch [52/100], Batch [49/147] train loss: 591.06, train corr: 0.03032
Epoch [52/100], Batch [50/147] train loss: 565.62, train corr: 0.03001
Epoch [52/100], Batch [51/147] train loss: 562.89, train corr: -0.01081
Epoch [52/100], Batch [52/147] train loss: 557.78, train corr: -0.02144
Epoch [52/100], Batch [53/147] train loss: 571.87, train corr: -0.01842
Epoch [52/100], Batch [54/147] train loss: 575.15, train corr: -0.00407
Epoch [52/100], Batch [55/147] train loss: 567.43, train corr: 0.01459
Epoch [52/100], Batch [56/147] train loss: 554.65, train corr: 0.00962
Epoch [52/100], Batch [57/147] train loss: 552.82, train corr: -0.01106
Epoch [52/100], Batch [58/147] train loss: 563.84, train corr: -0.01889
Epoch [52/100], Batch [59/147] train loss: 561.79, train corr: -0.01772
Epoch [52/100], Batch [60/147] train loss: 556.41, train corr: -0.01708
Epoch [52/100], Batch [61/147] train loss: 567.53, train corr: 0.00546
Epoch [52/100], Batch [62/147] train loss: 572.69, train corr: 0.02709
Epoch [52/100], Batch [63/147] train loss: 567.82, train corr: 0.01457
Epoch [52/100], Batch [64/147] train loss: 564.74, train corr: -0.00998
Epoch [52/100], Batch [65/147] train loss: 556.14, train corr: -0.01895
Epoch [52/100], Batch [66/147] train loss: 738.36, train corr: -0.01832
Epoch [52/100], Batch [67/147] train loss: 561.92, train corr: -0.02321
Epoch [52/100], Batch [68/147] train loss: 569.24, train corr: -0.00622
Epoch [52/100], Batch [69/147] train loss: 598.33, train corr: 0.03089
Epoch [52/100], Batch [70/147] train loss: 580.59, train corr: 0.02984
Epoch [52/100], Batch [71/147] train loss: 577.22, train corr: 0.03048
Epoch [52/100], Batch [72/147] train loss: 560.62, train corr: 0.03206
Epoch [52/100], Batch [73/147] train loss: 570.21, train corr: 0.00682
Epoch [52/100], Batch [74/147] train loss: 574.43, train corr: -0.01899
Epoch [52/100], Batch [75/147] train loss: 570.78, train corr: -0.01795
Epoch [52/100], Batch [76/147] train loss: 577.83, train corr: 0.01587
Epoch [52/100], Batch [77/147] train loss: 585.21, train corr: 0.03121
Epoch [52/100], Batch [78/147] train loss: 566.17, train corr: 0.03423
Epoch [52/100], Batch [79/147] train loss: 563.64, train corr: 0.01141
Epoch [52/100], Batch [80/147] train loss: 572.80, train corr: -0.01688
Epoch [52/100], Batch [81/147] train loss: 587.05, train corr: -0.01746
Epoch [52/100], Batch [82/147] train loss: 556.68, train corr: -0.01653
Epoch [52/100], Batch [83/147] train loss: 576.71, train corr: 0.02966
Epoch [52/100], Batch [84/147] train loss: 562.24, train corr: 0.03379
Epoch [52/100], Batch [85/147] train loss: 592.31, train corr: 0.02820
Epoch [52/100], Batch [86/147] train loss: 560.81, train corr: 0.01469
Epoch [52/100], Batch [87/147] train loss: 566.25, train corr: -0.01821
Epoch [52/100], Batch [88/147] train loss: 565.36, train corr: -0.01964
Epoch [52/100], Batch [89/147] train loss: 554.23, train corr: -0.01060
Epoch [52/100], Batch [90/147] train loss: 571.34, train corr: 0.02015
Epoch [52/100], Batch [91/147] train loss: 595.54, train corr: 0.02942
Epoch [52/100], Batch [92/147] train loss: 584.73, train corr: 0.02110
Epoch [52/100], Batch [93/147] train loss: 554.63, train corr: -0.01537
Epoch [52/100], Batch [94/147] train loss: 553.19, train corr: -0.02228
Epoch [52/100], Batch [95/147] train loss: 579.55, train corr: -0.01639
Epoch [52/100], Batch [96/147] train loss: 556.35, train corr: -0.01916
Epoch [52/100], Batch [97/147] train loss: 561.76, train corr: -0.00227
Epoch [52/100], Batch [98/147] train loss: 566.87, train corr: 0.00924
Epoch [52/100], Batch [99/147] train loss: 560.82, train corr: -0.00907
Epoch [52/100], Batch [100/147] train loss: 563.97, train corr: -0.01682
Epoch [52/100], Batch [101/147] train loss: 558.88, train corr: -0.01728
Epoch [52/100], Batch [102/147] train loss: 562.56, train corr: -0.01761
Epoch [52/100], Batch [103/147] train loss: 565.05, train corr: -0.01343
Epoch [52/100], Batch [104/147] train loss: 558.48, train corr: -0.00658
Epoch [52/100], Batch [105/147] train loss: 568.24, train corr: -0.00487
Epoch [52/100], Batch [106/147] train loss: 578.57, train corr: -0.01013
Epoch [52/100], Batch [107/147] train loss: 579.66, train corr: -0.00977
Epoch [52/100], Batch [108/147] train loss: 572.62, train corr: -0.01764
Epoch [52/100], Batch [109/147] train loss: 559.39, train corr: -0.01393
Epoch [52/100], Batch [110/147] train loss: 564.73, train corr: -0.00893
Epoch [52/100], Batch [111/147] train loss: 560.19, train corr: -0.00650
Epoch [52/100], Batch [112/147] train loss: 561.65, train corr: 0.00269
Epoch [52/100], Batch [113/147] train loss: 558.99, train corr: -0.00787
Epoch [52/100], Batch [114/147] train loss: 569.68, train corr: -0.00971
Epoch [52/100], Batch [115/147] train loss: 567.16, train corr: -0.00918
Epoch [52/100], Batch [116/147] train loss: 574.28, train corr: -0.01002
Epoch [52/100], Batch [117/147] train loss: 569.54, train corr: -0.00712
Epoch [52/100], Batch [118/147] train loss: 638.07, train corr: -0.00692
Epoch [52/100], Batch [119/147] train loss: 573.48, train corr: -0.00773
Epoch [52/100], Batch [120/147] train loss: 562.81, train corr: -0.01450
Epoch [52/100], Batch [121/147] train loss: 564.94, train corr: -0.01240
Epoch [52/100], Batch [122/147] train loss: 574.53, train corr: -0.01548
Epoch [52/100], Batch [123/147] train loss: 558.33, train corr: -0.01768
Epoch [52/100], Batch [124/147] train loss: 568.78, train corr: -0.01249
Epoch [52/100], Batch [125/147] train loss: 565.96, train corr: -0.01706
Epoch [52/100], Batch [126/147] train loss: 561.98, train corr: -0.01807
Epoch [52/100], Batch [127/147] train loss: 552.62, train corr: -0.01689
Epoch [52/100], Batch [128/147] train loss: 563.15, train corr: -0.01435
Epoch [52/100], Batch [129/147] train loss: 560.65, train corr: -0.01497
Epoch [52/100], Batch [130/147] train loss: 571.91, train corr: -0.01783
Epoch [52/100], Batch [131/147] train loss: 573.37, train corr: -0.01441
Epoch [52/100], Batch [132/147] train loss: 565.07, train corr: -0.01415
Epoch [52/100], Batch [133/147] train loss: 557.87, train corr: -0.01979
Epoch [52/100], Batch [134/147] train loss: 562.90, train corr: -0.01857
Epoch [52/100], Batch [135/147] train loss: 823.26, train corr: -0.01226
Epoch [52/100], Batch [136/147] train loss: 584.58, train corr: -0.02004
Epoch [52/100], Batch [137/147] train loss: 561.64, train corr: 0.02690
Epoch [52/100], Batch [138/147] train loss: 567.07, train corr: 0.03128
Epoch [52/100], Batch [139/147] train loss: 587.27, train corr: 0.02647
Epoch [52/100], Batch [140/147] train loss: 572.17, train corr: 0.03095
Epoch [52/100], Batch [141/147] train loss: 573.33, train corr: 0.03118
Epoch [52/100], Batch [142/147] train loss: 556.40, train corr: 0.03320
Epoch [52/100], Batch [143/147] train loss: 576.12, train corr: -0.00478
Epoch [52/100], Batch [144/147] train loss: 569.48, train corr: -0.01761
Epoch [52/100], Batch [145/147] train loss: 570.99, train corr: -0.00879
Epoch [52/100], Batch [146/147] train loss: 563.25, train corr: 0.02555
Epoch [52/100], Batch [147/147] train loss: 585.30, train corr: 0.02139
Epoch [52/100], validation loss: 599.57, validation correlation: 0.01660
Epoch [53/100], Batch [1/147] train loss: 577.38, train corr: 0.01640
Epoch [53/100], Batch [2/147] train loss: 551.64, train corr: -0.01635
Epoch [53/100], Batch [3/147] train loss: 570.50, train corr: -0.02749
Epoch [53/100], Batch [4/147] train loss: 570.58, train corr: -0.02576
Epoch [53/100], Batch [5/147] train loss: 558.65, train corr: -0.02497
Epoch [53/100], Batch [6/147] train loss: 567.80, train corr: -0.00079
Epoch [53/100], Batch [7/147] train loss: 543.65, train corr: 0.03037
Epoch [53/100], Batch [8/147] train loss: 577.14, train corr: 0.03146
Epoch [53/100], Batch [9/147] train loss: 556.24, train corr: 0.03150
Epoch [53/100], Batch [10/147] train loss: 553.39, train corr: 0.00397
Epoch [53/100], Batch [11/147] train loss: 563.89, train corr: -0.01522
Epoch [53/100], Batch [12/147] train loss: 576.53, train corr: -0.01253
Epoch [53/100], Batch [13/147] train loss: 566.26, train corr: -0.00513
Epoch [53/100], Batch [14/147] train loss: 585.53, train corr: 0.01595
Epoch [53/100], Batch [15/147] train loss: 560.51, train corr: 0.02020
Epoch [53/100], Batch [16/147] train loss: 570.14, train corr: 0.00370
Epoch [53/100], Batch [17/147] train loss: 560.73, train corr: -0.01196
Epoch [53/100], Batch [18/147] train loss: 561.40, train corr: -0.01576
Epoch [53/100], Batch [19/147] train loss: 574.42, train corr: -0.01303
Epoch [53/100], Batch [20/147] train loss: 573.77, train corr: -0.01373
Epoch [53/100], Batch [21/147] train loss: 582.45, train corr: 0.00316
Epoch [53/100], Batch [22/147] train loss: 567.83, train corr: 0.01326
Epoch [53/100], Batch [23/147] train loss: 793.90, train corr: -0.00337
Epoch [53/100], Batch [24/147] train loss: 581.97, train corr: -0.01952
Epoch [53/100], Batch [25/147] train loss: 571.74, train corr: 0.03214
Epoch [53/100], Batch [26/147] train loss: 557.98, train corr: 0.02973
Epoch [53/100], Batch [27/147] train loss: 567.13, train corr: 0.02743
Epoch [53/100], Batch [28/147] train loss: 568.16, train corr: 0.03070
Epoch [53/100], Batch [29/147] train loss: 573.74, train corr: 0.03036
Epoch [53/100], Batch [30/147] train loss: 581.40, train corr: 0.02778
Epoch [53/100], Batch [31/147] train loss: 581.12, train corr: 0.03093
Epoch [53/100], Batch [32/147] train loss: 561.44, train corr: -0.01921
Epoch [53/100], Batch [33/147] train loss: 560.62, train corr: -0.01765
Epoch [53/100], Batch [34/147] train loss: 576.89, train corr: 0.02950
Epoch [53/100], Batch [35/147] train loss: 567.21, train corr: 0.02278
Epoch [53/100], Batch [36/147] train loss: 563.72, train corr: 0.02146
Epoch [53/100], Batch [37/147] train loss: 577.77, train corr: 0.01756
Epoch [53/100], Batch [38/147] train loss: 554.84, train corr: -0.02663
Epoch [53/100], Batch [39/147] train loss: 562.26, train corr: -0.02952
Epoch [53/100], Batch [40/147] train loss: 566.64, train corr: -0.02735
Epoch [53/100], Batch [41/147] train loss: 571.42, train corr: -0.01798
Epoch [53/100], Batch [42/147] train loss: 564.87, train corr: 0.02731
Epoch [53/100], Batch [43/147] train loss: 565.06, train corr: 0.03089
Epoch [53/100], Batch [44/147] train loss: 563.72, train corr: 0.02743
Epoch [53/100], Batch [45/147] train loss: 576.32, train corr: 0.03433
Epoch [53/100], Batch [46/147] train loss: 625.63, train corr: -0.00576
Epoch [53/100], Batch [47/147] train loss: 571.57, train corr: -0.01466
Epoch [53/100], Batch [48/147] train loss: 567.79, train corr: -0.00628
Epoch [53/100], Batch [49/147] train loss: 568.65, train corr: 0.01971
Epoch [53/100], Batch [50/147] train loss: 565.04, train corr: 0.02052
Epoch [53/100], Batch [51/147] train loss: 566.09, train corr: -0.01131
Epoch [53/100], Batch [52/147] train loss: 566.16, train corr: -0.02193
Epoch [53/100], Batch [53/147] train loss: 560.82, train corr: -0.02661
Epoch [53/100], Batch [54/147] train loss: 557.87, train corr: -0.02411
Epoch [53/100], Batch [55/147] train loss: 574.59, train corr: -0.01444
Epoch [53/100], Batch [56/147] train loss: 569.84, train corr: 0.02661
Epoch [53/100], Batch [57/147] train loss: 585.49, train corr: 0.03300
Epoch [53/100], Batch [58/147] train loss: 558.39, train corr: 0.02639
Epoch [53/100], Batch [59/147] train loss: 588.09, train corr: -0.00617
Epoch [53/100], Batch [60/147] train loss: 572.13, train corr: -0.01376
Epoch [53/100], Batch [61/147] train loss: 575.55, train corr: -0.01765
Epoch [53/100], Batch [62/147] train loss: 595.30, train corr: 0.00316
Epoch [53/100], Batch [63/147] train loss: 567.05, train corr: 0.00790
Epoch [53/100], Batch [64/147] train loss: 583.86, train corr: 0.01202
Epoch [53/100], Batch [65/147] train loss: 568.42, train corr: -0.01080
Epoch [53/100], Batch [66/147] train loss: 565.84, train corr: -0.01596
Epoch [53/100], Batch [67/147] train loss: 562.91, train corr: -0.02216
Epoch [53/100], Batch [68/147] train loss: 551.10, train corr: -0.02084
Epoch [53/100], Batch [69/147] train loss: 565.92, train corr: -0.01519
Epoch [53/100], Batch [70/147] train loss: 553.00, train corr: -0.01125
Epoch [53/100], Batch [71/147] train loss: 563.36, train corr: -0.01202
Epoch [53/100], Batch [72/147] train loss: 585.16, train corr: -0.01057
Epoch [53/100], Batch [73/147] train loss: 560.87, train corr: -0.02047
Epoch [53/100], Batch [74/147] train loss: 562.45, train corr: -0.01822
Epoch [53/100], Batch [75/147] train loss: 568.27, train corr: -0.01238
Epoch [53/100], Batch [76/147] train loss: 565.51, train corr: -0.00261
Epoch [53/100], Batch [77/147] train loss: 565.73, train corr: -0.00182
Epoch [53/100], Batch [78/147] train loss: 572.36, train corr: -0.00534
Epoch [53/100], Batch [79/147] train loss: 544.91, train corr: -0.01315
Epoch [53/100], Batch [80/147] train loss: 561.63, train corr: -0.01556
Epoch [53/100], Batch [81/147] train loss: 571.14, train corr: -0.01086
Epoch [53/100], Batch [82/147] train loss: 570.73, train corr: -0.00758
Epoch [53/100], Batch [83/147] train loss: 589.56, train corr: 0.00072
Epoch [53/100], Batch [84/147] train loss: 559.43, train corr: -0.01120
Epoch [53/100], Batch [85/147] train loss: 567.75, train corr: -0.01886
Epoch [53/100], Batch [86/147] train loss: 563.68, train corr: -0.02078
Epoch [53/100], Batch [87/147] train loss: 575.91, train corr: -0.01976
Epoch [53/100], Batch [88/147] train loss: 625.32, train corr: -0.01616
Epoch [53/100], Batch [89/147] train loss: 576.56, train corr: -0.02306
Epoch [53/100], Batch [90/147] train loss: 570.52, train corr: -0.01661
Epoch [53/100], Batch [91/147] train loss: 566.33, train corr: 0.03133
Epoch [53/100], Batch [92/147] train loss: 559.75, train corr: 0.03039
Epoch [53/100], Batch [93/147] train loss: 737.03, train corr: 0.02844
Epoch [53/100], Batch [94/147] train loss: 580.57, train corr: -0.01978
Epoch [53/100], Batch [95/147] train loss: 570.45, train corr: -0.01976
Epoch [53/100], Batch [96/147] train loss: 565.93, train corr: 0.02991
Epoch [53/100], Batch [97/147] train loss: 554.05, train corr: 0.03026
Epoch [53/100], Batch [98/147] train loss: 587.34, train corr: 0.02871
Epoch [53/100], Batch [99/147] train loss: 577.92, train corr: 0.02955
Epoch [53/100], Batch [100/147] train loss: 569.56, train corr: 0.02875
Epoch [53/100], Batch [101/147] train loss: 563.02, train corr: -0.01302
Epoch [53/100], Batch [102/147] train loss: 559.48, train corr: -0.02316
Epoch [53/100], Batch [103/147] train loss: 556.09, train corr: 0.03256
Epoch [53/100], Batch [104/147] train loss: 581.01, train corr: 0.02560
Epoch [53/100], Batch [105/147] train loss: 569.75, train corr: 0.02754
Epoch [53/100], Batch [106/147] train loss: 566.64, train corr: 0.02942
Epoch [53/100], Batch [107/147] train loss: 582.30, train corr: 0.02673
Epoch [53/100], Batch [108/147] train loss: 562.38, train corr: 0.03025
Epoch [53/100], Batch [109/147] train loss: 553.52, train corr: -0.01040
Epoch [53/100], Batch [110/147] train loss: 559.95, train corr: -0.01899
Epoch [53/100], Batch [111/147] train loss: 558.54, train corr: 0.03033
Epoch [53/100], Batch [112/147] train loss: 565.63, train corr: 0.02797
Epoch [53/100], Batch [113/147] train loss: 582.99, train corr: 0.02729
Epoch [53/100], Batch [114/147] train loss: 565.21, train corr: 0.02761
Epoch [53/100], Batch [115/147] train loss: 570.15, train corr: -0.01824
Epoch [53/100], Batch [116/147] train loss: 583.54, train corr: -0.01931
Epoch [53/100], Batch [117/147] train loss: 561.01, train corr: -0.01894
Epoch [53/100], Batch [118/147] train loss: 581.76, train corr: 0.03257
Epoch [53/100], Batch [119/147] train loss: 576.58, train corr: 0.02916
Epoch [53/100], Batch [120/147] train loss: 569.51, train corr: 0.02910
Epoch [53/100], Batch [121/147] train loss: 610.06, train corr: 0.02383
Epoch [53/100], Batch [122/147] train loss: 546.13, train corr: 0.02724
Epoch [53/100], Batch [123/147] train loss: 575.51, train corr: -0.01167
Epoch [53/100], Batch [124/147] train loss: 557.55, train corr: -0.02181
Epoch [53/100], Batch [125/147] train loss: 584.13, train corr: -0.01410
Epoch [53/100], Batch [126/147] train loss: 620.68, train corr: -0.02080
Epoch [53/100], Batch [127/147] train loss: 568.37, train corr: -0.01999
Epoch [53/100], Batch [128/147] train loss: 573.61, train corr: -0.01810
Epoch [53/100], Batch [129/147] train loss: 569.46, train corr: -0.02105
Epoch [53/100], Batch [130/147] train loss: 605.94, train corr: -0.00485
Epoch [53/100], Batch [131/147] train loss: 580.32, train corr: -0.00602
Epoch [53/100], Batch [132/147] train loss: 566.77, train corr: 0.00085
Epoch [53/100], Batch [133/147] train loss: 558.50, train corr: 0.01319
Epoch [53/100], Batch [134/147] train loss: 558.92, train corr: 0.01295
Epoch [53/100], Batch [135/147] train loss: 573.60, train corr: 0.00581
Epoch [53/100], Batch [136/147] train loss: 556.51, train corr: -0.00653
Epoch [53/100], Batch [137/147] train loss: 562.30, train corr: -0.01327
Epoch [53/100], Batch [138/147] train loss: 564.59, train corr: -0.01709
Epoch [53/100], Batch [139/147] train loss: 568.61, train corr: -0.01793
Epoch [53/100], Batch [140/147] train loss: 567.84, train corr: -0.01374
Epoch [53/100], Batch [141/147] train loss: 561.11, train corr: -0.01369
Epoch [53/100], Batch [142/147] train loss: 556.09, train corr: -0.01481
Epoch [53/100], Batch [143/147] train loss: 573.84, train corr: -0.01349
Epoch [53/100], Batch [144/147] train loss: 558.20, train corr: -0.01470
Epoch [53/100], Batch [145/147] train loss: 565.80, train corr: -0.01080
Epoch [53/100], Batch [146/147] train loss: 569.27, train corr: -0.01000
Epoch [53/100], Batch [147/147] train loss: 556.49, train corr: -0.00477
Epoch [53/100], validation loss: 596.95, validation correlation: -0.00784
Epoch [54/100], Batch [1/147] train loss: 583.66, train corr: 0.00009
Epoch [54/100], Batch [2/147] train loss: 577.15, train corr: -0.01543
Epoch [54/100], Batch [3/147] train loss: 582.30, train corr: -0.01122
Epoch [54/100], Batch [4/147] train loss: 569.07, train corr: -0.01565
Epoch [54/100], Batch [5/147] train loss: 555.58, train corr: -0.01533
Epoch [54/100], Batch [6/147] train loss: 555.60, train corr: -0.00848
Epoch [54/100], Batch [7/147] train loss: 568.69, train corr: -0.00543
Epoch [54/100], Batch [8/147] train loss: 560.23, train corr: -0.01210
Epoch [54/100], Batch [9/147] train loss: 573.79, train corr: -0.01475
Epoch [54/100], Batch [10/147] train loss: 556.48, train corr: -0.01517
Epoch [54/100], Batch [11/147] train loss: 555.51, train corr: -0.01167
Epoch [54/100], Batch [12/147] train loss: 539.69, train corr: -0.01364
Epoch [54/100], Batch [13/147] train loss: 571.10, train corr: -0.00905
Epoch [54/100], Batch [14/147] train loss: 567.03, train corr: -0.00743
Epoch [54/100], Batch [15/147] train loss: 563.18, train corr: -0.01612
Epoch [54/100], Batch [16/147] train loss: 558.56, train corr: -0.02018
Epoch [54/100], Batch [17/147] train loss: 567.13, train corr: -0.01234
Epoch [54/100], Batch [18/147] train loss: 566.59, train corr: -0.01347
Epoch [54/100], Batch [19/147] train loss: 543.33, train corr: -0.01032
Epoch [54/100], Batch [20/147] train loss: 561.83, train corr: -0.00248
Epoch [54/100], Batch [21/147] train loss: 569.80, train corr: -0.00413
Epoch [54/100], Batch [22/147] train loss: 552.60, train corr: -0.01121
Epoch [54/100], Batch [23/147] train loss: 579.53, train corr: -0.00625
Epoch [54/100], Batch [24/147] train loss: 557.12, train corr: -0.01468
Epoch [54/100], Batch [25/147] train loss: 565.35, train corr: -0.01229
Epoch [54/100], Batch [26/147] train loss: 596.24, train corr: -0.00157
Epoch [54/100], Batch [27/147] train loss: 578.16, train corr: -0.01086
Epoch [54/100], Batch [28/147] train loss: 567.51, train corr: -0.01686
Epoch [54/100], Batch [29/147] train loss: 581.07, train corr: -0.01211
Epoch [54/100], Batch [30/147] train loss: 551.14, train corr: -0.02155
Epoch [54/100], Batch [31/147] train loss: 565.13, train corr: -0.01537
Epoch [54/100], Batch [32/147] train loss: 558.93, train corr: -0.01361
Epoch [54/100], Batch [33/147] train loss: 570.38, train corr: -0.01198
Epoch [54/100], Batch [34/147] train loss: 561.70, train corr: -0.01687
Epoch [54/100], Batch [35/147] train loss: 564.50, train corr: -0.01829
Epoch [54/100], Batch [36/147] train loss: 567.72, train corr: -0.01908
Epoch [54/100], Batch [37/147] train loss: 563.21, train corr: -0.01353
Epoch [54/100], Batch [38/147] train loss: 576.08, train corr: -0.00456
Epoch [54/100], Batch [39/147] train loss: 575.30, train corr: -0.00254
Epoch [54/100], Batch [40/147] train loss: 563.80, train corr: -0.01343
Epoch [54/100], Batch [41/147] train loss: 569.74, train corr: -0.01229
Epoch [54/100], Batch [42/147] train loss: 564.47, train corr: -0.01917
Epoch [54/100], Batch [43/147] train loss: 577.99, train corr: -0.01301
Epoch [54/100], Batch [44/147] train loss: 550.15, train corr: -0.01065
Epoch [54/100], Batch [45/147] train loss: 554.20, train corr: -0.01199
Epoch [54/100], Batch [46/147] train loss: 570.58, train corr: -0.01106
Epoch [54/100], Batch [47/147] train loss: 556.91, train corr: -0.01731
Epoch [54/100], Batch [48/147] train loss: 583.83, train corr: -0.01271
Epoch [54/100], Batch [49/147] train loss: 570.77, train corr: -0.01305
Epoch [54/100], Batch [50/147] train loss: 547.73, train corr: -0.01276
Epoch [54/100], Batch [51/147] train loss: 559.59, train corr: -0.01368
Epoch [54/100], Batch [52/147] train loss: 554.49, train corr: -0.01452
Epoch [54/100], Batch [53/147] train loss: 566.22, train corr: -0.01475
Epoch [54/100], Batch [54/147] train loss: 565.68, train corr: -0.01706
Epoch [54/100], Batch [55/147] train loss: 562.83, train corr: -0.01319
Epoch [54/100], Batch [56/147] train loss: 581.37, train corr: -0.01199
Epoch [54/100], Batch [57/147] train loss: 562.57, train corr: -0.01103
Epoch [54/100], Batch [58/147] train loss: 567.02, train corr: -0.01300
Epoch [54/100], Batch [59/147] train loss: 577.71, train corr: -0.01488
Epoch [54/100], Batch [60/147] train loss: 627.43, train corr: -0.01614
Epoch [54/100], Batch [61/147] train loss: 554.14, train corr: -0.01402
Epoch [54/100], Batch [62/147] train loss: 575.69, train corr: -0.01061
Epoch [54/100], Batch [63/147] train loss: 572.81, train corr: -0.00668
Epoch [54/100], Batch [64/147] train loss: 554.96, train corr: -0.00952
Epoch [54/100], Batch [65/147] train loss: 562.46, train corr: -0.01551
Epoch [54/100], Batch [66/147] train loss: 562.55, train corr: -0.01426
Epoch [54/100], Batch [67/147] train loss: 571.02, train corr: -0.01253
Epoch [54/100], Batch [68/147] train loss: 557.35, train corr: -0.01167
Epoch [54/100], Batch [69/147] train loss: 545.01, train corr: -0.01441
Epoch [54/100], Batch [70/147] train loss: 576.02, train corr: -0.01205
Epoch [54/100], Batch [71/147] train loss: 569.67, train corr: -0.01501
Epoch [54/100], Batch [72/147] train loss: 566.65, train corr: -0.01699
Epoch [54/100], Batch [73/147] train loss: 575.65, train corr: -0.01544
Epoch [54/100], Batch [74/147] train loss: 569.70, train corr: -0.01618
Epoch [54/100], Batch [75/147] train loss: 561.23, train corr: -0.01416
Epoch [54/100], Batch [76/147] train loss: 615.26, train corr: -0.00941
Epoch [54/100], Batch [77/147] train loss: 569.92, train corr: -0.01281
Epoch [54/100], Batch [78/147] train loss: 569.35, train corr: -0.01404
Epoch [54/100], Batch [79/147] train loss: 586.52, train corr: -0.00722
Epoch [54/100], Batch [80/147] train loss: 568.21, train corr: -0.00424
Epoch [54/100], Batch [81/147] train loss: 573.58, train corr: -0.00193
Epoch [54/100], Batch [82/147] train loss: 559.39, train corr: -0.01053
Epoch [54/100], Batch [83/147] train loss: 746.06, train corr: -0.01310
Epoch [54/100], Batch [84/147] train loss: 561.01, train corr: -0.02478
Epoch [54/100], Batch [85/147] train loss: 558.28, train corr: 0.03410
Epoch [54/100], Batch [86/147] train loss: 566.25, train corr: 0.02837
Epoch [54/100], Batch [87/147] train loss: 568.45, train corr: 0.02822
Epoch [54/100], Batch [88/147] train loss: 575.70, train corr: 0.02727
Epoch [54/100], Batch [89/147] train loss: 569.93, train corr: 0.02929
Epoch [54/100], Batch [90/147] train loss: 569.05, train corr: 0.03146
Epoch [54/100], Batch [91/147] train loss: 557.36, train corr: -0.02219
Epoch [54/100], Batch [92/147] train loss: 561.39, train corr: -0.02307
Epoch [54/100], Batch [93/147] train loss: 578.53, train corr: 0.03211
Epoch [54/100], Batch [94/147] train loss: 565.89, train corr: 0.02975
Epoch [54/100], Batch [95/147] train loss: 559.69, train corr: 0.02828
Epoch [54/100], Batch [96/147] train loss: 564.74, train corr: 0.02962
Epoch [54/100], Batch [97/147] train loss: 568.86, train corr: -0.01333
Epoch [54/100], Batch [98/147] train loss: 569.30, train corr: -0.02173
Epoch [54/100], Batch [99/147] train loss: 568.76, train corr: -0.01173
Epoch [54/100], Batch [100/147] train loss: 578.58, train corr: 0.02800
Epoch [54/100], Batch [101/147] train loss: 657.66, train corr: 0.02355
Epoch [54/100], Batch [102/147] train loss: 569.83, train corr: 0.03186
Epoch [54/100], Batch [103/147] train loss: 587.61, train corr: -0.01911
Epoch [54/100], Batch [104/147] train loss: 572.55, train corr: 0.02583
Epoch [54/100], Batch [105/147] train loss: 582.76, train corr: 0.02870
Epoch [54/100], Batch [106/147] train loss: 567.91, train corr: 0.02822
Epoch [54/100], Batch [107/147] train loss: 580.19, train corr: 0.02849
Epoch [54/100], Batch [108/147] train loss: 566.31, train corr: 0.02984
Epoch [54/100], Batch [109/147] train loss: 576.65, train corr: 0.02105
Epoch [54/100], Batch [110/147] train loss: 574.12, train corr: 0.02801
Epoch [54/100], Batch [111/147] train loss: 590.02, train corr: 0.02531
Epoch [54/100], Batch [112/147] train loss: 557.95, train corr: 0.02786
Epoch [54/100], Batch [113/147] train loss: 560.13, train corr: 0.02670
Epoch [54/100], Batch [114/147] train loss: 559.19, train corr: -0.02212
Epoch [54/100], Batch [115/147] train loss: 573.36, train corr: -0.02525
Epoch [54/100], Batch [116/147] train loss: 560.62, train corr: -0.01819
Epoch [54/100], Batch [117/147] train loss: 567.32, train corr: 0.02908
Epoch [54/100], Batch [118/147] train loss: 565.31, train corr: 0.02679
Epoch [54/100], Batch [119/147] train loss: 564.31, train corr: 0.02838
Epoch [54/100], Batch [120/147] train loss: 578.28, train corr: 0.03339
Epoch [54/100], Batch [121/147] train loss: 586.78, train corr: -0.01529
Epoch [54/100], Batch [122/147] train loss: 810.54, train corr: -0.01716
Epoch [54/100], Batch [123/147] train loss: 562.10, train corr: -0.02121
Epoch [54/100], Batch [124/147] train loss: 569.91, train corr: 0.01367
Epoch [54/100], Batch [125/147] train loss: 571.27, train corr: 0.03348
Epoch [54/100], Batch [126/147] train loss: 571.92, train corr: 0.03204
Epoch [54/100], Batch [127/147] train loss: 566.64, train corr: 0.03271
Epoch [54/100], Batch [128/147] train loss: 576.82, train corr: 0.00452
Epoch [54/100], Batch [129/147] train loss: 571.08, train corr: -0.01802
Epoch [54/100], Batch [130/147] train loss: 578.32, train corr: -0.01488
Epoch [54/100], Batch [131/147] train loss: 553.94, train corr: 0.03420
Epoch [54/100], Batch [132/147] train loss: 572.13, train corr: 0.02935
Epoch [54/100], Batch [133/147] train loss: 566.74, train corr: 0.02522
Epoch [54/100], Batch [134/147] train loss: 567.57, train corr: 0.02173
Epoch [54/100], Batch [135/147] train loss: 571.97, train corr: -0.02646
Epoch [54/100], Batch [136/147] train loss: 561.99, train corr: -0.02736
Epoch [54/100], Batch [137/147] train loss: 581.76, train corr: -0.02199
Epoch [54/100], Batch [138/147] train loss: 575.23, train corr: -0.01841
Epoch [54/100], Batch [139/147] train loss: 581.48, train corr: 0.02594
Epoch [54/100], Batch [140/147] train loss: 563.88, train corr: 0.02539
Epoch [54/100], Batch [141/147] train loss: 567.83, train corr: -0.00816
Epoch [54/100], Batch [142/147] train loss: 586.87, train corr: -0.01709
Epoch [54/100], Batch [143/147] train loss: 565.82, train corr: -0.01570
Epoch [54/100], Batch [144/147] train loss: 561.12, train corr: 0.02806
Epoch [54/100], Batch [145/147] train loss: 572.01, train corr: 0.03439
Epoch [54/100], Batch [146/147] train loss: 571.81, train corr: 0.03466
Epoch [54/100], Batch [147/147] train loss: 563.34, train corr: 0.01855
Epoch [54/100], validation loss: 597.23, validation correlation: -0.01604
Epoch [55/100], Batch [1/147] train loss: 558.92, train corr: -0.01662
Epoch [55/100], Batch [2/147] train loss: 578.33, train corr: -0.01593
Epoch [55/100], Batch [3/147] train loss: 559.14, train corr: -0.01620
Epoch [55/100], Batch [4/147] train loss: 555.94, train corr: 0.00046
Epoch [55/100], Batch [5/147] train loss: 564.70, train corr: 0.01791
Epoch [55/100], Batch [6/147] train loss: 567.80, train corr: -0.00380
Epoch [55/100], Batch [7/147] train loss: 576.23, train corr: -0.01383
Epoch [55/100], Batch [8/147] train loss: 556.74, train corr: -0.01634
Epoch [55/100], Batch [9/147] train loss: 583.86, train corr: -0.01075
Epoch [55/100], Batch [10/147] train loss: 563.85, train corr: 0.01248
Epoch [55/100], Batch [11/147] train loss: 566.64, train corr: 0.02671
Epoch [55/100], Batch [12/147] train loss: 571.09, train corr: 0.00514
Epoch [55/100], Batch [13/147] train loss: 565.72, train corr: -0.01540
Epoch [55/100], Batch [14/147] train loss: 570.06, train corr: -0.01834
Epoch [55/100], Batch [15/147] train loss: 583.22, train corr: -0.01387
Epoch [55/100], Batch [16/147] train loss: 573.83, train corr: -0.00923
Epoch [55/100], Batch [17/147] train loss: 751.88, train corr: -0.00706
Epoch [55/100], Batch [18/147] train loss: 552.89, train corr: -0.02600
Epoch [55/100], Batch [19/147] train loss: 556.43, train corr: 0.03262
Epoch [55/100], Batch [20/147] train loss: 564.68, train corr: 0.02957
Epoch [55/100], Batch [21/147] train loss: 570.50, train corr: 0.02740
Epoch [55/100], Batch [22/147] train loss: 562.75, train corr: 0.02991
Epoch [55/100], Batch [23/147] train loss: 625.49, train corr: 0.02712
Epoch [55/100], Batch [24/147] train loss: 564.83, train corr: 0.03379
Epoch [55/100], Batch [25/147] train loss: 584.68, train corr: -0.01805
Epoch [55/100], Batch [26/147] train loss: 564.48, train corr: 0.01794
Epoch [55/100], Batch [27/147] train loss: 562.49, train corr: 0.02835
Epoch [55/100], Batch [28/147] train loss: 564.74, train corr: 0.02487
Epoch [55/100], Batch [29/147] train loss: 576.45, train corr: 0.02455
Epoch [55/100], Batch [30/147] train loss: 570.50, train corr: 0.02688
Epoch [55/100], Batch [31/147] train loss: 557.43, train corr: -0.02229
Epoch [55/100], Batch [32/147] train loss: 555.21, train corr: -0.02495
Epoch [55/100], Batch [33/147] train loss: 550.97, train corr: 0.03062
Epoch [55/100], Batch [34/147] train loss: 573.41, train corr: 0.02789
Epoch [55/100], Batch [35/147] train loss: 556.97, train corr: 0.02969
Epoch [55/100], Batch [36/147] train loss: 558.86, train corr: 0.03017
Epoch [55/100], Batch [37/147] train loss: 562.14, train corr: -0.00761
Epoch [55/100], Batch [38/147] train loss: 554.29, train corr: -0.02484
Epoch [55/100], Batch [39/147] train loss: 580.84, train corr: -0.01875
Epoch [55/100], Batch [40/147] train loss: 572.22, train corr: 0.02986
Epoch [55/100], Batch [41/147] train loss: 566.83, train corr: 0.03190
Epoch [55/100], Batch [42/147] train loss: 579.08, train corr: 0.03395
Epoch [55/100], Batch [43/147] train loss: 558.33, train corr: -0.01563
Epoch [55/100], Batch [44/147] train loss: 565.90, train corr: -0.02206
Epoch [55/100], Batch [45/147] train loss: 572.77, train corr: -0.01904
Epoch [55/100], Batch [46/147] train loss: 574.87, train corr: 0.02721
Epoch [55/100], Batch [47/147] train loss: 570.72, train corr: 0.03366
Epoch [55/100], Batch [48/147] train loss: 566.57, train corr: 0.03448
Epoch [55/100], Batch [49/147] train loss: 573.78, train corr: -0.00202
Epoch [55/100], Batch [50/147] train loss: 574.11, train corr: -0.01503
Epoch [55/100], Batch [51/147] train loss: 561.38, train corr: -0.01880
Epoch [55/100], Batch [52/147] train loss: 577.90, train corr: 0.00606
Epoch [55/100], Batch [53/147] train loss: 569.55, train corr: 0.02962
Epoch [55/100], Batch [54/147] train loss: 554.90, train corr: 0.02833
Epoch [55/100], Batch [55/147] train loss: 570.39, train corr: -0.01019
Epoch [55/100], Batch [56/147] train loss: 556.39, train corr: -0.02175
Epoch [55/100], Batch [57/147] train loss: 569.81, train corr: -0.01872
Epoch [55/100], Batch [58/147] train loss: 573.93, train corr: -0.01185
Epoch [55/100], Batch [59/147] train loss: 579.78, train corr: 0.00238
Epoch [55/100], Batch [60/147] train loss: 575.48, train corr: 0.01283
Epoch [55/100], Batch [61/147] train loss: 561.05, train corr: -0.01132
Epoch [55/100], Batch [62/147] train loss: 570.30, train corr: -0.02173
Epoch [55/100], Batch [63/147] train loss: 575.77, train corr: -0.02079
Epoch [55/100], Batch [64/147] train loss: 578.25, train corr: -0.01934
Epoch [55/100], Batch [65/147] train loss: 573.17, train corr: -0.01253
Epoch [55/100], Batch [66/147] train loss: 569.41, train corr: -0.00095
Epoch [55/100], Batch [67/147] train loss: 548.54, train corr: -0.01396
Epoch [55/100], Batch [68/147] train loss: 564.55, train corr: -0.01520
Epoch [55/100], Batch [69/147] train loss: 564.11, train corr: -0.01526
Epoch [55/100], Batch [70/147] train loss: 563.69, train corr: -0.01582
Epoch [55/100], Batch [71/147] train loss: 607.74, train corr: -0.01304
Epoch [55/100], Batch [72/147] train loss: 566.66, train corr: -0.00611
Epoch [55/100], Batch [73/147] train loss: 557.08, train corr: -0.00700
Epoch [55/100], Batch [74/147] train loss: 558.50, train corr: -0.01656
Epoch [55/100], Batch [75/147] train loss: 564.26, train corr: -0.01605
Epoch [55/100], Batch [76/147] train loss: 579.51, train corr: -0.00793
Epoch [55/100], Batch [77/147] train loss: 563.41, train corr: -0.01361
Epoch [55/100], Batch [78/147] train loss: 570.34, train corr: -0.01040
Epoch [55/100], Batch [79/147] train loss: 648.90, train corr: -0.00571
Epoch [55/100], Batch [80/147] train loss: 567.21, train corr: -0.02139
Epoch [55/100], Batch [81/147] train loss: 564.56, train corr: 0.01066
Epoch [55/100], Batch [82/147] train loss: 569.18, train corr: 0.02783
Epoch [55/100], Batch [83/147] train loss: 553.17, train corr: 0.02961
Epoch [55/100], Batch [84/147] train loss: 580.93, train corr: 0.02913
Epoch [55/100], Batch [85/147] train loss: 568.90, train corr: 0.00538
Epoch [55/100], Batch [86/147] train loss: 562.91, train corr: -0.02356
Epoch [55/100], Batch [87/147] train loss: 568.38, train corr: -0.01797
Epoch [55/100], Batch [88/147] train loss: 577.68, train corr: 0.02800
Epoch [55/100], Batch [89/147] train loss: 571.38, train corr: 0.02794
Epoch [55/100], Batch [90/147] train loss: 569.41, train corr: 0.02432
Epoch [55/100], Batch [91/147] train loss: 567.69, train corr: -0.02504
Epoch [55/100], Batch [92/147] train loss: 570.36, train corr: -0.02750
Epoch [55/100], Batch [93/147] train loss: 553.63, train corr: -0.02632
Epoch [55/100], Batch [94/147] train loss: 570.79, train corr: 0.02151
Epoch [55/100], Batch [95/147] train loss: 588.83, train corr: 0.02187
Epoch [55/100], Batch [96/147] train loss: 559.50, train corr: 0.02618
Epoch [55/100], Batch [97/147] train loss: 577.10, train corr: -0.01882
Epoch [55/100], Batch [98/147] train loss: 580.34, train corr: -0.01918
Epoch [55/100], Batch [99/147] train loss: 564.71, train corr: -0.01983
Epoch [55/100], Batch [100/147] train loss: 562.25, train corr: 0.01504
Epoch [55/100], Batch [101/147] train loss: 563.58, train corr: 0.02921
Epoch [55/100], Batch [102/147] train loss: 571.88, train corr: -0.00392
Epoch [55/100], Batch [103/147] train loss: 559.39, train corr: -0.01961
Epoch [55/100], Batch [104/147] train loss: 584.64, train corr: -0.02010
Epoch [55/100], Batch [105/147] train loss: 558.04, train corr: -0.01087
Epoch [55/100], Batch [106/147] train loss: 558.44, train corr: 0.03019
Epoch [55/100], Batch [107/147] train loss: 562.04, train corr: 0.03420
Epoch [55/100], Batch [108/147] train loss: 562.97, train corr: 0.02404
Epoch [55/100], Batch [109/147] train loss: 597.82, train corr: -0.00288
Epoch [55/100], Batch [110/147] train loss: 561.46, train corr: -0.01624
Epoch [55/100], Batch [111/147] train loss: 576.68, train corr: -0.01425
Epoch [55/100], Batch [112/147] train loss: 558.49, train corr: -0.00178
Epoch [55/100], Batch [113/147] train loss: 562.78, train corr: 0.00995
Epoch [55/100], Batch [114/147] train loss: 564.47, train corr: -0.00662
Epoch [55/100], Batch [115/147] train loss: 564.14, train corr: -0.02199
Epoch [55/100], Batch [116/147] train loss: 561.30, train corr: -0.02283
Epoch [55/100], Batch [117/147] train loss: 567.49, train corr: -0.01915
Epoch [55/100], Batch [118/147] train loss: 585.15, train corr: -0.00281
Epoch [55/100], Batch [119/147] train loss: 569.70, train corr: 0.01811
Epoch [55/100], Batch [120/147] train loss: 556.91, train corr: 0.00307
Epoch [55/100], Batch [121/147] train loss: 573.75, train corr: -0.01180
Epoch [55/100], Batch [122/147] train loss: 575.99, train corr: -0.01737
Epoch [55/100], Batch [123/147] train loss: 827.92, train corr: -0.01212
Epoch [55/100], Batch [124/147] train loss: 571.83, train corr: -0.02376
Epoch [55/100], Batch [125/147] train loss: 582.59, train corr: 0.02927
Epoch [55/100], Batch [126/147] train loss: 573.49, train corr: 0.03074
Epoch [55/100], Batch [127/147] train loss: 578.67, train corr: 0.02750
Epoch [55/100], Batch [128/147] train loss: 586.56, train corr: 0.02875
Epoch [55/100], Batch [129/147] train loss: 577.87, train corr: 0.02687
Epoch [55/100], Batch [130/147] train loss: 583.38, train corr: 0.02459
Epoch [55/100], Batch [131/147] train loss: 570.20, train corr: 0.02995
Epoch [55/100], Batch [132/147] train loss: 564.29, train corr: 0.03100
Epoch [55/100], Batch [133/147] train loss: 576.31, train corr: -0.01015
Epoch [55/100], Batch [134/147] train loss: 551.87, train corr: -0.02348
Epoch [55/100], Batch [135/147] train loss: 564.26, train corr: -0.01742
Epoch [55/100], Batch [136/147] train loss: 567.56, train corr: -0.01143
Epoch [55/100], Batch [137/147] train loss: 573.57, train corr: -0.02477
Epoch [55/100], Batch [138/147] train loss: 559.39, train corr: -0.02986
Epoch [55/100], Batch [139/147] train loss: 565.49, train corr: -0.03055
Epoch [55/100], Batch [140/147] train loss: 572.74, train corr: -0.02976
Epoch [55/100], Batch [141/147] train loss: 558.89, train corr: -0.02943
Epoch [55/100], Batch [142/147] train loss: 569.07, train corr: 0.00884
Epoch [55/100], Batch [143/147] train loss: 568.74, train corr: 0.02369
Epoch [55/100], Batch [144/147] train loss: 584.46, train corr: 0.02090
Epoch [55/100], Batch [145/147] train loss: 566.34, train corr: 0.02922
Epoch [55/100], Batch [146/147] train loss: 578.98, train corr: 0.03010
Epoch [55/100], Batch [147/147] train loss: 571.68, train corr: 0.00818
Epoch [55/100], validation loss: 597.80, validation correlation: -0.01103
Epoch [56/100], Batch [1/147] train loss: 560.37, train corr: -0.01179
Epoch [56/100], Batch [2/147] train loss: 555.58, train corr: -0.01144
Epoch [56/100], Batch [3/147] train loss: 563.54, train corr: -0.01332
Epoch [56/100], Batch [4/147] train loss: 560.38, train corr: -0.01229
Epoch [56/100], Batch [5/147] train loss: 561.56, train corr: -0.01794
Epoch [56/100], Batch [6/147] train loss: 609.46, train corr: -0.01848
Epoch [56/100], Batch [7/147] train loss: 571.41, train corr: -0.00788
Epoch [56/100], Batch [8/147] train loss: 546.12, train corr: 0.00869
Epoch [56/100], Batch [9/147] train loss: 560.17, train corr: 0.03083
Epoch [56/100], Batch [10/147] train loss: 545.46, train corr: 0.03332
Epoch [56/100], Batch [11/147] train loss: 568.45, train corr: 0.03216
Epoch [56/100], Batch [12/147] train loss: 586.92, train corr: 0.00664
Epoch [56/100], Batch [13/147] train loss: 566.25, train corr: -0.01296
Epoch [56/100], Batch [14/147] train loss: 572.44, train corr: -0.01365
Epoch [56/100], Batch [15/147] train loss: 575.57, train corr: -0.01096
Epoch [56/100], Batch [16/147] train loss: 577.36, train corr: -0.00453
Epoch [56/100], Batch [17/147] train loss: 561.33, train corr: -0.01756
Epoch [56/100], Batch [18/147] train loss: 571.17, train corr: -0.02235
Epoch [56/100], Batch [19/147] train loss: 558.79, train corr: -0.02728
Epoch [56/100], Batch [20/147] train loss: 552.29, train corr: -0.02368
Epoch [56/100], Batch [21/147] train loss: 582.57, train corr: -0.01177
Epoch [56/100], Batch [22/147] train loss: 569.84, train corr: 0.01303
Epoch [56/100], Batch [23/147] train loss: 564.43, train corr: 0.00657
Epoch [56/100], Batch [24/147] train loss: 574.64, train corr: -0.01401
Epoch [56/100], Batch [25/147] train loss: 560.05, train corr: -0.01768
Epoch [56/100], Batch [26/147] train loss: 573.59, train corr: -0.01008
Epoch [56/100], Batch [27/147] train loss: 568.74, train corr: -0.00519
Epoch [56/100], Batch [28/147] train loss: 563.36, train corr: 0.00557
Epoch [56/100], Batch [29/147] train loss: 569.77, train corr: 0.00629
Epoch [56/100], Batch [30/147] train loss: 576.13, train corr: 0.00107
Epoch [56/100], Batch [31/147] train loss: 566.43, train corr: -0.00954
Epoch [56/100], Batch [32/147] train loss: 579.15, train corr: -0.00610
Epoch [56/100], Batch [33/147] train loss: 569.40, train corr: -0.00770
Epoch [56/100], Batch [34/147] train loss: 572.25, train corr: -0.00989
Epoch [56/100], Batch [35/147] train loss: 564.69, train corr: -0.01635
Epoch [56/100], Batch [36/147] train loss: 557.37, train corr: -0.01932
Epoch [56/100], Batch [37/147] train loss: 556.33, train corr: -0.02096
Epoch [56/100], Batch [38/147] train loss: 572.29, train corr: -0.01410
Epoch [56/100], Batch [39/147] train loss: 557.11, train corr: -0.01112
Epoch [56/100], Batch [40/147] train loss: 575.85, train corr: -0.00936
Epoch [56/100], Batch [41/147] train loss: 552.10, train corr: -0.01160
Epoch [56/100], Batch [42/147] train loss: 590.75, train corr: -0.00057
Epoch [56/100], Batch [43/147] train loss: 580.39, train corr: -0.00485
Epoch [56/100], Batch [44/147] train loss: 557.77, train corr: -0.00676
Epoch [56/100], Batch [45/147] train loss: 564.08, train corr: -0.00371
Epoch [56/100], Batch [46/147] train loss: 579.84, train corr: -0.00821
Epoch [56/100], Batch [47/147] train loss: 569.17, train corr: -0.01841
Epoch [56/100], Batch [48/147] train loss: 575.13, train corr: -0.01489
Epoch [56/100], Batch [49/147] train loss: 556.20, train corr: -0.01672
Epoch [56/100], Batch [50/147] train loss: 577.24, train corr: -0.01008
Epoch [56/100], Batch [51/147] train loss: 567.50, train corr: -0.00859
Epoch [56/100], Batch [52/147] train loss: 571.61, train corr: -0.00465
Epoch [56/100], Batch [53/147] train loss: 566.94, train corr: -0.00962
Epoch [56/100], Batch [54/147] train loss: 586.36, train corr: -0.00276
Epoch [56/100], Batch [55/147] train loss: 811.06, train corr: -0.00832
Epoch [56/100], Batch [56/147] train loss: 569.09, train corr: -0.02471
Epoch [56/100], Batch [57/147] train loss: 592.52, train corr: 0.02405
Epoch [56/100], Batch [58/147] train loss: 584.85, train corr: 0.02846
Epoch [56/100], Batch [59/147] train loss: 593.96, train corr: 0.02565
Epoch [56/100], Batch [60/147] train loss: 590.69, train corr: 0.02970
Epoch [56/100], Batch [61/147] train loss: 590.11, train corr: 0.02829
Epoch [56/100], Batch [62/147] train loss: 810.21, train corr: 0.02492
Epoch [56/100], Batch [63/147] train loss: 590.18, train corr: 0.02858
Epoch [56/100], Batch [64/147] train loss: 601.87, train corr: 0.02583
Epoch [56/100], Batch [65/147] train loss: 571.84, train corr: 0.02854
Epoch [56/100], Batch [66/147] train loss: 561.37, train corr: 0.02978
Epoch [56/100], Batch [67/147] train loss: 585.94, train corr: -0.02327
Epoch [56/100], Batch [68/147] train loss: 607.32, train corr: -0.02921
Epoch [56/100], Batch [69/147] train loss: 566.09, train corr: 0.02428
Epoch [56/100], Batch [70/147] train loss: 587.63, train corr: 0.02847
Epoch [56/100], Batch [71/147] train loss: 599.91, train corr: 0.02462
Epoch [56/100], Batch [72/147] train loss: 615.38, train corr: 0.02435
Epoch [56/100], Batch [73/147] train loss: 625.23, train corr: 0.02294
Epoch [56/100], Batch [74/147] train loss: 620.52, train corr: 0.02409
Epoch [56/100], Batch [75/147] train loss: 619.75, train corr: 0.02348
Epoch [56/100], Batch [76/147] train loss: 604.85, train corr: 0.02387
Epoch [56/100], Batch [77/147] train loss: 609.75, train corr: 0.02283
Epoch [56/100], Batch [78/147] train loss: 583.35, train corr: 0.02858
Epoch [56/100], Batch [79/147] train loss: 650.93, train corr: 0.02585
Epoch [56/100], Batch [80/147] train loss: 576.96, train corr: 0.02699
Epoch [56/100], Batch [81/147] train loss: 577.19, train corr: 0.02638
Epoch [56/100], Batch [82/147] train loss: 595.34, train corr: 0.02010
Epoch [56/100], Batch [83/147] train loss: 582.92, train corr: -0.01734
Epoch [56/100], Batch [84/147] train loss: 589.60, train corr: -0.02364
Epoch [56/100], Batch [85/147] train loss: 588.80, train corr: 0.02902
Epoch [56/100], Batch [86/147] train loss: 581.88, train corr: 0.02734
Epoch [56/100], Batch [87/147] train loss: 616.53, train corr: 0.02470
Epoch [56/100], Batch [88/147] train loss: 691.85, train corr: 0.02427
Epoch [56/100], Batch [89/147] train loss: 588.42, train corr: 0.02951
Epoch [56/100], Batch [90/147] train loss: 598.11, train corr: 0.02602
Epoch [56/100], Batch [91/147] train loss: 589.13, train corr: 0.02837
Epoch [56/100], Batch [92/147] train loss: 590.58, train corr: 0.03007
Epoch [56/100], Batch [93/147] train loss: 583.21, train corr: 0.03120
Epoch [56/100], Batch [94/147] train loss: 570.21, train corr: 0.03069
Epoch [56/100], Batch [95/147] train loss: 571.44, train corr: 0.01779
Epoch [56/100], Batch [96/147] train loss: 584.26, train corr: -0.00484
Epoch [56/100], Batch [97/147] train loss: 585.90, train corr: 0.03045
Epoch [56/100], Batch [98/147] train loss: 593.05, train corr: 0.02769
Epoch [56/100], Batch [99/147] train loss: 583.80, train corr: 0.02831
Epoch [56/100], Batch [100/147] train loss: 605.57, train corr: 0.02184
Epoch [56/100], Batch [101/147] train loss: 589.73, train corr: 0.02654
Epoch [56/100], Batch [102/147] train loss: 581.02, train corr: 0.02383
Epoch [56/100], Batch [103/147] train loss: 595.49, train corr: 0.02236
Epoch [56/100], Batch [104/147] train loss: 576.87, train corr: 0.02406
Epoch [56/100], Batch [105/147] train loss: 575.08, train corr: 0.01989
Epoch [56/100], Batch [106/147] train loss: 575.89, train corr: -0.01696
Epoch [56/100], Batch [107/147] train loss: 559.14, train corr: 0.01716
Epoch [56/100], Batch [108/147] train loss: 560.58, train corr: 0.02028
Epoch [56/100], Batch [109/147] train loss: 581.33, train corr: 0.02095
Epoch [56/100], Batch [110/147] train loss: 564.82, train corr: 0.01775
Epoch [56/100], Batch [111/147] train loss: 577.72, train corr: -0.00379
Epoch [56/100], Batch [112/147] train loss: 568.25, train corr: -0.02512
Epoch [56/100], Batch [113/147] train loss: 588.82, train corr: -0.02628
Epoch [56/100], Batch [114/147] train loss: 575.87, train corr: -0.02603
Epoch [56/100], Batch [115/147] train loss: 556.18, train corr: -0.00919
Epoch [56/100], Batch [116/147] train loss: 565.78, train corr: 0.01977
Epoch [56/100], Batch [117/147] train loss: 558.17, train corr: 0.02683
Epoch [56/100], Batch [118/147] train loss: 569.43, train corr: 0.02441
Epoch [56/100], Batch [119/147] train loss: 563.92, train corr: 0.02581
Epoch [56/100], Batch [120/147] train loss: 560.36, train corr: 0.02381
Epoch [56/100], Batch [121/147] train loss: 567.00, train corr: -0.00018
Epoch [56/100], Batch [122/147] train loss: 568.21, train corr: -0.01372
Epoch [56/100], Batch [123/147] train loss: 555.78, train corr: -0.01493
Epoch [56/100], Batch [124/147] train loss: 565.66, train corr: -0.01196
Epoch [56/100], Batch [125/147] train loss: 568.63, train corr: -0.01084
Epoch [56/100], Batch [126/147] train loss: 554.28, train corr: -0.01088
Epoch [56/100], Batch [127/147] train loss: 572.28, train corr: -0.00944
Epoch [56/100], Batch [128/147] train loss: 562.89, train corr: 0.00850
Epoch [56/100], Batch [129/147] train loss: 568.85, train corr: 0.02609
Epoch [56/100], Batch [130/147] train loss: 574.63, train corr: 0.02646
Epoch [56/100], Batch [131/147] train loss: 586.55, train corr: 0.02368
Epoch [56/100], Batch [132/147] train loss: 565.92, train corr: 0.02734
Epoch [56/100], Batch [133/147] train loss: 555.77, train corr: -0.01220
Epoch [56/100], Batch [134/147] train loss: 569.17, train corr: -0.01903
Epoch [56/100], Batch [135/147] train loss: 559.83, train corr: -0.02442
Epoch [56/100], Batch [136/147] train loss: 562.84, train corr: -0.02087
Epoch [56/100], Batch [137/147] train loss: 554.51, train corr: -0.01628
Epoch [56/100], Batch [138/147] train loss: 574.39, train corr: -0.01755
Epoch [56/100], Batch [139/147] train loss: 567.65, train corr: -0.02110
Epoch [56/100], Batch [140/147] train loss: 558.48, train corr: -0.02104
Epoch [56/100], Batch [141/147] train loss: 576.43, train corr: -0.01482
Epoch [56/100], Batch [142/147] train loss: 559.82, train corr: 0.00405
Epoch [56/100], Batch [143/147] train loss: 582.25, train corr: 0.03327
Epoch [56/100], Batch [144/147] train loss: 560.76, train corr: 0.02666
Epoch [56/100], Batch [145/147] train loss: 573.08, train corr: -0.01270
Epoch [56/100], Batch [146/147] train loss: 574.93, train corr: -0.02064
Epoch [56/100], Batch [147/147] train loss: 575.82, train corr: -0.02018
Epoch [56/100], validation loss: 596.98, validation correlation: -0.01482
Epoch [57/100], Batch [1/147] train loss: 564.25, train corr: -0.01430
Epoch [57/100], Batch [2/147] train loss: 563.87, train corr: 0.00090
Epoch [57/100], Batch [3/147] train loss: 553.56, train corr: -0.00633
Epoch [57/100], Batch [4/147] train loss: 575.59, train corr: -0.01324
Epoch [57/100], Batch [5/147] train loss: 547.50, train corr: -0.01949
Epoch [57/100], Batch [6/147] train loss: 564.38, train corr: -0.00917
Epoch [57/100], Batch [7/147] train loss: 566.56, train corr: -0.00619
Epoch [57/100], Batch [8/147] train loss: 569.21, train corr: 0.00645
Epoch [57/100], Batch [9/147] train loss: 583.40, train corr: -0.00216
Epoch [57/100], Batch [10/147] train loss: 555.10, train corr: -0.01652
Epoch [57/100], Batch [11/147] train loss: 577.38, train corr: -0.01341
Epoch [57/100], Batch [12/147] train loss: 577.47, train corr: -0.01001
Epoch [57/100], Batch [13/147] train loss: 559.10, train corr: -0.00011
Epoch [57/100], Batch [14/147] train loss: 573.80, train corr: 0.01350
Epoch [57/100], Batch [15/147] train loss: 550.99, train corr: 0.00082
Epoch [57/100], Batch [16/147] train loss: 550.95, train corr: -0.01050
Epoch [57/100], Batch [17/147] train loss: 566.10, train corr: -0.01098
Epoch [57/100], Batch [18/147] train loss: 558.04, train corr: -0.00951
Epoch [57/100], Batch [19/147] train loss: 811.22, train corr: -0.01000
Epoch [57/100], Batch [20/147] train loss: 579.11, train corr: -0.02139
Epoch [57/100], Batch [21/147] train loss: 570.39, train corr: 0.02586
Epoch [57/100], Batch [22/147] train loss: 581.47, train corr: 0.02837
Epoch [57/100], Batch [23/147] train loss: 589.54, train corr: 0.02439
Epoch [57/100], Batch [24/147] train loss: 590.61, train corr: 0.02640
Epoch [57/100], Batch [25/147] train loss: 583.70, train corr: 0.02773
Epoch [57/100], Batch [26/147] train loss: 623.79, train corr: 0.02671
Epoch [57/100], Batch [27/147] train loss: 568.90, train corr: 0.02800
Epoch [57/100], Batch [28/147] train loss: 583.53, train corr: 0.02262
Epoch [57/100], Batch [29/147] train loss: 585.09, train corr: 0.02412
Epoch [57/100], Batch [30/147] train loss: 571.14, train corr: 0.02923
Epoch [57/100], Batch [31/147] train loss: 559.63, train corr: -0.02147
Epoch [57/100], Batch [32/147] train loss: 587.59, train corr: -0.02012
Epoch [57/100], Batch [33/147] train loss: 753.22, train corr: -0.01546
Epoch [57/100], Batch [34/147] train loss: 578.20, train corr: -0.02697
Epoch [57/100], Batch [35/147] train loss: 574.69, train corr: -0.02409
Epoch [57/100], Batch [36/147] train loss: 551.10, train corr: -0.02721
Epoch [57/100], Batch [37/147] train loss: 568.16, train corr: -0.01803
Epoch [57/100], Batch [38/147] train loss: 589.76, train corr: 0.02895
Epoch [57/100], Batch [39/147] train loss: 572.60, train corr: 0.02916
Epoch [57/100], Batch [40/147] train loss: 571.02, train corr: 0.03115
Epoch [57/100], Batch [41/147] train loss: 560.65, train corr: -0.01247
Epoch [57/100], Batch [42/147] train loss: 572.35, train corr: -0.01844
Epoch [57/100], Batch [43/147] train loss: 566.51, train corr: 0.02889
Epoch [57/100], Batch [44/147] train loss: 575.93, train corr: 0.03176
Epoch [57/100], Batch [45/147] train loss: 570.79, train corr: 0.03121
Epoch [57/100], Batch [46/147] train loss: 574.50, train corr: 0.03192
Epoch [57/100], Batch [47/147] train loss: 553.78, train corr: -0.02441
Epoch [57/100], Batch [48/147] train loss: 568.97, train corr: -0.02639
Epoch [57/100], Batch [49/147] train loss: 573.53, train corr: -0.01874
Epoch [57/100], Batch [50/147] train loss: 567.60, train corr: 0.01308
Epoch [57/100], Batch [51/147] train loss: 559.42, train corr: 0.02229
Epoch [57/100], Batch [52/147] train loss: 553.97, train corr: 0.00252
Epoch [57/100], Batch [53/147] train loss: 567.83, train corr: -0.02579
Epoch [57/100], Batch [54/147] train loss: 570.48, train corr: -0.02315
Epoch [57/100], Batch [55/147] train loss: 556.65, train corr: -0.02196
Epoch [57/100], Batch [56/147] train loss: 587.86, train corr: 0.02526
Epoch [57/100], Batch [57/147] train loss: 581.11, train corr: 0.02750
Epoch [57/100], Batch [58/147] train loss: 559.26, train corr: 0.02862
Epoch [57/100], Batch [59/147] train loss: 560.68, train corr: -0.00372
Epoch [57/100], Batch [60/147] train loss: 569.00, train corr: -0.01611
Epoch [57/100], Batch [61/147] train loss: 574.66, train corr: -0.01633
Epoch [57/100], Batch [62/147] train loss: 566.47, train corr: -0.01606
Epoch [57/100], Batch [63/147] train loss: 563.12, train corr: -0.00903
Epoch [57/100], Batch [64/147] train loss: 570.91, train corr: -0.01762
Epoch [57/100], Batch [65/147] train loss: 567.19, train corr: -0.02496
Epoch [57/100], Batch [66/147] train loss: 563.66, train corr: -0.02352
Epoch [57/100], Batch [67/147] train loss: 559.71, train corr: -0.02159
Epoch [57/100], Batch [68/147] train loss: 559.06, train corr: -0.00134
Epoch [57/100], Batch [69/147] train loss: 573.84, train corr: 0.02909
Epoch [57/100], Batch [70/147] train loss: 563.69, train corr: 0.02515
Epoch [57/100], Batch [71/147] train loss: 574.55, train corr: 0.00132
Epoch [57/100], Batch [72/147] train loss: 562.63, train corr: -0.01033
Epoch [57/100], Batch [73/147] train loss: 571.09, train corr: -0.00429
Epoch [57/100], Batch [74/147] train loss: 581.94, train corr: 0.01125
Epoch [57/100], Batch [75/147] train loss: 572.46, train corr: 0.01307
Epoch [57/100], Batch [76/147] train loss: 559.64, train corr: 0.00170
Epoch [57/100], Batch [77/147] train loss: 564.24, train corr: -0.01214
Epoch [57/100], Batch [78/147] train loss: 568.95, train corr: -0.01329
Epoch [57/100], Batch [79/147] train loss: 575.15, train corr: -0.01267
Epoch [57/100], Batch [80/147] train loss: 566.93, train corr: -0.00873
Epoch [57/100], Batch [81/147] train loss: 581.77, train corr: 0.00060
Epoch [57/100], Batch [82/147] train loss: 561.35, train corr: -0.00296
Epoch [57/100], Batch [83/147] train loss: 630.48, train corr: -0.00832
Epoch [57/100], Batch [84/147] train loss: 567.34, train corr: 0.00319
Epoch [57/100], Batch [85/147] train loss: 569.66, train corr: 0.01001
Epoch [57/100], Batch [86/147] train loss: 557.02, train corr: 0.00640
Epoch [57/100], Batch [87/147] train loss: 585.58, train corr: -0.00986
Epoch [57/100], Batch [88/147] train loss: 549.04, train corr: -0.01962
Epoch [57/100], Batch [89/147] train loss: 550.14, train corr: -0.02263
Epoch [57/100], Batch [90/147] train loss: 563.20, train corr: -0.02428
Epoch [57/100], Batch [91/147] train loss: 585.26, train corr: -0.02035
Epoch [57/100], Batch [92/147] train loss: 574.25, train corr: -0.02035
Epoch [57/100], Batch [93/147] train loss: 560.84, train corr: -0.02462
Epoch [57/100], Batch [94/147] train loss: 584.25, train corr: -0.01676
Epoch [57/100], Batch [95/147] train loss: 567.31, train corr: -0.02284
Epoch [57/100], Batch [96/147] train loss: 564.32, train corr: -0.01756
Epoch [57/100], Batch [97/147] train loss: 570.55, train corr: -0.00975
Epoch [57/100], Batch [98/147] train loss: 569.17, train corr: -0.00582
Epoch [57/100], Batch [99/147] train loss: 579.43, train corr: -0.00820
Epoch [57/100], Batch [100/147] train loss: 544.52, train corr: -0.01220
Epoch [57/100], Batch [101/147] train loss: 582.80, train corr: 0.00514
Epoch [57/100], Batch [102/147] train loss: 568.70, train corr: 0.01308
Epoch [57/100], Batch [103/147] train loss: 563.84, train corr: -0.00177
Epoch [57/100], Batch [104/147] train loss: 575.59, train corr: -0.00980
Epoch [57/100], Batch [105/147] train loss: 558.28, train corr: -0.01691
Epoch [57/100], Batch [106/147] train loss: 583.42, train corr: -0.00900
Epoch [57/100], Batch [107/147] train loss: 564.31, train corr: -0.00326
Epoch [57/100], Batch [108/147] train loss: 559.56, train corr: -0.00099
Epoch [57/100], Batch [109/147] train loss: 553.69, train corr: -0.00723
Epoch [57/100], Batch [110/147] train loss: 561.95, train corr: -0.01380
Epoch [57/100], Batch [111/147] train loss: 551.36, train corr: -0.01568
Epoch [57/100], Batch [112/147] train loss: 566.60, train corr: -0.00742
Epoch [57/100], Batch [113/147] train loss: 565.62, train corr: 0.00583
Epoch [57/100], Batch [114/147] train loss: 646.83, train corr: 0.00306
Epoch [57/100], Batch [115/147] train loss: 584.09, train corr: -0.01557
Epoch [57/100], Batch [116/147] train loss: 560.38, train corr: 0.01420
Epoch [57/100], Batch [117/147] train loss: 554.51, train corr: 0.03273
Epoch [57/100], Batch [118/147] train loss: 573.17, train corr: 0.02910
Epoch [57/100], Batch [119/147] train loss: 569.30, train corr: 0.03063
Epoch [57/100], Batch [120/147] train loss: 563.87, train corr: 0.02628
Epoch [57/100], Batch [121/147] train loss: 579.03, train corr: -0.02400
Epoch [57/100], Batch [122/147] train loss: 563.93, train corr: -0.02615
Epoch [57/100], Batch [123/147] train loss: 581.76, train corr: 0.01550
Epoch [57/100], Batch [124/147] train loss: 563.61, train corr: 0.02417
Epoch [57/100], Batch [125/147] train loss: 574.31, train corr: 0.01834
Epoch [57/100], Batch [126/147] train loss: 564.09, train corr: -0.02385
Epoch [57/100], Batch [127/147] train loss: 566.90, train corr: -0.02541
Epoch [57/100], Batch [128/147] train loss: 582.71, train corr: -0.02260
Epoch [57/100], Batch [129/147] train loss: 564.50, train corr: 0.01709
Epoch [57/100], Batch [130/147] train loss: 584.65, train corr: 0.02471
Epoch [57/100], Batch [131/147] train loss: 570.00, train corr: 0.02970
Epoch [57/100], Batch [132/147] train loss: 544.05, train corr: 0.01144
Epoch [57/100], Batch [133/147] train loss: 571.51, train corr: -0.02190
Epoch [57/100], Batch [134/147] train loss: 561.68, train corr: -0.02039
Epoch [57/100], Batch [135/147] train loss: 586.35, train corr: -0.00436
Epoch [57/100], Batch [136/147] train loss: 573.46, train corr: 0.02196
Epoch [57/100], Batch [137/147] train loss: 563.97, train corr: -0.00284
Epoch [57/100], Batch [138/147] train loss: 574.10, train corr: -0.01941
Epoch [57/100], Batch [139/147] train loss: 569.73, train corr: -0.01930
Epoch [57/100], Batch [140/147] train loss: 559.08, train corr: -0.02136
Epoch [57/100], Batch [141/147] train loss: 561.03, train corr: 0.00808
Epoch [57/100], Batch [142/147] train loss: 583.40, train corr: 0.03078
Epoch [57/100], Batch [143/147] train loss: 565.85, train corr: 0.02560
Epoch [57/100], Batch [144/147] train loss: 562.28, train corr: -0.00465
Epoch [57/100], Batch [145/147] train loss: 558.98, train corr: -0.01858
Epoch [57/100], Batch [146/147] train loss: 570.17, train corr: -0.00856
Epoch [57/100], Batch [147/147] train loss: 577.60, train corr: -0.00223
Epoch [57/100], validation loss: 596.81, validation correlation: 0.01235
Epoch [58/100], Batch [1/147] train loss: 553.04, train corr: 0.01033
Epoch [58/100], Batch [2/147] train loss: 555.98, train corr: -0.00176
Epoch [58/100], Batch [3/147] train loss: 554.30, train corr: -0.01470
Epoch [58/100], Batch [4/147] train loss: 570.10, train corr: -0.01315
Epoch [58/100], Batch [5/147] train loss: 561.35, train corr: -0.01566
Epoch [58/100], Batch [6/147] train loss: 564.52, train corr: -0.00194
Epoch [58/100], Batch [7/147] train loss: 572.40, train corr: 0.00921
Epoch [58/100], Batch [8/147] train loss: 560.13, train corr: -0.00517
Epoch [58/100], Batch [9/147] train loss: 560.67, train corr: -0.01192
Epoch [58/100], Batch [10/147] train loss: 557.11, train corr: -0.01623
Epoch [58/100], Batch [11/147] train loss: 575.65, train corr: -0.00976
Epoch [58/100], Batch [12/147] train loss: 571.94, train corr: -0.00895
Epoch [58/100], Batch [13/147] train loss: 562.66, train corr: -0.01170
Epoch [58/100], Batch [14/147] train loss: 572.42, train corr: -0.00575
Epoch [58/100], Batch [15/147] train loss: 559.54, train corr: -0.01388
Epoch [58/100], Batch [16/147] train loss: 563.23, train corr: -0.01471
Epoch [58/100], Batch [17/147] train loss: 552.56, train corr: -0.01537
Epoch [58/100], Batch [18/147] train loss: 565.02, train corr: -0.00832
Epoch [58/100], Batch [19/147] train loss: 571.45, train corr: -0.00757
Epoch [58/100], Batch [20/147] train loss: 563.54, train corr: -0.01260
Epoch [58/100], Batch [21/147] train loss: 567.68, train corr: -0.01729
Epoch [58/100], Batch [22/147] train loss: 556.62, train corr: -0.01794
Epoch [58/100], Batch [23/147] train loss: 576.67, train corr: -0.01299
Epoch [58/100], Batch [24/147] train loss: 563.62, train corr: -0.01641
Epoch [58/100], Batch [25/147] train loss: 563.29, train corr: -0.01703
Epoch [58/100], Batch [26/147] train loss: 549.92, train corr: -0.01728
Epoch [58/100], Batch [27/147] train loss: 579.95, train corr: -0.01305
Epoch [58/100], Batch [28/147] train loss: 563.19, train corr: -0.00634
Epoch [58/100], Batch [29/147] train loss: 581.60, train corr: -0.00161
Epoch [58/100], Batch [30/147] train loss: 572.23, train corr: -0.01063
Epoch [58/100], Batch [31/147] train loss: 568.89, train corr: -0.01670
Epoch [58/100], Batch [32/147] train loss: 560.23, train corr: -0.01555
Epoch [58/100], Batch [33/147] train loss: 564.73, train corr: -0.01350
Epoch [58/100], Batch [34/147] train loss: 557.18, train corr: -0.00904
Epoch [58/100], Batch [35/147] train loss: 639.17, train corr: -0.01039
Epoch [58/100], Batch [36/147] train loss: 569.35, train corr: -0.02398
Epoch [58/100], Batch [37/147] train loss: 565.37, train corr: 0.03370
Epoch [58/100], Batch [38/147] train loss: 582.01, train corr: 0.02601
Epoch [58/100], Batch [39/147] train loss: 566.99, train corr: 0.02909
Epoch [58/100], Batch [40/147] train loss: 569.80, train corr: 0.03008
Epoch [58/100], Batch [41/147] train loss: 576.01, train corr: 0.01326
Epoch [58/100], Batch [42/147] train loss: 563.92, train corr: -0.02372
Epoch [58/100], Batch [43/147] train loss: 558.92, train corr: -0.01976
Epoch [58/100], Batch [44/147] train loss: 751.86, train corr: 0.02306
Epoch [58/100], Batch [45/147] train loss: 555.62, train corr: -0.02678
Epoch [58/100], Batch [46/147] train loss: 578.56, train corr: -0.02323
Epoch [58/100], Batch [47/147] train loss: 570.02, train corr: 0.02373
Epoch [58/100], Batch [48/147] train loss: 551.77, train corr: 0.02839
Epoch [58/100], Batch [49/147] train loss: 566.27, train corr: 0.03014
Epoch [58/100], Batch [50/147] train loss: 573.13, train corr: 0.02864
Epoch [58/100], Batch [51/147] train loss: 557.78, train corr: -0.01954
Epoch [58/100], Batch [52/147] train loss: 568.40, train corr: -0.01742
Epoch [58/100], Batch [53/147] train loss: 557.47, train corr: 0.02506
Epoch [58/100], Batch [54/147] train loss: 553.85, train corr: 0.03364
Epoch [58/100], Batch [55/147] train loss: 564.55, train corr: 0.03204
Epoch [58/100], Batch [56/147] train loss: 586.36, train corr: 0.02990
Epoch [58/100], Batch [57/147] train loss: 574.38, train corr: -0.01625
Epoch [58/100], Batch [58/147] train loss: 563.41, train corr: -0.01377
Epoch [58/100], Batch [59/147] train loss: 620.27, train corr: 0.00211
Epoch [58/100], Batch [60/147] train loss: 582.38, train corr: 0.03040
Epoch [58/100], Batch [61/147] train loss: 563.82, train corr: 0.03019
Epoch [58/100], Batch [62/147] train loss: 586.73, train corr: -0.00769
Epoch [58/100], Batch [63/147] train loss: 571.70, train corr: -0.01727
Epoch [58/100], Batch [64/147] train loss: 554.48, train corr: -0.01624
Epoch [58/100], Batch [65/147] train loss: 564.34, train corr: 0.02792
Epoch [58/100], Batch [66/147] train loss: 570.40, train corr: 0.02923
Epoch [58/100], Batch [67/147] train loss: 569.60, train corr: 0.03138
Epoch [58/100], Batch [68/147] train loss: 564.78, train corr: -0.01880
Epoch [58/100], Batch [69/147] train loss: 564.73, train corr: -0.02022
Epoch [58/100], Batch [70/147] train loss: 554.71, train corr: -0.02125
Epoch [58/100], Batch [71/147] train loss: 566.44, train corr: -0.01450
Epoch [58/100], Batch [72/147] train loss: 591.24, train corr: -0.00452
Epoch [58/100], Batch [73/147] train loss: 572.92, train corr: -0.01255
Epoch [58/100], Batch [74/147] train loss: 570.54, train corr: -0.02000
Epoch [58/100], Batch [75/147] train loss: 562.82, train corr: -0.01862
Epoch [58/100], Batch [76/147] train loss: 576.16, train corr: -0.01064
Epoch [58/100], Batch [77/147] train loss: 560.39, train corr: 0.01365
Epoch [58/100], Batch [78/147] train loss: 572.85, train corr: 0.01257
Epoch [58/100], Batch [79/147] train loss: 649.99, train corr: -0.00485
Epoch [58/100], Batch [80/147] train loss: 577.20, train corr: -0.01234
Epoch [58/100], Batch [81/147] train loss: 551.84, train corr: -0.01282
Epoch [58/100], Batch [82/147] train loss: 561.03, train corr: -0.00155
Epoch [58/100], Batch [83/147] train loss: 573.90, train corr: 0.00338
Epoch [58/100], Batch [84/147] train loss: 581.74, train corr: -0.00093
Epoch [58/100], Batch [85/147] train loss: 560.15, train corr: -0.01985
Epoch [58/100], Batch [86/147] train loss: 555.32, train corr: -0.02131
Epoch [58/100], Batch [87/147] train loss: 568.58, train corr: -0.01628
Epoch [58/100], Batch [88/147] train loss: 552.40, train corr: -0.00495
Epoch [58/100], Batch [89/147] train loss: 577.99, train corr: 0.01167
Epoch [58/100], Batch [90/147] train loss: 578.02, train corr: -0.00548
Epoch [58/100], Batch [91/147] train loss: 576.37, train corr: -0.01723
Epoch [58/100], Batch [92/147] train loss: 569.75, train corr: -0.01806
Epoch [58/100], Batch [93/147] train loss: 563.00, train corr: -0.01613
Epoch [58/100], Batch [94/147] train loss: 564.91, train corr: 0.00281
Epoch [58/100], Batch [95/147] train loss: 575.31, train corr: 0.01391
Epoch [58/100], Batch [96/147] train loss: 575.65, train corr: 0.00257
Epoch [58/100], Batch [97/147] train loss: 577.43, train corr: -0.00933
Epoch [58/100], Batch [98/147] train loss: 557.16, train corr: -0.01287
Epoch [58/100], Batch [99/147] train loss: 551.43, train corr: -0.00555
Epoch [58/100], Batch [100/147] train loss: 572.62, train corr: -0.00672
Epoch [58/100], Batch [101/147] train loss: 580.30, train corr: -0.00816
Epoch [58/100], Batch [102/147] train loss: 557.98, train corr: -0.02076
Epoch [58/100], Batch [103/147] train loss: 564.21, train corr: -0.01838
Epoch [58/100], Batch [104/147] train loss: 574.45, train corr: -0.01371
Epoch [58/100], Batch [105/147] train loss: 555.21, train corr: -0.01443
Epoch [58/100], Batch [106/147] train loss: 553.28, train corr: -0.01033
Epoch [58/100], Batch [107/147] train loss: 556.09, train corr: -0.01323
Epoch [58/100], Batch [108/147] train loss: 560.06, train corr: -0.01243
Epoch [58/100], Batch [109/147] train loss: 569.01, train corr: -0.00753
Epoch [58/100], Batch [110/147] train loss: 577.59, train corr: -0.00730
Epoch [58/100], Batch [111/147] train loss: 569.58, train corr: -0.00454
Epoch [58/100], Batch [112/147] train loss: 566.26, train corr: -0.01112
Epoch [58/100], Batch [113/147] train loss: 580.91, train corr: -0.00501
Epoch [58/100], Batch [114/147] train loss: 554.49, train corr: -0.01431
Epoch [58/100], Batch [115/147] train loss: 568.54, train corr: -0.00791
Epoch [58/100], Batch [116/147] train loss: 558.61, train corr: -0.00907
Epoch [58/100], Batch [117/147] train loss: 570.35, train corr: -0.00888
Epoch [58/100], Batch [118/147] train loss: 556.43, train corr: -0.01384
Epoch [58/100], Batch [119/147] train loss: 568.36, train corr: -0.01179
Epoch [58/100], Batch [120/147] train loss: 565.78, train corr: -0.01364
Epoch [58/100], Batch [121/147] train loss: 573.63, train corr: -0.00297
Epoch [58/100], Batch [122/147] train loss: 559.37, train corr: -0.00624
Epoch [58/100], Batch [123/147] train loss: 564.31, train corr: -0.01614
Epoch [58/100], Batch [124/147] train loss: 568.60, train corr: -0.01856
Epoch [58/100], Batch [125/147] train loss: 580.39, train corr: -0.01063
Epoch [58/100], Batch [126/147] train loss: 551.61, train corr: -0.01144
Epoch [58/100], Batch [127/147] train loss: 563.91, train corr: -0.00072
Epoch [58/100], Batch [128/147] train loss: 562.18, train corr: -0.01198
Epoch [58/100], Batch [129/147] train loss: 565.05, train corr: -0.01499
Epoch [58/100], Batch [130/147] train loss: 580.89, train corr: -0.01205
Epoch [58/100], Batch [131/147] train loss: 566.63, train corr: -0.01855
Epoch [58/100], Batch [132/147] train loss: 572.87, train corr: -0.00966
Epoch [58/100], Batch [133/147] train loss: 813.81, train corr: -0.00735
Epoch [58/100], Batch [134/147] train loss: 596.43, train corr: -0.02490
Epoch [58/100], Batch [135/147] train loss: 583.37, train corr: 0.02722
Epoch [58/100], Batch [136/147] train loss: 632.66, train corr: 0.02572
Epoch [58/100], Batch [137/147] train loss: 663.22, train corr: 0.02614
Epoch [58/100], Batch [138/147] train loss: 674.99, train corr: 0.02420
Epoch [58/100], Batch [139/147] train loss: 693.30, train corr: 0.01796
Epoch [58/100], Batch [140/147] train loss: 697.94, train corr: 0.02275
Epoch [58/100], Batch [141/147] train loss: 690.26, train corr: 0.02607
Epoch [58/100], Batch [142/147] train loss: 672.62, train corr: 0.02767
Epoch [58/100], Batch [143/147] train loss: 651.93, train corr: 0.02595
Epoch [58/100], Batch [144/147] train loss: 678.71, train corr: 0.02553
Epoch [58/100], Batch [145/147] train loss: 665.39, train corr: 0.02463
Epoch [58/100], Batch [146/147] train loss: 665.19, train corr: 0.02395
Epoch [58/100], Batch [147/147] train loss: 661.94, train corr: 0.02642
Epoch [58/100], validation loss: 681.82, validation correlation: 0.02744
Epoch [59/100], Batch [1/147] train loss: 660.44, train corr: 0.02570
Epoch [59/100], Batch [2/147] train loss: 637.29, train corr: 0.02873
Epoch [59/100], Batch [3/147] train loss: 654.20, train corr: 0.02063
Epoch [59/100], Batch [4/147] train loss: 627.13, train corr: 0.02662
Epoch [59/100], Batch [5/147] train loss: 624.71, train corr: 0.02802
Epoch [59/100], Batch [6/147] train loss: 601.23, train corr: 0.03009
Epoch [59/100], Batch [7/147] train loss: 602.83, train corr: 0.02969
Epoch [59/100], Batch [8/147] train loss: 598.69, train corr: 0.02693
Epoch [59/100], Batch [9/147] train loss: 604.94, train corr: 0.02289
Epoch [59/100], Batch [10/147] train loss: 576.23, train corr: 0.02842
Epoch [59/100], Batch [11/147] train loss: 659.45, train corr: 0.02560
Epoch [59/100], Batch [12/147] train loss: 676.04, train corr: 0.02586
Epoch [59/100], Batch [13/147] train loss: 632.47, train corr: 0.02346
Epoch [59/100], Batch [14/147] train loss: 624.42, train corr: 0.02874
Epoch [59/100], Batch [15/147] train loss: 645.96, train corr: 0.02625
Epoch [59/100], Batch [16/147] train loss: 650.42, train corr: 0.02548
Epoch [59/100], Batch [17/147] train loss: 654.15, train corr: 0.02857
Epoch [59/100], Batch [18/147] train loss: 641.84, train corr: 0.02574
Epoch [59/100], Batch [19/147] train loss: 613.54, train corr: 0.02864
Epoch [59/100], Batch [20/147] train loss: 619.61, train corr: 0.02554
Epoch [59/100], Batch [21/147] train loss: 617.69, train corr: 0.02861
Epoch [59/100], Batch [22/147] train loss: 641.23, train corr: 0.02454
Epoch [59/100], Batch [23/147] train loss: 619.89, train corr: 0.02745
Epoch [59/100], Batch [24/147] train loss: 622.34, train corr: 0.02690
Epoch [59/100], Batch [25/147] train loss: 617.74, train corr: 0.02568
Epoch [59/100], Batch [26/147] train loss: 599.91, train corr: 0.02880
Epoch [59/100], Batch [27/147] train loss: 606.34, train corr: 0.02642
Epoch [59/100], Batch [28/147] train loss: 700.98, train corr: 0.02603
Epoch [59/100], Batch [29/147] train loss: 598.24, train corr: 0.02634
Epoch [59/100], Batch [30/147] train loss: 596.84, train corr: 0.02483
Epoch [59/100], Batch [31/147] train loss: 574.37, train corr: 0.02665
Epoch [59/100], Batch [32/147] train loss: 571.62, train corr: 0.02810
Epoch [59/100], Batch [33/147] train loss: 572.37, train corr: -0.01640
Epoch [59/100], Batch [34/147] train loss: 587.21, train corr: -0.01701
Epoch [59/100], Batch [35/147] train loss: 570.77, train corr: 0.02684
Epoch [59/100], Batch [36/147] train loss: 592.26, train corr: 0.02705
Epoch [59/100], Batch [37/147] train loss: 574.43, train corr: 0.02701
Epoch [59/100], Batch [38/147] train loss: 579.03, train corr: 0.02836
Epoch [59/100], Batch [39/147] train loss: 584.33, train corr: 0.01838
Epoch [59/100], Batch [40/147] train loss: 566.28, train corr: -0.00477
Epoch [59/100], Batch [41/147] train loss: 566.67, train corr: 0.02901
Epoch [59/100], Batch [42/147] train loss: 581.87, train corr: 0.02910
Epoch [59/100], Batch [43/147] train loss: 567.61, train corr: 0.02875
Epoch [59/100], Batch [44/147] train loss: 554.59, train corr: 0.03145
Epoch [59/100], Batch [45/147] train loss: 578.51, train corr: 0.02599
Epoch [59/100], Batch [46/147] train loss: 569.48, train corr: 0.02888
Epoch [59/100], Batch [47/147] train loss: 580.26, train corr: 0.00341
Epoch [59/100], Batch [48/147] train loss: 572.10, train corr: -0.00671
Epoch [59/100], Batch [49/147] train loss: 585.73, train corr: 0.02602
Epoch [59/100], Batch [50/147] train loss: 559.98, train corr: 0.02693
Epoch [59/100], Batch [51/147] train loss: 582.01, train corr: 0.02806
Epoch [59/100], Batch [52/147] train loss: 572.07, train corr: 0.02664
Epoch [59/100], Batch [53/147] train loss: 577.95, train corr: 0.00226
Epoch [59/100], Batch [54/147] train loss: 566.55, train corr: -0.01272
Epoch [59/100], Batch [55/147] train loss: 556.32, train corr: 0.03193
Epoch [59/100], Batch [56/147] train loss: 822.77, train corr: 0.02557
Epoch [59/100], Batch [57/147] train loss: 582.67, train corr: -0.00351
Epoch [59/100], Batch [58/147] train loss: 560.78, train corr: -0.01675
Epoch [59/100], Batch [59/147] train loss: 553.42, train corr: 0.03136
Epoch [59/100], Batch [60/147] train loss: 581.77, train corr: 0.03080
Epoch [59/100], Batch [61/147] train loss: 593.54, train corr: 0.02742
Epoch [59/100], Batch [62/147] train loss: 575.21, train corr: 0.02905
Epoch [59/100], Batch [63/147] train loss: 568.67, train corr: 0.02970
Epoch [59/100], Batch [64/147] train loss: 567.81, train corr: 0.02906
Epoch [59/100], Batch [65/147] train loss: 581.86, train corr: 0.02875
Epoch [59/100], Batch [66/147] train loss: 574.86, train corr: 0.02991
Epoch [59/100], Batch [67/147] train loss: 564.19, train corr: -0.01591
Epoch [59/100], Batch [68/147] train loss: 596.62, train corr: -0.02215
Epoch [59/100], Batch [69/147] train loss: 575.22, train corr: -0.02945
Epoch [59/100], Batch [70/147] train loss: 575.56, train corr: -0.03281
Epoch [59/100], Batch [71/147] train loss: 573.71, train corr: -0.03289
Epoch [59/100], Batch [72/147] train loss: 571.25, train corr: -0.03363
Epoch [59/100], Batch [73/147] train loss: 563.66, train corr: -0.02976
Epoch [59/100], Batch [74/147] train loss: 554.56, train corr: -0.03205
Epoch [59/100], Batch [75/147] train loss: 549.63, train corr: 0.02108
Epoch [59/100], Batch [76/147] train loss: 565.15, train corr: 0.02546
Epoch [59/100], Batch [77/147] train loss: 556.76, train corr: 0.02753
Epoch [59/100], Batch [78/147] train loss: 576.61, train corr: 0.02591
Epoch [59/100], Batch [79/147] train loss: 561.30, train corr: 0.02956
Epoch [59/100], Batch [80/147] train loss: 561.46, train corr: 0.00334
Epoch [59/100], Batch [81/147] train loss: 570.87, train corr: -0.01985
Epoch [59/100], Batch [82/147] train loss: 570.53, train corr: -0.02375
Epoch [59/100], Batch [83/147] train loss: 566.09, train corr: -0.01374
Epoch [59/100], Batch [84/147] train loss: 561.43, train corr: -0.01052
Epoch [59/100], Batch [85/147] train loss: 571.21, train corr: -0.00965
Epoch [59/100], Batch [86/147] train loss: 580.13, train corr: -0.01071
Epoch [59/100], Batch [87/147] train loss: 564.10, train corr: -0.00630
Epoch [59/100], Batch [88/147] train loss: 568.94, train corr: 0.03076
Epoch [59/100], Batch [89/147] train loss: 564.06, train corr: 0.03074
Epoch [59/100], Batch [90/147] train loss: 567.52, train corr: 0.03047
Epoch [59/100], Batch [91/147] train loss: 582.73, train corr: 0.03089
Epoch [59/100], Batch [92/147] train loss: 568.89, train corr: 0.02843
Epoch [59/100], Batch [93/147] train loss: 572.78, train corr: -0.01733
Epoch [59/100], Batch [94/147] train loss: 567.58, train corr: -0.02315
Epoch [59/100], Batch [95/147] train loss: 753.42, train corr: -0.02109
Epoch [59/100], Batch [96/147] train loss: 565.43, train corr: -0.02380
Epoch [59/100], Batch [97/147] train loss: 553.22, train corr: 0.03135
Epoch [59/100], Batch [98/147] train loss: 585.49, train corr: 0.02450
Epoch [59/100], Batch [99/147] train loss: 565.09, train corr: 0.03009
Epoch [59/100], Batch [100/147] train loss: 556.55, train corr: 0.02808
Epoch [59/100], Batch [101/147] train loss: 568.13, train corr: 0.02983
Epoch [59/100], Batch [102/147] train loss: 575.71, train corr: 0.02984
Epoch [59/100], Batch [103/147] train loss: 558.69, train corr: 0.03143
Epoch [59/100], Batch [104/147] train loss: 564.19, train corr: -0.02630
Epoch [59/100], Batch [105/147] train loss: 565.42, train corr: 0.02414
Epoch [59/100], Batch [106/147] train loss: 570.70, train corr: 0.02761
Epoch [59/100], Batch [107/147] train loss: 578.12, train corr: 0.02850
Epoch [59/100], Batch [108/147] train loss: 571.26, train corr: 0.02658
Epoch [59/100], Batch [109/147] train loss: 574.52, train corr: 0.02814
Epoch [59/100], Batch [110/147] train loss: 565.27, train corr: 0.02816
Epoch [59/100], Batch [111/147] train loss: 555.91, train corr: -0.00810
Epoch [59/100], Batch [112/147] train loss: 548.12, train corr: -0.01336
Epoch [59/100], Batch [113/147] train loss: 560.40, train corr: 0.02929
Epoch [59/100], Batch [114/147] train loss: 551.15, train corr: 0.03032
Epoch [59/100], Batch [115/147] train loss: 585.62, train corr: 0.02652
Epoch [59/100], Batch [116/147] train loss: 579.85, train corr: 0.02918
Epoch [59/100], Batch [117/147] train loss: 577.70, train corr: -0.01764
Epoch [59/100], Batch [118/147] train loss: 569.94, train corr: -0.02383
Epoch [59/100], Batch [119/147] train loss: 577.27, train corr: 0.02627
Epoch [59/100], Batch [120/147] train loss: 602.78, train corr: 0.02287
Epoch [59/100], Batch [121/147] train loss: 571.94, train corr: 0.02956
Epoch [59/100], Batch [122/147] train loss: 569.61, train corr: 0.02887
Epoch [59/100], Batch [123/147] train loss: 571.13, train corr: 0.02802
Epoch [59/100], Batch [124/147] train loss: 580.01, train corr: 0.02821
Epoch [59/100], Batch [125/147] train loss: 556.33, train corr: 0.03113
Epoch [59/100], Batch [126/147] train loss: 584.18, train corr: -0.02280
Epoch [59/100], Batch [127/147] train loss: 566.27, train corr: -0.02824
Epoch [59/100], Batch [128/147] train loss: 570.76, train corr: 0.00136
Epoch [59/100], Batch [129/147] train loss: 563.44, train corr: 0.00765
Epoch [59/100], Batch [130/147] train loss: 574.00, train corr: -0.02766
Epoch [59/100], Batch [131/147] train loss: 575.56, train corr: -0.02849
Epoch [59/100], Batch [132/147] train loss: 581.40, train corr: -0.02572
Epoch [59/100], Batch [133/147] train loss: 568.21, train corr: 0.03244
Epoch [59/100], Batch [134/147] train loss: 567.30, train corr: 0.02971
Epoch [59/100], Batch [135/147] train loss: 569.39, train corr: 0.03224
Epoch [59/100], Batch [136/147] train loss: 561.41, train corr: 0.03121
Epoch [59/100], Batch [137/147] train loss: 545.34, train corr: 0.03113
Epoch [59/100], Batch [138/147] train loss: 577.30, train corr: 0.02828
Epoch [59/100], Batch [139/147] train loss: 557.33, train corr: -0.02340
Epoch [59/100], Batch [140/147] train loss: 562.35, train corr: -0.02541
Epoch [59/100], Batch [141/147] train loss: 557.35, train corr: -0.02481
Epoch [59/100], Batch [142/147] train loss: 569.12, train corr: -0.02623
Epoch [59/100], Batch [143/147] train loss: 564.21, train corr: -0.02615
Epoch [59/100], Batch [144/147] train loss: 568.38, train corr: -0.02491
Epoch [59/100], Batch [145/147] train loss: 562.36, train corr: -0.02485
Epoch [59/100], Batch [146/147] train loss: 560.60, train corr: 0.02317
Epoch [59/100], Batch [147/147] train loss: 561.43, train corr: 0.02932
Epoch [59/100], validation loss: 597.47, validation correlation: 0.03104
Epoch [60/100], Batch [1/147] train loss: 574.72, train corr: 0.03075
Epoch [60/100], Batch [2/147] train loss: 572.88, train corr: 0.02948
Epoch [60/100], Batch [3/147] train loss: 555.88, train corr: 0.02386
Epoch [60/100], Batch [4/147] train loss: 559.90, train corr: -0.01932
Epoch [60/100], Batch [5/147] train loss: 560.44, train corr: -0.01842
Epoch [60/100], Batch [6/147] train loss: 576.11, train corr: -0.00853
Epoch [60/100], Batch [7/147] train loss: 574.13, train corr: -0.00142
Epoch [60/100], Batch [8/147] train loss: 551.14, train corr: -0.01665
Epoch [60/100], Batch [9/147] train loss: 566.05, train corr: -0.01807
Epoch [60/100], Batch [10/147] train loss: 558.41, train corr: -0.02040
Epoch [60/100], Batch [11/147] train loss: 556.87, train corr: -0.00644
Epoch [60/100], Batch [12/147] train loss: 559.83, train corr: 0.02964
Epoch [60/100], Batch [13/147] train loss: 576.53, train corr: 0.03259
Epoch [60/100], Batch [14/147] train loss: 583.10, train corr: 0.02931
Epoch [60/100], Batch [15/147] train loss: 811.16, train corr: -0.00332
Epoch [60/100], Batch [16/147] train loss: 571.47, train corr: -0.02402
Epoch [60/100], Batch [17/147] train loss: 575.47, train corr: 0.02835
Epoch [60/100], Batch [18/147] train loss: 581.15, train corr: 0.02619
Epoch [60/100], Batch [19/147] train loss: 572.36, train corr: 0.02797
Epoch [60/100], Batch [20/147] train loss: 597.95, train corr: 0.02683
Epoch [60/100], Batch [21/147] train loss: 589.69, train corr: 0.02566
Epoch [60/100], Batch [22/147] train loss: 593.42, train corr: 0.02587
Epoch [60/100], Batch [23/147] train loss: 581.36, train corr: 0.02932
Epoch [60/100], Batch [24/147] train loss: 578.57, train corr: 0.02283
Epoch [60/100], Batch [25/147] train loss: 591.48, train corr: 0.02659
Epoch [60/100], Batch [26/147] train loss: 587.32, train corr: 0.02773
Epoch [60/100], Batch [27/147] train loss: 568.06, train corr: 0.02823
Epoch [60/100], Batch [28/147] train loss: 575.04, train corr: -0.02769
Epoch [60/100], Batch [29/147] train loss: 563.15, train corr: -0.02794
Epoch [60/100], Batch [30/147] train loss: 570.13, train corr: -0.01495
Epoch [60/100], Batch [31/147] train loss: 581.81, train corr: 0.02031
Epoch [60/100], Batch [32/147] train loss: 582.11, train corr: 0.02074
Epoch [60/100], Batch [33/147] train loss: 564.50, train corr: 0.02739
Epoch [60/100], Batch [34/147] train loss: 558.95, train corr: 0.03147
Epoch [60/100], Batch [35/147] train loss: 570.87, train corr: -0.01861
Epoch [60/100], Batch [36/147] train loss: 568.25, train corr: -0.01056
Epoch [60/100], Batch [37/147] train loss: 565.80, train corr: 0.03256
Epoch [60/100], Batch [38/147] train loss: 557.41, train corr: 0.03206
Epoch [60/100], Batch [39/147] train loss: 561.19, train corr: 0.03084
Epoch [60/100], Batch [40/147] train loss: 566.07, train corr: 0.03222
Epoch [60/100], Batch [41/147] train loss: 563.92, train corr: 0.03053
Epoch [60/100], Batch [42/147] train loss: 572.38, train corr: -0.01370
Epoch [60/100], Batch [43/147] train loss: 624.03, train corr: 0.02551
Epoch [60/100], Batch [44/147] train loss: 620.80, train corr: 0.02595
Epoch [60/100], Batch [45/147] train loss: 576.57, train corr: 0.02997
Epoch [60/100], Batch [46/147] train loss: 580.81, train corr: -0.00091
Epoch [60/100], Batch [47/147] train loss: 565.70, train corr: -0.02066
Epoch [60/100], Batch [48/147] train loss: 560.39, train corr: 0.00550
Epoch [60/100], Batch [49/147] train loss: 567.44, train corr: 0.02610
Epoch [60/100], Batch [50/147] train loss: 567.19, train corr: 0.02799
Epoch [60/100], Batch [51/147] train loss: 565.44, train corr: 0.02411
Epoch [60/100], Batch [52/147] train loss: 557.21, train corr: -0.02404
Epoch [60/100], Batch [53/147] train loss: 565.93, train corr: -0.02603
Epoch [60/100], Batch [54/147] train loss: 572.02, train corr: -0.02341
Epoch [60/100], Batch [55/147] train loss: 584.54, train corr: 0.02585
Epoch [60/100], Batch [56/147] train loss: 626.83, train corr: 0.02596
Epoch [60/100], Batch [57/147] train loss: 741.99, train corr: 0.02891
Epoch [60/100], Batch [58/147] train loss: 594.48, train corr: -0.01973
Epoch [60/100], Batch [59/147] train loss: 570.99, train corr: 0.02931
Epoch [60/100], Batch [60/147] train loss: 572.84, train corr: 0.02966
Epoch [60/100], Batch [61/147] train loss: 582.32, train corr: 0.02385
Epoch [60/100], Batch [62/147] train loss: 598.88, train corr: 0.02538
Epoch [60/100], Batch [63/147] train loss: 575.33, train corr: 0.02824
Epoch [60/100], Batch [64/147] train loss: 570.94, train corr: 0.02796
Epoch [60/100], Batch [65/147] train loss: 593.43, train corr: 0.02083
Epoch [60/100], Batch [66/147] train loss: 564.57, train corr: 0.02998
Epoch [60/100], Batch [67/147] train loss: 565.44, train corr: 0.02693
Epoch [60/100], Batch [68/147] train loss: 569.62, train corr: -0.02620
Epoch [60/100], Batch [69/147] train loss: 576.88, train corr: 0.02549
Epoch [60/100], Batch [70/147] train loss: 582.74, train corr: 0.02351
Epoch [60/100], Batch [71/147] train loss: 571.90, train corr: 0.02965
Epoch [60/100], Batch [72/147] train loss: 584.96, train corr: 0.02533
Epoch [60/100], Batch [73/147] train loss: 592.47, train corr: 0.02275
Epoch [60/100], Batch [74/147] train loss: 578.12, train corr: 0.02439
Epoch [60/100], Batch [75/147] train loss: 567.37, train corr: 0.02863
Epoch [60/100], Batch [76/147] train loss: 557.61, train corr: 0.02658
Epoch [60/100], Batch [77/147] train loss: 576.76, train corr: 0.02900
Epoch [60/100], Batch [78/147] train loss: 575.01, train corr: 0.02909
Epoch [60/100], Batch [79/147] train loss: 570.85, train corr: 0.03131
Epoch [60/100], Batch [80/147] train loss: 569.20, train corr: 0.02964
Epoch [60/100], Batch [81/147] train loss: 566.39, train corr: 0.02782
Epoch [60/100], Batch [82/147] train loss: 582.80, train corr: 0.02256
Epoch [60/100], Batch [83/147] train loss: 579.69, train corr: -0.02309
Epoch [60/100], Batch [84/147] train loss: 569.30, train corr: -0.02722
Epoch [60/100], Batch [85/147] train loss: 571.07, train corr: 0.02126
Epoch [60/100], Batch [86/147] train loss: 552.33, train corr: 0.03150
Epoch [60/100], Batch [87/147] train loss: 565.43, train corr: 0.03028
Epoch [60/100], Batch [88/147] train loss: 578.28, train corr: 0.03022
Epoch [60/100], Batch [89/147] train loss: 562.99, train corr: 0.02875
Epoch [60/100], Batch [90/147] train loss: 583.39, train corr: 0.02558
Epoch [60/100], Batch [91/147] train loss: 549.24, train corr: -0.01546
Epoch [60/100], Batch [92/147] train loss: 598.03, train corr: -0.02451
Epoch [60/100], Batch [93/147] train loss: 567.12, train corr: -0.02677
Epoch [60/100], Batch [94/147] train loss: 556.01, train corr: -0.02918
Epoch [60/100], Batch [95/147] train loss: 569.97, train corr: -0.02419
Epoch [60/100], Batch [96/147] train loss: 581.43, train corr: -0.02265
Epoch [60/100], Batch [97/147] train loss: 572.49, train corr: -0.02112
Epoch [60/100], Batch [98/147] train loss: 565.86, train corr: -0.01750
Epoch [60/100], Batch [99/147] train loss: 568.71, train corr: 0.02663
Epoch [60/100], Batch [100/147] train loss: 564.46, train corr: 0.03354
Epoch [60/100], Batch [101/147] train loss: 575.91, train corr: 0.02875
Epoch [60/100], Batch [102/147] train loss: 572.34, train corr: 0.03131
Epoch [60/100], Batch [103/147] train loss: 566.93, train corr: 0.03269
Epoch [60/100], Batch [104/147] train loss: 566.64, train corr: -0.00666
Epoch [60/100], Batch [105/147] train loss: 558.60, train corr: -0.02388
Epoch [60/100], Batch [106/147] train loss: 565.74, train corr: -0.02136
Epoch [60/100], Batch [107/147] train loss: 560.45, train corr: -0.01497
Epoch [60/100], Batch [108/147] train loss: 576.27, train corr: 0.01896
Epoch [60/100], Batch [109/147] train loss: 563.43, train corr: 0.01255
Epoch [60/100], Batch [110/147] train loss: 573.57, train corr: -0.01195
Epoch [60/100], Batch [111/147] train loss: 561.70, train corr: -0.01921
Epoch [60/100], Batch [112/147] train loss: 576.35, train corr: 0.00707
Epoch [60/100], Batch [113/147] train loss: 563.20, train corr: 0.03415
Epoch [60/100], Batch [114/147] train loss: 569.52, train corr: 0.02989
Epoch [60/100], Batch [115/147] train loss: 559.08, train corr: 0.03268
Epoch [60/100], Batch [116/147] train loss: 581.57, train corr: -0.00789
Epoch [60/100], Batch [117/147] train loss: 556.15, train corr: -0.02529
Epoch [60/100], Batch [118/147] train loss: 575.99, train corr: -0.02431
Epoch [60/100], Batch [119/147] train loss: 582.65, train corr: -0.01300
Epoch [60/100], Batch [120/147] train loss: 566.11, train corr: -0.00382
Epoch [60/100], Batch [121/147] train loss: 565.58, train corr: 0.01010
Epoch [60/100], Batch [122/147] train loss: 574.32, train corr: -0.00252
Epoch [60/100], Batch [123/147] train loss: 556.85, train corr: -0.01520
Epoch [60/100], Batch [124/147] train loss: 572.81, train corr: -0.00400
Epoch [60/100], Batch [125/147] train loss: 573.89, train corr: 0.02771
Epoch [60/100], Batch [126/147] train loss: 561.41, train corr: 0.03252
Epoch [60/100], Batch [127/147] train loss: 564.80, train corr: 0.02740
Epoch [60/100], Batch [128/147] train loss: 576.11, train corr: 0.00068
Epoch [60/100], Batch [129/147] train loss: 569.08, train corr: -0.01561
Epoch [60/100], Batch [130/147] train loss: 581.95, train corr: -0.01310
Epoch [60/100], Batch [131/147] train loss: 565.48, train corr: -0.00960
Epoch [60/100], Batch [132/147] train loss: 541.02, train corr: -0.00612
Epoch [60/100], Batch [133/147] train loss: 570.64, train corr: 0.00131
Epoch [60/100], Batch [134/147] train loss: 554.84, train corr: -0.00384
Epoch [60/100], Batch [135/147] train loss: 594.31, train corr: -0.00109
Epoch [60/100], Batch [136/147] train loss: 563.18, train corr: -0.00904
Epoch [60/100], Batch [137/147] train loss: 578.48, train corr: 0.00795
Epoch [60/100], Batch [138/147] train loss: 562.08, train corr: 0.01204
Epoch [60/100], Batch [139/147] train loss: 561.72, train corr: 0.00872
Epoch [60/100], Batch [140/147] train loss: 569.46, train corr: -0.01132
Epoch [60/100], Batch [141/147] train loss: 559.26, train corr: -0.02017
Epoch [60/100], Batch [142/147] train loss: 572.79, train corr: -0.01598
Epoch [60/100], Batch [143/147] train loss: 576.29, train corr: -0.01360
Epoch [60/100], Batch [144/147] train loss: 571.20, train corr: -0.00073
Epoch [60/100], Batch [145/147] train loss: 584.61, train corr: 0.01246
Epoch [60/100], Batch [146/147] train loss: 569.72, train corr: 0.00609
Epoch [60/100], Batch [147/147] train loss: 553.08, train corr: -0.00671
Epoch [60/100], validation loss: 596.81, validation correlation: -0.00702
Epoch [61/100], Batch [1/147] train loss: 573.17, train corr: -0.00579
Epoch [61/100], Batch [2/147] train loss: 578.04, train corr: -0.00143
Epoch [61/100], Batch [3/147] train loss: 563.04, train corr: 0.01337
Epoch [61/100], Batch [4/147] train loss: 569.71, train corr: 0.01012
Epoch [61/100], Batch [5/147] train loss: 559.20, train corr: -0.00659
Epoch [61/100], Batch [6/147] train loss: 566.01, train corr: -0.01241
Epoch [61/100], Batch [7/147] train loss: 572.50, train corr: -0.01336
Epoch [61/100], Batch [8/147] train loss: 587.91, train corr: -0.01413
Epoch [61/100], Batch [9/147] train loss: 565.94, train corr: -0.01962
Epoch [61/100], Batch [10/147] train loss: 563.27, train corr: -0.01463
Epoch [61/100], Batch [11/147] train loss: 551.48, train corr: -0.01182
Epoch [61/100], Batch [12/147] train loss: 570.18, train corr: 0.00098
Epoch [61/100], Batch [13/147] train loss: 569.07, train corr: -0.00039
Epoch [61/100], Batch [14/147] train loss: 549.22, train corr: -0.01248
Epoch [61/100], Batch [15/147] train loss: 565.88, train corr: -0.00973
Epoch [61/100], Batch [16/147] train loss: 574.71, train corr: -0.00361
Epoch [61/100], Batch [17/147] train loss: 607.51, train corr: -0.00749
Epoch [61/100], Batch [18/147] train loss: 589.89, train corr: 0.01008
Epoch [61/100], Batch [19/147] train loss: 572.09, train corr: 0.00234
Epoch [61/100], Batch [20/147] train loss: 573.01, train corr: -0.01071
Epoch [61/100], Batch [21/147] train loss: 577.21, train corr: -0.00857
Epoch [61/100], Batch [22/147] train loss: 572.46, train corr: -0.00791
Epoch [61/100], Batch [23/147] train loss: 555.99, train corr: -0.00231
Epoch [61/100], Batch [24/147] train loss: 567.94, train corr: 0.00355
Epoch [61/100], Batch [25/147] train loss: 560.08, train corr: -0.00244
Epoch [61/100], Batch [26/147] train loss: 562.11, train corr: -0.01351
Epoch [61/100], Batch [27/147] train loss: 576.51, train corr: -0.01485
Epoch [61/100], Batch [28/147] train loss: 561.16, train corr: -0.01150
Epoch [61/100], Batch [29/147] train loss: 564.83, train corr: -0.00227
Epoch [61/100], Batch [30/147] train loss: 561.27, train corr: -0.00010
Epoch [61/100], Batch [31/147] train loss: 551.62, train corr: -0.00626
Epoch [61/100], Batch [32/147] train loss: 558.45, train corr: -0.01605
Epoch [61/100], Batch [33/147] train loss: 567.56, train corr: -0.01288
Epoch [61/100], Batch [34/147] train loss: 550.71, train corr: -0.01504
Epoch [61/100], Batch [35/147] train loss: 578.99, train corr: -0.00623
Epoch [61/100], Batch [36/147] train loss: 577.58, train corr: -0.00576
Epoch [61/100], Batch [37/147] train loss: 552.34, train corr: -0.01216
Epoch [61/100], Batch [38/147] train loss: 576.01, train corr: -0.00476
Epoch [61/100], Batch [39/147] train loss: 564.15, train corr: -0.01053
Epoch [61/100], Batch [40/147] train loss: 566.35, train corr: -0.00491
Epoch [61/100], Batch [41/147] train loss: 568.22, train corr: -0.00256
Epoch [61/100], Batch [42/147] train loss: 569.99, train corr: -0.00325
Epoch [61/100], Batch [43/147] train loss: 580.06, train corr: -0.00313
Epoch [61/100], Batch [44/147] train loss: 565.33, train corr: 0.00014
Epoch [61/100], Batch [45/147] train loss: 567.67, train corr: 0.00289
Epoch [61/100], Batch [46/147] train loss: 557.00, train corr: 0.00513
Epoch [61/100], Batch [47/147] train loss: 564.56, train corr: 0.00482
Epoch [61/100], Batch [48/147] train loss: 641.77, train corr: -0.00023
Epoch [61/100], Batch [49/147] train loss: 551.98, train corr: -0.02148
Epoch [61/100], Batch [50/147] train loss: 572.98, train corr: -0.00111
Epoch [61/100], Batch [51/147] train loss: 560.59, train corr: 0.03417
Epoch [61/100], Batch [52/147] train loss: 553.45, train corr: 0.03277
Epoch [61/100], Batch [53/147] train loss: 881.47, train corr: 0.02366
Epoch [61/100], Batch [54/147] train loss: 635.44, train corr: -0.02162
Epoch [61/100], Batch [55/147] train loss: 614.26, train corr: 0.02611
Epoch [61/100], Batch [56/147] train loss: 694.53, train corr: 0.02745
Epoch [61/100], Batch [57/147] train loss: 778.64, train corr: 0.02669
Epoch [61/100], Batch [58/147] train loss: 801.38, train corr: 0.02661
Epoch [61/100], Batch [59/147] train loss: 824.06, train corr: 0.02671
Epoch [61/100], Batch [60/147] train loss: 812.74, train corr: 0.02749
Epoch [61/100], Batch [61/147] train loss: 830.91, train corr: 0.02708
Epoch [61/100], Batch [62/147] train loss: 783.47, train corr: 0.02822
Epoch [61/100], Batch [63/147] train loss: 794.58, train corr: 0.02677
Epoch [61/100], Batch [64/147] train loss: 758.23, train corr: 0.02683
Epoch [61/100], Batch [65/147] train loss: 789.76, train corr: 0.02739
Epoch [61/100], Batch [66/147] train loss: 791.87, train corr: 0.02865
Epoch [61/100], Batch [67/147] train loss: 799.35, train corr: 0.02645
Epoch [61/100], Batch [68/147] train loss: 788.55, train corr: 0.02801
Epoch [61/100], Batch [69/147] train loss: 785.21, train corr: 0.02708
Epoch [61/100], Batch [70/147] train loss: 806.96, train corr: 0.02250
Epoch [61/100], Batch [71/147] train loss: 751.66, train corr: 0.02763
Epoch [61/100], Batch [72/147] train loss: 754.50, train corr: 0.02877
Epoch [61/100], Batch [73/147] train loss: 734.37, train corr: 0.02532
Epoch [61/100], Batch [74/147] train loss: 756.30, train corr: 0.02414
Epoch [61/100], Batch [75/147] train loss: 725.66, train corr: 0.02350
Epoch [61/100], Batch [76/147] train loss: 711.37, train corr: 0.02676
Epoch [61/100], Batch [77/147] train loss: 711.24, train corr: 0.02701
Epoch [61/100], Batch [78/147] train loss: 711.10, train corr: 0.02489
Epoch [61/100], Batch [79/147] train loss: 685.85, train corr: 0.02833
Epoch [61/100], Batch [80/147] train loss: 686.42, train corr: 0.02557
Epoch [61/100], Batch [81/147] train loss: 684.84, train corr: 0.02623
Epoch [61/100], Batch [82/147] train loss: 687.30, train corr: 0.02352
Epoch [61/100], Batch [83/147] train loss: 668.15, train corr: 0.02731
Epoch [61/100], Batch [84/147] train loss: 645.59, train corr: 0.02799
Epoch [61/100], Batch [85/147] train loss: 624.41, train corr: 0.02716
Epoch [61/100], Batch [86/147] train loss: 629.02, train corr: 0.02744
Epoch [61/100], Batch [87/147] train loss: 630.48, train corr: 0.02339
Epoch [61/100], Batch [88/147] train loss: 605.16, train corr: 0.02849
Epoch [61/100], Batch [89/147] train loss: 605.82, train corr: 0.02532
Epoch [61/100], Batch [90/147] train loss: 638.53, train corr: 0.01986
Epoch [61/100], Batch [91/147] train loss: 602.26, train corr: 0.02385
Epoch [61/100], Batch [92/147] train loss: 598.59, train corr: 0.02838
Epoch [61/100], Batch [93/147] train loss: 598.81, train corr: 0.02593
Epoch [61/100], Batch [94/147] train loss: 601.80, train corr: 0.02677
Epoch [61/100], Batch [95/147] train loss: 574.43, train corr: 0.02897
Epoch [61/100], Batch [96/147] train loss: 589.17, train corr: 0.02860
Epoch [61/100], Batch [97/147] train loss: 578.81, train corr: 0.02841
Epoch [61/100], Batch [98/147] train loss: 568.27, train corr: 0.02409
Epoch [61/100], Batch [99/147] train loss: 580.96, train corr: -0.01480
Epoch [61/100], Batch [100/147] train loss: 567.26, train corr: -0.02468
Epoch [61/100], Batch [101/147] train loss: 588.05, train corr: 0.00707
Epoch [61/100], Batch [102/147] train loss: 565.16, train corr: 0.02860
Epoch [61/100], Batch [103/147] train loss: 573.58, train corr: 0.02867
Epoch [61/100], Batch [104/147] train loss: 571.28, train corr: 0.00244
Epoch [61/100], Batch [105/147] train loss: 583.22, train corr: 0.00307
Epoch [61/100], Batch [106/147] train loss: 576.65, train corr: 0.01686
Epoch [61/100], Batch [107/147] train loss: 573.59, train corr: 0.02202
Epoch [61/100], Batch [108/147] train loss: 572.84, train corr: 0.02138
Epoch [61/100], Batch [109/147] train loss: 579.68, train corr: 0.01510
Epoch [61/100], Batch [110/147] train loss: 552.76, train corr: -0.01943
Epoch [61/100], Batch [111/147] train loss: 568.48, train corr: -0.02517
Epoch [61/100], Batch [112/147] train loss: 555.78, train corr: 0.02685
Epoch [61/100], Batch [113/147] train loss: 565.15, train corr: 0.03250
Epoch [61/100], Batch [114/147] train loss: 571.91, train corr: 0.03166
Epoch [61/100], Batch [115/147] train loss: 572.46, train corr: 0.00793
Epoch [61/100], Batch [116/147] train loss: 583.54, train corr: -0.02014
Epoch [61/100], Batch [117/147] train loss: 575.18, train corr: 0.01849
Epoch [61/100], Batch [118/147] train loss: 581.83, train corr: 0.02494
Epoch [61/100], Batch [119/147] train loss: 741.20, train corr: 0.02068
Epoch [61/100], Batch [120/147] train loss: 576.31, train corr: -0.02531
Epoch [61/100], Batch [121/147] train loss: 576.25, train corr: 0.02068
Epoch [61/100], Batch [122/147] train loss: 562.03, train corr: 0.02713
Epoch [61/100], Batch [123/147] train loss: 576.43, train corr: 0.02784
Epoch [61/100], Batch [124/147] train loss: 585.11, train corr: 0.02320
Epoch [61/100], Batch [125/147] train loss: 570.47, train corr: 0.03002
Epoch [61/100], Batch [126/147] train loss: 568.75, train corr: -0.00974
Epoch [61/100], Batch [127/147] train loss: 586.39, train corr: -0.00563
Epoch [61/100], Batch [128/147] train loss: 567.29, train corr: 0.03094
Epoch [61/100], Batch [129/147] train loss: 560.71, train corr: 0.02730
Epoch [61/100], Batch [130/147] train loss: 561.07, train corr: 0.02482
Epoch [61/100], Batch [131/147] train loss: 571.59, train corr: -0.01725
Epoch [61/100], Batch [132/147] train loss: 557.41, train corr: -0.02822
Epoch [61/100], Batch [133/147] train loss: 561.06, train corr: 0.00356
Epoch [61/100], Batch [134/147] train loss: 568.16, train corr: 0.02527
Epoch [61/100], Batch [135/147] train loss: 564.59, train corr: 0.02862
Epoch [61/100], Batch [136/147] train loss: 572.22, train corr: 0.02882
Epoch [61/100], Batch [137/147] train loss: 578.81, train corr: 0.02880
Epoch [61/100], Batch [138/147] train loss: 558.01, train corr: 0.02884
Epoch [61/100], Batch [139/147] train loss: 568.82, train corr: 0.02709
Epoch [61/100], Batch [140/147] train loss: 559.27, train corr: 0.02770
Epoch [61/100], Batch [141/147] train loss: 574.01, train corr: -0.01023
Epoch [61/100], Batch [142/147] train loss: 572.62, train corr: -0.02559
Epoch [61/100], Batch [143/147] train loss: 578.36, train corr: -0.02854
Epoch [61/100], Batch [144/147] train loss: 562.75, train corr: -0.02023
Epoch [61/100], Batch [145/147] train loss: 563.24, train corr: 0.02311
Epoch [61/100], Batch [146/147] train loss: 566.15, train corr: 0.02920
Epoch [61/100], Batch [147/147] train loss: 586.05, train corr: 0.02889
Epoch [61/100], validation loss: 597.46, validation correlation: 0.03192
Epoch [62/100], Batch [1/147] train loss: 571.79, train corr: 0.03181
Epoch [62/100], Batch [2/147] train loss: 567.56, train corr: 0.03405
Epoch [62/100], Batch [3/147] train loss: 561.90, train corr: 0.03392
Epoch [62/100], Batch [4/147] train loss: 569.92, train corr: 0.03490
Epoch [62/100], Batch [5/147] train loss: 626.76, train corr: -0.00484
Epoch [62/100], Batch [6/147] train loss: 577.15, train corr: -0.01040
Epoch [62/100], Batch [7/147] train loss: 559.18, train corr: -0.00644
Epoch [62/100], Batch [8/147] train loss: 566.42, train corr: 0.01136
Epoch [62/100], Batch [9/147] train loss: 569.64, train corr: 0.02217
Epoch [62/100], Batch [10/147] train loss: 584.85, train corr: 0.01984
Epoch [62/100], Batch [11/147] train loss: 575.93, train corr: 0.02747
Epoch [62/100], Batch [12/147] train loss: 567.62, train corr: 0.03337
Epoch [62/100], Batch [13/147] train loss: 554.49, train corr: 0.03249
Epoch [62/100], Batch [14/147] train loss: 557.78, train corr: 0.03229
Epoch [62/100], Batch [15/147] train loss: 552.41, train corr: 0.00039
Epoch [62/100], Batch [16/147] train loss: 568.59, train corr: -0.01956
Epoch [62/100], Batch [17/147] train loss: 569.69, train corr: -0.02029
Epoch [62/100], Batch [18/147] train loss: 580.27, train corr: -0.01037
Epoch [62/100], Batch [19/147] train loss: 557.60, train corr: -0.00684
Epoch [62/100], Batch [20/147] train loss: 575.46, train corr: -0.01374
Epoch [62/100], Batch [21/147] train loss: 565.42, train corr: -0.01434
Epoch [62/100], Batch [22/147] train loss: 555.95, train corr: -0.00432
Epoch [62/100], Batch [23/147] train loss: 558.21, train corr: 0.02988
Epoch [62/100], Batch [24/147] train loss: 569.05, train corr: 0.02770
Epoch [62/100], Batch [25/147] train loss: 577.02, train corr: -0.00596
Epoch [62/100], Batch [26/147] train loss: 575.79, train corr: -0.02355
Epoch [62/100], Batch [27/147] train loss: 568.31, train corr: -0.02572
Epoch [62/100], Batch [28/147] train loss: 560.34, train corr: -0.01967
Epoch [62/100], Batch [29/147] train loss: 552.19, train corr: -0.01005
Epoch [62/100], Batch [30/147] train loss: 565.69, train corr: -0.00629
Epoch [62/100], Batch [31/147] train loss: 571.17, train corr: 0.00024
Epoch [62/100], Batch [32/147] train loss: 570.17, train corr: 0.00553
Epoch [62/100], Batch [33/147] train loss: 578.37, train corr: 0.03241
Epoch [62/100], Batch [34/147] train loss: 570.23, train corr: 0.03147
Epoch [62/100], Batch [35/147] train loss: 557.52, train corr: 0.02720
Epoch [62/100], Batch [36/147] train loss: 569.07, train corr: -0.00812
Epoch [62/100], Batch [37/147] train loss: 559.23, train corr: -0.01572
Epoch [62/100], Batch [38/147] train loss: 580.23, train corr: -0.00803
Epoch [62/100], Batch [39/147] train loss: 566.46, train corr: 0.01168
Epoch [62/100], Batch [40/147] train loss: 578.69, train corr: 0.01233
Epoch [62/100], Batch [41/147] train loss: 561.25, train corr: -0.00587
Epoch [62/100], Batch [42/147] train loss: 574.30, train corr: -0.00517
Epoch [62/100], Batch [43/147] train loss: 561.79, train corr: -0.00019
Epoch [62/100], Batch [44/147] train loss: 554.90, train corr: 0.02644
Epoch [62/100], Batch [45/147] train loss: 550.50, train corr: 0.03314
Epoch [62/100], Batch [46/147] train loss: 574.60, train corr: 0.03026
Epoch [62/100], Batch [47/147] train loss: 568.26, train corr: 0.01844
Epoch [62/100], Batch [48/147] train loss: 558.73, train corr: -0.00485
Epoch [62/100], Batch [49/147] train loss: 568.63, train corr: -0.00510
Epoch [62/100], Batch [50/147] train loss: 568.38, train corr: 0.00352
Epoch [62/100], Batch [51/147] train loss: 554.92, train corr: -0.00092
Epoch [62/100], Batch [52/147] train loss: 556.95, train corr: -0.00775
Epoch [62/100], Batch [53/147] train loss: 577.11, train corr: -0.00191
Epoch [62/100], Batch [54/147] train loss: 555.47, train corr: -0.00383
Epoch [62/100], Batch [55/147] train loss: 559.47, train corr: -0.00247
Epoch [62/100], Batch [56/147] train loss: 556.84, train corr: -0.00673
Epoch [62/100], Batch [57/147] train loss: 569.26, train corr: 0.01010
Epoch [62/100], Batch [58/147] train loss: 637.55, train corr: 0.00770
Epoch [62/100], Batch [59/147] train loss: 568.78, train corr: -0.02128
Epoch [62/100], Batch [60/147] train loss: 577.09, train corr: -0.02248
Epoch [62/100], Batch [61/147] train loss: 566.92, train corr: -0.01279
Epoch [62/100], Batch [62/147] train loss: 573.29, train corr: 0.02612
Epoch [62/100], Batch [63/147] train loss: 573.75, train corr: 0.03007
Epoch [62/100], Batch [64/147] train loss: 575.77, train corr: 0.00946
Epoch [62/100], Batch [65/147] train loss: 575.26, train corr: 0.00284
Epoch [62/100], Batch [66/147] train loss: 581.47, train corr: 0.02772
Epoch [62/100], Batch [67/147] train loss: 579.05, train corr: 0.03002
Epoch [62/100], Batch [68/147] train loss: 584.74, train corr: 0.03463
Epoch [62/100], Batch [69/147] train loss: 573.01, train corr: 0.02847
Epoch [62/100], Batch [70/147] train loss: 562.86, train corr: -0.00604
Epoch [62/100], Batch [71/147] train loss: 567.13, train corr: -0.01761
Epoch [62/100], Batch [72/147] train loss: 556.62, train corr: -0.01216
Epoch [62/100], Batch [73/147] train loss: 558.57, train corr: 0.00605
Epoch [62/100], Batch [74/147] train loss: 569.00, train corr: 0.01981
Epoch [62/100], Batch [75/147] train loss: 562.14, train corr: -0.00676
Epoch [62/100], Batch [76/147] train loss: 564.77, train corr: -0.01358
Epoch [62/100], Batch [77/147] train loss: 574.44, train corr: -0.00135
Epoch [62/100], Batch [78/147] train loss: 574.48, train corr: 0.02635
Epoch [62/100], Batch [79/147] train loss: 558.42, train corr: 0.02813
Epoch [62/100], Batch [80/147] train loss: 575.54, train corr: 0.01543
Epoch [62/100], Batch [81/147] train loss: 569.11, train corr: 0.00401
Epoch [62/100], Batch [82/147] train loss: 551.56, train corr: -0.00143
Epoch [62/100], Batch [83/147] train loss: 560.81, train corr: 0.02034
Epoch [62/100], Batch [84/147] train loss: 578.81, train corr: 0.02814
Epoch [62/100], Batch [85/147] train loss: 573.06, train corr: -0.00103
Epoch [62/100], Batch [86/147] train loss: 775.90, train corr: -0.01485
Epoch [62/100], Batch [87/147] train loss: 558.67, train corr: -0.02606
Epoch [62/100], Batch [88/147] train loss: 564.20, train corr: 0.02741
Epoch [62/100], Batch [89/147] train loss: 580.13, train corr: 0.02811
Epoch [62/100], Batch [90/147] train loss: 566.43, train corr: 0.02913
Epoch [62/100], Batch [91/147] train loss: 616.28, train corr: 0.02047
Epoch [62/100], Batch [92/147] train loss: 569.29, train corr: 0.02867
Epoch [62/100], Batch [93/147] train loss: 577.63, train corr: 0.02628
Epoch [62/100], Batch [94/147] train loss: 577.41, train corr: 0.03144
Epoch [62/100], Batch [95/147] train loss: 592.25, train corr: 0.02802
Epoch [62/100], Batch [96/147] train loss: 578.24, train corr: 0.03239
Epoch [62/100], Batch [97/147] train loss: 575.16, train corr: 0.02693
Epoch [62/100], Batch [98/147] train loss: 593.33, train corr: 0.01685
Epoch [62/100], Batch [99/147] train loss: 559.57, train corr: -0.02191
Epoch [62/100], Batch [100/147] train loss: 562.05, train corr: 0.03212
Epoch [62/100], Batch [101/147] train loss: 558.41, train corr: 0.03182
Epoch [62/100], Batch [102/147] train loss: 565.43, train corr: 0.02926
Epoch [62/100], Batch [103/147] train loss: 558.71, train corr: 0.03027
Epoch [62/100], Batch [104/147] train loss: 798.50, train corr: 0.02252
Epoch [62/100], Batch [105/147] train loss: 559.94, train corr: 0.01000
Epoch [62/100], Batch [106/147] train loss: 567.40, train corr: -0.00960
Epoch [62/100], Batch [107/147] train loss: 563.77, train corr: -0.01792
Epoch [62/100], Batch [108/147] train loss: 583.67, train corr: -0.01508
Epoch [62/100], Batch [109/147] train loss: 584.05, train corr: -0.00491
Epoch [62/100], Batch [110/147] train loss: 549.49, train corr: 0.00106
Epoch [62/100], Batch [111/147] train loss: 575.57, train corr: 0.00037
Epoch [62/100], Batch [112/147] train loss: 569.79, train corr: 0.02988
Epoch [62/100], Batch [113/147] train loss: 573.61, train corr: 0.02861
Epoch [62/100], Batch [114/147] train loss: 555.52, train corr: 0.02690
Epoch [62/100], Batch [115/147] train loss: 567.75, train corr: 0.02817
Epoch [62/100], Batch [116/147] train loss: 569.97, train corr: 0.03013
Epoch [62/100], Batch [117/147] train loss: 563.56, train corr: 0.03021
Epoch [62/100], Batch [118/147] train loss: 577.25, train corr: 0.02782
Epoch [62/100], Batch [119/147] train loss: 554.19, train corr: -0.01335
Epoch [62/100], Batch [120/147] train loss: 569.27, train corr: -0.00549
Epoch [62/100], Batch [121/147] train loss: 559.86, train corr: -0.00661
Epoch [62/100], Batch [122/147] train loss: 567.67, train corr: -0.00472
Epoch [62/100], Batch [123/147] train loss: 557.12, train corr: -0.01378
Epoch [62/100], Batch [124/147] train loss: 557.68, train corr: -0.01779
Epoch [62/100], Batch [125/147] train loss: 578.00, train corr: 0.02703
Epoch [62/100], Batch [126/147] train loss: 554.01, train corr: 0.02961
Epoch [62/100], Batch [127/147] train loss: 560.11, train corr: 0.02781
Epoch [62/100], Batch [128/147] train loss: 565.81, train corr: 0.02109
Epoch [62/100], Batch [129/147] train loss: 562.51, train corr: 0.02349
Epoch [62/100], Batch [130/147] train loss: 565.88, train corr: -0.02909
Epoch [62/100], Batch [131/147] train loss: 558.08, train corr: -0.02616
Epoch [62/100], Batch [132/147] train loss: 587.27, train corr: -0.01296
Epoch [62/100], Batch [133/147] train loss: 561.81, train corr: -0.01241
Epoch [62/100], Batch [134/147] train loss: 572.30, train corr: -0.01873
Epoch [62/100], Batch [135/147] train loss: 561.54, train corr: -0.02111
Epoch [62/100], Batch [136/147] train loss: 575.21, train corr: -0.01411
Epoch [62/100], Batch [137/147] train loss: 561.56, train corr: -0.00177
Epoch [62/100], Batch [138/147] train loss: 569.57, train corr: 0.03082
Epoch [62/100], Batch [139/147] train loss: 561.91, train corr: 0.03303
Epoch [62/100], Batch [140/147] train loss: 564.85, train corr: 0.03260
Epoch [62/100], Batch [141/147] train loss: 622.10, train corr: 0.02818
Epoch [62/100], Batch [142/147] train loss: 563.15, train corr: 0.02944
Epoch [62/100], Batch [143/147] train loss: 559.92, train corr: 0.02974
Epoch [62/100], Batch [144/147] train loss: 569.15, train corr: 0.00890
Epoch [62/100], Batch [145/147] train loss: 577.65, train corr: -0.00737
Epoch [62/100], Batch [146/147] train loss: 584.52, train corr: -0.00320
Epoch [62/100], Batch [147/147] train loss: 570.14, train corr: -0.01041
Epoch [62/100], validation loss: 597.44, validation correlation: -0.00295
Epoch [63/100], Batch [1/147] train loss: 571.77, train corr: -0.00259
Epoch [63/100], Batch [2/147] train loss: 563.80, train corr: 0.00157
Epoch [63/100], Batch [3/147] train loss: 567.57, train corr: 0.01735
Epoch [63/100], Batch [4/147] train loss: 567.56, train corr: 0.03109
Epoch [63/100], Batch [5/147] train loss: 559.68, train corr: 0.02827
Epoch [63/100], Batch [6/147] train loss: 567.06, train corr: 0.02506
Epoch [63/100], Batch [7/147] train loss: 605.92, train corr: -0.00240
Epoch [63/100], Batch [8/147] train loss: 567.99, train corr: -0.01999
Epoch [63/100], Batch [9/147] train loss: 552.94, train corr: -0.01747
Epoch [63/100], Batch [10/147] train loss: 565.11, train corr: -0.01601
Epoch [63/100], Batch [11/147] train loss: 563.58, train corr: -0.00623
Epoch [63/100], Batch [12/147] train loss: 571.44, train corr: 0.00655
Epoch [63/100], Batch [13/147] train loss: 566.81, train corr: 0.01439
Epoch [63/100], Batch [14/147] train loss: 571.87, train corr: 0.01310
Epoch [63/100], Batch [15/147] train loss: 578.29, train corr: 0.01222
Epoch [63/100], Batch [16/147] train loss: 569.59, train corr: 0.01304
Epoch [63/100], Batch [17/147] train loss: 573.09, train corr: 0.01044
Epoch [63/100], Batch [18/147] train loss: 561.26, train corr: -0.00216
Epoch [63/100], Batch [19/147] train loss: 573.43, train corr: -0.00637
Epoch [63/100], Batch [20/147] train loss: 558.10, train corr: -0.00125
Epoch [63/100], Batch [21/147] train loss: 565.03, train corr: 0.00725
Epoch [63/100], Batch [22/147] train loss: 559.46, train corr: 0.02040
Epoch [63/100], Batch [23/147] train loss: 559.45, train corr: 0.01566
Epoch [63/100], Batch [24/147] train loss: 565.84, train corr: 0.00531
Epoch [63/100], Batch [25/147] train loss: 574.89, train corr: -0.00873
Epoch [63/100], Batch [26/147] train loss: 558.27, train corr: -0.01571
Epoch [63/100], Batch [27/147] train loss: 578.08, train corr: -0.01382
Epoch [63/100], Batch [28/147] train loss: 569.26, train corr: -0.00925
Epoch [63/100], Batch [29/147] train loss: 559.41, train corr: -0.01813
Epoch [63/100], Batch [30/147] train loss: 559.62, train corr: -0.01109
Epoch [63/100], Batch [31/147] train loss: 581.25, train corr: 0.01177
Epoch [63/100], Batch [32/147] train loss: 587.93, train corr: 0.01382
Epoch [63/100], Batch [33/147] train loss: 571.66, train corr: -0.00022
Epoch [63/100], Batch [34/147] train loss: 558.82, train corr: -0.01260
Epoch [63/100], Batch [35/147] train loss: 566.59, train corr: -0.01422
Epoch [63/100], Batch [36/147] train loss: 561.59, train corr: -0.01356
Epoch [63/100], Batch [37/147] train loss: 556.53, train corr: -0.00034
Epoch [63/100], Batch [38/147] train loss: 555.12, train corr: 0.02610
Epoch [63/100], Batch [39/147] train loss: 568.03, train corr: 0.02654
Epoch [63/100], Batch [40/147] train loss: 647.45, train corr: 0.01042
Epoch [63/100], Batch [41/147] train loss: 569.99, train corr: -0.01513
Epoch [63/100], Batch [42/147] train loss: 580.11, train corr: -0.01394
Epoch [63/100], Batch [43/147] train loss: 562.07, train corr: -0.00385
Epoch [63/100], Batch [44/147] train loss: 565.42, train corr: 0.00158
Epoch [63/100], Batch [45/147] train loss: 565.72, train corr: -0.01646
Epoch [63/100], Batch [46/147] train loss: 574.01, train corr: -0.02020
Epoch [63/100], Batch [47/147] train loss: 559.26, train corr: -0.00315
Epoch [63/100], Batch [48/147] train loss: 559.35, train corr: 0.03303
Epoch [63/100], Batch [49/147] train loss: 564.36, train corr: 0.03104
Epoch [63/100], Batch [50/147] train loss: 574.65, train corr: 0.03525
Epoch [63/100], Batch [51/147] train loss: 585.68, train corr: 0.00774
Epoch [63/100], Batch [52/147] train loss: 555.59, train corr: -0.01501
Epoch [63/100], Batch [53/147] train loss: 554.33, train corr: -0.01153
Epoch [63/100], Batch [54/147] train loss: 569.56, train corr: -0.00217
Epoch [63/100], Batch [55/147] train loss: 584.61, train corr: 0.00764
Epoch [63/100], Batch [56/147] train loss: 586.23, train corr: -0.00410
Epoch [63/100], Batch [57/147] train loss: 563.22, train corr: -0.01097
Epoch [63/100], Batch [58/147] train loss: 573.61, train corr: -0.00609
Epoch [63/100], Batch [59/147] train loss: 585.33, train corr: 0.01591
Epoch [63/100], Batch [60/147] train loss: 564.94, train corr: 0.02289
Epoch [63/100], Batch [61/147] train loss: 571.08, train corr: 0.01035
Epoch [63/100], Batch [62/147] train loss: 570.18, train corr: -0.00345
Epoch [63/100], Batch [63/147] train loss: 568.21, train corr: 0.00124
Epoch [63/100], Batch [64/147] train loss: 576.14, train corr: 0.02435
Epoch [63/100], Batch [65/147] train loss: 552.35, train corr: 0.02672
Epoch [63/100], Batch [66/147] train loss: 558.58, train corr: 0.01733
Epoch [63/100], Batch [67/147] train loss: 561.14, train corr: 0.00361
Epoch [63/100], Batch [68/147] train loss: 560.96, train corr: -0.00674
Epoch [63/100], Batch [69/147] train loss: 569.10, train corr: -0.01139
Epoch [63/100], Batch [70/147] train loss: 572.34, train corr: -0.01359
Epoch [63/100], Batch [71/147] train loss: 572.73, train corr: -0.01799
Epoch [63/100], Batch [72/147] train loss: 557.73, train corr: -0.02570
Epoch [63/100], Batch [73/147] train loss: 566.42, train corr: -0.01979
Epoch [63/100], Batch [74/147] train loss: 562.88, train corr: -0.01386
Epoch [63/100], Batch [75/147] train loss: 560.50, train corr: -0.00203
Epoch [63/100], Batch [76/147] train loss: 589.35, train corr: 0.00823
Epoch [63/100], Batch [77/147] train loss: 561.37, train corr: -0.00023
Epoch [63/100], Batch [78/147] train loss: 581.01, train corr: -0.00004
Epoch [63/100], Batch [79/147] train loss: 561.02, train corr: -0.00502
Epoch [63/100], Batch [80/147] train loss: 572.77, train corr: -0.00542
Epoch [63/100], Batch [81/147] train loss: 558.34, train corr: -0.00472
Epoch [63/100], Batch [82/147] train loss: 570.45, train corr: 0.02021
Epoch [63/100], Batch [83/147] train loss: 563.33, train corr: 0.02540
Epoch [63/100], Batch [84/147] train loss: 558.14, train corr: 0.02923
Epoch [63/100], Batch [85/147] train loss: 569.94, train corr: 0.02434
Epoch [63/100], Batch [86/147] train loss: 564.88, train corr: 0.01431
Epoch [63/100], Batch [87/147] train loss: 759.07, train corr: 0.00594
Epoch [63/100], Batch [88/147] train loss: 581.47, train corr: -0.02355
Epoch [63/100], Batch [89/147] train loss: 566.58, train corr: 0.02789
Epoch [63/100], Batch [90/147] train loss: 561.39, train corr: 0.02746
Epoch [63/100], Batch [91/147] train loss: 585.17, train corr: 0.02672
Epoch [63/100], Batch [92/147] train loss: 563.28, train corr: 0.02827
Epoch [63/100], Batch [93/147] train loss: 569.81, train corr: 0.02806
Epoch [63/100], Batch [94/147] train loss: 580.10, train corr: 0.02996
Epoch [63/100], Batch [95/147] train loss: 567.59, train corr: 0.02764
Epoch [63/100], Batch [96/147] train loss: 576.76, train corr: 0.02841
Epoch [63/100], Batch [97/147] train loss: 565.28, train corr: 0.02884
Epoch [63/100], Batch [98/147] train loss: 569.85, train corr: 0.02760
Epoch [63/100], Batch [99/147] train loss: 574.15, train corr: 0.02742
Epoch [63/100], Batch [100/147] train loss: 568.70, train corr: 0.02851
Epoch [63/100], Batch [101/147] train loss: 807.78, train corr: -0.01825
Epoch [63/100], Batch [102/147] train loss: 578.18, train corr: 0.02608
Epoch [63/100], Batch [103/147] train loss: 576.62, train corr: 0.02794
Epoch [63/100], Batch [104/147] train loss: 594.57, train corr: 0.02791
Epoch [63/100], Batch [105/147] train loss: 604.21, train corr: 0.02651
Epoch [63/100], Batch [106/147] train loss: 587.85, train corr: 0.02750
Epoch [63/100], Batch [107/147] train loss: 591.13, train corr: 0.02502
Epoch [63/100], Batch [108/147] train loss: 602.11, train corr: 0.01926
Epoch [63/100], Batch [109/147] train loss: 591.54, train corr: 0.02670
Epoch [63/100], Batch [110/147] train loss: 582.02, train corr: 0.02589
Epoch [63/100], Batch [111/147] train loss: 603.99, train corr: 0.02815
Epoch [63/100], Batch [112/147] train loss: 593.81, train corr: 0.02601
Epoch [63/100], Batch [113/147] train loss: 579.64, train corr: 0.02653
Epoch [63/100], Batch [114/147] train loss: 573.06, train corr: 0.02895
Epoch [63/100], Batch [115/147] train loss: 582.33, train corr: 0.02740
Epoch [63/100], Batch [116/147] train loss: 569.69, train corr: 0.02589
Epoch [63/100], Batch [117/147] train loss: 568.39, train corr: 0.03118
Epoch [63/100], Batch [118/147] train loss: 568.02, train corr: 0.03007
Epoch [63/100], Batch [119/147] train loss: 554.86, train corr: 0.02644
Epoch [63/100], Batch [120/147] train loss: 573.12, train corr: 0.01915
Epoch [63/100], Batch [121/147] train loss: 572.38, train corr: 0.00393
Epoch [63/100], Batch [122/147] train loss: 576.45, train corr: -0.01890
Epoch [63/100], Batch [123/147] train loss: 559.01, train corr: -0.02792
Epoch [63/100], Batch [124/147] train loss: 551.21, train corr: -0.02868
Epoch [63/100], Batch [125/147] train loss: 584.15, train corr: -0.02657
Epoch [63/100], Batch [126/147] train loss: 603.93, train corr: -0.02293
Epoch [63/100], Batch [127/147] train loss: 620.64, train corr: -0.02242
Epoch [63/100], Batch [128/147] train loss: 553.10, train corr: -0.03134
Epoch [63/100], Batch [129/147] train loss: 581.90, train corr: -0.02578
Epoch [63/100], Batch [130/147] train loss: 569.93, train corr: -0.02685
Epoch [63/100], Batch [131/147] train loss: 576.04, train corr: -0.01603
Epoch [63/100], Batch [132/147] train loss: 570.92, train corr: -0.00693
Epoch [63/100], Batch [133/147] train loss: 575.23, train corr: -0.01572
Epoch [63/100], Batch [134/147] train loss: 576.57, train corr: -0.01768
Epoch [63/100], Batch [135/147] train loss: 568.80, train corr: -0.00803
Epoch [63/100], Batch [136/147] train loss: 570.18, train corr: 0.02258
Epoch [63/100], Batch [137/147] train loss: 562.88, train corr: 0.03293
Epoch [63/100], Batch [138/147] train loss: 580.71, train corr: 0.03241
Epoch [63/100], Batch [139/147] train loss: 560.98, train corr: 0.03097
Epoch [63/100], Batch [140/147] train loss: 566.51, train corr: 0.03174
Epoch [63/100], Batch [141/147] train loss: 552.97, train corr: 0.02361
Epoch [63/100], Batch [142/147] train loss: 573.43, train corr: -0.00051
Epoch [63/100], Batch [143/147] train loss: 553.33, train corr: -0.01859
Epoch [63/100], Batch [144/147] train loss: 568.90, train corr: -0.02064
Epoch [63/100], Batch [145/147] train loss: 573.59, train corr: -0.02138
Epoch [63/100], Batch [146/147] train loss: 557.76, train corr: -0.02055
Epoch [63/100], Batch [147/147] train loss: 583.80, train corr: 0.00409
Epoch [63/100], validation loss: 597.04, validation correlation: 0.01781
Epoch [64/100], Batch [1/147] train loss: 585.47, train corr: 0.01635
Epoch [64/100], Batch [2/147] train loss: 585.30, train corr: 0.02189
Epoch [64/100], Batch [3/147] train loss: 573.52, train corr: 0.00409
Epoch [64/100], Batch [4/147] train loss: 570.01, train corr: -0.00463
Epoch [64/100], Batch [5/147] train loss: 564.07, train corr: -0.00057
Epoch [64/100], Batch [6/147] train loss: 560.52, train corr: 0.01339
Epoch [64/100], Batch [7/147] train loss: 566.66, train corr: 0.01325
Epoch [64/100], Batch [8/147] train loss: 559.45, train corr: 0.01210
Epoch [64/100], Batch [9/147] train loss: 572.76, train corr: 0.00798
Epoch [64/100], Batch [10/147] train loss: 567.97, train corr: 0.00073
Epoch [64/100], Batch [11/147] train loss: 585.61, train corr: -0.00441
Epoch [64/100], Batch [12/147] train loss: 565.27, train corr: -0.01115
Epoch [64/100], Batch [13/147] train loss: 620.12, train corr: -0.01496
Epoch [64/100], Batch [14/147] train loss: 561.60, train corr: -0.01638
Epoch [64/100], Batch [15/147] train loss: 561.36, train corr: 0.00406
Epoch [64/100], Batch [16/147] train loss: 565.14, train corr: 0.02976
Epoch [64/100], Batch [17/147] train loss: 559.38, train corr: 0.02896
Epoch [64/100], Batch [18/147] train loss: 567.74, train corr: 0.03009
Epoch [64/100], Batch [19/147] train loss: 583.00, train corr: 0.01220
Epoch [64/100], Batch [20/147] train loss: 657.65, train corr: -0.01240
Epoch [64/100], Batch [21/147] train loss: 563.12, train corr: -0.02133
Epoch [64/100], Batch [22/147] train loss: 558.63, train corr: -0.01797
Epoch [64/100], Batch [23/147] train loss: 578.08, train corr: 0.00258
Epoch [64/100], Batch [24/147] train loss: 583.91, train corr: 0.01447
Epoch [64/100], Batch [25/147] train loss: 550.14, train corr: -0.01846
Epoch [64/100], Batch [26/147] train loss: 579.13, train corr: -0.02270
Epoch [64/100], Batch [27/147] train loss: 747.10, train corr: -0.01556
Epoch [64/100], Batch [28/147] train loss: 561.20, train corr: -0.02502
Epoch [64/100], Batch [29/147] train loss: 567.87, train corr: 0.02927
Epoch [64/100], Batch [30/147] train loss: 543.47, train corr: 0.02981
Epoch [64/100], Batch [31/147] train loss: 567.91, train corr: 0.02753
Epoch [64/100], Batch [32/147] train loss: 580.18, train corr: 0.02901
Epoch [64/100], Batch [33/147] train loss: 588.03, train corr: 0.03099
Epoch [64/100], Batch [34/147] train loss: 566.31, train corr: 0.03317
Epoch [64/100], Batch [35/147] train loss: 556.85, train corr: -0.01757
Epoch [64/100], Batch [36/147] train loss: 566.93, train corr: 0.02626
Epoch [64/100], Batch [37/147] train loss: 597.03, train corr: 0.01892
Epoch [64/100], Batch [38/147] train loss: 571.98, train corr: 0.02574
Epoch [64/100], Batch [39/147] train loss: 560.35, train corr: 0.02809
Epoch [64/100], Batch [40/147] train loss: 571.49, train corr: 0.02799
Epoch [64/100], Batch [41/147] train loss: 565.38, train corr: -0.02498
Epoch [64/100], Batch [42/147] train loss: 573.95, train corr: 0.02888
Epoch [64/100], Batch [43/147] train loss: 578.79, train corr: 0.02667
Epoch [64/100], Batch [44/147] train loss: 566.15, train corr: 0.02920
Epoch [64/100], Batch [45/147] train loss: 561.75, train corr: 0.02789
Epoch [64/100], Batch [46/147] train loss: 556.36, train corr: 0.02852
Epoch [64/100], Batch [47/147] train loss: 589.36, train corr: 0.02688
Epoch [64/100], Batch [48/147] train loss: 561.35, train corr: 0.03036
Epoch [64/100], Batch [49/147] train loss: 568.93, train corr: 0.02943
Epoch [64/100], Batch [50/147] train loss: 645.08, train corr: 0.02363
Epoch [64/100], Batch [51/147] train loss: 563.91, train corr: -0.01483
Epoch [64/100], Batch [52/147] train loss: 579.96, train corr: -0.02785
Epoch [64/100], Batch [53/147] train loss: 552.25, train corr: 0.01573
Epoch [64/100], Batch [54/147] train loss: 573.76, train corr: 0.02885
Epoch [64/100], Batch [55/147] train loss: 554.91, train corr: 0.02958
Epoch [64/100], Batch [56/147] train loss: 573.25, train corr: 0.03004
Epoch [64/100], Batch [57/147] train loss: 576.29, train corr: 0.03290
Epoch [64/100], Batch [58/147] train loss: 569.04, train corr: 0.03094
Epoch [64/100], Batch [59/147] train loss: 563.54, train corr: 0.03103
Epoch [64/100], Batch [60/147] train loss: 556.98, train corr: 0.03006
Epoch [64/100], Batch [61/147] train loss: 579.00, train corr: 0.02857
Epoch [64/100], Batch [62/147] train loss: 573.77, train corr: 0.02818
Epoch [64/100], Batch [63/147] train loss: 579.37, train corr: -0.01918
Epoch [64/100], Batch [64/147] train loss: 581.35, train corr: -0.01668
Epoch [64/100], Batch [65/147] train loss: 559.97, train corr: 0.03149
Epoch [64/100], Batch [66/147] train loss: 547.42, train corr: 0.02441
Epoch [64/100], Batch [67/147] train loss: 579.85, train corr: 0.00483
Epoch [64/100], Batch [68/147] train loss: 560.77, train corr: -0.02094
Epoch [64/100], Batch [69/147] train loss: 563.20, train corr: -0.02065
Epoch [64/100], Batch [70/147] train loss: 558.72, train corr: 0.01234
Epoch [64/100], Batch [71/147] train loss: 574.78, train corr: 0.02908
Epoch [64/100], Batch [72/147] train loss: 557.44, train corr: 0.02916
Epoch [64/100], Batch [73/147] train loss: 554.06, train corr: 0.02740
Epoch [64/100], Batch [74/147] train loss: 557.13, train corr: 0.02242
Epoch [64/100], Batch [75/147] train loss: 559.11, train corr: -0.00430
Epoch [64/100], Batch [76/147] train loss: 552.29, train corr: 0.00473
Epoch [64/100], Batch [77/147] train loss: 586.64, train corr: 0.02201
Epoch [64/100], Batch [78/147] train loss: 563.86, train corr: 0.00790
Epoch [64/100], Batch [79/147] train loss: 564.12, train corr: -0.01374
Epoch [64/100], Batch [80/147] train loss: 563.20, train corr: -0.02117
Epoch [64/100], Batch [81/147] train loss: 571.49, train corr: -0.01569
Epoch [64/100], Batch [82/147] train loss: 570.80, train corr: 0.01289
Epoch [64/100], Batch [83/147] train loss: 576.47, train corr: 0.02904
Epoch [64/100], Batch [84/147] train loss: 566.09, train corr: 0.02936
Epoch [64/100], Batch [85/147] train loss: 579.83, train corr: 0.02691
Epoch [64/100], Batch [86/147] train loss: 570.87, train corr: 0.00360
Epoch [64/100], Batch [87/147] train loss: 559.77, train corr: 0.00355
Epoch [64/100], Batch [88/147] train loss: 564.88, train corr: 0.01012
Epoch [64/100], Batch [89/147] train loss: 568.64, train corr: 0.01011
Epoch [64/100], Batch [90/147] train loss: 570.17, train corr: -0.00214
Epoch [64/100], Batch [91/147] train loss: 560.09, train corr: -0.01181
Epoch [64/100], Batch [92/147] train loss: 558.01, train corr: -0.01202
Epoch [64/100], Batch [93/147] train loss: 563.71, train corr: -0.01263
Epoch [64/100], Batch [94/147] train loss: 559.44, train corr: 0.00050
Epoch [64/100], Batch [95/147] train loss: 573.03, train corr: 0.02060
Epoch [64/100], Batch [96/147] train loss: 572.81, train corr: 0.02227
Epoch [64/100], Batch [97/147] train loss: 569.71, train corr: 0.01263
Epoch [64/100], Batch [98/147] train loss: 579.92, train corr: 0.02246
Epoch [64/100], Batch [99/147] train loss: 565.34, train corr: 0.02996
Epoch [64/100], Batch [100/147] train loss: 570.93, train corr: 0.02952
Epoch [64/100], Batch [101/147] train loss: 561.55, train corr: 0.01196
Epoch [64/100], Batch [102/147] train loss: 564.14, train corr: -0.00968
Epoch [64/100], Batch [103/147] train loss: 558.60, train corr: -0.01674
Epoch [64/100], Batch [104/147] train loss: 567.84, train corr: -0.01289
Epoch [64/100], Batch [105/147] train loss: 568.28, train corr: -0.00418
Epoch [64/100], Batch [106/147] train loss: 572.47, train corr: 0.00679
Epoch [64/100], Batch [107/147] train loss: 566.18, train corr: -0.00032
Epoch [64/100], Batch [108/147] train loss: 567.98, train corr: -0.00577
Epoch [64/100], Batch [109/147] train loss: 560.08, train corr: -0.00164
Epoch [64/100], Batch [110/147] train loss: 572.10, train corr: 0.02162
Epoch [64/100], Batch [111/147] train loss: 557.67, train corr: 0.02674
Epoch [64/100], Batch [112/147] train loss: 564.05, train corr: 0.00416
Epoch [64/100], Batch [113/147] train loss: 562.69, train corr: -0.01130
Epoch [64/100], Batch [114/147] train loss: 566.45, train corr: -0.01041
Epoch [64/100], Batch [115/147] train loss: 570.01, train corr: -0.00370
Epoch [64/100], Batch [116/147] train loss: 586.01, train corr: 0.01793
Epoch [64/100], Batch [117/147] train loss: 582.84, train corr: 0.01915
Epoch [64/100], Batch [118/147] train loss: 552.12, train corr: -0.00007
Epoch [64/100], Batch [119/147] train loss: 563.67, train corr: -0.00893
Epoch [64/100], Batch [120/147] train loss: 586.88, train corr: -0.00846
Epoch [64/100], Batch [121/147] train loss: 583.16, train corr: 0.01401
Epoch [64/100], Batch [122/147] train loss: 571.84, train corr: 0.02758
Epoch [64/100], Batch [123/147] train loss: 575.98, train corr: 0.02403
Epoch [64/100], Batch [124/147] train loss: 547.32, train corr: -0.00175
Epoch [64/100], Batch [125/147] train loss: 561.55, train corr: -0.00596
Epoch [64/100], Batch [126/147] train loss: 560.42, train corr: 0.00087
Epoch [64/100], Batch [127/147] train loss: 572.14, train corr: 0.01490
Epoch [64/100], Batch [128/147] train loss: 562.26, train corr: 0.01733
Epoch [64/100], Batch [129/147] train loss: 581.79, train corr: 0.01456
Epoch [64/100], Batch [130/147] train loss: 802.33, train corr: -0.00476
Epoch [64/100], Batch [131/147] train loss: 579.54, train corr: -0.02480
Epoch [64/100], Batch [132/147] train loss: 567.69, train corr: 0.02530
Epoch [64/100], Batch [133/147] train loss: 579.53, train corr: 0.02695
Epoch [64/100], Batch [134/147] train loss: 592.50, train corr: 0.02194
Epoch [64/100], Batch [135/147] train loss: 574.22, train corr: 0.02645
Epoch [64/100], Batch [136/147] train loss: 571.56, train corr: 0.02837
Epoch [64/100], Batch [137/147] train loss: 575.06, train corr: 0.02697
Epoch [64/100], Batch [138/147] train loss: 586.54, train corr: 0.02487
Epoch [64/100], Batch [139/147] train loss: 588.72, train corr: 0.02685
Epoch [64/100], Batch [140/147] train loss: 575.61, train corr: 0.02667
Epoch [64/100], Batch [141/147] train loss: 572.04, train corr: 0.02704
Epoch [64/100], Batch [142/147] train loss: 566.40, train corr: 0.02308
Epoch [64/100], Batch [143/147] train loss: 565.56, train corr: 0.02278
Epoch [64/100], Batch [144/147] train loss: 555.33, train corr: -0.00186
Epoch [64/100], Batch [145/147] train loss: 573.19, train corr: 0.01800
Epoch [64/100], Batch [146/147] train loss: 559.14, train corr: 0.02818
Epoch [64/100], Batch [147/147] train loss: 563.56, train corr: 0.03001
Epoch [64/100], validation loss: 600.09, validation correlation: 0.01352
Epoch [65/100], Batch [1/147] train loss: 568.64, train corr: 0.01359
Epoch [65/100], Batch [2/147] train loss: 580.78, train corr: -0.02191
Epoch [65/100], Batch [3/147] train loss: 559.64, train corr: -0.02635
Epoch [65/100], Batch [4/147] train loss: 576.75, train corr: -0.02008
Epoch [65/100], Batch [5/147] train loss: 551.85, train corr: -0.01867
Epoch [65/100], Batch [6/147] train loss: 569.81, train corr: 0.02846
Epoch [65/100], Batch [7/147] train loss: 565.84, train corr: 0.02464
Epoch [65/100], Batch [8/147] train loss: 572.92, train corr: 0.02657
Epoch [65/100], Batch [9/147] train loss: 577.85, train corr: 0.02441
Epoch [65/100], Batch [10/147] train loss: 557.14, train corr: 0.03008
Epoch [65/100], Batch [11/147] train loss: 584.00, train corr: 0.02511
Epoch [65/100], Batch [12/147] train loss: 564.36, train corr: 0.02939
Epoch [65/100], Batch [13/147] train loss: 557.54, train corr: 0.02275
Epoch [65/100], Batch [14/147] train loss: 578.86, train corr: -0.00908
Epoch [65/100], Batch [15/147] train loss: 564.27, train corr: -0.01685
Epoch [65/100], Batch [16/147] train loss: 581.21, train corr: -0.00282
Epoch [65/100], Batch [17/147] train loss: 583.70, train corr: 0.03026
Epoch [65/100], Batch [18/147] train loss: 563.41, train corr: 0.03028
Epoch [65/100], Batch [19/147] train loss: 575.22, train corr: 0.02187
Epoch [65/100], Batch [20/147] train loss: 574.05, train corr: -0.00287
Epoch [65/100], Batch [21/147] train loss: 567.78, train corr: -0.00495
Epoch [65/100], Batch [22/147] train loss: 545.92, train corr: 0.01004
Epoch [65/100], Batch [23/147] train loss: 579.94, train corr: 0.02107
Epoch [65/100], Batch [24/147] train loss: 557.43, train corr: 0.02349
Epoch [65/100], Batch [25/147] train loss: 576.78, train corr: -0.02333
Epoch [65/100], Batch [26/147] train loss: 579.51, train corr: -0.02698
Epoch [65/100], Batch [27/147] train loss: 568.48, train corr: -0.02873
Epoch [65/100], Batch [28/147] train loss: 573.53, train corr: -0.02586
Epoch [65/100], Batch [29/147] train loss: 585.02, train corr: -0.01330
Epoch [65/100], Batch [30/147] train loss: 567.06, train corr: -0.01395
Epoch [65/100], Batch [31/147] train loss: 579.52, train corr: -0.01368
Epoch [65/100], Batch [32/147] train loss: 614.10, train corr: -0.01413
Epoch [65/100], Batch [33/147] train loss: 568.97, train corr: -0.00361
Epoch [65/100], Batch [34/147] train loss: 558.61, train corr: 0.00524
Epoch [65/100], Batch [35/147] train loss: 578.45, train corr: 0.01841
Epoch [65/100], Batch [36/147] train loss: 562.38, train corr: 0.02265
Epoch [65/100], Batch [37/147] train loss: 568.34, train corr: 0.02934
Epoch [65/100], Batch [38/147] train loss: 567.54, train corr: 0.03426
Epoch [65/100], Batch [39/147] train loss: 557.23, train corr: 0.03346
Epoch [65/100], Batch [40/147] train loss: 572.34, train corr: 0.02888
Epoch [65/100], Batch [41/147] train loss: 562.42, train corr: 0.02371
Epoch [65/100], Batch [42/147] train loss: 569.69, train corr: -0.02491
Epoch [65/100], Batch [43/147] train loss: 562.04, train corr: -0.02888
Epoch [65/100], Batch [44/147] train loss: 569.79, train corr: -0.02138
Epoch [65/100], Batch [45/147] train loss: 570.60, train corr: -0.02313
Epoch [65/100], Batch [46/147] train loss: 560.52, train corr: -0.01758
Epoch [65/100], Batch [47/147] train loss: 562.40, train corr: -0.01148
Epoch [65/100], Batch [48/147] train loss: 572.85, train corr: -0.00573
Epoch [65/100], Batch [49/147] train loss: 582.90, train corr: 0.00421
Epoch [65/100], Batch [50/147] train loss: 546.18, train corr: 0.00052
Epoch [65/100], Batch [51/147] train loss: 558.90, train corr: 0.01231
Epoch [65/100], Batch [52/147] train loss: 567.40, train corr: 0.01610
Epoch [65/100], Batch [53/147] train loss: 557.97, train corr: 0.01035
Epoch [65/100], Batch [54/147] train loss: 561.20, train corr: -0.01023
Epoch [65/100], Batch [55/147] train loss: 566.63, train corr: -0.01592
Epoch [65/100], Batch [56/147] train loss: 560.30, train corr: -0.01788
Epoch [65/100], Batch [57/147] train loss: 579.71, train corr: -0.00421
Epoch [65/100], Batch [58/147] train loss: 556.13, train corr: 0.01507
Epoch [65/100], Batch [59/147] train loss: 580.91, train corr: 0.02473
Epoch [65/100], Batch [60/147] train loss: 567.53, train corr: 0.02072
Epoch [65/100], Batch [61/147] train loss: 576.82, train corr: 0.00926
Epoch [65/100], Batch [62/147] train loss: 559.04, train corr: 0.00787
Epoch [65/100], Batch [63/147] train loss: 556.32, train corr: 0.01138
Epoch [65/100], Batch [64/147] train loss: 550.54, train corr: 0.01897
Epoch [65/100], Batch [65/147] train loss: 568.90, train corr: 0.02458
Epoch [65/100], Batch [66/147] train loss: 569.61, train corr: 0.01490
Epoch [65/100], Batch [67/147] train loss: 559.60, train corr: -0.01792
Epoch [65/100], Batch [68/147] train loss: 764.20, train corr: -0.01847
Epoch [65/100], Batch [69/147] train loss: 566.37, train corr: -0.02651
Epoch [65/100], Batch [70/147] train loss: 570.63, train corr: 0.02763
Epoch [65/100], Batch [71/147] train loss: 561.61, train corr: 0.02888
Epoch [65/100], Batch [72/147] train loss: 563.27, train corr: 0.02744
Epoch [65/100], Batch [73/147] train loss: 566.69, train corr: 0.02889
Epoch [65/100], Batch [74/147] train loss: 546.49, train corr: 0.03066
Epoch [65/100], Batch [75/147] train loss: 576.87, train corr: 0.03266
Epoch [65/100], Batch [76/147] train loss: 583.09, train corr: -0.00502
Epoch [65/100], Batch [77/147] train loss: 577.35, train corr: 0.00212
Epoch [65/100], Batch [78/147] train loss: 558.91, train corr: 0.03173
Epoch [65/100], Batch [79/147] train loss: 810.23, train corr: 0.02482
Epoch [65/100], Batch [80/147] train loss: 575.84, train corr: -0.02911
Epoch [65/100], Batch [81/147] train loss: 567.68, train corr: 0.02735
Epoch [65/100], Batch [82/147] train loss: 591.52, train corr: 0.02400
Epoch [65/100], Batch [83/147] train loss: 573.51, train corr: 0.02960
Epoch [65/100], Batch [84/147] train loss: 564.95, train corr: 0.03007
Epoch [65/100], Batch [85/147] train loss: 599.23, train corr: 0.02772
Epoch [65/100], Batch [86/147] train loss: 603.10, train corr: 0.02426
Epoch [65/100], Batch [87/147] train loss: 569.59, train corr: 0.02729
Epoch [65/100], Batch [88/147] train loss: 582.68, train corr: 0.02363
Epoch [65/100], Batch [89/147] train loss: 569.17, train corr: 0.02811
Epoch [65/100], Batch [90/147] train loss: 582.59, train corr: 0.02567
Epoch [65/100], Batch [91/147] train loss: 584.91, train corr: 0.02482
Epoch [65/100], Batch [92/147] train loss: 573.16, train corr: 0.02853
Epoch [65/100], Batch [93/147] train loss: 582.43, train corr: 0.02770
Epoch [65/100], Batch [94/147] train loss: 579.10, train corr: 0.03050
Epoch [65/100], Batch [95/147] train loss: 572.25, train corr: 0.02625
Epoch [65/100], Batch [96/147] train loss: 565.66, train corr: 0.03220
Epoch [65/100], Batch [97/147] train loss: 576.54, train corr: 0.02782
Epoch [65/100], Batch [98/147] train loss: 574.52, train corr: 0.01267
Epoch [65/100], Batch [99/147] train loss: 603.67, train corr: -0.00728
Epoch [65/100], Batch [100/147] train loss: 576.30, train corr: -0.02486
Epoch [65/100], Batch [101/147] train loss: 560.65, train corr: -0.02769
Epoch [65/100], Batch [102/147] train loss: 567.39, train corr: -0.02822
Epoch [65/100], Batch [103/147] train loss: 572.26, train corr: -0.02602
Epoch [65/100], Batch [104/147] train loss: 560.91, train corr: -0.02255
Epoch [65/100], Batch [105/147] train loss: 577.15, train corr: 0.03192
Epoch [65/100], Batch [106/147] train loss: 557.08, train corr: 0.03119
Epoch [65/100], Batch [107/147] train loss: 561.12, train corr: 0.03048
Epoch [65/100], Batch [108/147] train loss: 557.40, train corr: 0.02945
Epoch [65/100], Batch [109/147] train loss: 567.80, train corr: 0.02498
Epoch [65/100], Batch [110/147] train loss: 568.94, train corr: 0.00790
Epoch [65/100], Batch [111/147] train loss: 580.81, train corr: -0.01379
Epoch [65/100], Batch [112/147] train loss: 561.02, train corr: -0.03014
Epoch [65/100], Batch [113/147] train loss: 567.73, train corr: -0.02731
Epoch [65/100], Batch [114/147] train loss: 568.60, train corr: -0.02674
Epoch [65/100], Batch [115/147] train loss: 557.53, train corr: -0.02560
Epoch [65/100], Batch [116/147] train loss: 567.27, train corr: 0.00036
Epoch [65/100], Batch [117/147] train loss: 559.83, train corr: 0.02853
Epoch [65/100], Batch [118/147] train loss: 563.40, train corr: 0.03115
Epoch [65/100], Batch [119/147] train loss: 576.07, train corr: 0.03007
Epoch [65/100], Batch [120/147] train loss: 575.76, train corr: 0.03140
Epoch [65/100], Batch [121/147] train loss: 570.19, train corr: 0.02622
Epoch [65/100], Batch [122/147] train loss: 559.75, train corr: -0.02679
Epoch [65/100], Batch [123/147] train loss: 659.16, train corr: -0.02313
Epoch [65/100], Batch [124/147] train loss: 548.43, train corr: -0.03204
Epoch [65/100], Batch [125/147] train loss: 568.36, train corr: -0.03148
Epoch [65/100], Batch [126/147] train loss: 576.56, train corr: -0.03032
Epoch [65/100], Batch [127/147] train loss: 564.81, train corr: 0.00370
Epoch [65/100], Batch [128/147] train loss: 554.81, train corr: -0.02538
Epoch [65/100], Batch [129/147] train loss: 564.82, train corr: 0.00998
Epoch [65/100], Batch [130/147] train loss: 567.10, train corr: 0.03258
Epoch [65/100], Batch [131/147] train loss: 573.43, train corr: 0.02671
Epoch [65/100], Batch [132/147] train loss: 557.40, train corr: -0.00499
Epoch [65/100], Batch [133/147] train loss: 562.60, train corr: -0.00482
Epoch [65/100], Batch [134/147] train loss: 571.09, train corr: 0.00472
Epoch [65/100], Batch [135/147] train loss: 574.53, train corr: 0.01343
Epoch [65/100], Batch [136/147] train loss: 574.46, train corr: -0.00481
Epoch [65/100], Batch [137/147] train loss: 632.27, train corr: -0.01837
Epoch [65/100], Batch [138/147] train loss: 560.37, train corr: -0.02165
Epoch [65/100], Batch [139/147] train loss: 578.16, train corr: -0.01809
Epoch [65/100], Batch [140/147] train loss: 568.97, train corr: -0.00537
Epoch [65/100], Batch [141/147] train loss: 574.86, train corr: 0.02140
Epoch [65/100], Batch [142/147] train loss: 558.54, train corr: 0.02932
Epoch [65/100], Batch [143/147] train loss: 555.33, train corr: 0.03414
Epoch [65/100], Batch [144/147] train loss: 573.83, train corr: 0.03250
Epoch [65/100], Batch [145/147] train loss: 557.72, train corr: 0.02107
Epoch [65/100], Batch [146/147] train loss: 568.11, train corr: -0.00423
Epoch [65/100], Batch [147/147] train loss: 614.77, train corr: 0.00186
Epoch [65/100], validation loss: 597.25, validation correlation: 0.00048
Epoch [66/100], Batch [1/147] train loss: 593.19, train corr: 0.00764
Epoch [66/100], Batch [2/147] train loss: 578.80, train corr: 0.02027
Epoch [66/100], Batch [3/147] train loss: 583.68, train corr: 0.01810
Epoch [66/100], Batch [4/147] train loss: 557.25, train corr: 0.00286
Epoch [66/100], Batch [5/147] train loss: 580.59, train corr: -0.00112
Epoch [66/100], Batch [6/147] train loss: 579.77, train corr: -0.00542
Epoch [66/100], Batch [7/147] train loss: 578.38, train corr: 0.01544
Epoch [66/100], Batch [8/147] train loss: 588.15, train corr: 0.02496
Epoch [66/100], Batch [9/147] train loss: 558.40, train corr: 0.02861
Epoch [66/100], Batch [10/147] train loss: 567.46, train corr: 0.01867
Epoch [66/100], Batch [11/147] train loss: 568.94, train corr: 0.00391
Epoch [66/100], Batch [12/147] train loss: 552.31, train corr: 0.00407
Epoch [66/100], Batch [13/147] train loss: 563.86, train corr: 0.00519
Epoch [66/100], Batch [14/147] train loss: 567.81, train corr: -0.00445
Epoch [66/100], Batch [15/147] train loss: 578.11, train corr: -0.00389
Epoch [66/100], Batch [16/147] train loss: 561.16, train corr: -0.01493
Epoch [66/100], Batch [17/147] train loss: 621.73, train corr: -0.01546
Epoch [66/100], Batch [18/147] train loss: 635.27, train corr: 0.01949
Epoch [66/100], Batch [19/147] train loss: 570.89, train corr: -0.02682
Epoch [66/100], Batch [20/147] train loss: 561.35, train corr: -0.02573
Epoch [66/100], Batch [21/147] train loss: 553.82, train corr: -0.02802
Epoch [66/100], Batch [22/147] train loss: 557.72, train corr: -0.02278
Epoch [66/100], Batch [23/147] train loss: 591.64, train corr: 0.00105
Epoch [66/100], Batch [24/147] train loss: 561.76, train corr: 0.00646
Epoch [66/100], Batch [25/147] train loss: 551.37, train corr: -0.00079
Epoch [66/100], Batch [26/147] train loss: 575.79, train corr: 0.01473
Epoch [66/100], Batch [27/147] train loss: 567.46, train corr: 0.03046
Epoch [66/100], Batch [28/147] train loss: 583.05, train corr: 0.03136
Epoch [66/100], Batch [29/147] train loss: 587.08, train corr: 0.03227
Epoch [66/100], Batch [30/147] train loss: 570.38, train corr: 0.03594
Epoch [66/100], Batch [31/147] train loss: 579.10, train corr: 0.02017
Epoch [66/100], Batch [32/147] train loss: 570.11, train corr: -0.00969
Epoch [66/100], Batch [33/147] train loss: 555.15, train corr: -0.02029
Epoch [66/100], Batch [34/147] train loss: 587.52, train corr: -0.01178
Epoch [66/100], Batch [35/147] train loss: 559.62, train corr: -0.01732
Epoch [66/100], Batch [36/147] train loss: 565.91, train corr: -0.01681
Epoch [66/100], Batch [37/147] train loss: 575.10, train corr: -0.01717
Epoch [66/100], Batch [38/147] train loss: 570.59, train corr: -0.01663
Epoch [66/100], Batch [39/147] train loss: 560.75, train corr: -0.00302
Epoch [66/100], Batch [40/147] train loss: 556.21, train corr: 0.02233
Epoch [66/100], Batch [41/147] train loss: 562.92, train corr: 0.03133
Epoch [66/100], Batch [42/147] train loss: 565.53, train corr: 0.03114
Epoch [66/100], Batch [43/147] train loss: 580.15, train corr: 0.02226
Epoch [66/100], Batch [44/147] train loss: 570.45, train corr: 0.02103
Epoch [66/100], Batch [45/147] train loss: 583.11, train corr: 0.02999
Epoch [66/100], Batch [46/147] train loss: 570.52, train corr: 0.02595
Epoch [66/100], Batch [47/147] train loss: 565.72, train corr: 0.01614
Epoch [66/100], Batch [48/147] train loss: 578.25, train corr: -0.01126
Epoch [66/100], Batch [49/147] train loss: 572.40, train corr: -0.02032
Epoch [66/100], Batch [50/147] train loss: 570.33, train corr: -0.02123
Epoch [66/100], Batch [51/147] train loss: 564.77, train corr: -0.01111
Epoch [66/100], Batch [52/147] train loss: 564.71, train corr: 0.00538
Epoch [66/100], Batch [53/147] train loss: 569.66, train corr: 0.01323
Epoch [66/100], Batch [54/147] train loss: 571.51, train corr: 0.00643
Epoch [66/100], Batch [55/147] train loss: 557.15, train corr: -0.00360
Epoch [66/100], Batch [56/147] train loss: 556.84, train corr: -0.00651
Epoch [66/100], Batch [57/147] train loss: 558.99, train corr: -0.01008
Epoch [66/100], Batch [58/147] train loss: 556.72, train corr: 0.00101
Epoch [66/100], Batch [59/147] train loss: 564.01, train corr: 0.00970
Epoch [66/100], Batch [60/147] train loss: 565.37, train corr: -0.00472
Epoch [66/100], Batch [61/147] train loss: 569.97, train corr: -0.01330
Epoch [66/100], Batch [62/147] train loss: 792.38, train corr: -0.01904
Epoch [66/100], Batch [63/147] train loss: 569.92, train corr: -0.02528
Epoch [66/100], Batch [64/147] train loss: 585.93, train corr: 0.02479
Epoch [66/100], Batch [65/147] train loss: 586.72, train corr: 0.02667
Epoch [66/100], Batch [66/147] train loss: 598.74, train corr: 0.02491
Epoch [66/100], Batch [67/147] train loss: 595.56, train corr: 0.02648
Epoch [66/100], Batch [68/147] train loss: 596.14, train corr: 0.02475
Epoch [66/100], Batch [69/147] train loss: 596.41, train corr: 0.02698
Epoch [66/100], Batch [70/147] train loss: 593.51, train corr: 0.02469
Epoch [66/100], Batch [71/147] train loss: 579.73, train corr: 0.02816
Epoch [66/100], Batch [72/147] train loss: 592.18, train corr: 0.02946
Epoch [66/100], Batch [73/147] train loss: 567.20, train corr: 0.02990
Epoch [66/100], Batch [74/147] train loss: 561.71, train corr: 0.02825
Epoch [66/100], Batch [75/147] train loss: 571.62, train corr: 0.02600
Epoch [66/100], Batch [76/147] train loss: 581.40, train corr: 0.02551
Epoch [66/100], Batch [77/147] train loss: 571.86, train corr: 0.02716
Epoch [66/100], Batch [78/147] train loss: 583.04, train corr: 0.02614
Epoch [66/100], Batch [79/147] train loss: 562.28, train corr: 0.02952
Epoch [66/100], Batch [80/147] train loss: 573.83, train corr: 0.02637
Epoch [66/100], Batch [81/147] train loss: 568.99, train corr: 0.02629
Epoch [66/100], Batch [82/147] train loss: 578.88, train corr: 0.03016
Epoch [66/100], Batch [83/147] train loss: 569.26, train corr: 0.01759
Epoch [66/100], Batch [84/147] train loss: 590.30, train corr: -0.01984
Epoch [66/100], Batch [85/147] train loss: 614.82, train corr: -0.01965
Epoch [66/100], Batch [86/147] train loss: 564.28, train corr: -0.01798
Epoch [66/100], Batch [87/147] train loss: 576.23, train corr: -0.01848
Epoch [66/100], Batch [88/147] train loss: 566.19, train corr: -0.01887
Epoch [66/100], Batch [89/147] train loss: 567.35, train corr: -0.02123
Epoch [66/100], Batch [90/147] train loss: 587.19, train corr: -0.01306
Epoch [66/100], Batch [91/147] train loss: 573.40, train corr: 0.01522
Epoch [66/100], Batch [92/147] train loss: 555.56, train corr: 0.03189
Epoch [66/100], Batch [93/147] train loss: 561.81, train corr: 0.03066
Epoch [66/100], Batch [94/147] train loss: 573.60, train corr: 0.02920
Epoch [66/100], Batch [95/147] train loss: 557.34, train corr: 0.02921
Epoch [66/100], Batch [96/147] train loss: 561.11, train corr: 0.01317
Epoch [66/100], Batch [97/147] train loss: 562.76, train corr: -0.02258
Epoch [66/100], Batch [98/147] train loss: 598.43, train corr: -0.02741
Epoch [66/100], Batch [99/147] train loss: 563.78, train corr: -0.03002
Epoch [66/100], Batch [100/147] train loss: 565.94, train corr: -0.03088
Epoch [66/100], Batch [101/147] train loss: 579.42, train corr: -0.02953
Epoch [66/100], Batch [102/147] train loss: 561.68, train corr: -0.01755
Epoch [66/100], Batch [103/147] train loss: 567.51, train corr: 0.00893
Epoch [66/100], Batch [104/147] train loss: 557.15, train corr: 0.02532
Epoch [66/100], Batch [105/147] train loss: 554.00, train corr: 0.02748
Epoch [66/100], Batch [106/147] train loss: 551.44, train corr: 0.03096
Epoch [66/100], Batch [107/147] train loss: 550.47, train corr: 0.02858
Epoch [66/100], Batch [108/147] train loss: 573.78, train corr: 0.00248
Epoch [66/100], Batch [109/147] train loss: 597.70, train corr: -0.01203
Epoch [66/100], Batch [110/147] train loss: 564.09, train corr: -0.00948
Epoch [66/100], Batch [111/147] train loss: 570.10, train corr: -0.01121
Epoch [66/100], Batch [112/147] train loss: 568.54, train corr: -0.01151
Epoch [66/100], Batch [113/147] train loss: 571.86, train corr: -0.01398
Epoch [66/100], Batch [114/147] train loss: 569.80, train corr: -0.01745
Epoch [66/100], Batch [115/147] train loss: 558.46, train corr: -0.01871
Epoch [66/100], Batch [116/147] train loss: 564.68, train corr: -0.01932
Epoch [66/100], Batch [117/147] train loss: 557.58, train corr: -0.02088
Epoch [66/100], Batch [118/147] train loss: 561.07, train corr: -0.01647
Epoch [66/100], Batch [119/147] train loss: 573.41, train corr: -0.00829
Epoch [66/100], Batch [120/147] train loss: 572.62, train corr: 0.00777
Epoch [66/100], Batch [121/147] train loss: 557.62, train corr: 0.01547
Epoch [66/100], Batch [122/147] train loss: 581.88, train corr: 0.03127
Epoch [66/100], Batch [123/147] train loss: 553.50, train corr: 0.03094
Epoch [66/100], Batch [124/147] train loss: 557.46, train corr: 0.02999
Epoch [66/100], Batch [125/147] train loss: 566.44, train corr: 0.03062
Epoch [66/100], Batch [126/147] train loss: 568.64, train corr: 0.02437
Epoch [66/100], Batch [127/147] train loss: 569.99, train corr: 0.00901
Epoch [66/100], Batch [128/147] train loss: 572.95, train corr: -0.00381
Epoch [66/100], Batch [129/147] train loss: 736.74, train corr: -0.00842
Epoch [66/100], Batch [130/147] train loss: 555.51, train corr: -0.02169
Epoch [66/100], Batch [131/147] train loss: 566.92, train corr: 0.03337
Epoch [66/100], Batch [132/147] train loss: 588.87, train corr: 0.02842
Epoch [66/100], Batch [133/147] train loss: 560.91, train corr: 0.03035
Epoch [66/100], Batch [134/147] train loss: 591.35, train corr: 0.02234
Epoch [66/100], Batch [135/147] train loss: 567.27, train corr: 0.02519
Epoch [66/100], Batch [136/147] train loss: 573.28, train corr: 0.03100
Epoch [66/100], Batch [137/147] train loss: 566.35, train corr: -0.01588
Epoch [66/100], Batch [138/147] train loss: 571.01, train corr: -0.02109
Epoch [66/100], Batch [139/147] train loss: 567.50, train corr: 0.03259
Epoch [66/100], Batch [140/147] train loss: 563.13, train corr: 0.02632
Epoch [66/100], Batch [141/147] train loss: 542.41, train corr: 0.02956
Epoch [66/100], Batch [142/147] train loss: 576.16, train corr: 0.02532
Epoch [66/100], Batch [143/147] train loss: 550.26, train corr: 0.02911
Epoch [66/100], Batch [144/147] train loss: 574.92, train corr: -0.02496
Epoch [66/100], Batch [145/147] train loss: 564.70, train corr: -0.02294
Epoch [66/100], Batch [146/147] train loss: 559.04, train corr: 0.02047
Epoch [66/100], Batch [147/147] train loss: 570.18, train corr: 0.03041
Epoch [66/100], validation loss: 598.07, validation correlation: 0.03123
Epoch [67/100], Batch [1/147] train loss: 575.13, train corr: 0.02864
Epoch [67/100], Batch [2/147] train loss: 565.53, train corr: 0.03349
Epoch [67/100], Batch [3/147] train loss: 566.63, train corr: -0.00174
Epoch [67/100], Batch [4/147] train loss: 562.97, train corr: -0.01620
Epoch [67/100], Batch [5/147] train loss: 572.12, train corr: -0.00302
Epoch [67/100], Batch [6/147] train loss: 549.53, train corr: 0.03507
Epoch [67/100], Batch [7/147] train loss: 577.54, train corr: 0.03275
Epoch [67/100], Batch [8/147] train loss: 588.90, train corr: 0.03276
Epoch [67/100], Batch [9/147] train loss: 560.40, train corr: 0.00091
Epoch [67/100], Batch [10/147] train loss: 570.16, train corr: -0.01792
Epoch [67/100], Batch [11/147] train loss: 561.05, train corr: -0.02209
Epoch [67/100], Batch [12/147] train loss: 575.68, train corr: -0.00325
Epoch [67/100], Batch [13/147] train loss: 564.38, train corr: 0.03328
Epoch [67/100], Batch [14/147] train loss: 560.24, train corr: 0.02982
Epoch [67/100], Batch [15/147] train loss: 557.95, train corr: 0.03108
Epoch [67/100], Batch [16/147] train loss: 566.72, train corr: 0.03318
Epoch [67/100], Batch [17/147] train loss: 573.28, train corr: -0.00811
Epoch [67/100], Batch [18/147] train loss: 582.11, train corr: -0.00798
Epoch [67/100], Batch [19/147] train loss: 595.54, train corr: 0.01912
Epoch [67/100], Batch [20/147] train loss: 570.27, train corr: 0.02822
Epoch [67/100], Batch [21/147] train loss: 556.94, train corr: 0.01202
Epoch [67/100], Batch [22/147] train loss: 564.04, train corr: -0.01597
Epoch [67/100], Batch [23/147] train loss: 561.84, train corr: -0.01943
Epoch [67/100], Batch [24/147] train loss: 554.34, train corr: -0.02009
Epoch [67/100], Batch [25/147] train loss: 562.09, train corr: -0.00896
Epoch [67/100], Batch [26/147] train loss: 577.21, train corr: 0.03024
Epoch [67/100], Batch [27/147] train loss: 569.45, train corr: 0.03290
Epoch [67/100], Batch [28/147] train loss: 554.06, train corr: 0.03269
Epoch [67/100], Batch [29/147] train loss: 561.98, train corr: 0.01591
Epoch [67/100], Batch [30/147] train loss: 558.72, train corr: -0.01298
Epoch [67/100], Batch [31/147] train loss: 550.41, train corr: -0.01836
Epoch [67/100], Batch [32/147] train loss: 566.63, train corr: -0.01221
Epoch [67/100], Batch [33/147] train loss: 582.40, train corr: -0.00219
Epoch [67/100], Batch [34/147] train loss: 577.63, train corr: 0.00286
Epoch [67/100], Batch [35/147] train loss: 552.15, train corr: -0.00692
Epoch [67/100], Batch [36/147] train loss: 556.17, train corr: -0.01267
Epoch [67/100], Batch [37/147] train loss: 558.34, train corr: -0.01343
Epoch [67/100], Batch [38/147] train loss: 570.81, train corr: 0.00270
Epoch [67/100], Batch [39/147] train loss: 559.91, train corr: 0.02415
Epoch [67/100], Batch [40/147] train loss: 574.69, train corr: 0.03369
Epoch [67/100], Batch [41/147] train loss: 570.27, train corr: 0.03093
Epoch [67/100], Batch [42/147] train loss: 566.14, train corr: 0.02199
Epoch [67/100], Batch [43/147] train loss: 582.10, train corr: 0.00040
Epoch [67/100], Batch [44/147] train loss: 560.46, train corr: -0.01511
Epoch [67/100], Batch [45/147] train loss: 574.35, train corr: -0.01324
Epoch [67/100], Batch [46/147] train loss: 561.01, train corr: -0.00663
Epoch [67/100], Batch [47/147] train loss: 571.82, train corr: 0.00106
Epoch [67/100], Batch [48/147] train loss: 571.50, train corr: 0.00145
Epoch [67/100], Batch [49/147] train loss: 555.60, train corr: -0.00233
Epoch [67/100], Batch [50/147] train loss: 545.35, train corr: -0.00445
Epoch [67/100], Batch [51/147] train loss: 578.02, train corr: 0.00852
Epoch [67/100], Batch [52/147] train loss: 572.65, train corr: 0.02231
Epoch [67/100], Batch [53/147] train loss: 566.60, train corr: 0.03078
Epoch [67/100], Batch [54/147] train loss: 566.26, train corr: 0.02894
Epoch [67/100], Batch [55/147] train loss: 568.13, train corr: 0.02564
Epoch [67/100], Batch [56/147] train loss: 561.58, train corr: 0.01758
Epoch [67/100], Batch [57/147] train loss: 579.67, train corr: 0.01145
Epoch [67/100], Batch [58/147] train loss: 562.68, train corr: -0.00125
Epoch [67/100], Batch [59/147] train loss: 568.75, train corr: -0.00740
Epoch [67/100], Batch [60/147] train loss: 587.89, train corr: -0.00981
Epoch [67/100], Batch [61/147] train loss: 554.01, train corr: -0.02001
Epoch [67/100], Batch [62/147] train loss: 556.21, train corr: -0.01620
Epoch [67/100], Batch [63/147] train loss: 753.02, train corr: -0.01060
Epoch [67/100], Batch [64/147] train loss: 562.37, train corr: -0.02444
Epoch [67/100], Batch [65/147] train loss: 556.98, train corr: 0.02957
Epoch [67/100], Batch [66/147] train loss: 566.95, train corr: 0.02984
Epoch [67/100], Batch [67/147] train loss: 557.79, train corr: 0.03013
Epoch [67/100], Batch [68/147] train loss: 558.63, train corr: 0.03051
Epoch [67/100], Batch [69/147] train loss: 571.92, train corr: 0.02652
Epoch [67/100], Batch [70/147] train loss: 569.30, train corr: 0.03185
Epoch [67/100], Batch [71/147] train loss: 569.32, train corr: -0.01457
Epoch [67/100], Batch [72/147] train loss: 560.66, train corr: -0.01411
Epoch [67/100], Batch [73/147] train loss: 565.42, train corr: 0.03186
Epoch [67/100], Batch [74/147] train loss: 578.71, train corr: 0.02248
Epoch [67/100], Batch [75/147] train loss: 577.74, train corr: 0.02231
Epoch [67/100], Batch [76/147] train loss: 604.04, train corr: 0.02882
Epoch [67/100], Batch [77/147] train loss: 563.97, train corr: 0.03019
Epoch [67/100], Batch [78/147] train loss: 578.89, train corr: -0.02100
Epoch [67/100], Batch [79/147] train loss: 602.87, train corr: -0.01189
Epoch [67/100], Batch [80/147] train loss: 582.74, train corr: 0.03435
Epoch [67/100], Batch [81/147] train loss: 558.59, train corr: 0.03093
Epoch [67/100], Batch [82/147] train loss: 573.54, train corr: 0.03098
Epoch [67/100], Batch [83/147] train loss: 565.02, train corr: 0.02980
Epoch [67/100], Batch [84/147] train loss: 565.52, train corr: -0.01021
Epoch [67/100], Batch [85/147] train loss: 561.76, train corr: 0.00247
Epoch [67/100], Batch [86/147] train loss: 575.42, train corr: 0.03190
Epoch [67/100], Batch [87/147] train loss: 563.71, train corr: 0.03092
Epoch [67/100], Batch [88/147] train loss: 574.62, train corr: 0.03008
Epoch [67/100], Batch [89/147] train loss: 552.74, train corr: 0.03276
Epoch [67/100], Batch [90/147] train loss: 577.49, train corr: -0.01266
Epoch [67/100], Batch [91/147] train loss: 556.21, train corr: -0.02292
Epoch [67/100], Batch [92/147] train loss: 576.67, train corr: -0.02503
Epoch [67/100], Batch [93/147] train loss: 579.24, train corr: 0.00822
Epoch [67/100], Batch [94/147] train loss: 581.94, train corr: 0.03326
Epoch [67/100], Batch [95/147] train loss: 568.94, train corr: 0.03346
Epoch [67/100], Batch [96/147] train loss: 563.83, train corr: 0.03470
Epoch [67/100], Batch [97/147] train loss: 564.84, train corr: 0.02469
Epoch [67/100], Batch [98/147] train loss: 554.70, train corr: 0.03216
Epoch [67/100], Batch [99/147] train loss: 562.70, train corr: 0.03281
Epoch [67/100], Batch [100/147] train loss: 568.01, train corr: 0.03456
Epoch [67/100], Batch [101/147] train loss: 804.02, train corr: 0.01177
Epoch [67/100], Batch [102/147] train loss: 578.45, train corr: -0.02621
Epoch [67/100], Batch [103/147] train loss: 576.89, train corr: 0.02958
Epoch [67/100], Batch [104/147] train loss: 589.07, train corr: 0.02703
Epoch [67/100], Batch [105/147] train loss: 630.09, train corr: 0.02505
Epoch [67/100], Batch [106/147] train loss: 633.90, train corr: 0.02879
Epoch [67/100], Batch [107/147] train loss: 626.82, train corr: 0.02884
Epoch [67/100], Batch [108/147] train loss: 640.58, train corr: 0.02514
Epoch [67/100], Batch [109/147] train loss: 634.52, train corr: 0.02660
Epoch [67/100], Batch [110/147] train loss: 650.67, train corr: 0.02662
Epoch [67/100], Batch [111/147] train loss: 629.52, train corr: 0.02954
Epoch [67/100], Batch [112/147] train loss: 626.17, train corr: 0.02589
Epoch [67/100], Batch [113/147] train loss: 630.74, train corr: 0.02618
Epoch [67/100], Batch [114/147] train loss: 700.23, train corr: 0.02605
Epoch [67/100], Batch [115/147] train loss: 611.76, train corr: 0.02738
Epoch [67/100], Batch [116/147] train loss: 623.71, train corr: 0.02307
Epoch [67/100], Batch [117/147] train loss: 613.11, train corr: 0.02711
Epoch [67/100], Batch [118/147] train loss: 610.78, train corr: 0.02646
Epoch [67/100], Batch [119/147] train loss: 584.80, train corr: 0.02968
Epoch [67/100], Batch [120/147] train loss: 596.01, train corr: 0.02850
Epoch [67/100], Batch [121/147] train loss: 607.07, train corr: 0.02638
Epoch [67/100], Batch [122/147] train loss: 574.54, train corr: 0.02713
Epoch [67/100], Batch [123/147] train loss: 582.07, train corr: 0.02759
Epoch [67/100], Batch [124/147] train loss: 566.70, train corr: 0.02944
Epoch [67/100], Batch [125/147] train loss: 588.07, train corr: 0.02873
Epoch [67/100], Batch [126/147] train loss: 582.73, train corr: 0.02933
Epoch [67/100], Batch [127/147] train loss: 574.14, train corr: 0.02925
Epoch [67/100], Batch [128/147] train loss: 580.15, train corr: 0.02841
Epoch [67/100], Batch [129/147] train loss: 575.22, train corr: 0.02908
Epoch [67/100], Batch [130/147] train loss: 561.54, train corr: 0.03073
Epoch [67/100], Batch [131/147] train loss: 589.68, train corr: 0.02558
Epoch [67/100], Batch [132/147] train loss: 573.10, train corr: 0.03126
Epoch [67/100], Batch [133/147] train loss: 564.77, train corr: 0.03086
Epoch [67/100], Batch [134/147] train loss: 570.86, train corr: 0.01314
Epoch [67/100], Batch [135/147] train loss: 560.91, train corr: -0.02444
Epoch [67/100], Batch [136/147] train loss: 576.96, train corr: -0.02662
Epoch [67/100], Batch [137/147] train loss: 566.77, train corr: 0.00082
Epoch [67/100], Batch [138/147] train loss: 567.54, train corr: 0.02305
Epoch [67/100], Batch [139/147] train loss: 572.10, train corr: 0.01997
Epoch [67/100], Batch [140/147] train loss: 568.61, train corr: 0.01042
Epoch [67/100], Batch [141/147] train loss: 576.48, train corr: -0.02790
Epoch [67/100], Batch [142/147] train loss: 660.55, train corr: -0.02806
Epoch [67/100], Batch [143/147] train loss: 582.53, train corr: -0.03062
Epoch [67/100], Batch [144/147] train loss: 569.59, train corr: -0.02146
Epoch [67/100], Batch [145/147] train loss: 578.46, train corr: -0.01522
Epoch [67/100], Batch [146/147] train loss: 553.97, train corr: -0.01628
Epoch [67/100], Batch [147/147] train loss: 565.22, train corr: -0.02416
Epoch [67/100], validation loss: 598.65, validation correlation: -0.01867
Epoch [68/100], Batch [1/147] train loss: 620.65, train corr: -0.01567
Epoch [68/100], Batch [2/147] train loss: 582.55, train corr: 0.00724
Epoch [68/100], Batch [3/147] train loss: 587.43, train corr: 0.00781
Epoch [68/100], Batch [4/147] train loss: 568.30, train corr: -0.01822
Epoch [68/100], Batch [5/147] train loss: 567.40, train corr: -0.02146
Epoch [68/100], Batch [6/147] train loss: 594.62, train corr: -0.01825
Epoch [68/100], Batch [7/147] train loss: 561.78, train corr: -0.00698
Epoch [68/100], Batch [8/147] train loss: 566.61, train corr: 0.01315
Epoch [68/100], Batch [9/147] train loss: 576.66, train corr: 0.01795
Epoch [68/100], Batch [10/147] train loss: 562.74, train corr: 0.00685
Epoch [68/100], Batch [11/147] train loss: 574.90, train corr: -0.00889
Epoch [68/100], Batch [12/147] train loss: 558.18, train corr: -0.01277
Epoch [68/100], Batch [13/147] train loss: 569.71, train corr: -0.01613
Epoch [68/100], Batch [14/147] train loss: 566.01, train corr: -0.01671
Epoch [68/100], Batch [15/147] train loss: 558.27, train corr: -0.02079
Epoch [68/100], Batch [16/147] train loss: 578.60, train corr: -0.01956
Epoch [68/100], Batch [17/147] train loss: 562.39, train corr: -0.02304
Epoch [68/100], Batch [18/147] train loss: 580.42, train corr: -0.01731
Epoch [68/100], Batch [19/147] train loss: 564.46, train corr: 0.02311
Epoch [68/100], Batch [20/147] train loss: 572.10, train corr: 0.03212
Epoch [68/100], Batch [21/147] train loss: 563.76, train corr: 0.01997
Epoch [68/100], Batch [22/147] train loss: 567.32, train corr: -0.01167
Epoch [68/100], Batch [23/147] train loss: 576.21, train corr: -0.01509
Epoch [68/100], Batch [24/147] train loss: 575.64, train corr: -0.01191
Epoch [68/100], Batch [25/147] train loss: 557.10, train corr: 0.00875
Epoch [68/100], Batch [26/147] train loss: 571.18, train corr: 0.02298
Epoch [68/100], Batch [27/147] train loss: 573.85, train corr: 0.01746
Epoch [68/100], Batch [28/147] train loss: 551.40, train corr: -0.00300
Epoch [68/100], Batch [29/147] train loss: 591.42, train corr: -0.00448
Epoch [68/100], Batch [30/147] train loss: 557.43, train corr: -0.01249
Epoch [68/100], Batch [31/147] train loss: 567.72, train corr: -0.00455
Epoch [68/100], Batch [32/147] train loss: 645.21, train corr: -0.00284
Epoch [68/100], Batch [33/147] train loss: 570.64, train corr: -0.01820
Epoch [68/100], Batch [34/147] train loss: 550.51, train corr: -0.01813
Epoch [68/100], Batch [35/147] train loss: 576.33, train corr: 0.02907
Epoch [68/100], Batch [36/147] train loss: 569.15, train corr: 0.03357
Epoch [68/100], Batch [37/147] train loss: 580.53, train corr: 0.03017
Epoch [68/100], Batch [38/147] train loss: 584.14, train corr: 0.03123
Epoch [68/100], Batch [39/147] train loss: 555.28, train corr: -0.01589
Epoch [68/100], Batch [40/147] train loss: 582.43, train corr: -0.01039
Epoch [68/100], Batch [41/147] train loss: 571.03, train corr: -0.00222
Epoch [68/100], Batch [42/147] train loss: 556.21, train corr: 0.01755
Epoch [68/100], Batch [43/147] train loss: 576.88, train corr: 0.00855
Epoch [68/100], Batch [44/147] train loss: 579.48, train corr: -0.00442
Epoch [68/100], Batch [45/147] train loss: 574.92, train corr: -0.01102
Epoch [68/100], Batch [46/147] train loss: 576.79, train corr: -0.00585
Epoch [68/100], Batch [47/147] train loss: 553.78, train corr: 0.01405
Epoch [68/100], Batch [48/147] train loss: 558.03, train corr: 0.02955
Epoch [68/100], Batch [49/147] train loss: 568.65, train corr: 0.02942
Epoch [68/100], Batch [50/147] train loss: 566.53, train corr: 0.01539
Epoch [68/100], Batch [51/147] train loss: 575.71, train corr: -0.01004
Epoch [68/100], Batch [52/147] train loss: 557.16, train corr: -0.01465
Epoch [68/100], Batch [53/147] train loss: 565.40, train corr: 0.00240
Epoch [68/100], Batch [54/147] train loss: 560.88, train corr: 0.03152
Epoch [68/100], Batch [55/147] train loss: 573.92, train corr: 0.02618
Epoch [68/100], Batch [56/147] train loss: 560.30, train corr: -0.01203
Epoch [68/100], Batch [57/147] train loss: 555.62, train corr: -0.01760
Epoch [68/100], Batch [58/147] train loss: 559.63, train corr: -0.01436
Epoch [68/100], Batch [59/147] train loss: 543.74, train corr: 0.00650
Epoch [68/100], Batch [60/147] train loss: 815.74, train corr: 0.00440
Epoch [68/100], Batch [61/147] train loss: 577.08, train corr: -0.02469
Epoch [68/100], Batch [62/147] train loss: 568.43, train corr: 0.02908
Epoch [68/100], Batch [63/147] train loss: 577.72, train corr: 0.02914
Epoch [68/100], Batch [64/147] train loss: 567.63, train corr: 0.02908
Epoch [68/100], Batch [65/147] train loss: 743.38, train corr: 0.02853
Epoch [68/100], Batch [66/147] train loss: 586.57, train corr: -0.02071
Epoch [68/100], Batch [67/147] train loss: 572.31, train corr: 0.03014
Epoch [68/100], Batch [68/147] train loss: 577.94, train corr: 0.02669
Epoch [68/100], Batch [69/147] train loss: 560.54, train corr: 0.03082
Epoch [68/100], Batch [70/147] train loss: 593.04, train corr: 0.02704
Epoch [68/100], Batch [71/147] train loss: 567.55, train corr: 0.02895
Epoch [68/100], Batch [72/147] train loss: 574.24, train corr: 0.02778
Epoch [68/100], Batch [73/147] train loss: 584.28, train corr: -0.02345
Epoch [68/100], Batch [74/147] train loss: 577.53, train corr: 0.00053
Epoch [68/100], Batch [75/147] train loss: 570.51, train corr: 0.02607
Epoch [68/100], Batch [76/147] train loss: 580.06, train corr: 0.02439
Epoch [68/100], Batch [77/147] train loss: 577.72, train corr: 0.02642
Epoch [68/100], Batch [78/147] train loss: 572.85, train corr: 0.03102
Epoch [68/100], Batch [79/147] train loss: 569.33, train corr: -0.01476
Epoch [68/100], Batch [80/147] train loss: 564.13, train corr: -0.02511
Epoch [68/100], Batch [81/147] train loss: 564.42, train corr: 0.03175
Epoch [68/100], Batch [82/147] train loss: 560.89, train corr: 0.03122
Epoch [68/100], Batch [83/147] train loss: 574.37, train corr: 0.03017
Epoch [68/100], Batch [84/147] train loss: 562.62, train corr: 0.03165
Epoch [68/100], Batch [85/147] train loss: 588.94, train corr: 0.03579
Epoch [68/100], Batch [86/147] train loss: 573.23, train corr: -0.00761
Epoch [68/100], Batch [87/147] train loss: 568.51, train corr: -0.00368
Epoch [68/100], Batch [88/147] train loss: 581.76, train corr: 0.03501
Epoch [68/100], Batch [89/147] train loss: 554.96, train corr: 0.03339
Epoch [68/100], Batch [90/147] train loss: 565.64, train corr: 0.02965
Epoch [68/100], Batch [91/147] train loss: 568.85, train corr: -0.01701
Epoch [68/100], Batch [92/147] train loss: 574.61, train corr: -0.02376
Epoch [68/100], Batch [93/147] train loss: 567.27, train corr: -0.01963
Epoch [68/100], Batch [94/147] train loss: 569.83, train corr: 0.03300
Epoch [68/100], Batch [95/147] train loss: 571.96, train corr: 0.03197
Epoch [68/100], Batch [96/147] train loss: 568.16, train corr: 0.03027
Epoch [68/100], Batch [97/147] train loss: 559.83, train corr: 0.03269
Epoch [68/100], Batch [98/147] train loss: 569.72, train corr: -0.02193
Epoch [68/100], Batch [99/147] train loss: 558.56, train corr: -0.02183
Epoch [68/100], Batch [100/147] train loss: 549.89, train corr: 0.01927
Epoch [68/100], Batch [101/147] train loss: 569.05, train corr: 0.02724
Epoch [68/100], Batch [102/147] train loss: 556.78, train corr: 0.03219
Epoch [68/100], Batch [103/147] train loss: 650.06, train corr: 0.01911
Epoch [68/100], Batch [104/147] train loss: 578.35, train corr: -0.01794
Epoch [68/100], Batch [105/147] train loss: 568.64, train corr: -0.02237
Epoch [68/100], Batch [106/147] train loss: 571.30, train corr: 0.03178
Epoch [68/100], Batch [107/147] train loss: 555.11, train corr: 0.02857
Epoch [68/100], Batch [108/147] train loss: 563.01, train corr: 0.03196
Epoch [68/100], Batch [109/147] train loss: 560.57, train corr: 0.03446
Epoch [68/100], Batch [110/147] train loss: 576.34, train corr: -0.01707
Epoch [68/100], Batch [111/147] train loss: 559.96, train corr: -0.02409
Epoch [68/100], Batch [112/147] train loss: 562.87, train corr: -0.01304
Epoch [68/100], Batch [113/147] train loss: 560.96, train corr: 0.03428
Epoch [68/100], Batch [114/147] train loss: 550.13, train corr: 0.03247
Epoch [68/100], Batch [115/147] train loss: 580.20, train corr: 0.02597
Epoch [68/100], Batch [116/147] train loss: 574.15, train corr: -0.01571
Epoch [68/100], Batch [117/147] train loss: 562.88, train corr: -0.02418
Epoch [68/100], Batch [118/147] train loss: 574.18, train corr: -0.01410
Epoch [68/100], Batch [119/147] train loss: 573.55, train corr: 0.03337
Epoch [68/100], Batch [120/147] train loss: 575.83, train corr: 0.03184
Epoch [68/100], Batch [121/147] train loss: 577.87, train corr: 0.03228
Epoch [68/100], Batch [122/147] train loss: 567.11, train corr: -0.00028
Epoch [68/100], Batch [123/147] train loss: 577.07, train corr: -0.01115
Epoch [68/100], Batch [124/147] train loss: 558.56, train corr: -0.00348
Epoch [68/100], Batch [125/147] train loss: 563.72, train corr: 0.03298
Epoch [68/100], Batch [126/147] train loss: 557.55, train corr: 0.03240
Epoch [68/100], Batch [127/147] train loss: 564.52, train corr: 0.03370
Epoch [68/100], Batch [128/147] train loss: 563.15, train corr: -0.00360
Epoch [68/100], Batch [129/147] train loss: 553.20, train corr: -0.01797
Epoch [68/100], Batch [130/147] train loss: 552.02, train corr: -0.00726
Epoch [68/100], Batch [131/147] train loss: 563.52, train corr: 0.02315
Epoch [68/100], Batch [132/147] train loss: 584.74, train corr: 0.03271
Epoch [68/100], Batch [133/147] train loss: 561.88, train corr: 0.01637
Epoch [68/100], Batch [134/147] train loss: 573.64, train corr: -0.00738
Epoch [68/100], Batch [135/147] train loss: 555.61, train corr: -0.01549
Epoch [68/100], Batch [136/147] train loss: 570.03, train corr: -0.00959
Epoch [68/100], Batch [137/147] train loss: 559.06, train corr: 0.01851
Epoch [68/100], Batch [138/147] train loss: 557.08, train corr: 0.02136
Epoch [68/100], Batch [139/147] train loss: 543.30, train corr: 0.00076
Epoch [68/100], Batch [140/147] train loss: 551.86, train corr: -0.00858
Epoch [68/100], Batch [141/147] train loss: 569.27, train corr: -0.00799
Epoch [68/100], Batch [142/147] train loss: 551.25, train corr: 0.00326
Epoch [68/100], Batch [143/147] train loss: 569.94, train corr: 0.02467
Epoch [68/100], Batch [144/147] train loss: 574.44, train corr: 0.02333
Epoch [68/100], Batch [145/147] train loss: 554.85, train corr: 0.00315
Epoch [68/100], Batch [146/147] train loss: 556.21, train corr: -0.01233
Epoch [68/100], Batch [147/147] train loss: 549.51, train corr: -0.01332
Epoch [68/100], validation loss: 596.84, validation correlation: -0.00854
Epoch [69/100], Batch [1/147] train loss: 568.63, train corr: -0.00708
Epoch [69/100], Batch [2/147] train loss: 551.34, train corr: -0.01003
Epoch [69/100], Batch [3/147] train loss: 559.78, train corr: -0.00883
Epoch [69/100], Batch [4/147] train loss: 581.47, train corr: -0.00851
Epoch [69/100], Batch [5/147] train loss: 549.39, train corr: -0.00990
Epoch [69/100], Batch [6/147] train loss: 560.92, train corr: -0.00295
Epoch [69/100], Batch [7/147] train loss: 568.33, train corr: 0.01985
Epoch [69/100], Batch [8/147] train loss: 569.47, train corr: 0.02925
Epoch [69/100], Batch [9/147] train loss: 569.70, train corr: 0.02462
Epoch [69/100], Batch [10/147] train loss: 563.72, train corr: 0.00314
Epoch [69/100], Batch [11/147] train loss: 647.75, train corr: -0.00633
Epoch [69/100], Batch [12/147] train loss: 559.17, train corr: -0.01811
Epoch [69/100], Batch [13/147] train loss: 586.21, train corr: -0.01436
Epoch [69/100], Batch [14/147] train loss: 564.71, train corr: 0.00132
Epoch [69/100], Batch [15/147] train loss: 574.96, train corr: 0.02900
Epoch [69/100], Batch [16/147] train loss: 583.04, train corr: 0.03154
Epoch [69/100], Batch [17/147] train loss: 560.59, train corr: 0.01066
Epoch [69/100], Batch [18/147] train loss: 569.49, train corr: -0.00078
Epoch [69/100], Batch [19/147] train loss: 570.17, train corr: 0.00601
Epoch [69/100], Batch [20/147] train loss: 551.68, train corr: 0.02804
Epoch [69/100], Batch [21/147] train loss: 566.23, train corr: 0.02454
Epoch [69/100], Batch [22/147] train loss: 553.76, train corr: -0.00488
Epoch [69/100], Batch [23/147] train loss: 555.96, train corr: -0.01557
Epoch [69/100], Batch [24/147] train loss: 557.14, train corr: -0.01845
Epoch [69/100], Batch [25/147] train loss: 559.88, train corr: -0.00771
Epoch [69/100], Batch [26/147] train loss: 572.56, train corr: 0.02578
Epoch [69/100], Batch [27/147] train loss: 577.40, train corr: 0.03384
Epoch [69/100], Batch [28/147] train loss: 560.48, train corr: 0.03108
Epoch [69/100], Batch [29/147] train loss: 570.01, train corr: 0.00625
Epoch [69/100], Batch [30/147] train loss: 564.72, train corr: -0.00964
Epoch [69/100], Batch [31/147] train loss: 543.07, train corr: -0.01394
Epoch [69/100], Batch [32/147] train loss: 567.60, train corr: -0.00449
Epoch [69/100], Batch [33/147] train loss: 560.63, train corr: 0.00147
Epoch [69/100], Batch [34/147] train loss: 571.51, train corr: -0.00156
Epoch [69/100], Batch [35/147] train loss: 556.73, train corr: -0.00834
Epoch [69/100], Batch [36/147] train loss: 567.83, train corr: -0.01181
Epoch [69/100], Batch [37/147] train loss: 575.35, train corr: -0.00332
Epoch [69/100], Batch [38/147] train loss: 584.47, train corr: 0.01478
Epoch [69/100], Batch [39/147] train loss: 561.73, train corr: 0.01700
Epoch [69/100], Batch [40/147] train loss: 558.27, train corr: 0.00377
Epoch [69/100], Batch [41/147] train loss: 548.90, train corr: -0.01157
Epoch [69/100], Batch [42/147] train loss: 611.91, train corr: -0.01248
Epoch [69/100], Batch [43/147] train loss: 567.46, train corr: 0.02705
Epoch [69/100], Batch [44/147] train loss: 563.16, train corr: 0.03413
Epoch [69/100], Batch [45/147] train loss: 558.49, train corr: 0.03473
Epoch [69/100], Batch [46/147] train loss: 570.16, train corr: 0.00737
Epoch [69/100], Batch [47/147] train loss: 566.08, train corr: -0.01334
Epoch [69/100], Batch [48/147] train loss: 568.98, train corr: -0.01769
Epoch [69/100], Batch [49/147] train loss: 574.37, train corr: -0.01580
Epoch [69/100], Batch [50/147] train loss: 604.41, train corr: 0.00375
Epoch [69/100], Batch [51/147] train loss: 581.01, train corr: -0.00084
Epoch [69/100], Batch [52/147] train loss: 578.45, train corr: 0.00265
Epoch [69/100], Batch [53/147] train loss: 588.83, train corr: 0.00605
Epoch [69/100], Batch [54/147] train loss: 561.39, train corr: 0.01001
Epoch [69/100], Batch [55/147] train loss: 573.23, train corr: 0.01459
Epoch [69/100], Batch [56/147] train loss: 574.59, train corr: 0.00899
Epoch [69/100], Batch [57/147] train loss: 575.86, train corr: 0.00514
Epoch [69/100], Batch [58/147] train loss: 573.74, train corr: 0.00532
Epoch [69/100], Batch [59/147] train loss: 567.69, train corr: 0.00642
Epoch [69/100], Batch [60/147] train loss: 573.57, train corr: 0.01643
Epoch [69/100], Batch [61/147] train loss: 563.08, train corr: 0.00789
Epoch [69/100], Batch [62/147] train loss: 572.40, train corr: 0.01291
Epoch [69/100], Batch [63/147] train loss: 563.68, train corr: 0.01168
Epoch [69/100], Batch [64/147] train loss: 556.12, train corr: 0.00792
Epoch [69/100], Batch [65/147] train loss: 598.17, train corr: 0.00687
Epoch [69/100], Batch [66/147] train loss: 565.77, train corr: -0.01331
Epoch [69/100], Batch [67/147] train loss: 558.59, train corr: -0.01397
Epoch [69/100], Batch [68/147] train loss: 570.04, train corr: 0.00164
Epoch [69/100], Batch [69/147] train loss: 577.37, train corr: 0.02307
Epoch [69/100], Batch [70/147] train loss: 585.96, train corr: 0.02478
Epoch [69/100], Batch [71/147] train loss: 561.09, train corr: 0.01197
Epoch [69/100], Batch [72/147] train loss: 569.22, train corr: -0.00828
Epoch [69/100], Batch [73/147] train loss: 570.19, train corr: -0.00694
Epoch [69/100], Batch [74/147] train loss: 563.97, train corr: -0.01572
Epoch [69/100], Batch [75/147] train loss: 572.73, train corr: -0.00483
Epoch [69/100], Batch [76/147] train loss: 564.28, train corr: -0.00527
Epoch [69/100], Batch [77/147] train loss: 563.53, train corr: -0.00816
Epoch [69/100], Batch [78/147] train loss: 548.97, train corr: -0.00594
Epoch [69/100], Batch [79/147] train loss: 559.21, train corr: 0.00177
Epoch [69/100], Batch [80/147] train loss: 573.02, train corr: 0.01843
Epoch [69/100], Batch [81/147] train loss: 570.85, train corr: 0.02753
Epoch [69/100], Batch [82/147] train loss: 807.75, train corr: 0.01441
Epoch [69/100], Batch [83/147] train loss: 559.68, train corr: -0.02413
Epoch [69/100], Batch [84/147] train loss: 544.69, train corr: 0.03450
Epoch [69/100], Batch [85/147] train loss: 564.84, train corr: 0.03039
Epoch [69/100], Batch [86/147] train loss: 576.36, train corr: 0.02733
Epoch [69/100], Batch [87/147] train loss: 581.82, train corr: 0.02974
Epoch [69/100], Batch [88/147] train loss: 573.32, train corr: 0.03406
Epoch [69/100], Batch [89/147] train loss: 570.49, train corr: -0.01663
Epoch [69/100], Batch [90/147] train loss: 570.07, train corr: -0.00242
Epoch [69/100], Batch [91/147] train loss: 572.97, train corr: 0.03197
Epoch [69/100], Batch [92/147] train loss: 549.33, train corr: 0.03217
Epoch [69/100], Batch [93/147] train loss: 570.99, train corr: 0.02798
Epoch [69/100], Batch [94/147] train loss: 568.18, train corr: -0.00146
Epoch [69/100], Batch [95/147] train loss: 556.47, train corr: -0.02677
Epoch [69/100], Batch [96/147] train loss: 554.26, train corr: -0.02518
Epoch [69/100], Batch [97/147] train loss: 582.80, train corr: 0.03351
Epoch [69/100], Batch [98/147] train loss: 566.28, train corr: 0.02896
Epoch [69/100], Batch [99/147] train loss: 575.62, train corr: 0.02759
Epoch [69/100], Batch [100/147] train loss: 562.42, train corr: 0.03172
Epoch [69/100], Batch [101/147] train loss: 572.49, train corr: -0.00817
Epoch [69/100], Batch [102/147] train loss: 567.95, train corr: -0.01885
Epoch [69/100], Batch [103/147] train loss: 573.12, train corr: 0.01036
Epoch [69/100], Batch [104/147] train loss: 630.95, train corr: 0.02891
Epoch [69/100], Batch [105/147] train loss: 570.87, train corr: 0.03338
Epoch [69/100], Batch [106/147] train loss: 572.67, train corr: -0.00969
Epoch [69/100], Batch [107/147] train loss: 555.91, train corr: -0.01670
Epoch [69/100], Batch [108/147] train loss: 580.58, train corr: -0.00258
Epoch [69/100], Batch [109/147] train loss: 567.09, train corr: 0.03188
Epoch [69/100], Batch [110/147] train loss: 580.06, train corr: 0.03085
Epoch [69/100], Batch [111/147] train loss: 589.60, train corr: 0.02832
Epoch [69/100], Batch [112/147] train loss: 568.59, train corr: 0.00722
Epoch [69/100], Batch [113/147] train loss: 565.26, train corr: -0.01906
Epoch [69/100], Batch [114/147] train loss: 565.27, train corr: -0.02067
Epoch [69/100], Batch [115/147] train loss: 568.21, train corr: -0.00842
Epoch [69/100], Batch [116/147] train loss: 558.56, train corr: 0.02061
Epoch [69/100], Batch [117/147] train loss: 573.50, train corr: 0.01774
Epoch [69/100], Batch [118/147] train loss: 556.40, train corr: -0.01676
Epoch [69/100], Batch [119/147] train loss: 566.60, train corr: -0.01779
Epoch [69/100], Batch [120/147] train loss: 572.44, train corr: -0.00827
Epoch [69/100], Batch [121/147] train loss: 574.25, train corr: 0.03132
Epoch [69/100], Batch [122/147] train loss: 563.96, train corr: 0.03181
Epoch [69/100], Batch [123/147] train loss: 561.05, train corr: 0.03461
Epoch [69/100], Batch [124/147] train loss: 580.98, train corr: 0.01551
Epoch [69/100], Batch [125/147] train loss: 564.46, train corr: -0.00720
Epoch [69/100], Batch [126/147] train loss: 554.20, train corr: -0.00996
Epoch [69/100], Batch [127/147] train loss: 577.66, train corr: 0.02769
Epoch [69/100], Batch [128/147] train loss: 751.68, train corr: 0.03227
Epoch [69/100], Batch [129/147] train loss: 572.84, train corr: -0.02000
Epoch [69/100], Batch [130/147] train loss: 556.03, train corr: 0.03299
Epoch [69/100], Batch [131/147] train loss: 573.70, train corr: 0.03025
Epoch [69/100], Batch [132/147] train loss: 574.07, train corr: 0.02783
Epoch [69/100], Batch [133/147] train loss: 582.33, train corr: 0.02852
Epoch [69/100], Batch [134/147] train loss: 577.66, train corr: 0.03282
Epoch [69/100], Batch [135/147] train loss: 565.41, train corr: -0.02333
Epoch [69/100], Batch [136/147] train loss: 565.97, train corr: -0.02426
Epoch [69/100], Batch [137/147] train loss: 569.86, train corr: 0.03196
Epoch [69/100], Batch [138/147] train loss: 581.02, train corr: 0.02692
Epoch [69/100], Batch [139/147] train loss: 577.15, train corr: 0.02486
Epoch [69/100], Batch [140/147] train loss: 546.73, train corr: 0.03076
Epoch [69/100], Batch [141/147] train loss: 558.45, train corr: 0.03311
Epoch [69/100], Batch [142/147] train loss: 559.22, train corr: -0.02513
Epoch [69/100], Batch [143/147] train loss: 562.77, train corr: -0.02193
Epoch [69/100], Batch [144/147] train loss: 565.63, train corr: 0.03277
Epoch [69/100], Batch [145/147] train loss: 583.70, train corr: 0.02803
Epoch [69/100], Batch [146/147] train loss: 559.54, train corr: 0.03293
Epoch [69/100], Batch [147/147] train loss: 555.91, train corr: 0.02808
Epoch [69/100], validation loss: 597.82, validation correlation: -0.00868
Epoch [70/100], Batch [1/147] train loss: 584.70, train corr: -0.00602
Epoch [70/100], Batch [2/147] train loss: 565.35, train corr: -0.01762
Epoch [70/100], Batch [3/147] train loss: 557.80, train corr: 0.00439
Epoch [70/100], Batch [4/147] train loss: 569.66, train corr: 0.03142
Epoch [70/100], Batch [5/147] train loss: 573.03, train corr: 0.02127
Epoch [70/100], Batch [6/147] train loss: 555.79, train corr: -0.01556
Epoch [70/100], Batch [7/147] train loss: 570.78, train corr: -0.02119
Epoch [70/100], Batch [8/147] train loss: 628.66, train corr: -0.01926
Epoch [70/100], Batch [9/147] train loss: 566.35, train corr: 0.03409
Epoch [70/100], Batch [10/147] train loss: 568.82, train corr: 0.03090
Epoch [70/100], Batch [11/147] train loss: 564.55, train corr: 0.02821
Epoch [70/100], Batch [12/147] train loss: 578.98, train corr: 0.02737
Epoch [70/100], Batch [13/147] train loss: 590.01, train corr: -0.01721
Epoch [70/100], Batch [14/147] train loss: 551.60, train corr: -0.01920
Epoch [70/100], Batch [15/147] train loss: 586.77, train corr: 0.02891
Epoch [70/100], Batch [16/147] train loss: 574.33, train corr: 0.03272
Epoch [70/100], Batch [17/147] train loss: 577.49, train corr: 0.03297
Epoch [70/100], Batch [18/147] train loss: 568.96, train corr: 0.02927
Epoch [70/100], Batch [19/147] train loss: 561.49, train corr: -0.00223
Epoch [70/100], Batch [20/147] train loss: 550.91, train corr: -0.01172
Epoch [70/100], Batch [21/147] train loss: 571.28, train corr: -0.00370
Epoch [70/100], Batch [22/147] train loss: 565.98, train corr: 0.00479
Epoch [70/100], Batch [23/147] train loss: 558.45, train corr: 0.00696
Epoch [70/100], Batch [24/147] train loss: 560.74, train corr: 0.00163
Epoch [70/100], Batch [25/147] train loss: 573.08, train corr: -0.01288
Epoch [70/100], Batch [26/147] train loss: 554.85, train corr: -0.01380
Epoch [70/100], Batch [27/147] train loss: 555.40, train corr: -0.01316
Epoch [70/100], Batch [28/147] train loss: 570.05, train corr: 0.00039
Epoch [70/100], Batch [29/147] train loss: 578.06, train corr: 0.00419
Epoch [70/100], Batch [30/147] train loss: 561.96, train corr: -0.00668
Epoch [70/100], Batch [31/147] train loss: 552.16, train corr: -0.01109
Epoch [70/100], Batch [32/147] train loss: 561.52, train corr: -0.00166
Epoch [70/100], Batch [33/147] train loss: 565.01, train corr: 0.00824
Epoch [70/100], Batch [34/147] train loss: 569.48, train corr: 0.02331
Epoch [70/100], Batch [35/147] train loss: 588.85, train corr: 0.02368
Epoch [70/100], Batch [36/147] train loss: 566.18, train corr: 0.00423
Epoch [70/100], Batch [37/147] train loss: 585.40, train corr: -0.00314
Epoch [70/100], Batch [38/147] train loss: 569.42, train corr: -0.01029
Epoch [70/100], Batch [39/147] train loss: 748.95, train corr: -0.01052
Epoch [70/100], Batch [40/147] train loss: 645.33, train corr: -0.02254
Epoch [70/100], Batch [41/147] train loss: 819.01, train corr: 0.02588
Epoch [70/100], Batch [42/147] train loss: 586.22, train corr: 0.02003
Epoch [70/100], Batch [43/147] train loss: 564.32, train corr: 0.03154
Epoch [70/100], Batch [44/147] train loss: 564.83, train corr: 0.02760
Epoch [70/100], Batch [45/147] train loss: 574.74, train corr: -0.02094
Epoch [70/100], Batch [46/147] train loss: 592.70, train corr: -0.01436
Epoch [70/100], Batch [47/147] train loss: 557.22, train corr: 0.03303
Epoch [70/100], Batch [48/147] train loss: 561.89, train corr: 0.03216
Epoch [70/100], Batch [49/147] train loss: 565.61, train corr: 0.02990
Epoch [70/100], Batch [50/147] train loss: 621.51, train corr: 0.03007
Epoch [70/100], Batch [51/147] train loss: 561.18, train corr: 0.03114
Epoch [70/100], Batch [52/147] train loss: 570.54, train corr: 0.03407
Epoch [70/100], Batch [53/147] train loss: 566.58, train corr: 0.03381
Epoch [70/100], Batch [54/147] train loss: 568.05, train corr: 0.03380
Epoch [70/100], Batch [55/147] train loss: 576.64, train corr: 0.03287
Epoch [70/100], Batch [56/147] train loss: 559.60, train corr: 0.02432
Epoch [70/100], Batch [57/147] train loss: 587.94, train corr: 0.01306
Epoch [70/100], Batch [58/147] train loss: 584.79, train corr: 0.02837
Epoch [70/100], Batch [59/147] train loss: 567.39, train corr: 0.03434
Epoch [70/100], Batch [60/147] train loss: 578.71, train corr: 0.03397
Epoch [70/100], Batch [61/147] train loss: 564.53, train corr: 0.03103
Epoch [70/100], Batch [62/147] train loss: 578.32, train corr: -0.01232
Epoch [70/100], Batch [63/147] train loss: 575.23, train corr: -0.01967
Epoch [70/100], Batch [64/147] train loss: 570.27, train corr: -0.01964
Epoch [70/100], Batch [65/147] train loss: 567.51, train corr: 0.02633
Epoch [70/100], Batch [66/147] train loss: 563.01, train corr: 0.03283
Epoch [70/100], Batch [67/147] train loss: 557.71, train corr: 0.03153
Epoch [70/100], Batch [68/147] train loss: 563.30, train corr: 0.03287
Epoch [70/100], Batch [69/147] train loss: 567.15, train corr: -0.00315
Epoch [70/100], Batch [70/147] train loss: 565.82, train corr: -0.02000
Epoch [70/100], Batch [71/147] train loss: 558.61, train corr: -0.01904
Epoch [70/100], Batch [72/147] train loss: 567.99, train corr: -0.00943
Epoch [70/100], Batch [73/147] train loss: 551.01, train corr: 0.02772
Epoch [70/100], Batch [74/147] train loss: 554.91, train corr: 0.02665
Epoch [70/100], Batch [75/147] train loss: 595.27, train corr: 0.01671
Epoch [70/100], Batch [76/147] train loss: 572.42, train corr: -0.00467
Epoch [70/100], Batch [77/147] train loss: 573.04, train corr: -0.00064
Epoch [70/100], Batch [78/147] train loss: 581.78, train corr: 0.00395
Epoch [70/100], Batch [79/147] train loss: 553.58, train corr: -0.00669
Epoch [70/100], Batch [80/147] train loss: 564.89, train corr: -0.01268
Epoch [70/100], Batch [81/147] train loss: 555.52, train corr: -0.02457
Epoch [70/100], Batch [82/147] train loss: 573.36, train corr: -0.01778
Epoch [70/100], Batch [83/147] train loss: 555.62, train corr: -0.01432
Epoch [70/100], Batch [84/147] train loss: 560.79, train corr: 0.03221
Epoch [70/100], Batch [85/147] train loss: 559.15, train corr: 0.03227
Epoch [70/100], Batch [86/147] train loss: 568.16, train corr: 0.03261
Epoch [70/100], Batch [87/147] train loss: 580.51, train corr: 0.00386
Epoch [70/100], Batch [88/147] train loss: 570.98, train corr: -0.01000
Epoch [70/100], Batch [89/147] train loss: 566.54, train corr: -0.00295
Epoch [70/100], Batch [90/147] train loss: 569.86, train corr: 0.01060
Epoch [70/100], Batch [91/147] train loss: 579.53, train corr: 0.02449
Epoch [70/100], Batch [92/147] train loss: 558.34, train corr: 0.01826
Epoch [70/100], Batch [93/147] train loss: 577.04, train corr: 0.00697
Epoch [70/100], Batch [94/147] train loss: 572.96, train corr: -0.01042
Epoch [70/100], Batch [95/147] train loss: 565.66, train corr: -0.00974
Epoch [70/100], Batch [96/147] train loss: 560.73, train corr: -0.00126
Epoch [70/100], Batch [97/147] train loss: 570.66, train corr: 0.03348
Epoch [70/100], Batch [98/147] train loss: 561.14, train corr: 0.03225
Epoch [70/100], Batch [99/147] train loss: 559.88, train corr: 0.02581
Epoch [70/100], Batch [100/147] train loss: 575.17, train corr: 0.00648
Epoch [70/100], Batch [101/147] train loss: 571.55, train corr: 0.00970
Epoch [70/100], Batch [102/147] train loss: 568.15, train corr: 0.01671
Epoch [70/100], Batch [103/147] train loss: 584.26, train corr: 0.01830
Epoch [70/100], Batch [104/147] train loss: 573.53, train corr: 0.01270
Epoch [70/100], Batch [105/147] train loss: 578.16, train corr: -0.00385
Epoch [70/100], Batch [106/147] train loss: 565.99, train corr: -0.01067
Epoch [70/100], Batch [107/147] train loss: 564.96, train corr: -0.01255
Epoch [70/100], Batch [108/147] train loss: 555.90, train corr: -0.00356
Epoch [70/100], Batch [109/147] train loss: 578.23, train corr: 0.02417
Epoch [70/100], Batch [110/147] train loss: 558.87, train corr: 0.03217
Epoch [70/100], Batch [111/147] train loss: 573.46, train corr: 0.03231
Epoch [70/100], Batch [112/147] train loss: 565.45, train corr: 0.02092
Epoch [70/100], Batch [113/147] train loss: 561.56, train corr: 0.00326
Epoch [70/100], Batch [114/147] train loss: 572.19, train corr: -0.00681
Epoch [70/100], Batch [115/147] train loss: 565.84, train corr: -0.01194
Epoch [70/100], Batch [116/147] train loss: 568.48, train corr: -0.00844
Epoch [70/100], Batch [117/147] train loss: 564.68, train corr: 0.00332
Epoch [70/100], Batch [118/147] train loss: 576.42, train corr: 0.00842
Epoch [70/100], Batch [119/147] train loss: 573.20, train corr: -0.00996
Epoch [70/100], Batch [120/147] train loss: 562.81, train corr: -0.01630
Epoch [70/100], Batch [121/147] train loss: 568.67, train corr: -0.00543
Epoch [70/100], Batch [122/147] train loss: 581.41, train corr: 0.02373
Epoch [70/100], Batch [123/147] train loss: 571.81, train corr: 0.02772
Epoch [70/100], Batch [124/147] train loss: 554.81, train corr: 0.01503
Epoch [70/100], Batch [125/147] train loss: 553.74, train corr: -0.00600
Epoch [70/100], Batch [126/147] train loss: 557.23, train corr: -0.00651
Epoch [70/100], Batch [127/147] train loss: 560.22, train corr: -0.00309
Epoch [70/100], Batch [128/147] train loss: 572.39, train corr: 0.00631
Epoch [70/100], Batch [129/147] train loss: 562.11, train corr: 0.00697
Epoch [70/100], Batch [130/147] train loss: 570.43, train corr: 0.00916
Epoch [70/100], Batch [131/147] train loss: 559.71, train corr: -0.00038
Epoch [70/100], Batch [132/147] train loss: 571.93, train corr: -0.00204
Epoch [70/100], Batch [133/147] train loss: 566.17, train corr: 0.00648
Epoch [70/100], Batch [134/147] train loss: 562.78, train corr: 0.00980
Epoch [70/100], Batch [135/147] train loss: 576.65, train corr: 0.01193
Epoch [70/100], Batch [136/147] train loss: 561.31, train corr: 0.00278
Epoch [70/100], Batch [137/147] train loss: 581.81, train corr: -0.00310
Epoch [70/100], Batch [138/147] train loss: 554.67, train corr: -0.00617
Epoch [70/100], Batch [139/147] train loss: 568.91, train corr: -0.00458
Epoch [70/100], Batch [140/147] train loss: 570.96, train corr: 0.00540
Epoch [70/100], Batch [141/147] train loss: 567.93, train corr: 0.01573
Epoch [70/100], Batch [142/147] train loss: 558.25, train corr: 0.00636
Epoch [70/100], Batch [143/147] train loss: 557.92, train corr: -0.00595
Epoch [70/100], Batch [144/147] train loss: 560.03, train corr: -0.01511
Epoch [70/100], Batch [145/147] train loss: 556.26, train corr: -0.01498
Epoch [70/100], Batch [146/147] train loss: 556.54, train corr: -0.00367
Epoch [70/100], Batch [147/147] train loss: 570.44, train corr: 0.03106
Epoch [70/100], validation loss: 597.04, validation correlation: 0.03449
Epoch [71/100], Batch [1/147] train loss: 573.51, train corr: 0.03510
Epoch [71/100], Batch [2/147] train loss: 567.42, train corr: 0.02857
Epoch [71/100], Batch [3/147] train loss: 573.37, train corr: 0.00077
Epoch [71/100], Batch [4/147] train loss: 582.62, train corr: -0.00480
Epoch [71/100], Batch [5/147] train loss: 560.25, train corr: -0.01271
Epoch [71/100], Batch [6/147] train loss: 569.85, train corr: -0.01257
Epoch [71/100], Batch [7/147] train loss: 574.53, train corr: -0.00945
Epoch [71/100], Batch [8/147] train loss: 556.08, train corr: -0.00412
Epoch [71/100], Batch [9/147] train loss: 643.57, train corr: 0.01075
Epoch [71/100], Batch [10/147] train loss: 559.07, train corr: -0.00210
Epoch [71/100], Batch [11/147] train loss: 574.55, train corr: 0.00193
Epoch [71/100], Batch [12/147] train loss: 563.61, train corr: 0.02576
Epoch [71/100], Batch [13/147] train loss: 554.03, train corr: 0.03199
Epoch [71/100], Batch [14/147] train loss: 582.45, train corr: 0.03302
Epoch [71/100], Batch [15/147] train loss: 579.34, train corr: 0.02783
Epoch [71/100], Batch [16/147] train loss: 569.66, train corr: -0.00513
Epoch [71/100], Batch [17/147] train loss: 562.08, train corr: -0.00470
Epoch [71/100], Batch [18/147] train loss: 570.56, train corr: 0.00338
Epoch [71/100], Batch [19/147] train loss: 568.73, train corr: 0.02277
Epoch [71/100], Batch [20/147] train loss: 562.16, train corr: 0.01886
Epoch [71/100], Batch [21/147] train loss: 818.32, train corr: 0.00140
Epoch [71/100], Batch [22/147] train loss: 604.70, train corr: 0.00730
Epoch [71/100], Batch [23/147] train loss: 578.05, train corr: 0.02823
Epoch [71/100], Batch [24/147] train loss: 592.61, train corr: 0.02978
Epoch [71/100], Batch [25/147] train loss: 597.72, train corr: 0.02590
Epoch [71/100], Batch [26/147] train loss: 596.81, train corr: 0.02953
Epoch [71/100], Batch [27/147] train loss: 687.73, train corr: 0.02213
Epoch [71/100], Batch [28/147] train loss: 580.10, train corr: 0.02652
Epoch [71/100], Batch [29/147] train loss: 595.49, train corr: 0.02461
Epoch [71/100], Batch [30/147] train loss: 594.57, train corr: 0.02373
Epoch [71/100], Batch [31/147] train loss: 572.42, train corr: 0.02503
Epoch [71/100], Batch [32/147] train loss: 564.27, train corr: 0.02545
Epoch [71/100], Batch [33/147] train loss: 582.56, train corr: 0.01729
Epoch [71/100], Batch [34/147] train loss: 583.14, train corr: -0.00715
Epoch [71/100], Batch [35/147] train loss: 564.55, train corr: -0.00809
Epoch [71/100], Batch [36/147] train loss: 582.48, train corr: -0.01067
Epoch [71/100], Batch [37/147] train loss: 564.38, train corr: -0.01636
Epoch [71/100], Batch [38/147] train loss: 572.69, train corr: -0.01624
Epoch [71/100], Batch [39/147] train loss: 577.74, train corr: -0.00758
Epoch [71/100], Batch [40/147] train loss: 551.59, train corr: 0.02590
Epoch [71/100], Batch [41/147] train loss: 580.45, train corr: 0.03331
Epoch [71/100], Batch [42/147] train loss: 583.67, train corr: 0.03012
Epoch [71/100], Batch [43/147] train loss: 546.24, train corr: 0.03060
Epoch [71/100], Batch [44/147] train loss: 571.38, train corr: 0.02798
Epoch [71/100], Batch [45/147] train loss: 582.51, train corr: 0.02114
Epoch [71/100], Batch [46/147] train loss: 572.68, train corr: -0.01459
Epoch [71/100], Batch [47/147] train loss: 582.83, train corr: -0.02944
Epoch [71/100], Batch [48/147] train loss: 568.64, train corr: -0.02683
Epoch [71/100], Batch [49/147] train loss: 557.85, train corr: -0.02387
Epoch [71/100], Batch [50/147] train loss: 578.54, train corr: -0.02948
Epoch [71/100], Batch [51/147] train loss: 563.48, train corr: -0.03082
Epoch [71/100], Batch [52/147] train loss: 577.45, train corr: -0.03280
Epoch [71/100], Batch [53/147] train loss: 575.06, train corr: -0.03331
Epoch [71/100], Batch [54/147] train loss: 560.44, train corr: -0.02900
Epoch [71/100], Batch [55/147] train loss: 549.16, train corr: -0.02490
Epoch [71/100], Batch [56/147] train loss: 563.96, train corr: -0.02456
Epoch [71/100], Batch [57/147] train loss: 541.86, train corr: -0.01267
Epoch [71/100], Batch [58/147] train loss: 564.77, train corr: 0.01502
Epoch [71/100], Batch [59/147] train loss: 588.43, train corr: 0.02178
Epoch [71/100], Batch [60/147] train loss: 557.90, train corr: 0.02925
Epoch [71/100], Batch [61/147] train loss: 584.43, train corr: 0.02856
Epoch [71/100], Batch [62/147] train loss: 562.48, train corr: 0.03282
Epoch [71/100], Batch [63/147] train loss: 562.38, train corr: 0.00513
Epoch [71/100], Batch [64/147] train loss: 568.67, train corr: -0.01010
Epoch [71/100], Batch [65/147] train loss: 576.17, train corr: -0.01023
Epoch [71/100], Batch [66/147] train loss: 582.13, train corr: -0.00115
Epoch [71/100], Batch [67/147] train loss: 749.03, train corr: 0.02043
Epoch [71/100], Batch [68/147] train loss: 570.89, train corr: -0.01106
Epoch [71/100], Batch [69/147] train loss: 565.83, train corr: 0.02744
Epoch [71/100], Batch [70/147] train loss: 581.84, train corr: 0.03110
Epoch [71/100], Batch [71/147] train loss: 578.15, train corr: 0.03306
Epoch [71/100], Batch [72/147] train loss: 564.46, train corr: 0.02783
Epoch [71/100], Batch [73/147] train loss: 578.78, train corr: 0.03012
Epoch [71/100], Batch [74/147] train loss: 569.74, train corr: -0.02416
Epoch [71/100], Batch [75/147] train loss: 582.44, train corr: -0.02304
Epoch [71/100], Batch [76/147] train loss: 565.88, train corr: -0.00867
Epoch [71/100], Batch [77/147] train loss: 575.98, train corr: 0.02919
Epoch [71/100], Batch [78/147] train loss: 586.18, train corr: 0.02761
Epoch [71/100], Batch [79/147] train loss: 564.24, train corr: 0.02650
Epoch [71/100], Batch [80/147] train loss: 562.22, train corr: 0.02831
Epoch [71/100], Batch [81/147] train loss: 576.77, train corr: 0.03312
Epoch [71/100], Batch [82/147] train loss: 575.70, train corr: -0.02256
Epoch [71/100], Batch [83/147] train loss: 577.09, train corr: -0.01946
Epoch [71/100], Batch [84/147] train loss: 586.20, train corr: 0.01511
Epoch [71/100], Batch [85/147] train loss: 556.47, train corr: 0.03291
Epoch [71/100], Batch [86/147] train loss: 562.12, train corr: 0.03412
Epoch [71/100], Batch [87/147] train loss: 555.29, train corr: 0.03459
Epoch [71/100], Batch [88/147] train loss: 575.05, train corr: 0.03529
Epoch [71/100], Batch [89/147] train loss: 575.34, train corr: 0.03145
Epoch [71/100], Batch [90/147] train loss: 565.49, train corr: 0.03357
Epoch [71/100], Batch [91/147] train loss: 562.70, train corr: 0.03479
Epoch [71/100], Batch [92/147] train loss: 606.53, train corr: 0.02494
Epoch [71/100], Batch [93/147] train loss: 575.85, train corr: -0.00314
Epoch [71/100], Batch [94/147] train loss: 582.92, train corr: -0.01573
Epoch [71/100], Batch [95/147] train loss: 563.07, train corr: -0.01840
Epoch [71/100], Batch [96/147] train loss: 557.58, train corr: 0.00212
Epoch [71/100], Batch [97/147] train loss: 563.70, train corr: 0.03298
Epoch [71/100], Batch [98/147] train loss: 584.72, train corr: 0.02980
Epoch [71/100], Batch [99/147] train loss: 567.10, train corr: 0.02986
Epoch [71/100], Batch [100/147] train loss: 565.55, train corr: -0.00362
Epoch [71/100], Batch [101/147] train loss: 551.62, train corr: -0.02079
Epoch [71/100], Batch [102/147] train loss: 553.45, train corr: -0.01978
Epoch [71/100], Batch [103/147] train loss: 546.49, train corr: -0.01078
Epoch [71/100], Batch [104/147] train loss: 579.92, train corr: 0.03289
Epoch [71/100], Batch [105/147] train loss: 569.43, train corr: 0.03394
Epoch [71/100], Batch [106/147] train loss: 578.34, train corr: 0.03122
Epoch [71/100], Batch [107/147] train loss: 553.49, train corr: 0.00005
Epoch [71/100], Batch [108/147] train loss: 564.95, train corr: -0.01137
Epoch [71/100], Batch [109/147] train loss: 574.67, train corr: -0.00199
Epoch [71/100], Batch [110/147] train loss: 584.12, train corr: 0.01296
Epoch [71/100], Batch [111/147] train loss: 572.32, train corr: 0.01350
Epoch [71/100], Batch [112/147] train loss: 555.18, train corr: -0.00486
Epoch [71/100], Batch [113/147] train loss: 559.44, train corr: -0.00733
Epoch [71/100], Batch [114/147] train loss: 559.64, train corr: -0.00625
Epoch [71/100], Batch [115/147] train loss: 548.11, train corr: 0.02246
Epoch [71/100], Batch [116/147] train loss: 576.20, train corr: 0.03226
Epoch [71/100], Batch [117/147] train loss: 549.46, train corr: 0.03405
Epoch [71/100], Batch [118/147] train loss: 579.17, train corr: 0.03450
Epoch [71/100], Batch [119/147] train loss: 559.02, train corr: 0.00693
Epoch [71/100], Batch [120/147] train loss: 566.08, train corr: -0.00620
Epoch [71/100], Batch [121/147] train loss: 568.95, train corr: -0.00352
Epoch [71/100], Batch [122/147] train loss: 567.90, train corr: 0.00679
Epoch [71/100], Batch [123/147] train loss: 566.90, train corr: 0.01176
Epoch [71/100], Batch [124/147] train loss: 562.68, train corr: 0.01095
Epoch [71/100], Batch [125/147] train loss: 560.23, train corr: 0.00678
Epoch [71/100], Batch [126/147] train loss: 563.16, train corr: -0.00143
Epoch [71/100], Batch [127/147] train loss: 561.63, train corr: -0.00243
Epoch [71/100], Batch [128/147] train loss: 576.36, train corr: 0.00564
Epoch [71/100], Batch [129/147] train loss: 555.68, train corr: 0.00475
Epoch [71/100], Batch [130/147] train loss: 556.09, train corr: 0.01756
Epoch [71/100], Batch [131/147] train loss: 565.23, train corr: 0.02328
Epoch [71/100], Batch [132/147] train loss: 565.18, train corr: 0.02459
Epoch [71/100], Batch [133/147] train loss: 569.83, train corr: 0.01109
Epoch [71/100], Batch [134/147] train loss: 561.29, train corr: 0.00147
Epoch [71/100], Batch [135/147] train loss: 558.51, train corr: 0.00231
Epoch [71/100], Batch [136/147] train loss: 572.49, train corr: 0.00745
Epoch [71/100], Batch [137/147] train loss: 587.83, train corr: 0.00174
Epoch [71/100], Batch [138/147] train loss: 565.71, train corr: -0.01248
Epoch [71/100], Batch [139/147] train loss: 575.36, train corr: -0.01298
Epoch [71/100], Batch [140/147] train loss: 562.15, train corr: -0.01189
Epoch [71/100], Batch [141/147] train loss: 552.85, train corr: 0.00399
Epoch [71/100], Batch [142/147] train loss: 571.07, train corr: 0.02373
Epoch [71/100], Batch [143/147] train loss: 558.89, train corr: 0.02167
Epoch [71/100], Batch [144/147] train loss: 568.25, train corr: 0.01262
Epoch [71/100], Batch [145/147] train loss: 571.85, train corr: 0.00436
Epoch [71/100], Batch [146/147] train loss: 593.16, train corr: 0.00904
Epoch [71/100], Batch [147/147] train loss: 566.12, train corr: 0.00698
Epoch [71/100], validation loss: 596.85, validation correlation: 0.01413
Epoch [72/100], Batch [1/147] train loss: 578.27, train corr: 0.01650
Epoch [72/100], Batch [2/147] train loss: 559.89, train corr: 0.01227
Epoch [72/100], Batch [3/147] train loss: 553.89, train corr: 0.00129
Epoch [72/100], Batch [4/147] train loss: 571.42, train corr: -0.00522
Epoch [72/100], Batch [5/147] train loss: 552.55, train corr: -0.01016
Epoch [72/100], Batch [6/147] train loss: 567.03, train corr: -0.00217
Epoch [72/100], Batch [7/147] train loss: 559.68, train corr: -0.00181
Epoch [72/100], Batch [8/147] train loss: 562.42, train corr: 0.00080
Epoch [72/100], Batch [9/147] train loss: 573.07, train corr: 0.00389
Epoch [72/100], Batch [10/147] train loss: 569.12, train corr: 0.00510
Epoch [72/100], Batch [11/147] train loss: 567.26, train corr: 0.01546
Epoch [72/100], Batch [12/147] train loss: 563.63, train corr: 0.01896
Epoch [72/100], Batch [13/147] train loss: 567.32, train corr: 0.02422
Epoch [72/100], Batch [14/147] train loss: 585.02, train corr: 0.02852
Epoch [72/100], Batch [15/147] train loss: 555.34, train corr: 0.01605
Epoch [72/100], Batch [16/147] train loss: 565.84, train corr: 0.01086
Epoch [72/100], Batch [17/147] train loss: 570.41, train corr: 0.00661
Epoch [72/100], Batch [18/147] train loss: 564.65, train corr: 0.00467
Epoch [72/100], Batch [19/147] train loss: 561.65, train corr: 0.00664
Epoch [72/100], Batch [20/147] train loss: 571.48, train corr: 0.01761
Epoch [72/100], Batch [21/147] train loss: 565.23, train corr: 0.01296
Epoch [72/100], Batch [22/147] train loss: 559.61, train corr: 0.00923
Epoch [72/100], Batch [23/147] train loss: 589.77, train corr: 0.01244
Epoch [72/100], Batch [24/147] train loss: 559.61, train corr: 0.00464
Epoch [72/100], Batch [25/147] train loss: 559.66, train corr: 0.00468
Epoch [72/100], Batch [26/147] train loss: 571.87, train corr: 0.00676
Epoch [72/100], Batch [27/147] train loss: 546.65, train corr: 0.00120
Epoch [72/100], Batch [28/147] train loss: 581.00, train corr: 0.01005
Epoch [72/100], Batch [29/147] train loss: 561.04, train corr: 0.00334
Epoch [72/100], Batch [30/147] train loss: 566.49, train corr: -0.00450
Epoch [72/100], Batch [31/147] train loss: 571.66, train corr: -0.00530
Epoch [72/100], Batch [32/147] train loss: 550.78, train corr: -0.00336
Epoch [72/100], Batch [33/147] train loss: 561.03, train corr: 0.00410
Epoch [72/100], Batch [34/147] train loss: 560.21, train corr: 0.01623
Epoch [72/100], Batch [35/147] train loss: 565.78, train corr: 0.02320
Epoch [72/100], Batch [36/147] train loss: 567.03, train corr: 0.00582
Epoch [72/100], Batch [37/147] train loss: 552.38, train corr: -0.00442
Epoch [72/100], Batch [38/147] train loss: 577.50, train corr: -0.00293
Epoch [72/100], Batch [39/147] train loss: 564.63, train corr: 0.00614
Epoch [72/100], Batch [40/147] train loss: 574.07, train corr: 0.01953
Epoch [72/100], Batch [41/147] train loss: 558.83, train corr: 0.01857
Epoch [72/100], Batch [42/147] train loss: 560.84, train corr: 0.00906
Epoch [72/100], Batch [43/147] train loss: 567.19, train corr: -0.00568
Epoch [72/100], Batch [44/147] train loss: 560.62, train corr: -0.00654
Epoch [72/100], Batch [45/147] train loss: 728.74, train corr: -0.00013
Epoch [72/100], Batch [46/147] train loss: 587.63, train corr: -0.01717
Epoch [72/100], Batch [47/147] train loss: 582.21, train corr: 0.02997
Epoch [72/100], Batch [48/147] train loss: 571.24, train corr: 0.02972
Epoch [72/100], Batch [49/147] train loss: 571.52, train corr: 0.02818
Epoch [72/100], Batch [50/147] train loss: 575.72, train corr: 0.02853
Epoch [72/100], Batch [51/147] train loss: 564.99, train corr: 0.03037
Epoch [72/100], Batch [52/147] train loss: 566.22, train corr: -0.02022
Epoch [72/100], Batch [53/147] train loss: 569.86, train corr: -0.02730
Epoch [72/100], Batch [54/147] train loss: 567.04, train corr: 0.03291
Epoch [72/100], Batch [55/147] train loss: 576.24, train corr: 0.02332
Epoch [72/100], Batch [56/147] train loss: 575.21, train corr: 0.02574
Epoch [72/100], Batch [57/147] train loss: 575.65, train corr: 0.02880
Epoch [72/100], Batch [58/147] train loss: 576.26, train corr: 0.02503
Epoch [72/100], Batch [59/147] train loss: 558.24, train corr: 0.03104
Epoch [72/100], Batch [60/147] train loss: 576.12, train corr: 0.03290
Epoch [72/100], Batch [61/147] train loss: 560.67, train corr: -0.01596
Epoch [72/100], Batch [62/147] train loss: 568.68, train corr: -0.01577
Epoch [72/100], Batch [63/147] train loss: 567.01, train corr: 0.02148
Epoch [72/100], Batch [64/147] train loss: 584.01, train corr: 0.03074
Epoch [72/100], Batch [65/147] train loss: 558.75, train corr: 0.03344
Epoch [72/100], Batch [66/147] train loss: 560.81, train corr: -0.00919
Epoch [72/100], Batch [67/147] train loss: 564.51, train corr: -0.02142
Epoch [72/100], Batch [68/147] train loss: 633.51, train corr: -0.01169
Epoch [72/100], Batch [69/147] train loss: 591.42, train corr: 0.02554
Epoch [72/100], Batch [70/147] train loss: 571.74, train corr: 0.03024
Epoch [72/100], Batch [71/147] train loss: 816.12, train corr: 0.02115
Epoch [72/100], Batch [72/147] train loss: 605.77, train corr: -0.02352
Epoch [72/100], Batch [73/147] train loss: 577.43, train corr: 0.02961
Epoch [72/100], Batch [74/147] train loss: 591.76, train corr: 0.02795
Epoch [72/100], Batch [75/147] train loss: 591.83, train corr: 0.02983
Epoch [72/100], Batch [76/147] train loss: 604.31, train corr: 0.02820
Epoch [72/100], Batch [77/147] train loss: 595.71, train corr: 0.02759
Epoch [72/100], Batch [78/147] train loss: 637.27, train corr: 0.02214
Epoch [72/100], Batch [79/147] train loss: 611.66, train corr: 0.02241
Epoch [72/100], Batch [80/147] train loss: 603.73, train corr: 0.02947
Epoch [72/100], Batch [81/147] train loss: 604.71, train corr: 0.02590
Epoch [72/100], Batch [82/147] train loss: 658.61, train corr: 0.02376
Epoch [72/100], Batch [83/147] train loss: 606.57, train corr: 0.02702
Epoch [72/100], Batch [84/147] train loss: 596.01, train corr: 0.02642
Epoch [72/100], Batch [85/147] train loss: 586.22, train corr: 0.02153
Epoch [72/100], Batch [86/147] train loss: 593.15, train corr: 0.02875
Epoch [72/100], Batch [87/147] train loss: 595.28, train corr: 0.02426
Epoch [72/100], Batch [88/147] train loss: 585.66, train corr: 0.02476
Epoch [72/100], Batch [89/147] train loss: 580.36, train corr: 0.02269
Epoch [72/100], Batch [90/147] train loss: 557.22, train corr: 0.02731
Epoch [72/100], Batch [91/147] train loss: 573.90, train corr: 0.02618
Epoch [72/100], Batch [92/147] train loss: 562.85, train corr: 0.03132
Epoch [72/100], Batch [93/147] train loss: 568.23, train corr: 0.02966
Epoch [72/100], Batch [94/147] train loss: 640.26, train corr: 0.02752
Epoch [72/100], Batch [95/147] train loss: 577.14, train corr: 0.02774
Epoch [72/100], Batch [96/147] train loss: 559.75, train corr: 0.03113
Epoch [72/100], Batch [97/147] train loss: 561.75, train corr: -0.01474
Epoch [72/100], Batch [98/147] train loss: 573.08, train corr: -0.02418
Epoch [72/100], Batch [99/147] train loss: 577.45, train corr: -0.02825
Epoch [72/100], Batch [100/147] train loss: 567.98, train corr: -0.00631
Epoch [72/100], Batch [101/147] train loss: 558.69, train corr: 0.01417
Epoch [72/100], Batch [102/147] train loss: 570.06, train corr: 0.01850
Epoch [72/100], Batch [103/147] train loss: 577.77, train corr: 0.01869
Epoch [72/100], Batch [104/147] train loss: 575.40, train corr: 0.01943
Epoch [72/100], Batch [105/147] train loss: 576.99, train corr: 0.03033
Epoch [72/100], Batch [106/147] train loss: 545.96, train corr: 0.03247
Epoch [72/100], Batch [107/147] train loss: 575.80, train corr: 0.03266
Epoch [72/100], Batch [108/147] train loss: 572.68, train corr: 0.03035
Epoch [72/100], Batch [109/147] train loss: 566.92, train corr: 0.02891
Epoch [72/100], Batch [110/147] train loss: 562.90, train corr: -0.00619
Epoch [72/100], Batch [111/147] train loss: 561.25, train corr: -0.00977
Epoch [72/100], Batch [112/147] train loss: 568.03, train corr: 0.00957
Epoch [72/100], Batch [113/147] train loss: 565.20, train corr: 0.03558
Epoch [72/100], Batch [114/147] train loss: 583.06, train corr: 0.03152
Epoch [72/100], Batch [115/147] train loss: 580.75, train corr: 0.02774
Epoch [72/100], Batch [116/147] train loss: 558.70, train corr: 0.02800
Epoch [72/100], Batch [117/147] train loss: 573.70, train corr: -0.02675
Epoch [72/100], Batch [118/147] train loss: 551.61, train corr: -0.03389
Epoch [72/100], Batch [119/147] train loss: 592.02, train corr: -0.03291
Epoch [72/100], Batch [120/147] train loss: 558.14, train corr: -0.02760
Epoch [72/100], Batch [121/147] train loss: 581.39, train corr: -0.02926
Epoch [72/100], Batch [122/147] train loss: 570.52, train corr: -0.03578
Epoch [72/100], Batch [123/147] train loss: 571.15, train corr: -0.02467
Epoch [72/100], Batch [124/147] train loss: 579.59, train corr: -0.01647
Epoch [72/100], Batch [125/147] train loss: 567.54, train corr: 0.00683
Epoch [72/100], Batch [126/147] train loss: 568.03, train corr: 0.02711
Epoch [72/100], Batch [127/147] train loss: 567.40, train corr: 0.03109
Epoch [72/100], Batch [128/147] train loss: 565.23, train corr: 0.02083
Epoch [72/100], Batch [129/147] train loss: 580.05, train corr: 0.00130
Epoch [72/100], Batch [130/147] train loss: 562.44, train corr: -0.01316
Epoch [72/100], Batch [131/147] train loss: 572.62, train corr: -0.00933
Epoch [72/100], Batch [132/147] train loss: 567.76, train corr: 0.02664
Epoch [72/100], Batch [133/147] train loss: 564.77, train corr: 0.03263
Epoch [72/100], Batch [134/147] train loss: 557.83, train corr: 0.03038
Epoch [72/100], Batch [135/147] train loss: 586.22, train corr: 0.02654
Epoch [72/100], Batch [136/147] train loss: 556.82, train corr: 0.03399
Epoch [72/100], Batch [137/147] train loss: 573.46, train corr: 0.00705
Epoch [72/100], Batch [138/147] train loss: 570.51, train corr: -0.00681
Epoch [72/100], Batch [139/147] train loss: 571.81, train corr: -0.00166
Epoch [72/100], Batch [140/147] train loss: 572.47, train corr: 0.00784
Epoch [72/100], Batch [141/147] train loss: 566.43, train corr: 0.01409
Epoch [72/100], Batch [142/147] train loss: 558.71, train corr: 0.00831
Epoch [72/100], Batch [143/147] train loss: 586.40, train corr: 0.01127
Epoch [72/100], Batch [144/147] train loss: 565.79, train corr: 0.00073
Epoch [72/100], Batch [145/147] train loss: 566.27, train corr: -0.01129
Epoch [72/100], Batch [146/147] train loss: 582.64, train corr: -0.01309
Epoch [72/100], Batch [147/147] train loss: 538.34, train corr: -0.01960
Epoch [72/100], validation loss: 597.09, validation correlation: -0.01446
Epoch [73/100], Batch [1/147] train loss: 570.64, train corr: -0.01073
Epoch [73/100], Batch [2/147] train loss: 571.52, train corr: -0.00307
Epoch [73/100], Batch [3/147] train loss: 560.96, train corr: 0.01135
Epoch [73/100], Batch [4/147] train loss: 580.95, train corr: 0.01926
Epoch [73/100], Batch [5/147] train loss: 564.08, train corr: 0.02428
Epoch [73/100], Batch [6/147] train loss: 554.77, train corr: 0.03053
Epoch [73/100], Batch [7/147] train loss: 563.06, train corr: 0.03103
Epoch [73/100], Batch [8/147] train loss: 555.24, train corr: 0.02258
Epoch [73/100], Batch [9/147] train loss: 552.75, train corr: 0.00340
Epoch [73/100], Batch [10/147] train loss: 573.33, train corr: -0.00768
Epoch [73/100], Batch [11/147] train loss: 567.85, train corr: -0.00409
Epoch [73/100], Batch [12/147] train loss: 575.82, train corr: 0.00997
Epoch [73/100], Batch [13/147] train loss: 561.73, train corr: 0.01775
Epoch [73/100], Batch [14/147] train loss: 559.39, train corr: 0.02870
Epoch [73/100], Batch [15/147] train loss: 563.43, train corr: 0.02980
Epoch [73/100], Batch [16/147] train loss: 580.42, train corr: 0.02540
Epoch [73/100], Batch [17/147] train loss: 575.33, train corr: -0.00611
Epoch [73/100], Batch [18/147] train loss: 567.21, train corr: -0.01740
Epoch [73/100], Batch [19/147] train loss: 557.51, train corr: -0.00865
Epoch [73/100], Batch [20/147] train loss: 576.99, train corr: 0.01241
Epoch [73/100], Batch [21/147] train loss: 565.11, train corr: 0.03196
Epoch [73/100], Batch [22/147] train loss: 562.86, train corr: 0.03268
Epoch [73/100], Batch [23/147] train loss: 557.49, train corr: 0.02870
Epoch [73/100], Batch [24/147] train loss: 568.81, train corr: 0.01047
Epoch [73/100], Batch [25/147] train loss: 617.04, train corr: -0.01091
Epoch [73/100], Batch [26/147] train loss: 561.06, train corr: -0.00846
Epoch [73/100], Batch [27/147] train loss: 574.58, train corr: -0.01133
Epoch [73/100], Batch [28/147] train loss: 568.80, train corr: -0.01702
Epoch [73/100], Batch [29/147] train loss: 556.17, train corr: -0.02386
Epoch [73/100], Batch [30/147] train loss: 576.44, train corr: -0.02429
Epoch [73/100], Batch [31/147] train loss: 562.61, train corr: 0.02898
Epoch [73/100], Batch [32/147] train loss: 561.85, train corr: 0.03237
Epoch [73/100], Batch [33/147] train loss: 567.10, train corr: 0.03183
Epoch [73/100], Batch [34/147] train loss: 581.30, train corr: 0.03152
Epoch [73/100], Batch [35/147] train loss: 556.69, train corr: 0.03317
Epoch [73/100], Batch [36/147] train loss: 566.40, train corr: 0.03288
Epoch [73/100], Batch [37/147] train loss: 549.40, train corr: -0.01555
Epoch [73/100], Batch [38/147] train loss: 563.25, train corr: -0.02704
Epoch [73/100], Batch [39/147] train loss: 557.51, train corr: -0.02572
Epoch [73/100], Batch [40/147] train loss: 567.81, train corr: -0.02176
Epoch [73/100], Batch [41/147] train loss: 583.56, train corr: 0.02545
Epoch [73/100], Batch [42/147] train loss: 574.35, train corr: 0.02134
Epoch [73/100], Batch [43/147] train loss: 563.81, train corr: 0.00546
Epoch [73/100], Batch [44/147] train loss: 577.26, train corr: 0.00072
Epoch [73/100], Batch [45/147] train loss: 588.23, train corr: 0.00314
Epoch [73/100], Batch [46/147] train loss: 568.25, train corr: 0.01297
Epoch [73/100], Batch [47/147] train loss: 562.36, train corr: 0.01545
Epoch [73/100], Batch [48/147] train loss: 558.31, train corr: 0.00558
Epoch [73/100], Batch [49/147] train loss: 567.61, train corr: -0.00665
Epoch [73/100], Batch [50/147] train loss: 549.40, train corr: -0.01295
Epoch [73/100], Batch [51/147] train loss: 565.67, train corr: -0.01211
Epoch [73/100], Batch [52/147] train loss: 579.74, train corr: -0.00164
Epoch [73/100], Batch [53/147] train loss: 750.20, train corr: 0.01599
Epoch [73/100], Batch [54/147] train loss: 582.11, train corr: -0.01682
Epoch [73/100], Batch [55/147] train loss: 586.02, train corr: 0.02879
Epoch [73/100], Batch [56/147] train loss: 571.16, train corr: 0.02242
Epoch [73/100], Batch [57/147] train loss: 561.17, train corr: 0.02843
Epoch [73/100], Batch [58/147] train loss: 601.46, train corr: 0.01634
Epoch [73/100], Batch [59/147] train loss: 566.10, train corr: 0.02746
Epoch [73/100], Batch [60/147] train loss: 577.99, train corr: 0.02427
Epoch [73/100], Batch [61/147] train loss: 559.99, train corr: 0.01201
Epoch [73/100], Batch [62/147] train loss: 585.75, train corr: -0.01979
Epoch [73/100], Batch [63/147] train loss: 580.16, train corr: 0.02458
Epoch [73/100], Batch [64/147] train loss: 577.56, train corr: 0.02462
Epoch [73/100], Batch [65/147] train loss: 562.46, train corr: 0.02911
Epoch [73/100], Batch [66/147] train loss: 568.27, train corr: 0.02673
Epoch [73/100], Batch [67/147] train loss: 575.19, train corr: -0.00200
Epoch [73/100], Batch [68/147] train loss: 557.90, train corr: -0.01825
Epoch [73/100], Batch [69/147] train loss: 566.54, train corr: -0.00126
Epoch [73/100], Batch [70/147] train loss: 579.29, train corr: 0.02684
Epoch [73/100], Batch [71/147] train loss: 572.03, train corr: 0.02911
Epoch [73/100], Batch [72/147] train loss: 585.54, train corr: 0.02165
Epoch [73/100], Batch [73/147] train loss: 809.00, train corr: 0.02040
Epoch [73/100], Batch [74/147] train loss: 592.28, train corr: -0.02495
Epoch [73/100], Batch [75/147] train loss: 579.23, train corr: 0.02746
Epoch [73/100], Batch [76/147] train loss: 604.21, train corr: 0.02822
Epoch [73/100], Batch [77/147] train loss: 636.41, train corr: 0.02922
Epoch [73/100], Batch [78/147] train loss: 637.71, train corr: 0.02445
Epoch [73/100], Batch [79/147] train loss: 608.02, train corr: 0.02958
Epoch [73/100], Batch [80/147] train loss: 626.10, train corr: 0.02926
Epoch [73/100], Batch [81/147] train loss: 612.89, train corr: 0.02851
Epoch [73/100], Batch [82/147] train loss: 626.14, train corr: 0.02590
Epoch [73/100], Batch [83/147] train loss: 596.47, train corr: 0.02775
Epoch [73/100], Batch [84/147] train loss: 594.49, train corr: 0.02823
Epoch [73/100], Batch [85/147] train loss: 625.86, train corr: 0.02469
Epoch [73/100], Batch [86/147] train loss: 610.31, train corr: 0.02402
Epoch [73/100], Batch [87/147] train loss: 584.48, train corr: 0.02958
Epoch [73/100], Batch [88/147] train loss: 599.29, train corr: 0.02372
Epoch [73/100], Batch [89/147] train loss: 593.71, train corr: 0.02610
Epoch [73/100], Batch [90/147] train loss: 593.57, train corr: 0.02744
Epoch [73/100], Batch [91/147] train loss: 595.49, train corr: 0.02664
Epoch [73/100], Batch [92/147] train loss: 581.09, train corr: 0.02803
Epoch [73/100], Batch [93/147] train loss: 574.46, train corr: 0.02797
Epoch [73/100], Batch [94/147] train loss: 576.41, train corr: 0.02757
Epoch [73/100], Batch [95/147] train loss: 569.61, train corr: 0.02746
Epoch [73/100], Batch [96/147] train loss: 578.77, train corr: 0.02680
Epoch [73/100], Batch [97/147] train loss: 569.58, train corr: 0.02650
Epoch [73/100], Batch [98/147] train loss: 563.59, train corr: 0.02699
Epoch [73/100], Batch [99/147] train loss: 570.18, train corr: 0.02932
Epoch [73/100], Batch [100/147] train loss: 578.71, train corr: 0.02912
Epoch [73/100], Batch [101/147] train loss: 624.03, train corr: 0.02823
Epoch [73/100], Batch [102/147] train loss: 574.52, train corr: 0.03041
Epoch [73/100], Batch [103/147] train loss: 576.10, train corr: 0.03313
Epoch [73/100], Batch [104/147] train loss: 589.93, train corr: 0.02859
Epoch [73/100], Batch [105/147] train loss: 568.50, train corr: 0.01381
Epoch [73/100], Batch [106/147] train loss: 574.41, train corr: 0.02261
Epoch [73/100], Batch [107/147] train loss: 566.40, train corr: 0.03103
Epoch [73/100], Batch [108/147] train loss: 574.16, train corr: 0.02736
Epoch [73/100], Batch [109/147] train loss: 567.66, train corr: 0.02776
Epoch [73/100], Batch [110/147] train loss: 562.99, train corr: 0.02351
Epoch [73/100], Batch [111/147] train loss: 565.44, train corr: 0.01628
Epoch [73/100], Batch [112/147] train loss: 636.57, train corr: -0.00471
Epoch [73/100], Batch [113/147] train loss: 572.01, train corr: -0.02789
Epoch [73/100], Batch [114/147] train loss: 560.33, train corr: -0.03102
Epoch [73/100], Batch [115/147] train loss: 566.21, train corr: -0.01076
Epoch [73/100], Batch [116/147] train loss: 558.00, train corr: -0.00561
Epoch [73/100], Batch [117/147] train loss: 576.55, train corr: -0.01486
Epoch [73/100], Batch [118/147] train loss: 560.44, train corr: -0.02081
Epoch [73/100], Batch [119/147] train loss: 583.32, train corr: -0.02153
Epoch [73/100], Batch [120/147] train loss: 574.72, train corr: -0.02914
Epoch [73/100], Batch [121/147] train loss: 580.32, train corr: -0.03112
Epoch [73/100], Batch [122/147] train loss: 579.50, train corr: -0.01221
Epoch [73/100], Batch [123/147] train loss: 569.03, train corr: 0.00216
Epoch [73/100], Batch [124/147] train loss: 567.69, train corr: -0.00226
Epoch [73/100], Batch [125/147] train loss: 567.31, train corr: -0.01320
Epoch [73/100], Batch [126/147] train loss: 580.01, train corr: -0.02168
Epoch [73/100], Batch [127/147] train loss: 566.37, train corr: -0.02639
Epoch [73/100], Batch [128/147] train loss: 563.89, train corr: -0.02804
Epoch [73/100], Batch [129/147] train loss: 564.92, train corr: -0.03180
Epoch [73/100], Batch [130/147] train loss: 566.25, train corr: -0.01262
Epoch [73/100], Batch [131/147] train loss: 571.61, train corr: -0.00286
Epoch [73/100], Batch [132/147] train loss: 564.78, train corr: -0.00501
Epoch [73/100], Batch [133/147] train loss: 568.69, train corr: -0.01499
Epoch [73/100], Batch [134/147] train loss: 580.08, train corr: -0.01752
Epoch [73/100], Batch [135/147] train loss: 564.66, train corr: -0.01348
Epoch [73/100], Batch [136/147] train loss: 572.63, train corr: -0.00473
Epoch [73/100], Batch [137/147] train loss: 577.99, train corr: 0.01174
Epoch [73/100], Batch [138/147] train loss: 573.95, train corr: 0.01731
Epoch [73/100], Batch [139/147] train loss: 553.69, train corr: 0.02567
Epoch [73/100], Batch [140/147] train loss: 553.40, train corr: 0.02367
Epoch [73/100], Batch [141/147] train loss: 556.63, train corr: 0.02158
Epoch [73/100], Batch [142/147] train loss: 571.74, train corr: 0.01822
Epoch [73/100], Batch [143/147] train loss: 554.79, train corr: 0.01600
Epoch [73/100], Batch [144/147] train loss: 570.73, train corr: 0.01155
Epoch [73/100], Batch [145/147] train loss: 577.01, train corr: 0.00939
Epoch [73/100], Batch [146/147] train loss: 561.76, train corr: -0.00659
Epoch [73/100], Batch [147/147] train loss: 563.79, train corr: -0.00862
Epoch [73/100], validation loss: 597.15, validation correlation: -0.00794
Epoch [74/100], Batch [1/147] train loss: 558.05, train corr: -0.01099
Epoch [74/100], Batch [2/147] train loss: 569.63, train corr: 0.00807
Epoch [74/100], Batch [3/147] train loss: 741.58, train corr: 0.02755
Epoch [74/100], Batch [4/147] train loss: 568.05, train corr: -0.01517
Epoch [74/100], Batch [5/147] train loss: 571.26, train corr: 0.01012
Epoch [74/100], Batch [6/147] train loss: 566.63, train corr: 0.02777
Epoch [74/100], Batch [7/147] train loss: 555.69, train corr: 0.02964
Epoch [74/100], Batch [8/147] train loss: 580.69, train corr: 0.02868
Epoch [74/100], Batch [9/147] train loss: 558.07, train corr: 0.02808
Epoch [74/100], Batch [10/147] train loss: 573.10, train corr: 0.02648
Epoch [74/100], Batch [11/147] train loss: 571.67, train corr: -0.00827
Epoch [74/100], Batch [12/147] train loss: 567.40, train corr: -0.02152
Epoch [74/100], Batch [13/147] train loss: 582.92, train corr: 0.00261
Epoch [74/100], Batch [14/147] train loss: 571.76, train corr: 0.02943
Epoch [74/100], Batch [15/147] train loss: 574.65, train corr: 0.02770
Epoch [74/100], Batch [16/147] train loss: 562.73, train corr: 0.02833
Epoch [74/100], Batch [17/147] train loss: 580.86, train corr: 0.02628
Epoch [74/100], Batch [18/147] train loss: 581.30, train corr: 0.02817
Epoch [74/100], Batch [19/147] train loss: 571.29, train corr: 0.02237
Epoch [74/100], Batch [20/147] train loss: 585.23, train corr: -0.01624
Epoch [74/100], Batch [21/147] train loss: 571.83, train corr: -0.01795
Epoch [74/100], Batch [22/147] train loss: 563.37, train corr: 0.02310
Epoch [74/100], Batch [23/147] train loss: 555.32, train corr: 0.02689
Epoch [74/100], Batch [24/147] train loss: 566.56, train corr: 0.02548
Epoch [74/100], Batch [25/147] train loss: 556.68, train corr: -0.01309
Epoch [74/100], Batch [26/147] train loss: 567.40, train corr: -0.01555
Epoch [74/100], Batch [27/147] train loss: 559.41, train corr: -0.00510
Epoch [74/100], Batch [28/147] train loss: 579.81, train corr: 0.03243
Epoch [74/100], Batch [29/147] train loss: 811.22, train corr: 0.02689
Epoch [74/100], Batch [30/147] train loss: 572.92, train corr: -0.02111
Epoch [74/100], Batch [31/147] train loss: 559.83, train corr: -0.01795
Epoch [74/100], Batch [32/147] train loss: 611.25, train corr: 0.00039
Epoch [74/100], Batch [33/147] train loss: 571.40, train corr: 0.03094
Epoch [74/100], Batch [34/147] train loss: 553.80, train corr: 0.03113
Epoch [74/100], Batch [35/147] train loss: 585.67, train corr: 0.02192
Epoch [74/100], Batch [36/147] train loss: 571.68, train corr: 0.02694
Epoch [74/100], Batch [37/147] train loss: 563.12, train corr: 0.02991
Epoch [74/100], Batch [38/147] train loss: 565.04, train corr: 0.02961
Epoch [74/100], Batch [39/147] train loss: 562.93, train corr: 0.02645
Epoch [74/100], Batch [40/147] train loss: 557.37, train corr: 0.02887
Epoch [74/100], Batch [41/147] train loss: 563.57, train corr: 0.03028
Epoch [74/100], Batch [42/147] train loss: 588.72, train corr: 0.03139
Epoch [74/100], Batch [43/147] train loss: 556.99, train corr: -0.01216
Epoch [74/100], Batch [44/147] train loss: 583.61, train corr: -0.01891
Epoch [74/100], Batch [45/147] train loss: 562.54, train corr: -0.01738
Epoch [74/100], Batch [46/147] train loss: 560.07, train corr: 0.01738
Epoch [74/100], Batch [47/147] train loss: 559.71, train corr: 0.03146
Epoch [74/100], Batch [48/147] train loss: 567.73, train corr: 0.03024
Epoch [74/100], Batch [49/147] train loss: 565.55, train corr: 0.03082
Epoch [74/100], Batch [50/147] train loss: 569.72, train corr: 0.02885
Epoch [74/100], Batch [51/147] train loss: 570.14, train corr: 0.03257
Epoch [74/100], Batch [52/147] train loss: 549.11, train corr: 0.02992
Epoch [74/100], Batch [53/147] train loss: 561.39, train corr: 0.01798
Epoch [74/100], Batch [54/147] train loss: 557.72, train corr: 0.00698
Epoch [74/100], Batch [55/147] train loss: 567.75, train corr: -0.00153
Epoch [74/100], Batch [56/147] train loss: 586.59, train corr: 0.00240
Epoch [74/100], Batch [57/147] train loss: 555.84, train corr: -0.00646
Epoch [74/100], Batch [58/147] train loss: 561.96, train corr: -0.00940
Epoch [74/100], Batch [59/147] train loss: 567.58, train corr: 0.00179
Epoch [74/100], Batch [60/147] train loss: 572.19, train corr: 0.02428
Epoch [74/100], Batch [61/147] train loss: 576.42, train corr: 0.02666
Epoch [74/100], Batch [62/147] train loss: 561.36, train corr: 0.02860
Epoch [74/100], Batch [63/147] train loss: 581.60, train corr: 0.02639
Epoch [74/100], Batch [64/147] train loss: 566.90, train corr: -0.00084
Epoch [74/100], Batch [65/147] train loss: 560.42, train corr: -0.01318
Epoch [74/100], Batch [66/147] train loss: 570.66, train corr: -0.01576
Epoch [74/100], Batch [67/147] train loss: 576.69, train corr: 0.00417
Epoch [74/100], Batch [68/147] train loss: 563.24, train corr: 0.02429
Epoch [74/100], Batch [69/147] train loss: 561.09, train corr: 0.03041
Epoch [74/100], Batch [70/147] train loss: 561.92, train corr: 0.02893
Epoch [74/100], Batch [71/147] train loss: 568.84, train corr: 0.02386
Epoch [74/100], Batch [72/147] train loss: 571.16, train corr: 0.01357
Epoch [74/100], Batch [73/147] train loss: 597.50, train corr: 0.01446
Epoch [74/100], Batch [74/147] train loss: 552.58, train corr: 0.00255
Epoch [74/100], Batch [75/147] train loss: 573.83, train corr: 0.01012
Epoch [74/100], Batch [76/147] train loss: 569.21, train corr: 0.01094
Epoch [74/100], Batch [77/147] train loss: 574.62, train corr: 0.01088
Epoch [74/100], Batch [78/147] train loss: 572.81, train corr: 0.00650
Epoch [74/100], Batch [79/147] train loss: 572.92, train corr: 0.00644
Epoch [74/100], Batch [80/147] train loss: 572.20, train corr: -0.00097
Epoch [74/100], Batch [81/147] train loss: 561.98, train corr: 0.00590
Epoch [74/100], Batch [82/147] train loss: 555.33, train corr: 0.01628
Epoch [74/100], Batch [83/147] train loss: 566.35, train corr: 0.02654
Epoch [74/100], Batch [84/147] train loss: 577.13, train corr: 0.03209
Epoch [74/100], Batch [85/147] train loss: 576.07, train corr: 0.03318
Epoch [74/100], Batch [86/147] train loss: 582.60, train corr: 0.03470
Epoch [74/100], Batch [87/147] train loss: 654.46, train corr: 0.01915
Epoch [74/100], Batch [88/147] train loss: 562.37, train corr: 0.01173
Epoch [74/100], Batch [89/147] train loss: 575.28, train corr: 0.00846
Epoch [74/100], Batch [90/147] train loss: 565.49, train corr: 0.00736
Epoch [74/100], Batch [91/147] train loss: 566.71, train corr: 0.02254
Epoch [74/100], Batch [92/147] train loss: 556.25, train corr: 0.03133
Epoch [74/100], Batch [93/147] train loss: 571.82, train corr: 0.03233
Epoch [74/100], Batch [94/147] train loss: 577.80, train corr: 0.03038
Epoch [74/100], Batch [95/147] train loss: 573.30, train corr: 0.02518
Epoch [74/100], Batch [96/147] train loss: 557.35, train corr: 0.01293
Epoch [74/100], Batch [97/147] train loss: 564.03, train corr: 0.00570
Epoch [74/100], Batch [98/147] train loss: 547.92, train corr: 0.00075
Epoch [74/100], Batch [99/147] train loss: 630.18, train corr: 0.00205
Epoch [74/100], Batch [100/147] train loss: 555.59, train corr: 0.00226
Epoch [74/100], Batch [101/147] train loss: 583.88, train corr: 0.00871
Epoch [74/100], Batch [102/147] train loss: 569.40, train corr: 0.01019
Epoch [74/100], Batch [103/147] train loss: 569.16, train corr: 0.01505
Epoch [74/100], Batch [104/147] train loss: 580.39, train corr: 0.02858
Epoch [74/100], Batch [105/147] train loss: 569.96, train corr: 0.03176
Epoch [74/100], Batch [106/147] train loss: 576.46, train corr: 0.03304
Epoch [74/100], Batch [107/147] train loss: 569.35, train corr: 0.03136
Epoch [74/100], Batch [108/147] train loss: 556.01, train corr: 0.02076
Epoch [74/100], Batch [109/147] train loss: 560.51, train corr: 0.00300
Epoch [74/100], Batch [110/147] train loss: 554.50, train corr: 0.00062
Epoch [74/100], Batch [111/147] train loss: 567.37, train corr: 0.00099
Epoch [74/100], Batch [112/147] train loss: 559.31, train corr: 0.01254
Epoch [74/100], Batch [113/147] train loss: 584.67, train corr: 0.01902
Epoch [74/100], Batch [114/147] train loss: 572.50, train corr: 0.02055
Epoch [74/100], Batch [115/147] train loss: 567.45, train corr: 0.01560
Epoch [74/100], Batch [116/147] train loss: 556.78, train corr: 0.01886
Epoch [74/100], Batch [117/147] train loss: 567.54, train corr: 0.02001
Epoch [74/100], Batch [118/147] train loss: 556.40, train corr: 0.02053
Epoch [74/100], Batch [119/147] train loss: 565.02, train corr: 0.02103
Epoch [74/100], Batch [120/147] train loss: 558.34, train corr: 0.00793
Epoch [74/100], Batch [121/147] train loss: 572.94, train corr: -0.00450
Epoch [74/100], Batch [122/147] train loss: 561.36, train corr: -0.01254
Epoch [74/100], Batch [123/147] train loss: 589.19, train corr: -0.00342
Epoch [74/100], Batch [124/147] train loss: 561.79, train corr: -0.00265
Epoch [74/100], Batch [125/147] train loss: 558.11, train corr: 0.01791
Epoch [74/100], Batch [126/147] train loss: 579.71, train corr: 0.02801
Epoch [74/100], Batch [127/147] train loss: 575.68, train corr: 0.03340
Epoch [74/100], Batch [128/147] train loss: 561.09, train corr: 0.03303
Epoch [74/100], Batch [129/147] train loss: 565.00, train corr: 0.03113
Epoch [74/100], Batch [130/147] train loss: 577.40, train corr: 0.02843
Epoch [74/100], Batch [131/147] train loss: 580.98, train corr: 0.01651
Epoch [74/100], Batch [132/147] train loss: 571.39, train corr: 0.00024
Epoch [74/100], Batch [133/147] train loss: 559.13, train corr: -0.00701
Epoch [74/100], Batch [134/147] train loss: 571.64, train corr: -0.00644
Epoch [74/100], Batch [135/147] train loss: 581.72, train corr: 0.00579
Epoch [74/100], Batch [136/147] train loss: 578.10, train corr: 0.01834
Epoch [74/100], Batch [137/147] train loss: 557.86, train corr: 0.02649
Epoch [74/100], Batch [138/147] train loss: 560.77, train corr: 0.03058
Epoch [74/100], Batch [139/147] train loss: 579.77, train corr: 0.03126
Epoch [74/100], Batch [140/147] train loss: 554.70, train corr: 0.03123
Epoch [74/100], Batch [141/147] train loss: 550.57, train corr: 0.02924
Epoch [74/100], Batch [142/147] train loss: 574.14, train corr: 0.02934
Epoch [74/100], Batch [143/147] train loss: 571.38, train corr: 0.02375
Epoch [74/100], Batch [144/147] train loss: 565.91, train corr: 0.00509
Epoch [74/100], Batch [145/147] train loss: 565.96, train corr: -0.00625
Epoch [74/100], Batch [146/147] train loss: 572.52, train corr: -0.01051
Epoch [74/100], Batch [147/147] train loss: 553.70, train corr: -0.01520
Epoch [74/100], validation loss: 597.08, validation correlation: -0.01035
Epoch [75/100], Batch [1/147] train loss: 574.98, train corr: -0.00709
Epoch [75/100], Batch [2/147] train loss: 576.04, train corr: -0.00198
Epoch [75/100], Batch [3/147] train loss: 563.56, train corr: 0.01056
Epoch [75/100], Batch [4/147] train loss: 583.29, train corr: 0.01754
Epoch [75/100], Batch [5/147] train loss: 550.06, train corr: 0.02125
Epoch [75/100], Batch [6/147] train loss: 618.27, train corr: 0.01667
Epoch [75/100], Batch [7/147] train loss: 576.44, train corr: 0.02254
Epoch [75/100], Batch [8/147] train loss: 560.78, train corr: 0.01528
Epoch [75/100], Batch [9/147] train loss: 565.41, train corr: 0.00803
Epoch [75/100], Batch [10/147] train loss: 556.84, train corr: 0.00300
Epoch [75/100], Batch [11/147] train loss: 569.57, train corr: 0.00280
Epoch [75/100], Batch [12/147] train loss: 567.69, train corr: 0.00346
Epoch [75/100], Batch [13/147] train loss: 551.97, train corr: 0.00740
Epoch [75/100], Batch [14/147] train loss: 572.94, train corr: 0.01993
Epoch [75/100], Batch [15/147] train loss: 561.06, train corr: 0.02494
Epoch [75/100], Batch [16/147] train loss: 567.74, train corr: 0.02657
Epoch [75/100], Batch [17/147] train loss: 578.55, train corr: 0.02366
Epoch [75/100], Batch [18/147] train loss: 560.49, train corr: 0.01360
Epoch [75/100], Batch [19/147] train loss: 573.39, train corr: 0.01232
Epoch [75/100], Batch [20/147] train loss: 562.80, train corr: 0.01639
Epoch [75/100], Batch [21/147] train loss: 571.88, train corr: 0.02485
Epoch [75/100], Batch [22/147] train loss: 558.62, train corr: 0.03181
Epoch [75/100], Batch [23/147] train loss: 569.86, train corr: 0.03248
Epoch [75/100], Batch [24/147] train loss: 579.01, train corr: 0.02722
Epoch [75/100], Batch [25/147] train loss: 561.85, train corr: 0.00724
Epoch [75/100], Batch [26/147] train loss: 552.01, train corr: 0.00109
Epoch [75/100], Batch [27/147] train loss: 562.78, train corr: -0.00117
Epoch [75/100], Batch [28/147] train loss: 579.95, train corr: 0.00148
Epoch [75/100], Batch [29/147] train loss: 611.85, train corr: -0.00046
Epoch [75/100], Batch [30/147] train loss: 577.83, train corr: 0.01692
Epoch [75/100], Batch [31/147] train loss: 569.87, train corr: 0.02281
Epoch [75/100], Batch [32/147] train loss: 569.56, train corr: 0.02358
Epoch [75/100], Batch [33/147] train loss: 564.47, train corr: 0.02761
Epoch [75/100], Batch [34/147] train loss: 575.63, train corr: 0.03174
Epoch [75/100], Batch [35/147] train loss: 551.97, train corr: 0.02583
Epoch [75/100], Batch [36/147] train loss: 583.94, train corr: 0.02091
Epoch [75/100], Batch [37/147] train loss: 575.19, train corr: 0.00369
Epoch [75/100], Batch [38/147] train loss: 569.47, train corr: -0.00179
Epoch [75/100], Batch [39/147] train loss: 565.49, train corr: -0.00009
Epoch [75/100], Batch [40/147] train loss: 552.67, train corr: 0.00503
Epoch [75/100], Batch [41/147] train loss: 568.57, train corr: 0.01884
Epoch [75/100], Batch [42/147] train loss: 555.85, train corr: 0.02140
Epoch [75/100], Batch [43/147] train loss: 559.64, train corr: 0.02455
Epoch [75/100], Batch [44/147] train loss: 567.66, train corr: 0.02275
Epoch [75/100], Batch [45/147] train loss: 573.87, train corr: 0.01997
Epoch [75/100], Batch [46/147] train loss: 554.13, train corr: 0.00696
Epoch [75/100], Batch [47/147] train loss: 574.46, train corr: 0.01261
Epoch [75/100], Batch [48/147] train loss: 576.94, train corr: 0.01987
Epoch [75/100], Batch [49/147] train loss: 570.94, train corr: 0.02450
Epoch [75/100], Batch [50/147] train loss: 579.92, train corr: 0.02147
Epoch [75/100], Batch [51/147] train loss: 566.70, train corr: 0.00849
Epoch [75/100], Batch [52/147] train loss: 582.50, train corr: 0.01222
Epoch [75/100], Batch [53/147] train loss: 557.52, train corr: 0.01604
Epoch [75/100], Batch [54/147] train loss: 588.06, train corr: 0.02890
Epoch [75/100], Batch [55/147] train loss: 574.34, train corr: 0.02652
Epoch [75/100], Batch [56/147] train loss: 564.25, train corr: 0.01996
Epoch [75/100], Batch [57/147] train loss: 638.23, train corr: 0.00703
Epoch [75/100], Batch [58/147] train loss: 559.11, train corr: -0.00592
Epoch [75/100], Batch [59/147] train loss: 577.37, train corr: -0.00371
Epoch [75/100], Batch [60/147] train loss: 565.18, train corr: -0.00528
Epoch [75/100], Batch [61/147] train loss: 556.49, train corr: 0.01169
Epoch [75/100], Batch [62/147] train loss: 555.51, train corr: 0.02794
Epoch [75/100], Batch [63/147] train loss: 573.77, train corr: 0.03110
Epoch [75/100], Batch [64/147] train loss: 558.36, train corr: 0.03454
Epoch [75/100], Batch [65/147] train loss: 564.04, train corr: 0.03206
Epoch [75/100], Batch [66/147] train loss: 561.99, train corr: 0.03027
Epoch [75/100], Batch [67/147] train loss: 561.08, train corr: 0.02944
Epoch [75/100], Batch [68/147] train loss: 559.59, train corr: 0.02590
Epoch [75/100], Batch [69/147] train loss: 567.85, train corr: 0.01716
Epoch [75/100], Batch [70/147] train loss: 583.87, train corr: 0.00291
Epoch [75/100], Batch [71/147] train loss: 563.28, train corr: -0.00849
Epoch [75/100], Batch [72/147] train loss: 587.07, train corr: 0.00142
Epoch [75/100], Batch [73/147] train loss: 557.20, train corr: 0.00530
Epoch [75/100], Batch [74/147] train loss: 546.31, train corr: 0.02597
Epoch [75/100], Batch [75/147] train loss: 564.18, train corr: 0.03266
Epoch [75/100], Batch [76/147] train loss: 569.51, train corr: 0.03293
Epoch [75/100], Batch [77/147] train loss: 575.94, train corr: 0.02954
Epoch [75/100], Batch [78/147] train loss: 569.50, train corr: 0.01875
Epoch [75/100], Batch [79/147] train loss: 573.09, train corr: 0.00439
Epoch [75/100], Batch [80/147] train loss: 560.92, train corr: 0.00480
Epoch [75/100], Batch [81/147] train loss: 552.40, train corr: 0.00787
Epoch [75/100], Batch [82/147] train loss: 575.40, train corr: 0.01903
Epoch [75/100], Batch [83/147] train loss: 583.30, train corr: 0.02455
Epoch [75/100], Batch [84/147] train loss: 577.86, train corr: 0.02080
Epoch [75/100], Batch [85/147] train loss: 563.67, train corr: 0.01800
Epoch [75/100], Batch [86/147] train loss: 584.61, train corr: 0.02348
Epoch [75/100], Batch [87/147] train loss: 576.76, train corr: 0.02120
Epoch [75/100], Batch [88/147] train loss: 559.02, train corr: 0.02363
Epoch [75/100], Batch [89/147] train loss: 567.47, train corr: 0.02542
Epoch [75/100], Batch [90/147] train loss: 558.47, train corr: 0.01776
Epoch [75/100], Batch [91/147] train loss: 591.32, train corr: -0.00528
Epoch [75/100], Batch [92/147] train loss: 563.10, train corr: -0.01645
Epoch [75/100], Batch [93/147] train loss: 563.69, train corr: -0.01883
Epoch [75/100], Batch [94/147] train loss: 563.84, train corr: -0.00897
Epoch [75/100], Batch [95/147] train loss: 559.50, train corr: 0.01939
Epoch [75/100], Batch [96/147] train loss: 580.08, train corr: 0.03094
Epoch [75/100], Batch [97/147] train loss: 805.95, train corr: 0.02283
Epoch [75/100], Batch [98/147] train loss: 572.95, train corr: -0.00738
Epoch [75/100], Batch [99/147] train loss: 567.63, train corr: 0.02904
Epoch [75/100], Batch [100/147] train loss: 586.86, train corr: 0.02909
Epoch [75/100], Batch [101/147] train loss: 594.33, train corr: 0.02428
Epoch [75/100], Batch [102/147] train loss: 572.89, train corr: 0.02825
Epoch [75/100], Batch [103/147] train loss: 599.62, train corr: 0.02581
Epoch [75/100], Batch [104/147] train loss: 567.62, train corr: 0.02835
Epoch [75/100], Batch [105/147] train loss: 585.97, train corr: 0.02720
Epoch [75/100], Batch [106/147] train loss: 578.60, train corr: 0.02652
Epoch [75/100], Batch [107/147] train loss: 571.98, train corr: 0.02699
Epoch [75/100], Batch [108/147] train loss: 580.83, train corr: 0.01925
Epoch [75/100], Batch [109/147] train loss: 566.50, train corr: 0.02374
Epoch [75/100], Batch [110/147] train loss: 570.45, train corr: 0.01591
Epoch [75/100], Batch [111/147] train loss: 568.26, train corr: -0.01384
Epoch [75/100], Batch [112/147] train loss: 573.27, train corr: -0.03264
Epoch [75/100], Batch [113/147] train loss: 586.09, train corr: -0.03216
Epoch [75/100], Batch [114/147] train loss: 576.49, train corr: -0.00008
Epoch [75/100], Batch [115/147] train loss: 575.03, train corr: 0.01470
Epoch [75/100], Batch [116/147] train loss: 582.55, train corr: 0.02427
Epoch [75/100], Batch [117/147] train loss: 577.48, train corr: 0.02188
Epoch [75/100], Batch [118/147] train loss: 572.05, train corr: 0.01484
Epoch [75/100], Batch [119/147] train loss: 579.99, train corr: 0.00174
Epoch [75/100], Batch [120/147] train loss: 575.59, train corr: -0.02522
Epoch [75/100], Batch [121/147] train loss: 569.33, train corr: -0.03239
Epoch [75/100], Batch [122/147] train loss: 564.23, train corr: -0.03400
Epoch [75/100], Batch [123/147] train loss: 575.06, train corr: -0.03257
Epoch [75/100], Batch [124/147] train loss: 565.79, train corr: -0.03448
Epoch [75/100], Batch [125/147] train loss: 560.33, train corr: -0.03109
Epoch [75/100], Batch [126/147] train loss: 563.19, train corr: -0.00862
Epoch [75/100], Batch [127/147] train loss: 567.67, train corr: 0.02109
Epoch [75/100], Batch [128/147] train loss: 553.98, train corr: 0.02640
Epoch [75/100], Batch [129/147] train loss: 574.63, train corr: 0.02930
Epoch [75/100], Batch [130/147] train loss: 573.33, train corr: 0.02652
Epoch [75/100], Batch [131/147] train loss: 554.97, train corr: 0.02955
Epoch [75/100], Batch [132/147] train loss: 572.75, train corr: 0.02878
Epoch [75/100], Batch [133/147] train loss: 562.45, train corr: -0.01924
Epoch [75/100], Batch [134/147] train loss: 570.71, train corr: -0.02364
Epoch [75/100], Batch [135/147] train loss: 558.76, train corr: -0.02077
Epoch [75/100], Batch [136/147] train loss: 571.14, train corr: -0.00171
Epoch [75/100], Batch [137/147] train loss: 576.96, train corr: 0.02871
Epoch [75/100], Batch [138/147] train loss: 549.85, train corr: 0.03442
Epoch [75/100], Batch [139/147] train loss: 556.98, train corr: 0.03241
Epoch [75/100], Batch [140/147] train loss: 567.74, train corr: 0.03414
Epoch [75/100], Batch [141/147] train loss: 572.02, train corr: 0.03253
Epoch [75/100], Batch [142/147] train loss: 552.31, train corr: 0.02817
Epoch [75/100], Batch [143/147] train loss: 569.24, train corr: 0.00575
Epoch [75/100], Batch [144/147] train loss: 547.32, train corr: -0.00955
Epoch [75/100], Batch [145/147] train loss: 571.67, train corr: -0.01263
Epoch [75/100], Batch [146/147] train loss: 755.26, train corr: -0.01010
Epoch [75/100], Batch [147/147] train loss: 583.11, train corr: -0.02023
Epoch [75/100], validation loss: 598.86, validation correlation: 0.03357
Epoch [76/100], Batch [1/147] train loss: 564.54, train corr: 0.03210
Epoch [76/100], Batch [2/147] train loss: 566.82, train corr: 0.03202
Epoch [76/100], Batch [3/147] train loss: 575.59, train corr: 0.03029
Epoch [76/100], Batch [4/147] train loss: 583.65, train corr: 0.02640
Epoch [76/100], Batch [5/147] train loss: 559.94, train corr: 0.02843
Epoch [76/100], Batch [6/147] train loss: 557.49, train corr: 0.03141
Epoch [76/100], Batch [7/147] train loss: 577.93, train corr: 0.02555
Epoch [76/100], Batch [8/147] train loss: 582.87, train corr: 0.02916
Epoch [76/100], Batch [9/147] train loss: 563.54, train corr: -0.02168
Epoch [76/100], Batch [10/147] train loss: 813.99, train corr: -0.01498
Epoch [76/100], Batch [11/147] train loss: 588.87, train corr: -0.02181
Epoch [76/100], Batch [12/147] train loss: 611.15, train corr: 0.00512
Epoch [76/100], Batch [13/147] train loss: 583.02, train corr: 0.02820
Epoch [76/100], Batch [14/147] train loss: 582.34, train corr: 0.02939
Epoch [76/100], Batch [15/147] train loss: 590.98, train corr: 0.02716
Epoch [76/100], Batch [16/147] train loss: 564.26, train corr: 0.03182
Epoch [76/100], Batch [17/147] train loss: 575.28, train corr: 0.02873
Epoch [76/100], Batch [18/147] train loss: 573.79, train corr: 0.03123
Epoch [76/100], Batch [19/147] train loss: 570.25, train corr: 0.02887
Epoch [76/100], Batch [20/147] train loss: 575.41, train corr: 0.02763
Epoch [76/100], Batch [21/147] train loss: 570.27, train corr: 0.02637
Epoch [76/100], Batch [22/147] train loss: 580.25, train corr: -0.00752
Epoch [76/100], Batch [23/147] train loss: 586.07, train corr: -0.02051
Epoch [76/100], Batch [24/147] train loss: 575.48, train corr: -0.02482
Epoch [76/100], Batch [25/147] train loss: 573.93, train corr: -0.02231
Epoch [76/100], Batch [26/147] train loss: 559.88, train corr: 0.01636
Epoch [76/100], Batch [27/147] train loss: 558.22, train corr: 0.03328
Epoch [76/100], Batch [28/147] train loss: 571.85, train corr: 0.02879
Epoch [76/100], Batch [29/147] train loss: 569.65, train corr: 0.02886
Epoch [76/100], Batch [30/147] train loss: 576.75, train corr: 0.02968
Epoch [76/100], Batch [31/147] train loss: 568.83, train corr: 0.03212
Epoch [76/100], Batch [32/147] train loss: 571.49, train corr: 0.03234
Epoch [76/100], Batch [33/147] train loss: 770.37, train corr: 0.02710
Epoch [76/100], Batch [34/147] train loss: 573.97, train corr: -0.02059
Epoch [76/100], Batch [35/147] train loss: 580.44, train corr: 0.00076
Epoch [76/100], Batch [36/147] train loss: 560.12, train corr: 0.03202
Epoch [76/100], Batch [37/147] train loss: 577.69, train corr: 0.03235
Epoch [76/100], Batch [38/147] train loss: 572.00, train corr: 0.03195
Epoch [76/100], Batch [39/147] train loss: 565.06, train corr: 0.03198
Epoch [76/100], Batch [40/147] train loss: 560.39, train corr: 0.03377
Epoch [76/100], Batch [41/147] train loss: 556.09, train corr: 0.02048
Epoch [76/100], Batch [42/147] train loss: 562.91, train corr: -0.01098
Epoch [76/100], Batch [43/147] train loss: 577.45, train corr: -0.00095
Epoch [76/100], Batch [44/147] train loss: 557.10, train corr: 0.02466
Epoch [76/100], Batch [45/147] train loss: 551.74, train corr: 0.02328
Epoch [76/100], Batch [46/147] train loss: 565.10, train corr: 0.01717
Epoch [76/100], Batch [47/147] train loss: 579.99, train corr: -0.00696
Epoch [76/100], Batch [48/147] train loss: 554.05, train corr: -0.02834
Epoch [76/100], Batch [49/147] train loss: 574.11, train corr: -0.02455
Epoch [76/100], Batch [50/147] train loss: 579.00, train corr: 0.02332
Epoch [76/100], Batch [51/147] train loss: 571.72, train corr: 0.02894
Epoch [76/100], Batch [52/147] train loss: 575.57, train corr: 0.02970
Epoch [76/100], Batch [53/147] train loss: 572.89, train corr: 0.03021
Epoch [76/100], Batch [54/147] train loss: 569.25, train corr: 0.02964
Epoch [76/100], Batch [55/147] train loss: 560.45, train corr: -0.01691
Epoch [76/100], Batch [56/147] train loss: 560.86, train corr: -0.02253
Epoch [76/100], Batch [57/147] train loss: 566.21, train corr: -0.02237
Epoch [76/100], Batch [58/147] train loss: 566.21, train corr: -0.00829
Epoch [76/100], Batch [59/147] train loss: 573.26, train corr: 0.02984
Epoch [76/100], Batch [60/147] train loss: 571.16, train corr: 0.03043
Epoch [76/100], Batch [61/147] train loss: 567.44, train corr: 0.03278
Epoch [76/100], Batch [62/147] train loss: 570.75, train corr: 0.02911
Epoch [76/100], Batch [63/147] train loss: 568.40, train corr: 0.02560
Epoch [76/100], Batch [64/147] train loss: 567.98, train corr: 0.03400
Epoch [76/100], Batch [65/147] train loss: 559.81, train corr: 0.03204
Epoch [76/100], Batch [66/147] train loss: 555.27, train corr: 0.03408
Epoch [76/100], Batch [67/147] train loss: 572.73, train corr: 0.03200
Epoch [76/100], Batch [68/147] train loss: 566.82, train corr: 0.02593
Epoch [76/100], Batch [69/147] train loss: 565.54, train corr: -0.00429
Epoch [76/100], Batch [70/147] train loss: 558.77, train corr: -0.00945
Epoch [76/100], Batch [71/147] train loss: 559.03, train corr: -0.00309
Epoch [76/100], Batch [72/147] train loss: 548.75, train corr: 0.01928
Epoch [76/100], Batch [73/147] train loss: 573.72, train corr: 0.03316
Epoch [76/100], Batch [74/147] train loss: 580.31, train corr: 0.03238
Epoch [76/100], Batch [75/147] train loss: 637.78, train corr: 0.02557
Epoch [76/100], Batch [76/147] train loss: 570.01, train corr: -0.00059
Epoch [76/100], Batch [77/147] train loss: 561.41, train corr: -0.00923
Epoch [76/100], Batch [78/147] train loss: 558.44, train corr: 0.01191
Epoch [76/100], Batch [79/147] train loss: 566.71, train corr: 0.03437
Epoch [76/100], Batch [80/147] train loss: 567.56, train corr: 0.03268
Epoch [76/100], Batch [81/147] train loss: 567.15, train corr: 0.03229
Epoch [76/100], Batch [82/147] train loss: 571.12, train corr: 0.03244
Epoch [76/100], Batch [83/147] train loss: 554.19, train corr: 0.03169
Epoch [76/100], Batch [84/147] train loss: 566.38, train corr: 0.01543
Epoch [76/100], Batch [85/147] train loss: 562.11, train corr: 0.00666
Epoch [76/100], Batch [86/147] train loss: 566.13, train corr: 0.01590
Epoch [76/100], Batch [87/147] train loss: 571.80, train corr: 0.02258
Epoch [76/100], Batch [88/147] train loss: 578.44, train corr: 0.01301
Epoch [76/100], Batch [89/147] train loss: 567.67, train corr: -0.00257
Epoch [76/100], Batch [90/147] train loss: 551.76, train corr: -0.01346
Epoch [76/100], Batch [91/147] train loss: 558.51, train corr: -0.01157
Epoch [76/100], Batch [92/147] train loss: 565.25, train corr: 0.00564
Epoch [76/100], Batch [93/147] train loss: 571.94, train corr: 0.03407
Epoch [76/100], Batch [94/147] train loss: 571.93, train corr: 0.03385
Epoch [76/100], Batch [95/147] train loss: 557.28, train corr: 0.03347
Epoch [76/100], Batch [96/147] train loss: 570.32, train corr: 0.03416
Epoch [76/100], Batch [97/147] train loss: 581.83, train corr: 0.02928
Epoch [76/100], Batch [98/147] train loss: 584.82, train corr: 0.02103
Epoch [76/100], Batch [99/147] train loss: 576.21, train corr: 0.02470
Epoch [76/100], Batch [100/147] train loss: 567.91, train corr: 0.03112
Epoch [76/100], Batch [101/147] train loss: 569.76, train corr: 0.03222
Epoch [76/100], Batch [102/147] train loss: 551.11, train corr: 0.03156
Epoch [76/100], Batch [103/147] train loss: 565.01, train corr: 0.02995
Epoch [76/100], Batch [104/147] train loss: 566.75, train corr: 0.02471
Epoch [76/100], Batch [105/147] train loss: 564.39, train corr: 0.02418
Epoch [76/100], Batch [106/147] train loss: 565.57, train corr: 0.02921
Epoch [76/100], Batch [107/147] train loss: 570.75, train corr: 0.03209
Epoch [76/100], Batch [108/147] train loss: 561.43, train corr: 0.02966
Epoch [76/100], Batch [109/147] train loss: 569.79, train corr: 0.01917
Epoch [76/100], Batch [110/147] train loss: 589.08, train corr: 0.00901
Epoch [76/100], Batch [111/147] train loss: 560.05, train corr: -0.00310
Epoch [76/100], Batch [112/147] train loss: 575.89, train corr: 0.00028
Epoch [76/100], Batch [113/147] train loss: 572.96, train corr: 0.00622
Epoch [76/100], Batch [114/147] train loss: 559.20, train corr: 0.02056
Epoch [76/100], Batch [115/147] train loss: 554.34, train corr: 0.02814
Epoch [76/100], Batch [116/147] train loss: 552.42, train corr: 0.02897
Epoch [76/100], Batch [117/147] train loss: 558.08, train corr: 0.02633
Epoch [76/100], Batch [118/147] train loss: 575.73, train corr: 0.02207
Epoch [76/100], Batch [119/147] train loss: 559.40, train corr: 0.01324
Epoch [76/100], Batch [120/147] train loss: 571.90, train corr: 0.01528
Epoch [76/100], Batch [121/147] train loss: 558.25, train corr: 0.01703
Epoch [76/100], Batch [122/147] train loss: 576.49, train corr: 0.02257
Epoch [76/100], Batch [123/147] train loss: 557.00, train corr: 0.02357
Epoch [76/100], Batch [124/147] train loss: 570.77, train corr: 0.02426
Epoch [76/100], Batch [125/147] train loss: 573.63, train corr: 0.02194
Epoch [76/100], Batch [126/147] train loss: 565.95, train corr: 0.01852
Epoch [76/100], Batch [127/147] train loss: 567.42, train corr: 0.02126
Epoch [76/100], Batch [128/147] train loss: 571.61, train corr: 0.02532
Epoch [76/100], Batch [129/147] train loss: 544.11, train corr: 0.02540
Epoch [76/100], Batch [130/147] train loss: 568.40, train corr: 0.03147
Epoch [76/100], Batch [131/147] train loss: 566.55, train corr: 0.02561
Epoch [76/100], Batch [132/147] train loss: 568.74, train corr: 0.01947
Epoch [76/100], Batch [133/147] train loss: 572.76, train corr: 0.01190
Epoch [76/100], Batch [134/147] train loss: 558.36, train corr: 0.01041
Epoch [76/100], Batch [135/147] train loss: 628.57, train corr: 0.01687
Epoch [76/100], Batch [136/147] train loss: 574.79, train corr: 0.03240
Epoch [76/100], Batch [137/147] train loss: 569.78, train corr: 0.03258
Epoch [76/100], Batch [138/147] train loss: 576.89, train corr: 0.03063
Epoch [76/100], Batch [139/147] train loss: 579.55, train corr: 0.02055
Epoch [76/100], Batch [140/147] train loss: 558.68, train corr: 0.01277
Epoch [76/100], Batch [141/147] train loss: 568.45, train corr: 0.02368
Epoch [76/100], Batch [142/147] train loss: 563.99, train corr: 0.03198
Epoch [76/100], Batch [143/147] train loss: 586.55, train corr: 0.03348
Epoch [76/100], Batch [144/147] train loss: 566.36, train corr: 0.03119
Epoch [76/100], Batch [145/147] train loss: 552.98, train corr: 0.01117
Epoch [76/100], Batch [146/147] train loss: 561.29, train corr: -0.00627
Epoch [76/100], Batch [147/147] train loss: 568.80, train corr: -0.01057
Epoch [76/100], validation loss: 597.18, validation correlation: -0.00716
Epoch [77/100], Batch [1/147] train loss: 579.06, train corr: -0.00465
Epoch [77/100], Batch [2/147] train loss: 562.72, train corr: 0.00719
Epoch [77/100], Batch [3/147] train loss: 573.18, train corr: 0.02527
Epoch [77/100], Batch [4/147] train loss: 565.13, train corr: 0.03382
Epoch [77/100], Batch [5/147] train loss: 557.07, train corr: 0.03261
Epoch [77/100], Batch [6/147] train loss: 570.46, train corr: 0.03229
Epoch [77/100], Batch [7/147] train loss: 569.08, train corr: 0.02658
Epoch [77/100], Batch [8/147] train loss: 563.22, train corr: 0.01839
Epoch [77/100], Batch [9/147] train loss: 578.60, train corr: 0.02373
Epoch [77/100], Batch [10/147] train loss: 580.16, train corr: 0.02993
Epoch [77/100], Batch [11/147] train loss: 567.17, train corr: 0.03073
Epoch [77/100], Batch [12/147] train loss: 642.75, train corr: 0.02741
Epoch [77/100], Batch [13/147] train loss: 556.19, train corr: 0.02796
Epoch [77/100], Batch [14/147] train loss: 569.18, train corr: 0.02504
Epoch [77/100], Batch [15/147] train loss: 559.94, train corr: 0.01767
Epoch [77/100], Batch [16/147] train loss: 565.56, train corr: 0.01242
Epoch [77/100], Batch [17/147] train loss: 570.68, train corr: 0.01093
Epoch [77/100], Batch [18/147] train loss: 573.00, train corr: 0.01417
Epoch [77/100], Batch [19/147] train loss: 550.50, train corr: 0.01694
Epoch [77/100], Batch [20/147] train loss: 570.21, train corr: 0.01915
Epoch [77/100], Batch [21/147] train loss: 578.04, train corr: 0.02153
Epoch [77/100], Batch [22/147] train loss: 569.89, train corr: 0.01867
Epoch [77/100], Batch [23/147] train loss: 581.15, train corr: 0.02655
Epoch [77/100], Batch [24/147] train loss: 572.46, train corr: 0.02886
Epoch [77/100], Batch [25/147] train loss: 567.01, train corr: 0.03305
Epoch [77/100], Batch [26/147] train loss: 570.38, train corr: 0.03040
Epoch [77/100], Batch [27/147] train loss: 562.83, train corr: 0.02892
Epoch [77/100], Batch [28/147] train loss: 572.16, train corr: 0.01937
Epoch [77/100], Batch [29/147] train loss: 555.49, train corr: -0.00255
Epoch [77/100], Batch [30/147] train loss: 558.21, train corr: -0.00971
Epoch [77/100], Batch [31/147] train loss: 642.29, train corr: -0.00175
Epoch [77/100], Batch [32/147] train loss: 573.59, train corr: 0.00350
Epoch [77/100], Batch [33/147] train loss: 569.47, train corr: 0.01039
Epoch [77/100], Batch [34/147] train loss: 565.95, train corr: 0.01758
Epoch [77/100], Batch [35/147] train loss: 568.94, train corr: 0.02756
Epoch [77/100], Batch [36/147] train loss: 568.73, train corr: 0.03060
Epoch [77/100], Batch [37/147] train loss: 565.39, train corr: 0.03304
Epoch [77/100], Batch [38/147] train loss: 578.19, train corr: 0.03398
Epoch [77/100], Batch [39/147] train loss: 562.06, train corr: 0.03325
Epoch [77/100], Batch [40/147] train loss: 556.50, train corr: 0.03429
Epoch [77/100], Batch [41/147] train loss: 573.62, train corr: 0.03401
Epoch [77/100], Batch [42/147] train loss: 566.29, train corr: 0.02030
Epoch [77/100], Batch [43/147] train loss: 560.90, train corr: -0.00903
Epoch [77/100], Batch [44/147] train loss: 567.22, train corr: -0.01390
Epoch [77/100], Batch [45/147] train loss: 577.71, train corr: -0.01325
Epoch [77/100], Batch [46/147] train loss: 557.96, train corr: -0.01124
Epoch [77/100], Batch [47/147] train loss: 552.49, train corr: 0.01813
Epoch [77/100], Batch [48/147] train loss: 570.51, train corr: 0.03284
Epoch [77/100], Batch [49/147] train loss: 568.97, train corr: 0.03268
Epoch [77/100], Batch [50/147] train loss: 558.63, train corr: 0.03376
Epoch [77/100], Batch [51/147] train loss: 571.75, train corr: 0.03455
Epoch [77/100], Batch [52/147] train loss: 572.99, train corr: 0.03128
Epoch [77/100], Batch [53/147] train loss: 576.68, train corr: 0.02978
Epoch [77/100], Batch [54/147] train loss: 571.21, train corr: 0.02967
Epoch [77/100], Batch [55/147] train loss: 573.25, train corr: 0.02567
Epoch [77/100], Batch [56/147] train loss: 564.44, train corr: 0.01987
Epoch [77/100], Batch [57/147] train loss: 568.45, train corr: 0.01359
Epoch [77/100], Batch [58/147] train loss: 577.54, train corr: 0.00753
Epoch [77/100], Batch [59/147] train loss: 551.27, train corr: 0.00787
Epoch [77/100], Batch [60/147] train loss: 573.28, train corr: 0.02431
Epoch [77/100], Batch [61/147] train loss: 559.78, train corr: 0.03025
Epoch [77/100], Batch [62/147] train loss: 568.11, train corr: 0.03127
Epoch [77/100], Batch [63/147] train loss: 571.45, train corr: 0.03153
Epoch [77/100], Batch [64/147] train loss: 556.43, train corr: 0.01899
Epoch [77/100], Batch [65/147] train loss: 572.48, train corr: 0.01171
Epoch [77/100], Batch [66/147] train loss: 566.42, train corr: 0.01255
Epoch [77/100], Batch [67/147] train loss: 565.18, train corr: 0.01971
Epoch [77/100], Batch [68/147] train loss: 569.89, train corr: 0.02634
Epoch [77/100], Batch [69/147] train loss: 566.42, train corr: 0.01752
Epoch [77/100], Batch [70/147] train loss: 570.56, train corr: 0.00835
Epoch [77/100], Batch [71/147] train loss: 549.26, train corr: -0.00042
Epoch [77/100], Batch [72/147] train loss: 577.31, train corr: 0.00533
Epoch [77/100], Batch [73/147] train loss: 566.79, train corr: 0.01399
Epoch [77/100], Batch [74/147] train loss: 560.24, train corr: 0.02298
Epoch [77/100], Batch [75/147] train loss: 547.68, train corr: 0.02873
Epoch [77/100], Batch [76/147] train loss: 566.34, train corr: 0.02952
Epoch [77/100], Batch [77/147] train loss: 561.13, train corr: 0.02177
Epoch [77/100], Batch [78/147] train loss: 561.75, train corr: 0.01523
Epoch [77/100], Batch [79/147] train loss: 567.12, train corr: 0.01634
Epoch [77/100], Batch [80/147] train loss: 567.45, train corr: 0.02469
Epoch [77/100], Batch [81/147] train loss: 575.12, train corr: 0.03229
Epoch [77/100], Batch [82/147] train loss: 566.96, train corr: 0.03275
Epoch [77/100], Batch [83/147] train loss: 588.90, train corr: 0.03040
Epoch [77/100], Batch [84/147] train loss: 560.67, train corr: 0.01693
Epoch [77/100], Batch [85/147] train loss: 558.38, train corr: 0.01285
Epoch [77/100], Batch [86/147] train loss: 561.61, train corr: 0.01331
Epoch [77/100], Batch [87/147] train loss: 560.09, train corr: 0.02589
Epoch [77/100], Batch [88/147] train loss: 571.34, train corr: 0.03165
Epoch [77/100], Batch [89/147] train loss: 559.71, train corr: 0.03255
Epoch [77/100], Batch [90/147] train loss: 550.67, train corr: 0.02974
Epoch [77/100], Batch [91/147] train loss: 567.08, train corr: 0.03284
Epoch [77/100], Batch [92/147] train loss: 572.72, train corr: 0.03252
Epoch [77/100], Batch [93/147] train loss: 567.18, train corr: 0.03027
Epoch [77/100], Batch [94/147] train loss: 579.50, train corr: 0.01968
Epoch [77/100], Batch [95/147] train loss: 559.75, train corr: 0.00914
Epoch [77/100], Batch [96/147] train loss: 575.21, train corr: 0.00513
Epoch [77/100], Batch [97/147] train loss: 563.49, train corr: 0.01148
Epoch [77/100], Batch [98/147] train loss: 561.96, train corr: 0.01802
Epoch [77/100], Batch [99/147] train loss: 568.90, train corr: 0.02808
Epoch [77/100], Batch [100/147] train loss: 570.71, train corr: 0.03054
Epoch [77/100], Batch [101/147] train loss: 562.91, train corr: 0.02846
Epoch [77/100], Batch [102/147] train loss: 578.65, train corr: 0.02535
Epoch [77/100], Batch [103/147] train loss: 571.36, train corr: 0.01521
Epoch [77/100], Batch [104/147] train loss: 556.90, train corr: 0.00779
Epoch [77/100], Batch [105/147] train loss: 576.90, train corr: 0.00549
Epoch [77/100], Batch [106/147] train loss: 584.83, train corr: 0.00103
Epoch [77/100], Batch [107/147] train loss: 554.44, train corr: -0.00591
Epoch [77/100], Batch [108/147] train loss: 556.84, train corr: -0.00217
Epoch [77/100], Batch [109/147] train loss: 614.92, train corr: 0.00826
Epoch [77/100], Batch [110/147] train loss: 559.49, train corr: 0.03100
Epoch [77/100], Batch [111/147] train loss: 550.69, train corr: 0.03494
Epoch [77/100], Batch [112/147] train loss: 565.77, train corr: 0.03115
Epoch [77/100], Batch [113/147] train loss: 556.26, train corr: 0.03396
Epoch [77/100], Batch [114/147] train loss: 574.15, train corr: 0.03264
Epoch [77/100], Batch [115/147] train loss: 579.14, train corr: 0.02535
Epoch [77/100], Batch [116/147] train loss: 735.43, train corr: -0.01273
Epoch [77/100], Batch [117/147] train loss: 573.70, train corr: -0.02697
Epoch [77/100], Batch [118/147] train loss: 572.22, train corr: 0.02559
Epoch [77/100], Batch [119/147] train loss: 592.62, train corr: 0.02490
Epoch [77/100], Batch [120/147] train loss: 565.86, train corr: 0.03094
Epoch [77/100], Batch [121/147] train loss: 569.32, train corr: 0.03059
Epoch [77/100], Batch [122/147] train loss: 574.48, train corr: 0.02897
Epoch [77/100], Batch [123/147] train loss: 578.14, train corr: 0.02953
Epoch [77/100], Batch [124/147] train loss: 581.32, train corr: 0.03345
Epoch [77/100], Batch [125/147] train loss: 573.12, train corr: 0.03304
Epoch [77/100], Batch [126/147] train loss: 573.20, train corr: 0.03256
Epoch [77/100], Batch [127/147] train loss: 568.87, train corr: 0.01691
Epoch [77/100], Batch [128/147] train loss: 576.45, train corr: -0.01664
Epoch [77/100], Batch [129/147] train loss: 577.94, train corr: -0.02667
Epoch [77/100], Batch [130/147] train loss: 565.48, train corr: -0.02866
Epoch [77/100], Batch [131/147] train loss: 569.27, train corr: -0.03000
Epoch [77/100], Batch [132/147] train loss: 565.92, train corr: -0.02341
Epoch [77/100], Batch [133/147] train loss: 563.83, train corr: 0.00883
Epoch [77/100], Batch [134/147] train loss: 560.34, train corr: 0.02063
Epoch [77/100], Batch [135/147] train loss: 562.94, train corr: 0.02415
Epoch [77/100], Batch [136/147] train loss: 581.98, train corr: 0.02330
Epoch [77/100], Batch [137/147] train loss: 816.80, train corr: 0.01735
Epoch [77/100], Batch [138/147] train loss: 579.45, train corr: -0.02460
Epoch [77/100], Batch [139/147] train loss: 579.28, train corr: 0.02688
Epoch [77/100], Batch [140/147] train loss: 598.93, train corr: 0.02907
Epoch [77/100], Batch [141/147] train loss: 622.59, train corr: 0.02852
Epoch [77/100], Batch [142/147] train loss: 608.21, train corr: 0.02684
Epoch [77/100], Batch [143/147] train loss: 601.55, train corr: 0.02755
Epoch [77/100], Batch [144/147] train loss: 594.21, train corr: 0.02481
Epoch [77/100], Batch [145/147] train loss: 594.60, train corr: 0.02549
Epoch [77/100], Batch [146/147] train loss: 624.06, train corr: 0.02469
Epoch [77/100], Batch [147/147] train loss: 576.50, train corr: 0.02949
Epoch [77/100], validation loss: 621.51, validation correlation: 0.02752
Epoch [78/100], Batch [1/147] train loss: 620.16, train corr: 0.02054
Epoch [78/100], Batch [2/147] train loss: 595.35, train corr: 0.02414
Epoch [78/100], Batch [3/147] train loss: 595.28, train corr: 0.02523
Epoch [78/100], Batch [4/147] train loss: 592.44, train corr: 0.02514
Epoch [78/100], Batch [5/147] train loss: 578.44, train corr: 0.02897
Epoch [78/100], Batch [6/147] train loss: 589.56, train corr: 0.02478
Epoch [78/100], Batch [7/147] train loss: 571.18, train corr: 0.02582
Epoch [78/100], Batch [8/147] train loss: 575.80, train corr: 0.02653
Epoch [78/100], Batch [9/147] train loss: 556.88, train corr: 0.02819
Epoch [78/100], Batch [10/147] train loss: 563.38, train corr: 0.02696
Epoch [78/100], Batch [11/147] train loss: 556.52, train corr: 0.03056
Epoch [78/100], Batch [12/147] train loss: 579.48, train corr: 0.03015
Epoch [78/100], Batch [13/147] train loss: 581.48, train corr: -0.00782
Epoch [78/100], Batch [14/147] train loss: 569.85, train corr: -0.01922
Epoch [78/100], Batch [15/147] train loss: 568.03, train corr: -0.02358
Epoch [78/100], Batch [16/147] train loss: 566.32, train corr: -0.01964
Epoch [78/100], Batch [17/147] train loss: 558.85, train corr: -0.01562
Epoch [78/100], Batch [18/147] train loss: 571.54, train corr: 0.00464
Epoch [78/100], Batch [19/147] train loss: 580.73, train corr: 0.02624
Epoch [78/100], Batch [20/147] train loss: 752.54, train corr: 0.02684
Epoch [78/100], Batch [21/147] train loss: 569.89, train corr: 0.01095
Epoch [78/100], Batch [22/147] train loss: 565.69, train corr: 0.00643
Epoch [78/100], Batch [23/147] train loss: 570.34, train corr: 0.02091
Epoch [78/100], Batch [24/147] train loss: 565.67, train corr: 0.02758
Epoch [78/100], Batch [25/147] train loss: 568.54, train corr: 0.02988
Epoch [78/100], Batch [26/147] train loss: 579.48, train corr: 0.02092
Epoch [78/100], Batch [27/147] train loss: 565.83, train corr: -0.01868
Epoch [78/100], Batch [28/147] train loss: 567.74, train corr: -0.02223
Epoch [78/100], Batch [29/147] train loss: 574.50, train corr: -0.02000
Epoch [78/100], Batch [30/147] train loss: 569.76, train corr: -0.01383
Epoch [78/100], Batch [31/147] train loss: 576.50, train corr: 0.03188
Epoch [78/100], Batch [32/147] train loss: 560.88, train corr: 0.03236
Epoch [78/100], Batch [33/147] train loss: 566.67, train corr: 0.03085
Epoch [78/100], Batch [34/147] train loss: 574.80, train corr: 0.02944
Epoch [78/100], Batch [35/147] train loss: 558.02, train corr: 0.02938
Epoch [78/100], Batch [36/147] train loss: 563.46, train corr: 0.03051
Epoch [78/100], Batch [37/147] train loss: 559.36, train corr: 0.02750
Epoch [78/100], Batch [38/147] train loss: 565.72, train corr: 0.02746
Epoch [78/100], Batch [39/147] train loss: 566.53, train corr: 0.00235
Epoch [78/100], Batch [40/147] train loss: 568.72, train corr: -0.02606
Epoch [78/100], Batch [41/147] train loss: 571.70, train corr: -0.02753
Epoch [78/100], Batch [42/147] train loss: 570.22, train corr: -0.02839
Epoch [78/100], Batch [43/147] train loss: 556.89, train corr: -0.02775
Epoch [78/100], Batch [44/147] train loss: 601.47, train corr: -0.01778
Epoch [78/100], Batch [45/147] train loss: 567.95, train corr: -0.02247
Epoch [78/100], Batch [46/147] train loss: 570.22, train corr: -0.01307
Epoch [78/100], Batch [47/147] train loss: 561.67, train corr: 0.00727
Epoch [78/100], Batch [48/147] train loss: 561.07, train corr: 0.02882
Epoch [78/100], Batch [49/147] train loss: 573.62, train corr: 0.03441
Epoch [78/100], Batch [50/147] train loss: 570.30, train corr: 0.03206
Epoch [78/100], Batch [51/147] train loss: 552.93, train corr: 0.03311
Epoch [78/100], Batch [52/147] train loss: 565.21, train corr: 0.03231
Epoch [78/100], Batch [53/147] train loss: 564.38, train corr: 0.03348
Epoch [78/100], Batch [54/147] train loss: 563.51, train corr: -0.01225
Epoch [78/100], Batch [55/147] train loss: 817.06, train corr: -0.02240
Epoch [78/100], Batch [56/147] train loss: 562.98, train corr: -0.02946
Epoch [78/100], Batch [57/147] train loss: 559.25, train corr: -0.03333
Epoch [78/100], Batch [58/147] train loss: 576.66, train corr: -0.02991
Epoch [78/100], Batch [59/147] train loss: 557.97, train corr: 0.01784
Epoch [78/100], Batch [60/147] train loss: 578.58, train corr: 0.02407
Epoch [78/100], Batch [61/147] train loss: 583.08, train corr: 0.02099
Epoch [78/100], Batch [62/147] train loss: 566.74, train corr: 0.02850
Epoch [78/100], Batch [63/147] train loss: 563.31, train corr: 0.02790
Epoch [78/100], Batch [64/147] train loss: 616.19, train corr: 0.02722
Epoch [78/100], Batch [65/147] train loss: 579.14, train corr: 0.02906
Epoch [78/100], Batch [66/147] train loss: 591.21, train corr: 0.02924
Epoch [78/100], Batch [67/147] train loss: 585.88, train corr: 0.03008
Epoch [78/100], Batch [68/147] train loss: 629.95, train corr: 0.02857
Epoch [78/100], Batch [69/147] train loss: 594.50, train corr: 0.02964
Epoch [78/100], Batch [70/147] train loss: 567.18, train corr: -0.00861
Epoch [78/100], Batch [71/147] train loss: 584.84, train corr: -0.01259
Epoch [78/100], Batch [72/147] train loss: 592.00, train corr: -0.00667
Epoch [78/100], Batch [73/147] train loss: 568.12, train corr: 0.02009
Epoch [78/100], Batch [74/147] train loss: 569.68, train corr: 0.03220
Epoch [78/100], Batch [75/147] train loss: 560.51, train corr: 0.03094
Epoch [78/100], Batch [76/147] train loss: 562.18, train corr: 0.03193
Epoch [78/100], Batch [77/147] train loss: 577.45, train corr: 0.02638
Epoch [78/100], Batch [78/147] train loss: 573.59, train corr: 0.03056
Epoch [78/100], Batch [79/147] train loss: 552.15, train corr: 0.02958
Epoch [78/100], Batch [80/147] train loss: 573.98, train corr: 0.03285
Epoch [78/100], Batch [81/147] train loss: 569.03, train corr: 0.03414
Epoch [78/100], Batch [82/147] train loss: 550.45, train corr: 0.01217
Epoch [78/100], Batch [83/147] train loss: 567.42, train corr: -0.01480
Epoch [78/100], Batch [84/147] train loss: 569.26, train corr: -0.02049
Epoch [78/100], Batch [85/147] train loss: 568.27, train corr: -0.02110
Epoch [78/100], Batch [86/147] train loss: 584.48, train corr: -0.01949
Epoch [78/100], Batch [87/147] train loss: 573.34, train corr: -0.02002
Epoch [78/100], Batch [88/147] train loss: 567.62, train corr: 0.00569
Epoch [78/100], Batch [89/147] train loss: 559.46, train corr: 0.02740
Epoch [78/100], Batch [90/147] train loss: 561.12, train corr: 0.03024
Epoch [78/100], Batch [91/147] train loss: 569.07, train corr: 0.02852
Epoch [78/100], Batch [92/147] train loss: 557.92, train corr: 0.02850
Epoch [78/100], Batch [93/147] train loss: 566.77, train corr: 0.02710
Epoch [78/100], Batch [94/147] train loss: 576.78, train corr: 0.02938
Epoch [78/100], Batch [95/147] train loss: 562.68, train corr: 0.03117
Epoch [78/100], Batch [96/147] train loss: 575.31, train corr: 0.02977
Epoch [78/100], Batch [97/147] train loss: 563.41, train corr: 0.02132
Epoch [78/100], Batch [98/147] train loss: 586.06, train corr: -0.00166
Epoch [78/100], Batch [99/147] train loss: 579.63, train corr: -0.01729
Epoch [78/100], Batch [100/147] train loss: 583.16, train corr: -0.01644
Epoch [78/100], Batch [101/147] train loss: 579.69, train corr: -0.01611
Epoch [78/100], Batch [102/147] train loss: 567.91, train corr: -0.00972
Epoch [78/100], Batch [103/147] train loss: 576.79, train corr: 0.01541
Epoch [78/100], Batch [104/147] train loss: 576.81, train corr: 0.03573
Epoch [78/100], Batch [105/147] train loss: 571.70, train corr: 0.03424
Epoch [78/100], Batch [106/147] train loss: 579.14, train corr: 0.03377
Epoch [78/100], Batch [107/147] train loss: 567.26, train corr: 0.03178
Epoch [78/100], Batch [108/147] train loss: 560.06, train corr: 0.02664
Epoch [78/100], Batch [109/147] train loss: 556.27, train corr: 0.02693
Epoch [78/100], Batch [110/147] train loss: 559.66, train corr: 0.03056
Epoch [78/100], Batch [111/147] train loss: 581.97, train corr: 0.02811
Epoch [78/100], Batch [112/147] train loss: 573.83, train corr: 0.00208
Epoch [78/100], Batch [113/147] train loss: 573.37, train corr: -0.00853
Epoch [78/100], Batch [114/147] train loss: 564.18, train corr: -0.01345
Epoch [78/100], Batch [115/147] train loss: 575.04, train corr: -0.00354
Epoch [78/100], Batch [116/147] train loss: 560.78, train corr: 0.01264
Epoch [78/100], Batch [117/147] train loss: 566.34, train corr: 0.03086
Epoch [78/100], Batch [118/147] train loss: 573.02, train corr: 0.03421
Epoch [78/100], Batch [119/147] train loss: 561.16, train corr: 0.03534
Epoch [78/100], Batch [120/147] train loss: 559.08, train corr: 0.03434
Epoch [78/100], Batch [121/147] train loss: 570.75, train corr: 0.03316
Epoch [78/100], Batch [122/147] train loss: 561.29, train corr: 0.02513
Epoch [78/100], Batch [123/147] train loss: 553.82, train corr: 0.02176
Epoch [78/100], Batch [124/147] train loss: 568.32, train corr: 0.01847
Epoch [78/100], Batch [125/147] train loss: 566.39, train corr: 0.01334
Epoch [78/100], Batch [126/147] train loss: 574.60, train corr: 0.00487
Epoch [78/100], Batch [127/147] train loss: 640.42, train corr: -0.00091
Epoch [78/100], Batch [128/147] train loss: 555.59, train corr: -0.00526
Epoch [78/100], Batch [129/147] train loss: 576.33, train corr: 0.01614
Epoch [78/100], Batch [130/147] train loss: 560.64, train corr: 0.03346
Epoch [78/100], Batch [131/147] train loss: 562.64, train corr: 0.03065
Epoch [78/100], Batch [132/147] train loss: 569.47, train corr: 0.02634
Epoch [78/100], Batch [133/147] train loss: 570.79, train corr: 0.02400
Epoch [78/100], Batch [134/147] train loss: 558.19, train corr: 0.00013
Epoch [78/100], Batch [135/147] train loss: 561.61, train corr: -0.01096
Epoch [78/100], Batch [136/147] train loss: 559.06, train corr: 0.00331
Epoch [78/100], Batch [137/147] train loss: 557.27, train corr: 0.02915
Epoch [78/100], Batch [138/147] train loss: 570.63, train corr: 0.03349
Epoch [78/100], Batch [139/147] train loss: 554.10, train corr: 0.03198
Epoch [78/100], Batch [140/147] train loss: 577.21, train corr: 0.03143
Epoch [78/100], Batch [141/147] train loss: 554.11, train corr: 0.00084
Epoch [78/100], Batch [142/147] train loss: 569.48, train corr: -0.01977
Epoch [78/100], Batch [143/147] train loss: 542.62, train corr: -0.02134
Epoch [78/100], Batch [144/147] train loss: 554.51, train corr: -0.00643
Epoch [78/100], Batch [145/147] train loss: 578.87, train corr: 0.03194
Epoch [78/100], Batch [146/147] train loss: 561.59, train corr: 0.03337
Epoch [78/100], Batch [147/147] train loss: 598.70, train corr: 0.03257
Epoch [78/100], validation loss: 597.14, validation correlation: 0.03451
Epoch [79/100], Batch [1/147] train loss: 560.77, train corr: 0.03389
Epoch [79/100], Batch [2/147] train loss: 565.11, train corr: 0.02522
Epoch [79/100], Batch [3/147] train loss: 576.81, train corr: 0.01816
Epoch [79/100], Batch [4/147] train loss: 563.03, train corr: 0.01885
Epoch [79/100], Batch [5/147] train loss: 557.82, train corr: 0.02592
Epoch [79/100], Batch [6/147] train loss: 553.82, train corr: 0.02222
Epoch [79/100], Batch [7/147] train loss: 573.13, train corr: 0.01247
Epoch [79/100], Batch [8/147] train loss: 565.50, train corr: -0.00492
Epoch [79/100], Batch [9/147] train loss: 552.45, train corr: -0.01160
Epoch [79/100], Batch [10/147] train loss: 565.88, train corr: -0.00686
Epoch [79/100], Batch [11/147] train loss: 565.27, train corr: 0.01875
Epoch [79/100], Batch [12/147] train loss: 565.69, train corr: 0.03275
Epoch [79/100], Batch [13/147] train loss: 564.16, train corr: 0.03348
Epoch [79/100], Batch [14/147] train loss: 561.02, train corr: 0.03506
Epoch [79/100], Batch [15/147] train loss: 565.69, train corr: 0.03030
Epoch [79/100], Batch [16/147] train loss: 568.08, train corr: 0.01532
Epoch [79/100], Batch [17/147] train loss: 566.07, train corr: 0.00255
Epoch [79/100], Batch [18/147] train loss: 644.19, train corr: -0.00531
Epoch [79/100], Batch [19/147] train loss: 571.71, train corr: 0.01027
Epoch [79/100], Batch [20/147] train loss: 580.31, train corr: 0.02902
Epoch [79/100], Batch [21/147] train loss: 571.78, train corr: 0.03443
Epoch [79/100], Batch [22/147] train loss: 561.70, train corr: 0.03107
Epoch [79/100], Batch [23/147] train loss: 574.11, train corr: 0.02754
Epoch [79/100], Batch [24/147] train loss: 567.42, train corr: 0.01625
Epoch [79/100], Batch [25/147] train loss: 560.32, train corr: -0.02169
Epoch [79/100], Batch [26/147] train loss: 565.91, train corr: -0.02474
Epoch [79/100], Batch [27/147] train loss: 566.82, train corr: -0.01605
Epoch [79/100], Batch [28/147] train loss: 551.26, train corr: 0.00484
Epoch [79/100], Batch [29/147] train loss: 555.51, train corr: 0.02988
Epoch [79/100], Batch [30/147] train loss: 555.06, train corr: 0.02832
Epoch [79/100], Batch [31/147] train loss: 570.24, train corr: 0.02540
Epoch [79/100], Batch [32/147] train loss: 569.33, train corr: 0.01392
Epoch [79/100], Batch [33/147] train loss: 569.80, train corr: 0.00320
Epoch [79/100], Batch [34/147] train loss: 574.69, train corr: -0.00196
Epoch [79/100], Batch [35/147] train loss: 562.47, train corr: -0.00333
Epoch [79/100], Batch [36/147] train loss: 565.25, train corr: -0.00005
Epoch [79/100], Batch [37/147] train loss: 567.38, train corr: -0.00080
Epoch [79/100], Batch [38/147] train loss: 569.24, train corr: -0.00591
Epoch [79/100], Batch [39/147] train loss: 566.14, train corr: -0.00371
Epoch [79/100], Batch [40/147] train loss: 581.54, train corr: 0.01135
Epoch [79/100], Batch [41/147] train loss: 561.08, train corr: 0.02275
Epoch [79/100], Batch [42/147] train loss: 549.18, train corr: 0.02910
Epoch [79/100], Batch [43/147] train loss: 559.24, train corr: 0.03330
Epoch [79/100], Batch [44/147] train loss: 568.82, train corr: 0.03219
Epoch [79/100], Batch [45/147] train loss: 581.86, train corr: 0.03288
Epoch [79/100], Batch [46/147] train loss: 580.71, train corr: 0.02097
Epoch [79/100], Batch [47/147] train loss: 594.09, train corr: -0.00061
Epoch [79/100], Batch [48/147] train loss: 559.00, train corr: -0.00890
Epoch [79/100], Batch [49/147] train loss: 631.07, train corr: -0.00131
Epoch [79/100], Batch [50/147] train loss: 554.00, train corr: 0.02992
Epoch [79/100], Batch [51/147] train loss: 578.67, train corr: 0.03030
Epoch [79/100], Batch [52/147] train loss: 570.07, train corr: 0.02411
Epoch [79/100], Batch [53/147] train loss: 565.98, train corr: 0.03122
Epoch [79/100], Batch [54/147] train loss: 572.04, train corr: 0.02956
Epoch [79/100], Batch [55/147] train loss: 558.77, train corr: 0.01730
Epoch [79/100], Batch [56/147] train loss: 555.94, train corr: 0.01575
Epoch [79/100], Batch [57/147] train loss: 568.55, train corr: 0.02858
Epoch [79/100], Batch [58/147] train loss: 566.94, train corr: 0.03204
Epoch [79/100], Batch [59/147] train loss: 580.74, train corr: 0.03237
Epoch [79/100], Batch [60/147] train loss: 570.28, train corr: 0.00477
Epoch [79/100], Batch [61/147] train loss: 589.89, train corr: -0.00785
Epoch [79/100], Batch [62/147] train loss: 571.22, train corr: -0.01455
Epoch [79/100], Batch [63/147] train loss: 560.69, train corr: -0.01152
Epoch [79/100], Batch [64/147] train loss: 555.99, train corr: 0.00761
Epoch [79/100], Batch [65/147] train loss: 586.03, train corr: 0.02798
Epoch [79/100], Batch [66/147] train loss: 568.43, train corr: 0.03291
Epoch [79/100], Batch [67/147] train loss: 560.79, train corr: 0.03207
Epoch [79/100], Batch [68/147] train loss: 563.07, train corr: 0.02835
Epoch [79/100], Batch [69/147] train loss: 551.67, train corr: 0.02325
Epoch [79/100], Batch [70/147] train loss: 555.67, train corr: 0.02390
Epoch [79/100], Batch [71/147] train loss: 561.65, train corr: 0.02304
Epoch [79/100], Batch [72/147] train loss: 573.47, train corr: 0.02076
Epoch [79/100], Batch [73/147] train loss: 564.17, train corr: 0.01836
Epoch [79/100], Batch [74/147] train loss: 553.69, train corr: 0.01181
Epoch [79/100], Batch [75/147] train loss: 562.54, train corr: 0.00537
Epoch [79/100], Batch [76/147] train loss: 574.96, train corr: 0.00343
Epoch [79/100], Batch [77/147] train loss: 600.37, train corr: 0.01654
Epoch [79/100], Batch [78/147] train loss: 567.96, train corr: 0.01953
Epoch [79/100], Batch [79/147] train loss: 559.90, train corr: 0.03033
Epoch [79/100], Batch [80/147] train loss: 552.60, train corr: 0.02940
Epoch [79/100], Batch [81/147] train loss: 576.06, train corr: 0.02980
Epoch [79/100], Batch [82/147] train loss: 576.86, train corr: 0.02310
Epoch [79/100], Batch [83/147] train loss: 568.11, train corr: 0.01329
Epoch [79/100], Batch [84/147] train loss: 567.23, train corr: 0.00487
Epoch [79/100], Batch [85/147] train loss: 570.28, train corr: 0.00384
Epoch [79/100], Batch [86/147] train loss: 563.50, train corr: 0.00851
Epoch [79/100], Batch [87/147] train loss: 560.28, train corr: 0.00692
Epoch [79/100], Batch [88/147] train loss: 574.33, train corr: 0.01137
Epoch [79/100], Batch [89/147] train loss: 564.11, train corr: 0.00877
Epoch [79/100], Batch [90/147] train loss: 558.07, train corr: 0.01314
Epoch [79/100], Batch [91/147] train loss: 561.31, train corr: 0.02615
Epoch [79/100], Batch [92/147] train loss: 575.57, train corr: 0.03426
Epoch [79/100], Batch [93/147] train loss: 550.31, train corr: 0.03347
Epoch [79/100], Batch [94/147] train loss: 582.56, train corr: 0.03339
Epoch [79/100], Batch [95/147] train loss: 566.30, train corr: 0.03366
Epoch [79/100], Batch [96/147] train loss: 561.92, train corr: 0.03035
Epoch [79/100], Batch [97/147] train loss: 564.90, train corr: 0.01276
Epoch [79/100], Batch [98/147] train loss: 566.42, train corr: 0.00361
Epoch [79/100], Batch [99/147] train loss: 557.11, train corr: 0.00100
Epoch [79/100], Batch [100/147] train loss: 569.58, train corr: 0.00924
Epoch [79/100], Batch [101/147] train loss: 562.20, train corr: 0.01242
Epoch [79/100], Batch [102/147] train loss: 581.55, train corr: 0.01905
Epoch [79/100], Batch [103/147] train loss: 576.16, train corr: 0.01719
Epoch [79/100], Batch [104/147] train loss: 574.26, train corr: 0.01148
Epoch [79/100], Batch [105/147] train loss: 569.67, train corr: 0.01754
Epoch [79/100], Batch [106/147] train loss: 573.29, train corr: 0.02892
Epoch [79/100], Batch [107/147] train loss: 556.04, train corr: 0.03130
Epoch [79/100], Batch [108/147] train loss: 556.62, train corr: 0.03217
Epoch [79/100], Batch [109/147] train loss: 577.25, train corr: 0.02929
Epoch [79/100], Batch [110/147] train loss: 558.92, train corr: 0.01859
Epoch [79/100], Batch [111/147] train loss: 614.55, train corr: 0.00553
Epoch [79/100], Batch [112/147] train loss: 570.49, train corr: 0.01805
Epoch [79/100], Batch [113/147] train loss: 555.47, train corr: 0.02836
Epoch [79/100], Batch [114/147] train loss: 562.40, train corr: 0.02922
Epoch [79/100], Batch [115/147] train loss: 573.88, train corr: 0.02728
Epoch [79/100], Batch [116/147] train loss: 555.13, train corr: 0.01437
Epoch [79/100], Batch [117/147] train loss: 575.36, train corr: 0.01069
Epoch [79/100], Batch [118/147] train loss: 570.68, train corr: 0.00908
Epoch [79/100], Batch [119/147] train loss: 559.47, train corr: 0.01837
Epoch [79/100], Batch [120/147] train loss: 570.08, train corr: 0.02913
Epoch [79/100], Batch [121/147] train loss: 553.61, train corr: 0.03035
Epoch [79/100], Batch [122/147] train loss: 804.81, train corr: 0.02513
Epoch [79/100], Batch [123/147] train loss: 979.10, train corr: -0.01467
Epoch [79/100], Batch [124/147] train loss: 627.98, train corr: 0.02640
Epoch [79/100], Batch [125/147] train loss: 695.20, train corr: 0.02633
Epoch [79/100], Batch [126/147] train loss: 727.30, train corr: 0.02853
Epoch [79/100], Batch [127/147] train loss: 764.54, train corr: 0.02789
Epoch [79/100], Batch [128/147] train loss: 777.36, train corr: 0.02985
Epoch [79/100], Batch [129/147] train loss: 824.62, train corr: 0.02518
Epoch [79/100], Batch [130/147] train loss: 834.66, train corr: 0.02444
Epoch [79/100], Batch [131/147] train loss: 813.86, train corr: 0.02643
Epoch [79/100], Batch [132/147] train loss: 808.93, train corr: 0.02920
Epoch [79/100], Batch [133/147] train loss: 751.92, train corr: 0.02634
Epoch [79/100], Batch [134/147] train loss: 746.62, train corr: 0.02865
Epoch [79/100], Batch [135/147] train loss: 765.97, train corr: -0.01683
Epoch [79/100], Batch [136/147] train loss: 831.05, train corr: 0.03146
Epoch [79/100], Batch [137/147] train loss: 992.79, train corr: 0.03060
Epoch [79/100], Batch [138/147] train loss: 871.62, train corr: 0.02740
Epoch [79/100], Batch [139/147] train loss: 916.48, train corr: 0.02763
Epoch [79/100], Batch [140/147] train loss: 974.22, train corr: 0.02572
Epoch [79/100], Batch [141/147] train loss: 1007.48, train corr: 0.02532
Epoch [79/100], Batch [142/147] train loss: 1004.31, train corr: 0.02479
Epoch [79/100], Batch [143/147] train loss: 982.01, train corr: 0.02952
Epoch [79/100], Batch [144/147] train loss: 1004.57, train corr: 0.02399
Epoch [79/100], Batch [145/147] train loss: 935.64, train corr: 0.02735
Epoch [79/100], Batch [146/147] train loss: 1504.87, train corr: 0.02633
Epoch [79/100], Batch [147/147] train loss: 907.74, train corr: 0.03261
Epoch [79/100], validation loss: 903.09, validation correlation: 0.02933
Epoch [80/100], Batch [1/147] train loss: 885.98, train corr: 0.02354
Epoch [80/100], Batch [2/147] train loss: 1092.11, train corr: 0.02856
Epoch [80/100], Batch [3/147] train loss: 819.95, train corr: -0.00353
Epoch [80/100], Batch [4/147] train loss: 883.67, train corr: 0.00739
Epoch [80/100], Batch [5/147] train loss: 744.25, train corr: 0.01019
Epoch [80/100], Batch [6/147] train loss: 683.55, train corr: 0.00524
Epoch [80/100], Batch [7/147] train loss: 1300.90, train corr: 0.02322
Epoch [80/100], Batch [8/147] train loss: 1568.33, train corr: 0.02571
Epoch [80/100], Batch [9/147] train loss: 1124.17, train corr: -0.01211
Epoch [80/100], Batch [10/147] train loss: 1390.28, train corr: -0.01186
Epoch [80/100], Batch [11/147] train loss: 1311.67, train corr: -0.01691
Epoch [80/100], Batch [12/147] train loss: 1344.97, train corr: -0.01075
Epoch [80/100], Batch [13/147] train loss: 1214.97, train corr: -0.02000
Epoch [80/100], Batch [14/147] train loss: 1159.02, train corr: -0.02849
Epoch [80/100], Batch [15/147] train loss: 987.61, train corr: -0.02835
Epoch [80/100], Batch [16/147] train loss: 1180.60, train corr: -0.02202
Epoch [80/100], Batch [17/147] train loss: 881.19, train corr: -0.02627
Epoch [80/100], Batch [18/147] train loss: 1999.91, train corr: -0.02923
Epoch [80/100], Batch [19/147] train loss: 1537.47, train corr: -0.01070
Epoch [80/100], Batch [20/147] train loss: 1586.24, train corr: -0.00834
Epoch [80/100], Batch [21/147] train loss: 1562.87, train corr: -0.00655
Epoch [80/100], Batch [22/147] train loss: 1687.17, train corr: -0.01569
Epoch [80/100], Batch [23/147] train loss: 3093.73, train corr: -0.01441
Epoch [80/100], Batch [24/147] train loss: 8752.31, train corr: -0.01633
Epoch [80/100], Batch [25/147] train loss: 5862.04, train corr: -0.00649
Epoch [80/100], Batch [26/147] train loss: 6216.76, train corr: -0.01070
Epoch [80/100], Batch [27/147] train loss: 4806.09, train corr: -0.00814
Epoch [80/100], Batch [28/147] train loss: 14235.97, train corr: -0.00444
Epoch [80/100], Batch [29/147] train loss: 17708.66, train corr: -0.00419
Epoch [80/100], Batch [30/147] train loss: 12865.83, train corr: -0.00335
Epoch [80/100], Batch [31/147] train loss: 9591.39, train corr: 0.00277
Epoch [80/100], Batch [32/147] train loss: 6807.71, train corr: 0.00277
Epoch [80/100], Batch [33/147] train loss: 5445.46, train corr: 0.01792
Epoch [80/100], Batch [34/147] train loss: 3159.66, train corr: 0.01948
Epoch [80/100], Batch [35/147] train loss: 4202.75, train corr: -0.00774
Epoch [80/100], Batch [36/147] train loss: 5154.06, train corr: -0.00492
Epoch [80/100], Batch [37/147] train loss: 5281.81, train corr: 0.00356
Epoch [80/100], Batch [38/147] train loss: 4506.41, train corr: -0.00192
Epoch [80/100], Batch [39/147] train loss: 5050.16, train corr: 0.00017
Epoch [80/100], Batch [40/147] train loss: 4652.64, train corr: -0.01687
Epoch [80/100], Batch [41/147] train loss: 3774.27, train corr: -0.01655
Epoch [80/100], Batch [42/147] train loss: 3964.07, train corr: -0.00772
Epoch [80/100], Batch [43/147] train loss: 2975.16, train corr: -0.00115
Epoch [80/100], Batch [44/147] train loss: 3211.75, train corr: -0.00493
Epoch [80/100], Batch [45/147] train loss: 1955.94, train corr: 0.01085
Epoch [80/100], Batch [46/147] train loss: 1685.27, train corr: 0.00864
Epoch [80/100], Batch [47/147] train loss: 1609.94, train corr: 0.00661
Epoch [80/100], Batch [48/147] train loss: 1527.78, train corr: 0.01115
Epoch [80/100], Batch [49/147] train loss: 1277.92, train corr: 0.00919
Epoch [80/100], Batch [50/147] train loss: 1032.83, train corr: 0.01856
Epoch [80/100], Batch [51/147] train loss: 1053.42, train corr: 0.00097
Epoch [80/100], Batch [52/147] train loss: 1312.02, train corr: 0.00020
Epoch [80/100], Batch [53/147] train loss: 1137.25, train corr: -0.00073
Epoch [80/100], Batch [54/147] train loss: 1021.64, train corr: -0.00360
Epoch [80/100], Batch [55/147] train loss: 811.32, train corr: 0.01185
Epoch [80/100], Batch [56/147] train loss: 1098.49, train corr: 0.00818
Epoch [80/100], Batch [57/147] train loss: 1297.15, train corr: 0.00370
Epoch [80/100], Batch [58/147] train loss: 2683.66, train corr: 0.00308
Epoch [80/100], Batch [59/147] train loss: 1234.14, train corr: 0.00034
Epoch [80/100], Batch [60/147] train loss: 1024.24, train corr: 0.00049
Epoch [80/100], Batch [61/147] train loss: 857.68, train corr: -0.00611
Epoch [80/100], Batch [62/147] train loss: 777.75, train corr: -0.02173
Epoch [80/100], Batch [63/147] train loss: 776.55, train corr: -0.02619
Epoch [80/100], Batch [64/147] train loss: 767.31, train corr: -0.02994
Epoch [80/100], Batch [65/147] train loss: 710.43, train corr: -0.02118
Epoch [80/100], Batch [66/147] train loss: 714.76, train corr: -0.00517
Epoch [80/100], Batch [67/147] train loss: 722.94, train corr: -0.00260
Epoch [80/100], Batch [68/147] train loss: 678.23, train corr: 0.01465
Epoch [80/100], Batch [69/147] train loss: 643.93, train corr: 0.02671
Epoch [80/100], Batch [70/147] train loss: 664.05, train corr: 0.02558
Epoch [80/100], Batch [71/147] train loss: 629.02, train corr: 0.02251
Epoch [80/100], Batch [72/147] train loss: 615.32, train corr: 0.01854
Epoch [80/100], Batch [73/147] train loss: 645.33, train corr: 0.01903
Epoch [80/100], Batch [74/147] train loss: 629.79, train corr: 0.01966
Epoch [80/100], Batch [75/147] train loss: 600.71, train corr: 0.02134
Epoch [80/100], Batch [76/147] train loss: 593.85, train corr: 0.01437
Epoch [80/100], Batch [77/147] train loss: 596.66, train corr: 0.00916
Epoch [80/100], Batch [78/147] train loss: 587.01, train corr: 0.01188
Epoch [80/100], Batch [79/147] train loss: 590.19, train corr: 0.01247
Epoch [80/100], Batch [80/147] train loss: 587.04, train corr: -0.00389
Epoch [80/100], Batch [81/147] train loss: 588.81, train corr: -0.01226
Epoch [80/100], Batch [82/147] train loss: 582.65, train corr: -0.01066
Epoch [80/100], Batch [83/147] train loss: 569.12, train corr: -0.01173
Epoch [80/100], Batch [84/147] train loss: 574.80, train corr: -0.02462
Epoch [80/100], Batch [85/147] train loss: 618.14, train corr: -0.01829
Epoch [80/100], Batch [86/147] train loss: 581.15, train corr: -0.01302
Epoch [80/100], Batch [87/147] train loss: 569.73, train corr: -0.00384
Epoch [80/100], Batch [88/147] train loss: 628.99, train corr: 0.00001
Epoch [80/100], Batch [89/147] train loss: 600.14, train corr: -0.00023
Epoch [80/100], Batch [90/147] train loss: 580.92, train corr: 0.00733
Epoch [80/100], Batch [91/147] train loss: 565.72, train corr: 0.00851
Epoch [80/100], Batch [92/147] train loss: 582.23, train corr: 0.00701
Epoch [80/100], Batch [93/147] train loss: 591.44, train corr: 0.01435
Epoch [80/100], Batch [94/147] train loss: 577.06, train corr: 0.01265
Epoch [80/100], Batch [95/147] train loss: 577.55, train corr: 0.01740
Epoch [80/100], Batch [96/147] train loss: 582.21, train corr: 0.01082
Epoch [80/100], Batch [97/147] train loss: 580.23, train corr: 0.00615
Epoch [80/100], Batch [98/147] train loss: 575.89, train corr: 0.00575
Epoch [80/100], Batch [99/147] train loss: 578.13, train corr: -0.01085
Epoch [80/100], Batch [100/147] train loss: 569.17, train corr: -0.01262
Epoch [80/100], Batch [101/147] train loss: 576.62, train corr: 0.00015
Epoch [80/100], Batch [102/147] train loss: 568.89, train corr: 0.01906
Epoch [80/100], Batch [103/147] train loss: 560.01, train corr: 0.02190
Epoch [80/100], Batch [104/147] train loss: 571.66, train corr: 0.01875
Epoch [80/100], Batch [105/147] train loss: 573.91, train corr: 0.01922
Epoch [80/100], Batch [106/147] train loss: 559.97, train corr: 0.01732
Epoch [80/100], Batch [107/147] train loss: 589.41, train corr: 0.01879
Epoch [80/100], Batch [108/147] train loss: 570.36, train corr: 0.02894
Epoch [80/100], Batch [109/147] train loss: 561.68, train corr: 0.02876
Epoch [80/100], Batch [110/147] train loss: 572.66, train corr: 0.02702
Epoch [80/100], Batch [111/147] train loss: 564.69, train corr: 0.03015
Epoch [80/100], Batch [112/147] train loss: 573.76, train corr: 0.02818
Epoch [80/100], Batch [113/147] train loss: 571.42, train corr: 0.02552
Epoch [80/100], Batch [114/147] train loss: 584.05, train corr: 0.02504
Epoch [80/100], Batch [115/147] train loss: 567.54, train corr: 0.02785
Epoch [80/100], Batch [116/147] train loss: 581.62, train corr: 0.02836
Epoch [80/100], Batch [117/147] train loss: 568.95, train corr: 0.02811
Epoch [80/100], Batch [118/147] train loss: 566.33, train corr: 0.02499
Epoch [80/100], Batch [119/147] train loss: 571.81, train corr: 0.01570
Epoch [80/100], Batch [120/147] train loss: 551.29, train corr: 0.01652
Epoch [80/100], Batch [121/147] train loss: 583.65, train corr: 0.01613
Epoch [80/100], Batch [122/147] train loss: 582.74, train corr: 0.01594
Epoch [80/100], Batch [123/147] train loss: 576.05, train corr: 0.01857
Epoch [80/100], Batch [124/147] train loss: 626.87, train corr: 0.01768
Epoch [80/100], Batch [125/147] train loss: 553.35, train corr: 0.02073
Epoch [80/100], Batch [126/147] train loss: 578.13, train corr: 0.01682
Epoch [80/100], Batch [127/147] train loss: 564.50, train corr: 0.01663
Epoch [80/100], Batch [128/147] train loss: 560.56, train corr: 0.01693
Epoch [80/100], Batch [129/147] train loss: 572.15, train corr: 0.01885
Epoch [80/100], Batch [130/147] train loss: 579.67, train corr: 0.01340
Epoch [80/100], Batch [131/147] train loss: 556.48, train corr: 0.01816
Epoch [80/100], Batch [132/147] train loss: 565.54, train corr: 0.02077
Epoch [80/100], Batch [133/147] train loss: 749.74, train corr: 0.02044
Epoch [80/100], Batch [134/147] train loss: 664.16, train corr: 0.01717
Epoch [80/100], Batch [135/147] train loss: 725.42, train corr: -0.01005
Epoch [80/100], Batch [136/147] train loss: 963.75, train corr: -0.00974
Epoch [80/100], Batch [137/147] train loss: 1102.93, train corr: -0.00239
Epoch [80/100], Batch [138/147] train loss: 943.34, train corr: -0.01191
Epoch [80/100], Batch [139/147] train loss: 835.94, train corr: -0.01034
Epoch [80/100], Batch [140/147] train loss: 705.38, train corr: -0.00974
Epoch [80/100], Batch [141/147] train loss: 644.07, train corr: 0.00531
Epoch [80/100], Batch [142/147] train loss: 866.01, train corr: 0.01206
Epoch [80/100], Batch [143/147] train loss: 604.25, train corr: 0.01208
Epoch [80/100], Batch [144/147] train loss: 707.96, train corr: 0.00019
Epoch [80/100], Batch [145/147] train loss: 748.03, train corr: 0.00322
Epoch [80/100], Batch [146/147] train loss: 781.86, train corr: 0.00573
Epoch [80/100], Batch [147/147] train loss: 807.94, train corr: 0.00828
Epoch [80/100], validation loss: 747.72, validation correlation: 0.01790
Epoch [81/100], Batch [1/147] train loss: 720.56, train corr: 0.01777
Epoch [81/100], Batch [2/147] train loss: 674.37, train corr: 0.01400
Epoch [81/100], Batch [3/147] train loss: 620.73, train corr: 0.02009
Epoch [81/100], Batch [4/147] train loss: 821.68, train corr: 0.02062
Epoch [81/100], Batch [5/147] train loss: 682.85, train corr: 0.02677
Epoch [81/100], Batch [6/147] train loss: 616.33, train corr: 0.00763
Epoch [81/100], Batch [7/147] train loss: 648.25, train corr: -0.00261
Epoch [81/100], Batch [8/147] train loss: 669.94, train corr: -0.00537
Epoch [81/100], Batch [9/147] train loss: 641.47, train corr: -0.00468
Epoch [81/100], Batch [10/147] train loss: 636.73, train corr: -0.01131
Epoch [81/100], Batch [11/147] train loss: 604.23, train corr: -0.00977
Epoch [81/100], Batch [12/147] train loss: 608.49, train corr: -0.01297
Epoch [81/100], Batch [13/147] train loss: 731.20, train corr: -0.00882
Epoch [81/100], Batch [14/147] train loss: 601.13, train corr: -0.00644
Epoch [81/100], Batch [15/147] train loss: 599.11, train corr: 0.00276
Epoch [81/100], Batch [16/147] train loss: 621.72, train corr: 0.00558
Epoch [81/100], Batch [17/147] train loss: 610.08, train corr: 0.01208
Epoch [81/100], Batch [18/147] train loss: 600.72, train corr: 0.01609
Epoch [81/100], Batch [19/147] train loss: 571.99, train corr: 0.02053
Epoch [81/100], Batch [20/147] train loss: 608.71, train corr: 0.02063
Epoch [81/100], Batch [21/147] train loss: 590.06, train corr: 0.02271
Epoch [81/100], Batch [22/147] train loss: 845.09, train corr: 0.02107
Epoch [81/100], Batch [23/147] train loss: 579.69, train corr: 0.02335
Epoch [81/100], Batch [24/147] train loss: 593.31, train corr: 0.02708
Epoch [81/100], Batch [25/147] train loss: 574.23, train corr: 0.02567
Epoch [81/100], Batch [26/147] train loss: 576.37, train corr: 0.02645
Epoch [81/100], Batch [27/147] train loss: 574.25, train corr: 0.02669
Epoch [81/100], Batch [28/147] train loss: 590.28, train corr: 0.02872
Epoch [81/100], Batch [29/147] train loss: 568.20, train corr: 0.02751
Epoch [81/100], Batch [30/147] train loss: 569.03, train corr: 0.02446
Epoch [81/100], Batch [31/147] train loss: 596.92, train corr: 0.01933
Epoch [81/100], Batch [32/147] train loss: 574.09, train corr: 0.02116
Epoch [81/100], Batch [33/147] train loss: 570.21, train corr: 0.02066
Epoch [81/100], Batch [34/147] train loss: 567.69, train corr: 0.02211
Epoch [81/100], Batch [35/147] train loss: 573.55, train corr: 0.02555
Epoch [81/100], Batch [36/147] train loss: 571.11, train corr: 0.02602
Epoch [81/100], Batch [37/147] train loss: 583.93, train corr: 0.02407
Epoch [81/100], Batch [38/147] train loss: 567.28, train corr: 0.02914
Epoch [81/100], Batch [39/147] train loss: 569.17, train corr: 0.03076
Epoch [81/100], Batch [40/147] train loss: 570.16, train corr: 0.03294
Epoch [81/100], Batch [41/147] train loss: 572.54, train corr: 0.03168
Epoch [81/100], Batch [42/147] train loss: 574.74, train corr: 0.03263
Epoch [81/100], Batch [43/147] train loss: 584.71, train corr: 0.03092
Epoch [81/100], Batch [44/147] train loss: 558.56, train corr: 0.03250
Epoch [81/100], Batch [45/147] train loss: 568.66, train corr: 0.03214
Epoch [81/100], Batch [46/147] train loss: 583.52, train corr: 0.03171
Epoch [81/100], Batch [47/147] train loss: 585.35, train corr: 0.03135
Epoch [81/100], Batch [48/147] train loss: 578.76, train corr: 0.03152
Epoch [81/100], Batch [49/147] train loss: 573.58, train corr: 0.03016
Epoch [81/100], Batch [50/147] train loss: 573.81, train corr: 0.03028
Epoch [81/100], Batch [51/147] train loss: 572.04, train corr: 0.02911
Epoch [81/100], Batch [52/147] train loss: 574.23, train corr: 0.03006
Epoch [81/100], Batch [53/147] train loss: 557.00, train corr: 0.03035
Epoch [81/100], Batch [54/147] train loss: 583.41, train corr: 0.02909
Epoch [81/100], Batch [55/147] train loss: 565.80, train corr: 0.03293
Epoch [81/100], Batch [56/147] train loss: 567.59, train corr: 0.03205
Epoch [81/100], Batch [57/147] train loss: 561.73, train corr: 0.03388
Epoch [81/100], Batch [58/147] train loss: 572.00, train corr: 0.03256
Epoch [81/100], Batch [59/147] train loss: 578.30, train corr: 0.03080
Epoch [81/100], Batch [60/147] train loss: 565.29, train corr: 0.03323
Epoch [81/100], Batch [61/147] train loss: 568.42, train corr: 0.03135
Epoch [81/100], Batch [62/147] train loss: 563.11, train corr: 0.03158
Epoch [81/100], Batch [63/147] train loss: 569.49, train corr: 0.02978
Epoch [81/100], Batch [64/147] train loss: 557.06, train corr: 0.03190
Epoch [81/100], Batch [65/147] train loss: 561.92, train corr: 0.03223
Epoch [81/100], Batch [66/147] train loss: 575.01, train corr: 0.03284
Epoch [81/100], Batch [67/147] train loss: 580.14, train corr: 0.03249
Epoch [81/100], Batch [68/147] train loss: 572.48, train corr: 0.03196
Epoch [81/100], Batch [69/147] train loss: 570.25, train corr: 0.03129
Epoch [81/100], Batch [70/147] train loss: 578.94, train corr: 0.03035
Epoch [81/100], Batch [71/147] train loss: 560.71, train corr: 0.03292
Epoch [81/100], Batch [72/147] train loss: 559.16, train corr: 0.03216
Epoch [81/100], Batch [73/147] train loss: 577.02, train corr: 0.03331
Epoch [81/100], Batch [74/147] train loss: 557.66, train corr: 0.03316
Epoch [81/100], Batch [75/147] train loss: 582.57, train corr: 0.03026
Epoch [81/100], Batch [76/147] train loss: 575.08, train corr: 0.03088
Epoch [81/100], Batch [77/147] train loss: 604.38, train corr: 0.02602
Epoch [81/100], Batch [78/147] train loss: 572.93, train corr: 0.03078
Epoch [81/100], Batch [79/147] train loss: 561.68, train corr: 0.03243
Epoch [81/100], Batch [80/147] train loss: 567.14, train corr: 0.03288
Epoch [81/100], Batch [81/147] train loss: 574.79, train corr: 0.03141
Epoch [81/100], Batch [82/147] train loss: 568.66, train corr: 0.03274
Epoch [81/100], Batch [83/147] train loss: 566.78, train corr: 0.03251
Epoch [81/100], Batch [84/147] train loss: 578.55, train corr: 0.03307
Epoch [81/100], Batch [85/147] train loss: 574.67, train corr: 0.03282
Epoch [81/100], Batch [86/147] train loss: 577.51, train corr: 0.03386
Epoch [81/100], Batch [87/147] train loss: 573.93, train corr: 0.03306
Epoch [81/100], Batch [88/147] train loss: 551.45, train corr: 0.03217
Epoch [81/100], Batch [89/147] train loss: 557.09, train corr: 0.03216
Epoch [81/100], Batch [90/147] train loss: 561.48, train corr: 0.03142
Epoch [81/100], Batch [91/147] train loss: 570.30, train corr: 0.03039
Epoch [81/100], Batch [92/147] train loss: 565.72, train corr: 0.03045
Epoch [81/100], Batch [93/147] train loss: 561.32, train corr: 0.03090
Epoch [81/100], Batch [94/147] train loss: 562.90, train corr: 0.03221
Epoch [81/100], Batch [95/147] train loss: 559.95, train corr: 0.03218
Epoch [81/100], Batch [96/147] train loss: 597.11, train corr: 0.02837
Epoch [81/100], Batch [97/147] train loss: 568.20, train corr: 0.03131
Epoch [81/100], Batch [98/147] train loss: 577.42, train corr: 0.03071
Epoch [81/100], Batch [99/147] train loss: 572.15, train corr: 0.03212
Epoch [81/100], Batch [100/147] train loss: 567.15, train corr: 0.03213
Epoch [81/100], Batch [101/147] train loss: 569.88, train corr: 0.02983
Epoch [81/100], Batch [102/147] train loss: 587.92, train corr: 0.02934
Epoch [81/100], Batch [103/147] train loss: 555.12, train corr: 0.03233
Epoch [81/100], Batch [104/147] train loss: 569.43, train corr: 0.03290
Epoch [81/100], Batch [105/147] train loss: 579.49, train corr: 0.02922
Epoch [81/100], Batch [106/147] train loss: 569.43, train corr: 0.03082
Epoch [81/100], Batch [107/147] train loss: 552.38, train corr: 0.03274
Epoch [81/100], Batch [108/147] train loss: 586.01, train corr: 0.02878
Epoch [81/100], Batch [109/147] train loss: 568.60, train corr: 0.03226
Epoch [81/100], Batch [110/147] train loss: 558.76, train corr: 0.03154
Epoch [81/100], Batch [111/147] train loss: 577.35, train corr: 0.03216
Epoch [81/100], Batch [112/147] train loss: 554.48, train corr: 0.03127
Epoch [81/100], Batch [113/147] train loss: 577.60, train corr: 0.02876
Epoch [81/100], Batch [114/147] train loss: 564.79, train corr: 0.03151
Epoch [81/100], Batch [115/147] train loss: 567.46, train corr: 0.03080
Epoch [81/100], Batch [116/147] train loss: 574.37, train corr: 0.02970
Epoch [81/100], Batch [117/147] train loss: 561.17, train corr: 0.03310
Epoch [81/100], Batch [118/147] train loss: 575.13, train corr: 0.02977
Epoch [81/100], Batch [119/147] train loss: 566.71, train corr: 0.03147
Epoch [81/100], Batch [120/147] train loss: 570.31, train corr: 0.03290
Epoch [81/100], Batch [121/147] train loss: 576.01, train corr: 0.03201
Epoch [81/100], Batch [122/147] train loss: 576.50, train corr: 0.03414
Epoch [81/100], Batch [123/147] train loss: 578.38, train corr: 0.02988
Epoch [81/100], Batch [124/147] train loss: 574.80, train corr: 0.03282
Epoch [81/100], Batch [125/147] train loss: 551.40, train corr: 0.03251
Epoch [81/100], Batch [126/147] train loss: 580.85, train corr: 0.03201
Epoch [81/100], Batch [127/147] train loss: 557.72, train corr: 0.03346
Epoch [81/100], Batch [128/147] train loss: 564.59, train corr: 0.03232
Epoch [81/100], Batch [129/147] train loss: 579.50, train corr: 0.03512
Epoch [81/100], Batch [130/147] train loss: 560.99, train corr: 0.03308
Epoch [81/100], Batch [131/147] train loss: 583.33, train corr: 0.03135
Epoch [81/100], Batch [132/147] train loss: 566.07, train corr: 0.03099
Epoch [81/100], Batch [133/147] train loss: 568.29, train corr: 0.03047
Epoch [81/100], Batch [134/147] train loss: 566.79, train corr: 0.03133
Epoch [81/100], Batch [135/147] train loss: 568.53, train corr: 0.03218
Epoch [81/100], Batch [136/147] train loss: 579.41, train corr: 0.03177
Epoch [81/100], Batch [137/147] train loss: 565.11, train corr: 0.03054
Epoch [81/100], Batch [138/147] train loss: 562.98, train corr: 0.03168
Epoch [81/100], Batch [139/147] train loss: 563.31, train corr: 0.03148
Epoch [81/100], Batch [140/147] train loss: 745.38, train corr: 0.03054
Epoch [81/100], Batch [141/147] train loss: 579.18, train corr: 0.03273
Epoch [81/100], Batch [142/147] train loss: 564.38, train corr: 0.03257
Epoch [81/100], Batch [143/147] train loss: 594.06, train corr: 0.02949
Epoch [81/100], Batch [144/147] train loss: 569.10, train corr: 0.03321
Epoch [81/100], Batch [145/147] train loss: 553.98, train corr: 0.03197
Epoch [81/100], Batch [146/147] train loss: 565.03, train corr: 0.03150
Epoch [81/100], Batch [147/147] train loss: 574.44, train corr: 0.03135
Epoch [81/100], validation loss: 599.68, validation correlation: 0.03126
Epoch [82/100], Batch [1/147] train loss: 572.60, train corr: 0.03176
Epoch [82/100], Batch [2/147] train loss: 572.26, train corr: 0.03312
Epoch [82/100], Batch [3/147] train loss: 596.79, train corr: 0.03294
Epoch [82/100], Batch [4/147] train loss: 574.01, train corr: 0.03215
Epoch [82/100], Batch [5/147] train loss: 580.41, train corr: 0.03216
Epoch [82/100], Batch [6/147] train loss: 563.36, train corr: 0.03164
Epoch [82/100], Batch [7/147] train loss: 568.16, train corr: 0.03196
Epoch [82/100], Batch [8/147] train loss: 550.06, train corr: 0.03206
Epoch [82/100], Batch [9/147] train loss: 581.41, train corr: 0.02951
Epoch [82/100], Batch [10/147] train loss: 563.41, train corr: 0.03114
Epoch [82/100], Batch [11/147] train loss: 558.16, train corr: 0.03023
Epoch [82/100], Batch [12/147] train loss: 575.37, train corr: 0.03015
Epoch [82/100], Batch [13/147] train loss: 563.72, train corr: 0.03177
Epoch [82/100], Batch [14/147] train loss: 580.58, train corr: 0.02759
Epoch [82/100], Batch [15/147] train loss: 556.42, train corr: 0.03306
Epoch [82/100], Batch [16/147] train loss: 557.18, train corr: 0.03228
Epoch [82/100], Batch [17/147] train loss: 546.14, train corr: 0.03244
Epoch [82/100], Batch [18/147] train loss: 581.64, train corr: 0.03132
Epoch [82/100], Batch [19/147] train loss: 622.92, train corr: 0.02743
Epoch [82/100], Batch [20/147] train loss: 569.73, train corr: 0.03133
Epoch [82/100], Batch [21/147] train loss: 564.22, train corr: 0.03231
Epoch [82/100], Batch [22/147] train loss: 568.20, train corr: 0.03242
Epoch [82/100], Batch [23/147] train loss: 563.53, train corr: 0.03220
Epoch [82/100], Batch [24/147] train loss: 564.24, train corr: 0.03116
Epoch [82/100], Batch [25/147] train loss: 563.97, train corr: 0.03238
Epoch [82/100], Batch [26/147] train loss: 558.35, train corr: 0.03165
Epoch [82/100], Batch [27/147] train loss: 573.53, train corr: 0.03043
Epoch [82/100], Batch [28/147] train loss: 574.00, train corr: 0.03279
Epoch [82/100], Batch [29/147] train loss: 570.09, train corr: 0.03081
Epoch [82/100], Batch [30/147] train loss: 562.52, train corr: 0.03159
Epoch [82/100], Batch [31/147] train loss: 565.12, train corr: 0.03175
Epoch [82/100], Batch [32/147] train loss: 576.34, train corr: 0.03128
Epoch [82/100], Batch [33/147] train loss: 556.95, train corr: 0.03163
Epoch [82/100], Batch [34/147] train loss: 568.31, train corr: 0.03172
Epoch [82/100], Batch [35/147] train loss: 574.48, train corr: 0.03288
Epoch [82/100], Batch [36/147] train loss: 569.77, train corr: 0.03255
Epoch [82/100], Batch [37/147] train loss: 558.48, train corr: 0.03236
Epoch [82/100], Batch [38/147] train loss: 565.98, train corr: 0.03265
Epoch [82/100], Batch [39/147] train loss: 566.56, train corr: 0.03280
Epoch [82/100], Batch [40/147] train loss: 576.43, train corr: 0.03162
Epoch [82/100], Batch [41/147] train loss: 551.72, train corr: 0.03154
Epoch [82/100], Batch [42/147] train loss: 589.15, train corr: 0.03042
Epoch [82/100], Batch [43/147] train loss: 576.58, train corr: 0.03225
Epoch [82/100], Batch [44/147] train loss: 569.40, train corr: 0.03273
Epoch [82/100], Batch [45/147] train loss: 568.07, train corr: 0.03117
Epoch [82/100], Batch [46/147] train loss: 747.81, train corr: 0.02978
Epoch [82/100], Batch [47/147] train loss: 594.40, train corr: 0.03137
Epoch [82/100], Batch [48/147] train loss: 572.09, train corr: 0.03048
Epoch [82/100], Batch [49/147] train loss: 575.66, train corr: 0.03010
Epoch [82/100], Batch [50/147] train loss: 574.38, train corr: 0.02942
Epoch [82/100], Batch [51/147] train loss: 577.06, train corr: 0.03117
Epoch [82/100], Batch [52/147] train loss: 550.27, train corr: 0.03190
Epoch [82/100], Batch [53/147] train loss: 586.78, train corr: 0.03311
Epoch [82/100], Batch [54/147] train loss: 581.04, train corr: 0.02967
Epoch [82/100], Batch [55/147] train loss: 584.73, train corr: 0.02901
Epoch [82/100], Batch [56/147] train loss: 577.64, train corr: 0.03206
Epoch [82/100], Batch [57/147] train loss: 576.20, train corr: 0.03105
Epoch [82/100], Batch [58/147] train loss: 584.58, train corr: 0.03281
Epoch [82/100], Batch [59/147] train loss: 565.08, train corr: 0.03324
Epoch [82/100], Batch [60/147] train loss: 567.49, train corr: 0.03164
Epoch [82/100], Batch [61/147] train loss: 570.91, train corr: 0.03191
Epoch [82/100], Batch [62/147] train loss: 567.37, train corr: 0.03155
Epoch [82/100], Batch [63/147] train loss: 564.70, train corr: 0.03093
Epoch [82/100], Batch [64/147] train loss: 565.29, train corr: 0.03002
Epoch [82/100], Batch [65/147] train loss: 569.00, train corr: 0.03025
Epoch [82/100], Batch [66/147] train loss: 564.09, train corr: 0.02979
Epoch [82/100], Batch [67/147] train loss: 560.55, train corr: 0.03051
Epoch [82/100], Batch [68/147] train loss: 560.14, train corr: 0.03089
Epoch [82/100], Batch [69/147] train loss: 582.09, train corr: 0.03142
Epoch [82/100], Batch [70/147] train loss: 568.67, train corr: 0.03090
Epoch [82/100], Batch [71/147] train loss: 562.65, train corr: 0.03002
Epoch [82/100], Batch [72/147] train loss: 590.62, train corr: 0.03017
Epoch [82/100], Batch [73/147] train loss: 576.22, train corr: 0.03129
Epoch [82/100], Batch [74/147] train loss: 575.93, train corr: 0.03090
Epoch [82/100], Batch [75/147] train loss: 593.83, train corr: 0.03043
Epoch [82/100], Batch [76/147] train loss: 558.70, train corr: 0.03203
Epoch [82/100], Batch [77/147] train loss: 567.85, train corr: 0.03179
Epoch [82/100], Batch [78/147] train loss: 573.18, train corr: 0.02865
Epoch [82/100], Batch [79/147] train loss: 566.84, train corr: 0.03149
Epoch [82/100], Batch [80/147] train loss: 563.87, train corr: 0.03213
Epoch [82/100], Batch [81/147] train loss: 548.70, train corr: 0.02979
Epoch [82/100], Batch [82/147] train loss: 572.50, train corr: 0.02930
Epoch [82/100], Batch [83/147] train loss: 569.08, train corr: 0.03070
Epoch [82/100], Batch [84/147] train loss: 583.72, train corr: 0.03170
Epoch [82/100], Batch [85/147] train loss: 566.61, train corr: 0.02932
Epoch [82/100], Batch [86/147] train loss: 584.35, train corr: 0.03034
Epoch [82/100], Batch [87/147] train loss: 576.99, train corr: 0.03044
Epoch [82/100], Batch [88/147] train loss: 564.95, train corr: 0.03077
Epoch [82/100], Batch [89/147] train loss: 579.41, train corr: 0.03022
Epoch [82/100], Batch [90/147] train loss: 597.73, train corr: 0.03023
Epoch [82/100], Batch [91/147] train loss: 567.31, train corr: 0.02999
Epoch [82/100], Batch [92/147] train loss: 573.83, train corr: 0.03105
Epoch [82/100], Batch [93/147] train loss: 596.89, train corr: 0.03008
Epoch [82/100], Batch [94/147] train loss: 556.97, train corr: 0.03048
Epoch [82/100], Batch [95/147] train loss: 564.41, train corr: 0.03213
Epoch [82/100], Batch [96/147] train loss: 571.69, train corr: 0.03194
Epoch [82/100], Batch [97/147] train loss: 562.47, train corr: 0.03011
Epoch [82/100], Batch [98/147] train loss: 558.92, train corr: 0.03201
Epoch [82/100], Batch [99/147] train loss: 560.55, train corr: 0.03197
Epoch [82/100], Batch [100/147] train loss: 573.21, train corr: 0.03143
Epoch [82/100], Batch [101/147] train loss: 612.18, train corr: 0.02997
Epoch [82/100], Batch [102/147] train loss: 589.50, train corr: 0.03046
Epoch [82/100], Batch [103/147] train loss: 575.72, train corr: 0.03156
Epoch [82/100], Batch [104/147] train loss: 570.32, train corr: 0.03072
Epoch [82/100], Batch [105/147] train loss: 568.44, train corr: 0.02915
Epoch [82/100], Batch [106/147] train loss: 577.82, train corr: 0.03069
Epoch [82/100], Batch [107/147] train loss: 564.89, train corr: 0.03113
Epoch [82/100], Batch [108/147] train loss: 565.65, train corr: 0.03058
Epoch [82/100], Batch [109/147] train loss: 568.71, train corr: 0.03053
Epoch [82/100], Batch [110/147] train loss: 566.82, train corr: 0.03158
Epoch [82/100], Batch [111/147] train loss: 565.61, train corr: 0.03210
Epoch [82/100], Batch [112/147] train loss: 578.02, train corr: 0.03166
Epoch [82/100], Batch [113/147] train loss: 568.85, train corr: 0.03162
Epoch [82/100], Batch [114/147] train loss: 664.89, train corr: 0.02635
Epoch [82/100], Batch [115/147] train loss: 577.20, train corr: 0.02987
Epoch [82/100], Batch [116/147] train loss: 564.00, train corr: 0.03130
Epoch [82/100], Batch [117/147] train loss: 577.71, train corr: 0.03121
Epoch [82/100], Batch [118/147] train loss: 570.00, train corr: 0.03170
Epoch [82/100], Batch [119/147] train loss: 566.03, train corr: 0.03080
Epoch [82/100], Batch [120/147] train loss: 560.16, train corr: 0.03168
Epoch [82/100], Batch [121/147] train loss: 574.33, train corr: 0.02847
Epoch [82/100], Batch [122/147] train loss: 556.65, train corr: 0.03202
Epoch [82/100], Batch [123/147] train loss: 593.02, train corr: 0.02958
Epoch [82/100], Batch [124/147] train loss: 573.11, train corr: 0.03247
Epoch [82/100], Batch [125/147] train loss: 565.11, train corr: 0.03129
Epoch [82/100], Batch [126/147] train loss: 572.12, train corr: 0.02831
Epoch [82/100], Batch [127/147] train loss: 558.18, train corr: 0.03173
Epoch [82/100], Batch [128/147] train loss: 574.16, train corr: 0.02895
Epoch [82/100], Batch [129/147] train loss: 574.94, train corr: 0.02990
Epoch [82/100], Batch [130/147] train loss: 573.59, train corr: 0.03033
Epoch [82/100], Batch [131/147] train loss: 568.09, train corr: 0.03120
Epoch [82/100], Batch [132/147] train loss: 580.67, train corr: 0.03029
Epoch [82/100], Batch [133/147] train loss: 588.65, train corr: 0.03088
Epoch [82/100], Batch [134/147] train loss: 569.96, train corr: 0.02928
Epoch [82/100], Batch [135/147] train loss: 565.41, train corr: 0.03112
Epoch [82/100], Batch [136/147] train loss: 568.82, train corr: 0.03232
Epoch [82/100], Batch [137/147] train loss: 554.80, train corr: 0.03160
Epoch [82/100], Batch [138/147] train loss: 568.90, train corr: 0.03332
Epoch [82/100], Batch [139/147] train loss: 565.19, train corr: 0.02988
Epoch [82/100], Batch [140/147] train loss: 571.99, train corr: 0.03121
Epoch [82/100], Batch [141/147] train loss: 580.13, train corr: 0.03227
Epoch [82/100], Batch [142/147] train loss: 561.67, train corr: 0.03383
Epoch [82/100], Batch [143/147] train loss: 584.57, train corr: 0.03251
Epoch [82/100], Batch [144/147] train loss: 559.81, train corr: 0.02960
Epoch [82/100], Batch [145/147] train loss: 817.32, train corr: 0.02552
Epoch [82/100], Batch [146/147] train loss: 553.20, train corr: 0.03110
Epoch [82/100], Batch [147/147] train loss: 560.27, train corr: 0.03210
Epoch [82/100], validation loss: 601.01, validation correlation: 0.03132
Epoch [83/100], Batch [1/147] train loss: 565.80, train corr: 0.03166
Epoch [83/100], Batch [2/147] train loss: 564.35, train corr: 0.03158
Epoch [83/100], Batch [3/147] train loss: 561.81, train corr: 0.03143
Epoch [83/100], Batch [4/147] train loss: 571.16, train corr: 0.02767
Epoch [83/100], Batch [5/147] train loss: 745.44, train corr: 0.02946
Epoch [83/100], Batch [6/147] train loss: 597.78, train corr: 0.02840
Epoch [83/100], Batch [7/147] train loss: 572.76, train corr: 0.03071
Epoch [83/100], Batch [8/147] train loss: 593.24, train corr: 0.03242
Epoch [83/100], Batch [9/147] train loss: 587.08, train corr: 0.03073
Epoch [83/100], Batch [10/147] train loss: 567.95, train corr: 0.03158
Epoch [83/100], Batch [11/147] train loss: 581.01, train corr: 0.03129
Epoch [83/100], Batch [12/147] train loss: 588.41, train corr: 0.03163
Epoch [83/100], Batch [13/147] train loss: 565.36, train corr: 0.03216
Epoch [83/100], Batch [14/147] train loss: 571.30, train corr: 0.03064
Epoch [83/100], Batch [15/147] train loss: 580.97, train corr: 0.03188
Epoch [83/100], Batch [16/147] train loss: 567.62, train corr: 0.02826
Epoch [83/100], Batch [17/147] train loss: 563.15, train corr: 0.03227
Epoch [83/100], Batch [18/147] train loss: 637.25, train corr: 0.02660
Epoch [83/100], Batch [19/147] train loss: 578.46, train corr: 0.03233
Epoch [83/100], Batch [20/147] train loss: 562.98, train corr: 0.03167
Epoch [83/100], Batch [21/147] train loss: 584.69, train corr: 0.02971
Epoch [83/100], Batch [22/147] train loss: 564.27, train corr: 0.02805
Epoch [83/100], Batch [23/147] train loss: 567.94, train corr: 0.02968
Epoch [83/100], Batch [24/147] train loss: 577.95, train corr: 0.02849
Epoch [83/100], Batch [25/147] train loss: 564.25, train corr: 0.03044
Epoch [83/100], Batch [26/147] train loss: 587.50, train corr: 0.03044
Epoch [83/100], Batch [27/147] train loss: 577.37, train corr: 0.03100
Epoch [83/100], Batch [28/147] train loss: 565.05, train corr: 0.03031
Epoch [83/100], Batch [29/147] train loss: 578.38, train corr: 0.03000
Epoch [83/100], Batch [30/147] train loss: 582.26, train corr: 0.03010
Epoch [83/100], Batch [31/147] train loss: 566.25, train corr: 0.03117
Epoch [83/100], Batch [32/147] train loss: 558.41, train corr: 0.03073
Epoch [83/100], Batch [33/147] train loss: 581.65, train corr: 0.03094
Epoch [83/100], Batch [34/147] train loss: 571.38, train corr: 0.03009
Epoch [83/100], Batch [35/147] train loss: 575.86, train corr: 0.03227
Epoch [83/100], Batch [36/147] train loss: 582.82, train corr: 0.03114
Epoch [83/100], Batch [37/147] train loss: 573.23, train corr: 0.02859
Epoch [83/100], Batch [38/147] train loss: 566.51, train corr: 0.03015
Epoch [83/100], Batch [39/147] train loss: 563.02, train corr: 0.03122
Epoch [83/100], Batch [40/147] train loss: 571.54, train corr: 0.03127
Epoch [83/100], Batch [41/147] train loss: 569.81, train corr: 0.03082
Epoch [83/100], Batch [42/147] train loss: 564.53, train corr: 0.03078
Epoch [83/100], Batch [43/147] train loss: 560.29, train corr: 0.03142
Epoch [83/100], Batch [44/147] train loss: 569.19, train corr: 0.03011
Epoch [83/100], Batch [45/147] train loss: 576.01, train corr: 0.03007
Epoch [83/100], Batch [46/147] train loss: 569.43, train corr: 0.02993
Epoch [83/100], Batch [47/147] train loss: 568.97, train corr: 0.03117
Epoch [83/100], Batch [48/147] train loss: 577.10, train corr: 0.02975
Epoch [83/100], Batch [49/147] train loss: 564.12, train corr: 0.03166
Epoch [83/100], Batch [50/147] train loss: 579.41, train corr: 0.03068
Epoch [83/100], Batch [51/147] train loss: 577.06, train corr: 0.03101
Epoch [83/100], Batch [52/147] train loss: 599.37, train corr: 0.03068
Epoch [83/100], Batch [53/147] train loss: 559.01, train corr: 0.03165
Epoch [83/100], Batch [54/147] train loss: 594.19, train corr: 0.03036
Epoch [83/100], Batch [55/147] train loss: 583.65, train corr: 0.02828
Epoch [83/100], Batch [56/147] train loss: 563.89, train corr: 0.03065
Epoch [83/100], Batch [57/147] train loss: 569.54, train corr: 0.03093
Epoch [83/100], Batch [58/147] train loss: 566.62, train corr: 0.03161
Epoch [83/100], Batch [59/147] train loss: 573.40, train corr: 0.02969
Epoch [83/100], Batch [60/147] train loss: 569.82, train corr: 0.03211
Epoch [83/100], Batch [61/147] train loss: 571.60, train corr: 0.03066
Epoch [83/100], Batch [62/147] train loss: 576.54, train corr: 0.02923
Epoch [83/100], Batch [63/147] train loss: 559.94, train corr: 0.03008
Epoch [83/100], Batch [64/147] train loss: 578.72, train corr: 0.02871
Epoch [83/100], Batch [65/147] train loss: 568.35, train corr: 0.03118
Epoch [83/100], Batch [66/147] train loss: 564.51, train corr: 0.02964
Epoch [83/100], Batch [67/147] train loss: 575.86, train corr: 0.03163
Epoch [83/100], Batch [68/147] train loss: 575.83, train corr: 0.03058
Epoch [83/100], Batch [69/147] train loss: 593.61, train corr: 0.03254
Epoch [83/100], Batch [70/147] train loss: 570.10, train corr: 0.03133
Epoch [83/100], Batch [71/147] train loss: 575.44, train corr: 0.02917
Epoch [83/100], Batch [72/147] train loss: 554.87, train corr: 0.02998
Epoch [83/100], Batch [73/147] train loss: 562.36, train corr: 0.03059
Epoch [83/100], Batch [74/147] train loss: 567.39, train corr: 0.03040
Epoch [83/100], Batch [75/147] train loss: 566.89, train corr: 0.03249
Epoch [83/100], Batch [76/147] train loss: 578.86, train corr: 0.03038
Epoch [83/100], Batch [77/147] train loss: 585.50, train corr: 0.02975
Epoch [83/100], Batch [78/147] train loss: 569.27, train corr: 0.03038
Epoch [83/100], Batch [79/147] train loss: 572.03, train corr: 0.02960
Epoch [83/100], Batch [80/147] train loss: 564.87, train corr: 0.02957
Epoch [83/100], Batch [81/147] train loss: 558.64, train corr: 0.03058
Epoch [83/100], Batch [82/147] train loss: 554.03, train corr: 0.03105
Epoch [83/100], Batch [83/147] train loss: 564.99, train corr: 0.03140
Epoch [83/100], Batch [84/147] train loss: 809.83, train corr: 0.02558
Epoch [83/100], Batch [85/147] train loss: 599.25, train corr: 0.02832
Epoch [83/100], Batch [86/147] train loss: 589.26, train corr: 0.03095
Epoch [83/100], Batch [87/147] train loss: 568.97, train corr: 0.03154
Epoch [83/100], Batch [88/147] train loss: 560.07, train corr: 0.03278
Epoch [83/100], Batch [89/147] train loss: 564.58, train corr: 0.03016
Epoch [83/100], Batch [90/147] train loss: 567.98, train corr: 0.03030
Epoch [83/100], Batch [91/147] train loss: 574.12, train corr: 0.03171
Epoch [83/100], Batch [92/147] train loss: 595.73, train corr: 0.02695
Epoch [83/100], Batch [93/147] train loss: 571.05, train corr: 0.03174
Epoch [83/100], Batch [94/147] train loss: 571.67, train corr: 0.03085
Epoch [83/100], Batch [95/147] train loss: 571.08, train corr: 0.02892
Epoch [83/100], Batch [96/147] train loss: 556.05, train corr: 0.03199
Epoch [83/100], Batch [97/147] train loss: 568.06, train corr: 0.03074
Epoch [83/100], Batch [98/147] train loss: 568.92, train corr: 0.03182
Epoch [83/100], Batch [99/147] train loss: 567.49, train corr: 0.02990
Epoch [83/100], Batch [100/147] train loss: 560.56, train corr: 0.03012
Epoch [83/100], Batch [101/147] train loss: 568.98, train corr: 0.03027
Epoch [83/100], Batch [102/147] train loss: 559.28, train corr: 0.03072
Epoch [83/100], Batch [103/147] train loss: 559.83, train corr: 0.03110
Epoch [83/100], Batch [104/147] train loss: 567.89, train corr: 0.03141
Epoch [83/100], Batch [105/147] train loss: 580.01, train corr: 0.03085
Epoch [83/100], Batch [106/147] train loss: 638.61, train corr: 0.02466
Epoch [83/100], Batch [107/147] train loss: 566.03, train corr: 0.03182
Epoch [83/100], Batch [108/147] train loss: 578.52, train corr: 0.02970
Epoch [83/100], Batch [109/147] train loss: 565.98, train corr: 0.03030
Epoch [83/100], Batch [110/147] train loss: 557.25, train corr: 0.03187
Epoch [83/100], Batch [111/147] train loss: 572.16, train corr: 0.03143
Epoch [83/100], Batch [112/147] train loss: 569.28, train corr: 0.03136
Epoch [83/100], Batch [113/147] train loss: 558.63, train corr: 0.03062
Epoch [83/100], Batch [114/147] train loss: 560.94, train corr: 0.03097
Epoch [83/100], Batch [115/147] train loss: 581.38, train corr: 0.03013
Epoch [83/100], Batch [116/147] train loss: 568.74, train corr: 0.03092
Epoch [83/100], Batch [117/147] train loss: 566.09, train corr: 0.02994
Epoch [83/100], Batch [118/147] train loss: 572.65, train corr: 0.03117
Epoch [83/100], Batch [119/147] train loss: 563.04, train corr: 0.02798
Epoch [83/100], Batch [120/147] train loss: 571.20, train corr: 0.03110
Epoch [83/100], Batch [121/147] train loss: 566.27, train corr: 0.02938
Epoch [83/100], Batch [122/147] train loss: 563.30, train corr: 0.03086
Epoch [83/100], Batch [123/147] train loss: 566.62, train corr: 0.03150
Epoch [83/100], Batch [124/147] train loss: 585.16, train corr: 0.03088
Epoch [83/100], Batch [125/147] train loss: 556.60, train corr: 0.03022
Epoch [83/100], Batch [126/147] train loss: 561.21, train corr: 0.03067
Epoch [83/100], Batch [127/147] train loss: 563.26, train corr: 0.03181
Epoch [83/100], Batch [128/147] train loss: 572.14, train corr: 0.03054
Epoch [83/100], Batch [129/147] train loss: 571.20, train corr: 0.03078
Epoch [83/100], Batch [130/147] train loss: 567.87, train corr: 0.02965
Epoch [83/100], Batch [131/147] train loss: 558.95, train corr: 0.03002
Epoch [83/100], Batch [132/147] train loss: 551.22, train corr: 0.03111
Epoch [83/100], Batch [133/147] train loss: 561.46, train corr: 0.03062
Epoch [83/100], Batch [134/147] train loss: 579.22, train corr: 0.02725
Epoch [83/100], Batch [135/147] train loss: 561.74, train corr: 0.03154
Epoch [83/100], Batch [136/147] train loss: 582.83, train corr: 0.03142
Epoch [83/100], Batch [137/147] train loss: 565.66, train corr: 0.03118
Epoch [83/100], Batch [138/147] train loss: 573.50, train corr: 0.03039
Epoch [83/100], Batch [139/147] train loss: 556.85, train corr: 0.02829
Epoch [83/100], Batch [140/147] train loss: 571.52, train corr: 0.03069
Epoch [83/100], Batch [141/147] train loss: 572.32, train corr: 0.02975
Epoch [83/100], Batch [142/147] train loss: 572.33, train corr: 0.02863
Epoch [83/100], Batch [143/147] train loss: 565.86, train corr: 0.02912
Epoch [83/100], Batch [144/147] train loss: 562.48, train corr: 0.03107
Epoch [83/100], Batch [145/147] train loss: 590.19, train corr: 0.02932
Epoch [83/100], Batch [146/147] train loss: 563.14, train corr: 0.02849
Epoch [83/100], Batch [147/147] train loss: 564.85, train corr: 0.02665
Epoch [83/100], validation loss: 598.39, validation correlation: 0.03070
Epoch [84/100], Batch [1/147] train loss: 560.83, train corr: 0.03164
Epoch [84/100], Batch [2/147] train loss: 561.61, train corr: 0.03073
Epoch [84/100], Batch [3/147] train loss: 573.11, train corr: 0.03228
Epoch [84/100], Batch [4/147] train loss: 552.08, train corr: 0.02993
Epoch [84/100], Batch [5/147] train loss: 571.97, train corr: 0.03104
Epoch [84/100], Batch [6/147] train loss: 575.87, train corr: 0.03025
Epoch [84/100], Batch [7/147] train loss: 582.76, train corr: 0.03024
Epoch [84/100], Batch [8/147] train loss: 550.28, train corr: 0.03027
Epoch [84/100], Batch [9/147] train loss: 565.34, train corr: 0.02991
Epoch [84/100], Batch [10/147] train loss: 579.14, train corr: 0.02982
Epoch [84/100], Batch [11/147] train loss: 575.36, train corr: 0.03119
Epoch [84/100], Batch [12/147] train loss: 566.24, train corr: 0.03079
Epoch [84/100], Batch [13/147] train loss: 577.91, train corr: 0.03062
Epoch [84/100], Batch [14/147] train loss: 573.83, train corr: 0.03015
Epoch [84/100], Batch [15/147] train loss: 584.21, train corr: 0.02903
Epoch [84/100], Batch [16/147] train loss: 566.76, train corr: 0.03003
Epoch [84/100], Batch [17/147] train loss: 579.54, train corr: 0.02910
Epoch [84/100], Batch [18/147] train loss: 558.21, train corr: 0.03097
Epoch [84/100], Batch [19/147] train loss: 565.19, train corr: 0.02996
Epoch [84/100], Batch [20/147] train loss: 569.35, train corr: 0.03016
Epoch [84/100], Batch [21/147] train loss: 570.96, train corr: 0.03100
Epoch [84/100], Batch [22/147] train loss: 550.79, train corr: 0.02924
Epoch [84/100], Batch [23/147] train loss: 572.71, train corr: 0.02896
Epoch [84/100], Batch [24/147] train loss: 572.18, train corr: 0.03297
Epoch [84/100], Batch [25/147] train loss: 581.31, train corr: 0.03044
Epoch [84/100], Batch [26/147] train loss: 570.36, train corr: 0.03105
Epoch [84/100], Batch [27/147] train loss: 561.18, train corr: 0.02879
Epoch [84/100], Batch [28/147] train loss: 569.41, train corr: 0.03076
Epoch [84/100], Batch [29/147] train loss: 550.75, train corr: 0.03156
Epoch [84/100], Batch [30/147] train loss: 564.27, train corr: 0.03035
Epoch [84/100], Batch [31/147] train loss: 570.12, train corr: 0.02907
Epoch [84/100], Batch [32/147] train loss: 573.00, train corr: 0.02956
Epoch [84/100], Batch [33/147] train loss: 564.16, train corr: 0.02982
Epoch [84/100], Batch [34/147] train loss: 574.52, train corr: 0.03201
Epoch [84/100], Batch [35/147] train loss: 576.05, train corr: 0.03106
Epoch [84/100], Batch [36/147] train loss: 551.64, train corr: 0.03041
Epoch [84/100], Batch [37/147] train loss: 579.87, train corr: 0.03018
Epoch [84/100], Batch [38/147] train loss: 581.38, train corr: 0.03158
Epoch [84/100], Batch [39/147] train loss: 563.08, train corr: 0.03067
Epoch [84/100], Batch [40/147] train loss: 566.27, train corr: 0.02954
Epoch [84/100], Batch [41/147] train loss: 571.70, train corr: 0.02970
Epoch [84/100], Batch [42/147] train loss: 570.13, train corr: 0.02887
Epoch [84/100], Batch [43/147] train loss: 560.98, train corr: 0.03162
Epoch [84/100], Batch [44/147] train loss: 562.80, train corr: 0.03075
Epoch [84/100], Batch [45/147] train loss: 563.46, train corr: 0.02985
Epoch [84/100], Batch [46/147] train loss: 555.47, train corr: 0.03095
Epoch [84/100], Batch [47/147] train loss: 561.26, train corr: 0.02785
Epoch [84/100], Batch [48/147] train loss: 577.41, train corr: 0.03210
Epoch [84/100], Batch [49/147] train loss: 550.40, train corr: 0.03052
Epoch [84/100], Batch [50/147] train loss: 563.69, train corr: 0.03128
Epoch [84/100], Batch [51/147] train loss: 561.85, train corr: 0.03043
Epoch [84/100], Batch [52/147] train loss: 548.50, train corr: 0.02941
Epoch [84/100], Batch [53/147] train loss: 553.68, train corr: 0.03121
Epoch [84/100], Batch [54/147] train loss: 593.82, train corr: 0.02880
Epoch [84/100], Batch [55/147] train loss: 561.59, train corr: 0.03016
Epoch [84/100], Batch [56/147] train loss: 562.57, train corr: 0.03077
Epoch [84/100], Batch [57/147] train loss: 568.84, train corr: 0.03044
Epoch [84/100], Batch [58/147] train loss: 575.80, train corr: 0.02966
Epoch [84/100], Batch [59/147] train loss: 558.35, train corr: 0.03093
Epoch [84/100], Batch [60/147] train loss: 558.83, train corr: 0.03080
Epoch [84/100], Batch [61/147] train loss: 565.11, train corr: 0.03039
Epoch [84/100], Batch [62/147] train loss: 577.11, train corr: 0.03032
Epoch [84/100], Batch [63/147] train loss: 578.54, train corr: 0.03168
Epoch [84/100], Batch [64/147] train loss: 572.02, train corr: 0.03003
Epoch [84/100], Batch [65/147] train loss: 567.70, train corr: 0.03132
Epoch [84/100], Batch [66/147] train loss: 572.04, train corr: 0.03209
Epoch [84/100], Batch [67/147] train loss: 556.58, train corr: 0.02971
Epoch [84/100], Batch [68/147] train loss: 576.19, train corr: 0.03070
Epoch [84/100], Batch [69/147] train loss: 576.95, train corr: 0.03013
Epoch [84/100], Batch [70/147] train loss: 573.21, train corr: 0.02760
Epoch [84/100], Batch [71/147] train loss: 565.96, train corr: 0.02977
Epoch [84/100], Batch [72/147] train loss: 567.32, train corr: 0.02895
Epoch [84/100], Batch [73/147] train loss: 541.29, train corr: 0.03100
Epoch [84/100], Batch [74/147] train loss: 565.62, train corr: 0.02936
Epoch [84/100], Batch [75/147] train loss: 555.59, train corr: 0.03025
Epoch [84/100], Batch [76/147] train loss: 565.94, train corr: 0.03150
Epoch [84/100], Batch [77/147] train loss: 569.31, train corr: 0.02804
Epoch [84/100], Batch [78/147] train loss: 568.27, train corr: 0.03045
Epoch [84/100], Batch [79/147] train loss: 569.25, train corr: 0.02979
Epoch [84/100], Batch [80/147] train loss: 578.52, train corr: 0.03020
Epoch [84/100], Batch [81/147] train loss: 565.30, train corr: 0.02993
Epoch [84/100], Batch [82/147] train loss: 558.00, train corr: 0.02932
Epoch [84/100], Batch [83/147] train loss: 574.16, train corr: 0.02979
Epoch [84/100], Batch [84/147] train loss: 569.27, train corr: 0.03192
Epoch [84/100], Batch [85/147] train loss: 567.36, train corr: 0.03070
Epoch [84/100], Batch [86/147] train loss: 573.06, train corr: 0.03070
Epoch [84/100], Batch [87/147] train loss: 557.88, train corr: 0.03058
Epoch [84/100], Batch [88/147] train loss: 568.42, train corr: 0.03002
Epoch [84/100], Batch [89/147] train loss: 570.20, train corr: 0.03183
Epoch [84/100], Batch [90/147] train loss: 568.31, train corr: 0.03064
Epoch [84/100], Batch [91/147] train loss: 815.80, train corr: 0.02446
Epoch [84/100], Batch [92/147] train loss: 569.89, train corr: 0.03176
Epoch [84/100], Batch [93/147] train loss: 622.24, train corr: 0.02879
Epoch [84/100], Batch [94/147] train loss: 565.94, train corr: 0.02994
Epoch [84/100], Batch [95/147] train loss: 555.83, train corr: 0.03169
Epoch [84/100], Batch [96/147] train loss: 581.03, train corr: 0.02921
Epoch [84/100], Batch [97/147] train loss: 573.20, train corr: 0.03162
Epoch [84/100], Batch [98/147] train loss: 586.64, train corr: 0.02634
Epoch [84/100], Batch [99/147] train loss: 570.84, train corr: 0.03170
Epoch [84/100], Batch [100/147] train loss: 591.04, train corr: 0.02805
Epoch [84/100], Batch [101/147] train loss: 564.22, train corr: 0.03059
Epoch [84/100], Batch [102/147] train loss: 582.68, train corr: 0.03121
Epoch [84/100], Batch [103/147] train loss: 590.32, train corr: 0.02759
Epoch [84/100], Batch [104/147] train loss: 575.77, train corr: 0.02838
Epoch [84/100], Batch [105/147] train loss: 612.61, train corr: 0.02387
Epoch [84/100], Batch [106/147] train loss: 566.85, train corr: 0.02977
Epoch [84/100], Batch [107/147] train loss: 579.77, train corr: 0.03055
Epoch [84/100], Batch [108/147] train loss: 577.49, train corr: 0.02810
Epoch [84/100], Batch [109/147] train loss: 581.81, train corr: 0.03207
Epoch [84/100], Batch [110/147] train loss: 564.55, train corr: 0.03142
Epoch [84/100], Batch [111/147] train loss: 568.95, train corr: 0.03171
Epoch [84/100], Batch [112/147] train loss: 578.48, train corr: 0.03206
Epoch [84/100], Batch [113/147] train loss: 559.95, train corr: 0.03030
Epoch [84/100], Batch [114/147] train loss: 564.53, train corr: 0.02944
Epoch [84/100], Batch [115/147] train loss: 565.67, train corr: 0.02975
Epoch [84/100], Batch [116/147] train loss: 561.12, train corr: 0.03044
Epoch [84/100], Batch [117/147] train loss: 571.18, train corr: 0.02840
Epoch [84/100], Batch [118/147] train loss: 562.68, train corr: 0.03172
Epoch [84/100], Batch [119/147] train loss: 575.03, train corr: 0.03004
Epoch [84/100], Batch [120/147] train loss: 571.84, train corr: 0.02900
Epoch [84/100], Batch [121/147] train loss: 558.65, train corr: 0.03035
Epoch [84/100], Batch [122/147] train loss: 569.45, train corr: 0.03044
Epoch [84/100], Batch [123/147] train loss: 571.20, train corr: 0.02981
Epoch [84/100], Batch [124/147] train loss: 576.49, train corr: 0.03077
Epoch [84/100], Batch [125/147] train loss: 569.11, train corr: 0.03100
Epoch [84/100], Batch [126/147] train loss: 570.94, train corr: 0.03077
Epoch [84/100], Batch [127/147] train loss: 560.56, train corr: 0.03029
Epoch [84/100], Batch [128/147] train loss: 562.71, train corr: 0.02958
Epoch [84/100], Batch [129/147] train loss: 562.15, train corr: 0.03017
Epoch [84/100], Batch [130/147] train loss: 580.01, train corr: 0.02929
Epoch [84/100], Batch [131/147] train loss: 585.46, train corr: 0.02900
Epoch [84/100], Batch [132/147] train loss: 577.39, train corr: 0.03110
Epoch [84/100], Batch [133/147] train loss: 590.16, train corr: 0.03065
Epoch [84/100], Batch [134/147] train loss: 587.41, train corr: 0.02872
Epoch [84/100], Batch [135/147] train loss: 575.89, train corr: 0.03165
Epoch [84/100], Batch [136/147] train loss: 579.69, train corr: 0.03129
Epoch [84/100], Batch [137/147] train loss: 568.77, train corr: 0.02947
Epoch [84/100], Batch [138/147] train loss: 569.53, train corr: 0.03072
Epoch [84/100], Batch [139/147] train loss: 560.97, train corr: 0.03103
Epoch [84/100], Batch [140/147] train loss: 549.49, train corr: 0.02969
Epoch [84/100], Batch [141/147] train loss: 567.76, train corr: 0.03074
Epoch [84/100], Batch [142/147] train loss: 575.55, train corr: 0.03094
Epoch [84/100], Batch [143/147] train loss: 547.35, train corr: 0.03006
Epoch [84/100], Batch [144/147] train loss: 578.30, train corr: 0.02819
Epoch [84/100], Batch [145/147] train loss: 569.57, train corr: 0.03103
Epoch [84/100], Batch [146/147] train loss: 827.54, train corr: 0.02431
Epoch [84/100], Batch [147/147] train loss: 588.35, train corr: 0.02749
Epoch [84/100], validation loss: 605.42, validation correlation: 0.02990
Epoch [85/100], Batch [1/147] train loss: 566.08, train corr: 0.02887
Epoch [85/100], Batch [2/147] train loss: 603.45, train corr: 0.03012
Epoch [85/100], Batch [3/147] train loss: 583.75, train corr: 0.02992
Epoch [85/100], Batch [4/147] train loss: 581.61, train corr: 0.02934
Epoch [85/100], Batch [5/147] train loss: 564.19, train corr: 0.03019
Epoch [85/100], Batch [6/147] train loss: 638.66, train corr: 0.02859
Epoch [85/100], Batch [7/147] train loss: 574.16, train corr: 0.03070
Epoch [85/100], Batch [8/147] train loss: 588.73, train corr: 0.02805
Epoch [85/100], Batch [9/147] train loss: 625.96, train corr: 0.03074
Epoch [85/100], Batch [10/147] train loss: 573.60, train corr: 0.03013
Epoch [85/100], Batch [11/147] train loss: 566.50, train corr: 0.03136
Epoch [85/100], Batch [12/147] train loss: 597.83, train corr: 0.02427
Epoch [85/100], Batch [13/147] train loss: 574.57, train corr: 0.02152
Epoch [85/100], Batch [14/147] train loss: 585.12, train corr: 0.02582
Epoch [85/100], Batch [15/147] train loss: 590.90, train corr: 0.02710
Epoch [85/100], Batch [16/147] train loss: 607.78, train corr: 0.02354
Epoch [85/100], Batch [17/147] train loss: 569.87, train corr: 0.02832
Epoch [85/100], Batch [18/147] train loss: 572.36, train corr: 0.02775
Epoch [85/100], Batch [19/147] train loss: 563.34, train corr: 0.02943
Epoch [85/100], Batch [20/147] train loss: 570.73, train corr: 0.03030
Epoch [85/100], Batch [21/147] train loss: 597.22, train corr: 0.03019
Epoch [85/100], Batch [22/147] train loss: 583.41, train corr: 0.02893
Epoch [85/100], Batch [23/147] train loss: 560.31, train corr: 0.02858
Epoch [85/100], Batch [24/147] train loss: 570.60, train corr: 0.02682
Epoch [85/100], Batch [25/147] train loss: 566.77, train corr: 0.02869
Epoch [85/100], Batch [26/147] train loss: 571.44, train corr: 0.02672
Epoch [85/100], Batch [27/147] train loss: 570.39, train corr: 0.02784
Epoch [85/100], Batch [28/147] train loss: 591.57, train corr: 0.02881
Epoch [85/100], Batch [29/147] train loss: 569.86, train corr: 0.02778
Epoch [85/100], Batch [30/147] train loss: 569.91, train corr: 0.02771
Epoch [85/100], Batch [31/147] train loss: 627.85, train corr: 0.02389
Epoch [85/100], Batch [32/147] train loss: 553.84, train corr: 0.02820
Epoch [85/100], Batch [33/147] train loss: 576.00, train corr: 0.02959
Epoch [85/100], Batch [34/147] train loss: 581.73, train corr: 0.02967
Epoch [85/100], Batch [35/147] train loss: 576.62, train corr: 0.02979
Epoch [85/100], Batch [36/147] train loss: 740.06, train corr: 0.02780
Epoch [85/100], Batch [37/147] train loss: 590.25, train corr: 0.03071
Epoch [85/100], Batch [38/147] train loss: 570.03, train corr: 0.02901
Epoch [85/100], Batch [39/147] train loss: 587.67, train corr: 0.03016
Epoch [85/100], Batch [40/147] train loss: 592.00, train corr: 0.02928
Epoch [85/100], Batch [41/147] train loss: 579.44, train corr: 0.02921
Epoch [85/100], Batch [42/147] train loss: 569.42, train corr: 0.02911
Epoch [85/100], Batch [43/147] train loss: 621.06, train corr: 0.02842
Epoch [85/100], Batch [44/147] train loss: 557.95, train corr: 0.02794
Epoch [85/100], Batch [45/147] train loss: 586.27, train corr: 0.02692
Epoch [85/100], Batch [46/147] train loss: 585.15, train corr: 0.02832
Epoch [85/100], Batch [47/147] train loss: 582.61, train corr: 0.02717
Epoch [85/100], Batch [48/147] train loss: 567.71, train corr: 0.02950
Epoch [85/100], Batch [49/147] train loss: 584.27, train corr: 0.02935
Epoch [85/100], Batch [50/147] train loss: 562.00, train corr: 0.02700
Epoch [85/100], Batch [51/147] train loss: 571.39, train corr: 0.02828
Epoch [85/100], Batch [52/147] train loss: 576.70, train corr: 0.02714
Epoch [85/100], Batch [53/147] train loss: 591.41, train corr: 0.02965
Epoch [85/100], Batch [54/147] train loss: 569.10, train corr: 0.02995
Epoch [85/100], Batch [55/147] train loss: 579.40, train corr: 0.02927
Epoch [85/100], Batch [56/147] train loss: 582.33, train corr: 0.03020
Epoch [85/100], Batch [57/147] train loss: 558.59, train corr: 0.02798
Epoch [85/100], Batch [58/147] train loss: 582.88, train corr: 0.02858
Epoch [85/100], Batch [59/147] train loss: 583.53, train corr: 0.02869
Epoch [85/100], Batch [60/147] train loss: 600.51, train corr: 0.02870
Epoch [85/100], Batch [61/147] train loss: 569.72, train corr: 0.02522
Epoch [85/100], Batch [62/147] train loss: 543.73, train corr: 0.02728
Epoch [85/100], Batch [63/147] train loss: 566.96, train corr: 0.02740
Epoch [85/100], Batch [64/147] train loss: 568.48, train corr: 0.02766
Epoch [85/100], Batch [65/147] train loss: 566.81, train corr: 0.02689
Epoch [85/100], Batch [66/147] train loss: 590.57, train corr: 0.02958
Epoch [85/100], Batch [67/147] train loss: 573.26, train corr: 0.02907
Epoch [85/100], Batch [68/147] train loss: 902.02, train corr: 0.02070
Epoch [85/100], Batch [69/147] train loss: 595.61, train corr: 0.02359
Epoch [85/100], Batch [70/147] train loss: 591.08, train corr: 0.02825
Epoch [85/100], Batch [71/147] train loss: 573.62, train corr: 0.02708
Epoch [85/100], Batch [72/147] train loss: 582.86, train corr: 0.02808
Epoch [85/100], Batch [73/147] train loss: 578.25, train corr: 0.02874
Epoch [85/100], Batch [74/147] train loss: 567.66, train corr: 0.02772
Epoch [85/100], Batch [75/147] train loss: 580.62, train corr: 0.02868
Epoch [85/100], Batch [76/147] train loss: 593.42, train corr: 0.02716
Epoch [85/100], Batch [77/147] train loss: 569.27, train corr: 0.02897
Epoch [85/100], Batch [78/147] train loss: 584.18, train corr: 0.02923
Epoch [85/100], Batch [79/147] train loss: 569.89, train corr: 0.02614
Epoch [85/100], Batch [80/147] train loss: 573.09, train corr: 0.02786
Epoch [85/100], Batch [81/147] train loss: 563.57, train corr: 0.02762
Epoch [85/100], Batch [82/147] train loss: 578.43, train corr: 0.02806
Epoch [85/100], Batch [83/147] train loss: 566.99, train corr: 0.02514
Epoch [85/100], Batch [84/147] train loss: 559.15, train corr: 0.02643
Epoch [85/100], Batch [85/147] train loss: 567.03, train corr: 0.02886
Epoch [85/100], Batch [86/147] train loss: 560.23, train corr: 0.02566
Epoch [85/100], Batch [87/147] train loss: 587.72, train corr: 0.02697
Epoch [85/100], Batch [88/147] train loss: 562.14, train corr: 0.02477
Epoch [85/100], Batch [89/147] train loss: 559.91, train corr: 0.02836
Epoch [85/100], Batch [90/147] train loss: 570.01, train corr: 0.02602
Epoch [85/100], Batch [91/147] train loss: 572.77, train corr: 0.02703
Epoch [85/100], Batch [92/147] train loss: 556.80, train corr: 0.02709
Epoch [85/100], Batch [93/147] train loss: 559.88, train corr: 0.02705
Epoch [85/100], Batch [94/147] train loss: 579.09, train corr: 0.02585
Epoch [85/100], Batch [95/147] train loss: 551.42, train corr: 0.02338
Epoch [85/100], Batch [96/147] train loss: 559.48, train corr: 0.02832
Epoch [85/100], Batch [97/147] train loss: 569.09, train corr: 0.02708
Epoch [85/100], Batch [98/147] train loss: 586.52, train corr: 0.02600
Epoch [85/100], Batch [99/147] train loss: 570.90, train corr: 0.02721
Epoch [85/100], Batch [100/147] train loss: 553.32, train corr: 0.02847
Epoch [85/100], Batch [101/147] train loss: 560.07, train corr: 0.02722
Epoch [85/100], Batch [102/147] train loss: 575.99, train corr: 0.02879
Epoch [85/100], Batch [103/147] train loss: 572.00, train corr: 0.02890
Epoch [85/100], Batch [104/147] train loss: 584.01, train corr: 0.03024
Epoch [85/100], Batch [105/147] train loss: 562.77, train corr: 0.02729
Epoch [85/100], Batch [106/147] train loss: 570.18, train corr: 0.02723
Epoch [85/100], Batch [107/147] train loss: 571.49, train corr: 0.02873
Epoch [85/100], Batch [108/147] train loss: 555.25, train corr: 0.02974
Epoch [85/100], Batch [109/147] train loss: 568.52, train corr: 0.02860
Epoch [85/100], Batch [110/147] train loss: 560.92, train corr: 0.02834
Epoch [85/100], Batch [111/147] train loss: 575.27, train corr: 0.02754
Epoch [85/100], Batch [112/147] train loss: 580.80, train corr: 0.02671
Epoch [85/100], Batch [113/147] train loss: 564.73, train corr: 0.02856
Epoch [85/100], Batch [114/147] train loss: 575.86, train corr: 0.02423
Epoch [85/100], Batch [115/147] train loss: 570.12, train corr: 0.02712
Epoch [85/100], Batch [116/147] train loss: 573.98, train corr: 0.02666
Epoch [85/100], Batch [117/147] train loss: 571.09, train corr: 0.02759
Epoch [85/100], Batch [118/147] train loss: 568.71, train corr: 0.02783
Epoch [85/100], Batch [119/147] train loss: 567.56, train corr: 0.02863
Epoch [85/100], Batch [120/147] train loss: 566.77, train corr: 0.02867
Epoch [85/100], Batch [121/147] train loss: 565.56, train corr: 0.02685
Epoch [85/100], Batch [122/147] train loss: 572.62, train corr: 0.02777
Epoch [85/100], Batch [123/147] train loss: 575.92, train corr: 0.02832
Epoch [85/100], Batch [124/147] train loss: 567.17, train corr: 0.02920
Epoch [85/100], Batch [125/147] train loss: 573.21, train corr: 0.02949
Epoch [85/100], Batch [126/147] train loss: 564.31, train corr: 0.02714
Epoch [85/100], Batch [127/147] train loss: 563.40, train corr: 0.02655
Epoch [85/100], Batch [128/147] train loss: 565.43, train corr: 0.02850
Epoch [85/100], Batch [129/147] train loss: 550.68, train corr: 0.02763
Epoch [85/100], Batch [130/147] train loss: 564.89, train corr: 0.02972
Epoch [85/100], Batch [131/147] train loss: 565.56, train corr: 0.02747
Epoch [85/100], Batch [132/147] train loss: 566.99, train corr: 0.02897
Epoch [85/100], Batch [133/147] train loss: 559.19, train corr: 0.02752
Epoch [85/100], Batch [134/147] train loss: 572.57, train corr: 0.02743
Epoch [85/100], Batch [135/147] train loss: 561.88, train corr: 0.02811
Epoch [85/100], Batch [136/147] train loss: 565.11, train corr: 0.02773
Epoch [85/100], Batch [137/147] train loss: 569.01, train corr: 0.02788
Epoch [85/100], Batch [138/147] train loss: 565.51, train corr: 0.02872
Epoch [85/100], Batch [139/147] train loss: 564.41, train corr: 0.02872
Epoch [85/100], Batch [140/147] train loss: 569.69, train corr: 0.02626
Epoch [85/100], Batch [141/147] train loss: 577.02, train corr: 0.02713
Epoch [85/100], Batch [142/147] train loss: 569.62, train corr: 0.02790
Epoch [85/100], Batch [143/147] train loss: 568.11, train corr: 0.02769
Epoch [85/100], Batch [144/147] train loss: 555.88, train corr: 0.02686
Epoch [85/100], Batch [145/147] train loss: 558.42, train corr: 0.02814
Epoch [85/100], Batch [146/147] train loss: 580.62, train corr: 0.02801
Epoch [85/100], Batch [147/147] train loss: 572.35, train corr: 0.02961
Epoch [85/100], validation loss: 598.34, validation correlation: 0.02744
Epoch [86/100], Batch [1/147] train loss: 560.96, train corr: 0.02829
Epoch [86/100], Batch [2/147] train loss: 558.31, train corr: 0.02691
Epoch [86/100], Batch [3/147] train loss: 565.33, train corr: 0.02829
Epoch [86/100], Batch [4/147] train loss: 580.58, train corr: 0.02849
Epoch [86/100], Batch [5/147] train loss: 582.79, train corr: 0.02985
Epoch [86/100], Batch [6/147] train loss: 574.20, train corr: 0.02741
Epoch [86/100], Batch [7/147] train loss: 567.73, train corr: 0.02916
Epoch [86/100], Batch [8/147] train loss: 578.89, train corr: 0.02988
Epoch [86/100], Batch [9/147] train loss: 572.91, train corr: 0.02895
Epoch [86/100], Batch [10/147] train loss: 574.02, train corr: 0.02651
Epoch [86/100], Batch [11/147] train loss: 580.65, train corr: 0.02930
Epoch [86/100], Batch [12/147] train loss: 588.82, train corr: 0.02837
Epoch [86/100], Batch [13/147] train loss: 564.40, train corr: 0.02630
Epoch [86/100], Batch [14/147] train loss: 577.56, train corr: 0.02934
Epoch [86/100], Batch [15/147] train loss: 590.19, train corr: 0.02794
Epoch [86/100], Batch [16/147] train loss: 583.28, train corr: 0.02597
Epoch [86/100], Batch [17/147] train loss: 565.25, train corr: 0.02794
Epoch [86/100], Batch [18/147] train loss: 556.04, train corr: 0.02788
Epoch [86/100], Batch [19/147] train loss: 554.82, train corr: 0.02778
Epoch [86/100], Batch [20/147] train loss: 566.71, train corr: 0.02727
Epoch [86/100], Batch [21/147] train loss: 570.20, train corr: 0.02501
Epoch [86/100], Batch [22/147] train loss: 564.35, train corr: 0.02923
Epoch [86/100], Batch [23/147] train loss: 563.44, train corr: 0.02635
Epoch [86/100], Batch [24/147] train loss: 567.38, train corr: 0.02757
Epoch [86/100], Batch [25/147] train loss: 564.83, train corr: 0.02708
Epoch [86/100], Batch [26/147] train loss: 588.66, train corr: 0.02868
Epoch [86/100], Batch [27/147] train loss: 567.75, train corr: 0.02782
Epoch [86/100], Batch [28/147] train loss: 567.99, train corr: 0.02942
Epoch [86/100], Batch [29/147] train loss: 578.31, train corr: 0.02840
Epoch [86/100], Batch [30/147] train loss: 582.52, train corr: 0.02884
Epoch [86/100], Batch [31/147] train loss: 575.11, train corr: 0.02760
Epoch [86/100], Batch [32/147] train loss: 569.88, train corr: 0.02637
Epoch [86/100], Batch [33/147] train loss: 582.27, train corr: 0.02874
Epoch [86/100], Batch [34/147] train loss: 565.89, train corr: 0.02715
Epoch [86/100], Batch [35/147] train loss: 608.68, train corr: 0.02717
Epoch [86/100], Batch [36/147] train loss: 573.00, train corr: 0.02660
Epoch [86/100], Batch [37/147] train loss: 565.47, train corr: 0.02740
Epoch [86/100], Batch [38/147] train loss: 569.34, train corr: 0.02569
Epoch [86/100], Batch [39/147] train loss: 577.38, train corr: 0.02866
Epoch [86/100], Batch [40/147] train loss: 562.44, train corr: 0.02591
Epoch [86/100], Batch [41/147] train loss: 569.98, train corr: 0.02736
Epoch [86/100], Batch [42/147] train loss: 548.43, train corr: 0.02878
Epoch [86/100], Batch [43/147] train loss: 582.68, train corr: 0.02786
Epoch [86/100], Batch [44/147] train loss: 629.80, train corr: 0.02163
Epoch [86/100], Batch [45/147] train loss: 563.99, train corr: 0.02699
Epoch [86/100], Batch [46/147] train loss: 567.50, train corr: 0.02782
Epoch [86/100], Batch [47/147] train loss: 563.55, train corr: 0.02691
Epoch [86/100], Batch [48/147] train loss: 553.75, train corr: 0.02549
Epoch [86/100], Batch [49/147] train loss: 578.75, train corr: 0.02681
Epoch [86/100], Batch [50/147] train loss: 582.33, train corr: 0.02642
Epoch [86/100], Batch [51/147] train loss: 561.81, train corr: 0.02642
Epoch [86/100], Batch [52/147] train loss: 580.30, train corr: 0.02646
Epoch [86/100], Batch [53/147] train loss: 557.36, train corr: 0.02627
Epoch [86/100], Batch [54/147] train loss: 578.29, train corr: 0.02786
Epoch [86/100], Batch [55/147] train loss: 560.12, train corr: 0.02717
Epoch [86/100], Batch [56/147] train loss: 572.14, train corr: 0.02771
Epoch [86/100], Batch [57/147] train loss: 571.92, train corr: 0.02801
Epoch [86/100], Batch [58/147] train loss: 575.69, train corr: 0.02760
Epoch [86/100], Batch [59/147] train loss: 562.19, train corr: 0.02759
Epoch [86/100], Batch [60/147] train loss: 559.04, train corr: 0.02654
Epoch [86/100], Batch [61/147] train loss: 570.23, train corr: 0.02818
Epoch [86/100], Batch [62/147] train loss: 582.58, train corr: 0.02477
Epoch [86/100], Batch [63/147] train loss: 566.04, train corr: 0.02685
Epoch [86/100], Batch [64/147] train loss: 562.85, train corr: 0.02761
Epoch [86/100], Batch [65/147] train loss: 578.53, train corr: 0.02640
Epoch [86/100], Batch [66/147] train loss: 575.19, train corr: 0.02420
Epoch [86/100], Batch [67/147] train loss: 567.65, train corr: 0.02777
Epoch [86/100], Batch [68/147] train loss: 559.55, train corr: 0.02638
Epoch [86/100], Batch [69/147] train loss: 589.17, train corr: 0.02898
Epoch [86/100], Batch [70/147] train loss: 572.19, train corr: 0.02843
Epoch [86/100], Batch [71/147] train loss: 553.71, train corr: 0.02480
Epoch [86/100], Batch [72/147] train loss: 571.11, train corr: 0.02746
Epoch [86/100], Batch [73/147] train loss: 567.77, train corr: 0.02864
Epoch [86/100], Batch [74/147] train loss: 571.69, train corr: 0.02640
Epoch [86/100], Batch [75/147] train loss: 562.06, train corr: 0.02708
Epoch [86/100], Batch [76/147] train loss: 574.06, train corr: 0.02487
Epoch [86/100], Batch [77/147] train loss: 582.54, train corr: 0.02973
Epoch [86/100], Batch [78/147] train loss: 561.02, train corr: 0.02791
Epoch [86/100], Batch [79/147] train loss: 567.25, train corr: 0.02792
Epoch [86/100], Batch [80/147] train loss: 579.65, train corr: 0.02765
Epoch [86/100], Batch [81/147] train loss: 560.92, train corr: 0.02686
Epoch [86/100], Batch [82/147] train loss: 567.55, train corr: 0.02605
Epoch [86/100], Batch [83/147] train loss: 560.99, train corr: 0.02866
Epoch [86/100], Batch [84/147] train loss: 548.82, train corr: 0.02637
Epoch [86/100], Batch [85/147] train loss: 555.33, train corr: 0.02602
Epoch [86/100], Batch [86/147] train loss: 560.43, train corr: 0.02691
Epoch [86/100], Batch [87/147] train loss: 557.37, train corr: 0.02596
Epoch [86/100], Batch [88/147] train loss: 576.92, train corr: 0.02887
Epoch [86/100], Batch [89/147] train loss: 574.36, train corr: 0.02612
Epoch [86/100], Batch [90/147] train loss: 558.98, train corr: 0.02630
Epoch [86/100], Batch [91/147] train loss: 613.69, train corr: 0.02604
Epoch [86/100], Batch [92/147] train loss: 562.73, train corr: 0.02639
Epoch [86/100], Batch [93/147] train loss: 552.03, train corr: 0.02764
Epoch [86/100], Batch [94/147] train loss: 562.47, train corr: 0.02861
Epoch [86/100], Batch [95/147] train loss: 568.91, train corr: 0.02883
Epoch [86/100], Batch [96/147] train loss: 567.28, train corr: 0.02551
Epoch [86/100], Batch [97/147] train loss: 565.75, train corr: 0.02790
Epoch [86/100], Batch [98/147] train loss: 581.30, train corr: 0.02826
Epoch [86/100], Batch [99/147] train loss: 578.25, train corr: 0.02738
Epoch [86/100], Batch [100/147] train loss: 562.58, train corr: 0.02728
Epoch [86/100], Batch [101/147] train loss: 569.75, train corr: 0.02629
Epoch [86/100], Batch [102/147] train loss: 539.81, train corr: 0.02621
Epoch [86/100], Batch [103/147] train loss: 556.80, train corr: 0.02690
Epoch [86/100], Batch [104/147] train loss: 571.49, train corr: 0.02759
Epoch [86/100], Batch [105/147] train loss: 565.25, train corr: 0.02678
Epoch [86/100], Batch [106/147] train loss: 557.41, train corr: 0.02907
Epoch [86/100], Batch [107/147] train loss: 549.50, train corr: 0.02721
Epoch [86/100], Batch [108/147] train loss: 561.51, train corr: 0.02780
Epoch [86/100], Batch [109/147] train loss: 569.12, train corr: 0.02591
Epoch [86/100], Batch [110/147] train loss: 739.70, train corr: 0.02602
Epoch [86/100], Batch [111/147] train loss: 603.61, train corr: 0.02667
Epoch [86/100], Batch [112/147] train loss: 566.50, train corr: 0.02730
Epoch [86/100], Batch [113/147] train loss: 593.35, train corr: 0.02580
Epoch [86/100], Batch [114/147] train loss: 597.37, train corr: 0.02391
Epoch [86/100], Batch [115/147] train loss: 659.48, train corr: 0.02094
Epoch [86/100], Batch [116/147] train loss: 567.00, train corr: 0.02600
Epoch [86/100], Batch [117/147] train loss: 607.86, train corr: 0.02597
Epoch [86/100], Batch [118/147] train loss: 584.34, train corr: 0.02746
Epoch [86/100], Batch [119/147] train loss: 630.25, train corr: 0.02561
Epoch [86/100], Batch [120/147] train loss: 627.12, train corr: 0.02580
Epoch [86/100], Batch [121/147] train loss: 604.83, train corr: 0.02559
Epoch [86/100], Batch [122/147] train loss: 589.92, train corr: 0.02759
Epoch [86/100], Batch [123/147] train loss: 571.60, train corr: 0.02761
Epoch [86/100], Batch [124/147] train loss: 918.60, train corr: 0.02098
Epoch [86/100], Batch [125/147] train loss: 618.64, train corr: 0.02683
Epoch [86/100], Batch [126/147] train loss: 732.39, train corr: 0.02618
Epoch [86/100], Batch [127/147] train loss: 780.76, train corr: 0.02814
Epoch [86/100], Batch [128/147] train loss: 835.94, train corr: 0.02699
Epoch [86/100], Batch [129/147] train loss: 795.40, train corr: 0.02775
Epoch [86/100], Batch [130/147] train loss: 757.62, train corr: 0.02539
Epoch [86/100], Batch [131/147] train loss: 719.50, train corr: 0.02152
Epoch [86/100], Batch [132/147] train loss: 658.00, train corr: 0.01982
Epoch [86/100], Batch [133/147] train loss: 640.21, train corr: 0.01608
Epoch [86/100], Batch [134/147] train loss: 624.22, train corr: 0.01886
Epoch [86/100], Batch [135/147] train loss: 704.77, train corr: 0.01793
Epoch [86/100], Batch [136/147] train loss: 607.99, train corr: 0.01926
Epoch [86/100], Batch [137/147] train loss: 616.28, train corr: 0.01668
Epoch [86/100], Batch [138/147] train loss: 606.94, train corr: 0.01668
Epoch [86/100], Batch [139/147] train loss: 635.78, train corr: 0.01510
Epoch [86/100], Batch [140/147] train loss: 649.78, train corr: 0.01292
Epoch [86/100], Batch [141/147] train loss: 626.03, train corr: 0.01757
Epoch [86/100], Batch [142/147] train loss: 621.34, train corr: 0.01671
Epoch [86/100], Batch [143/147] train loss: 594.73, train corr: 0.01688
Epoch [86/100], Batch [144/147] train loss: 573.89, train corr: 0.01906
Epoch [86/100], Batch [145/147] train loss: 614.92, train corr: 0.01841
Epoch [86/100], Batch [146/147] train loss: 601.57, train corr: 0.01927
Epoch [86/100], Batch [147/147] train loss: 581.51, train corr: 0.01654
Epoch [86/100], validation loss: 615.96, validation correlation: 0.01791
Epoch [87/100], Batch [1/147] train loss: 585.10, train corr: 0.01799
Epoch [87/100], Batch [2/147] train loss: 597.53, train corr: 0.01783
Epoch [87/100], Batch [3/147] train loss: 594.89, train corr: 0.01640
Epoch [87/100], Batch [4/147] train loss: 582.37, train corr: 0.01821
Epoch [87/100], Batch [5/147] train loss: 591.84, train corr: 0.01827
Epoch [87/100], Batch [6/147] train loss: 568.89, train corr: 0.01857
Epoch [87/100], Batch [7/147] train loss: 582.52, train corr: 0.01688
Epoch [87/100], Batch [8/147] train loss: 576.72, train corr: 0.01749
Epoch [87/100], Batch [9/147] train loss: 563.44, train corr: 0.01855
Epoch [87/100], Batch [10/147] train loss: 557.57, train corr: 0.01817
Epoch [87/100], Batch [11/147] train loss: 559.48, train corr: 0.01998
Epoch [87/100], Batch [12/147] train loss: 569.47, train corr: 0.01975
Epoch [87/100], Batch [13/147] train loss: 574.07, train corr: 0.01886
Epoch [87/100], Batch [14/147] train loss: 570.55, train corr: 0.02003
Epoch [87/100], Batch [15/147] train loss: 561.40, train corr: 0.01968
Epoch [87/100], Batch [16/147] train loss: 566.99, train corr: 0.02092
Epoch [87/100], Batch [17/147] train loss: 570.66, train corr: 0.02057
Epoch [87/100], Batch [18/147] train loss: 572.09, train corr: 0.02046
Epoch [87/100], Batch [19/147] train loss: 571.43, train corr: 0.02083
Epoch [87/100], Batch [20/147] train loss: 559.66, train corr: 0.02066
Epoch [87/100], Batch [21/147] train loss: 587.18, train corr: 0.01750
Epoch [87/100], Batch [22/147] train loss: 563.77, train corr: 0.02240
Epoch [87/100], Batch [23/147] train loss: 580.32, train corr: 0.01901
Epoch [87/100], Batch [24/147] train loss: 568.27, train corr: 0.02038
Epoch [87/100], Batch [25/147] train loss: 576.21, train corr: 0.01934
Epoch [87/100], Batch [26/147] train loss: 580.74, train corr: 0.01947
Epoch [87/100], Batch [27/147] train loss: 564.80, train corr: 0.02164
Epoch [87/100], Batch [28/147] train loss: 572.65, train corr: 0.02034
Epoch [87/100], Batch [29/147] train loss: 569.99, train corr: 0.02080
Epoch [87/100], Batch [30/147] train loss: 564.46, train corr: 0.01908
Epoch [87/100], Batch [31/147] train loss: 560.93, train corr: 0.02285
Epoch [87/100], Batch [32/147] train loss: 559.23, train corr: 0.02177
Epoch [87/100], Batch [33/147] train loss: 565.02, train corr: 0.01991
Epoch [87/100], Batch [34/147] train loss: 555.23, train corr: 0.02347
Epoch [87/100], Batch [35/147] train loss: 562.93, train corr: 0.02122
Epoch [87/100], Batch [36/147] train loss: 578.28, train corr: 0.01520
Epoch [87/100], Batch [37/147] train loss: 557.53, train corr: 0.02126
Epoch [87/100], Batch [38/147] train loss: 587.73, train corr: 0.02302
Epoch [87/100], Batch [39/147] train loss: 560.26, train corr: 0.02050
Epoch [87/100], Batch [40/147] train loss: 569.11, train corr: 0.02101
Epoch [87/100], Batch [41/147] train loss: 578.65, train corr: 0.02059
Epoch [87/100], Batch [42/147] train loss: 572.29, train corr: 0.02332
Epoch [87/100], Batch [43/147] train loss: 587.52, train corr: 0.01908
Epoch [87/100], Batch [44/147] train loss: 560.77, train corr: 0.02421
Epoch [87/100], Batch [45/147] train loss: 560.83, train corr: 0.02317
Epoch [87/100], Batch [46/147] train loss: 549.04, train corr: 0.02376
Epoch [87/100], Batch [47/147] train loss: 565.33, train corr: 0.02286
Epoch [87/100], Batch [48/147] train loss: 571.79, train corr: 0.02104
Epoch [87/100], Batch [49/147] train loss: 587.58, train corr: 0.02081
Epoch [87/100], Batch [50/147] train loss: 571.22, train corr: 0.02218
Epoch [87/100], Batch [51/147] train loss: 554.91, train corr: 0.02416
Epoch [87/100], Batch [52/147] train loss: 560.75, train corr: 0.02329
Epoch [87/100], Batch [53/147] train loss: 561.96, train corr: 0.02318
Epoch [87/100], Batch [54/147] train loss: 583.65, train corr: 0.02361
Epoch [87/100], Batch [55/147] train loss: 570.17, train corr: 0.01894
Epoch [87/100], Batch [56/147] train loss: 555.99, train corr: 0.02397
Epoch [87/100], Batch [57/147] train loss: 565.98, train corr: 0.02217
Epoch [87/100], Batch [58/147] train loss: 624.35, train corr: 0.02095
Epoch [87/100], Batch [59/147] train loss: 563.19, train corr: 0.02186
Epoch [87/100], Batch [60/147] train loss: 574.10, train corr: 0.02305
Epoch [87/100], Batch [61/147] train loss: 571.82, train corr: 0.02159
Epoch [87/100], Batch [62/147] train loss: 569.74, train corr: 0.02324
Epoch [87/100], Batch [63/147] train loss: 559.26, train corr: 0.02298
Epoch [87/100], Batch [64/147] train loss: 579.55, train corr: 0.01988
Epoch [87/100], Batch [65/147] train loss: 574.83, train corr: 0.02123
Epoch [87/100], Batch [66/147] train loss: 577.29, train corr: 0.01937
Epoch [87/100], Batch [67/147] train loss: 562.33, train corr: 0.02320
Epoch [87/100], Batch [68/147] train loss: 576.96, train corr: 0.02276
Epoch [87/100], Batch [69/147] train loss: 635.04, train corr: 0.01920
Epoch [87/100], Batch [70/147] train loss: 581.60, train corr: 0.01998
Epoch [87/100], Batch [71/147] train loss: 555.24, train corr: 0.02234
Epoch [87/100], Batch [72/147] train loss: 566.34, train corr: 0.02127
Epoch [87/100], Batch [73/147] train loss: 583.00, train corr: 0.02080
Epoch [87/100], Batch [74/147] train loss: 575.57, train corr: 0.01978
Epoch [87/100], Batch [75/147] train loss: 810.90, train corr: 0.01829
Epoch [87/100], Batch [76/147] train loss: 571.71, train corr: 0.02011
Epoch [87/100], Batch [77/147] train loss: 751.61, train corr: 0.01802
Epoch [87/100], Batch [78/147] train loss: 561.84, train corr: 0.02338
Epoch [87/100], Batch [79/147] train loss: 583.69, train corr: 0.02204
Epoch [87/100], Batch [80/147] train loss: 580.76, train corr: 0.01732
Epoch [87/100], Batch [81/147] train loss: 592.27, train corr: 0.01884
Epoch [87/100], Batch [82/147] train loss: 583.07, train corr: 0.01945
Epoch [87/100], Batch [83/147] train loss: 582.08, train corr: 0.02145
Epoch [87/100], Batch [84/147] train loss: 568.59, train corr: 0.02187
Epoch [87/100], Batch [85/147] train loss: 582.61, train corr: 0.02015
Epoch [87/100], Batch [86/147] train loss: 576.75, train corr: 0.02176
Epoch [87/100], Batch [87/147] train loss: 572.37, train corr: 0.02059
Epoch [87/100], Batch [88/147] train loss: 565.63, train corr: 0.02325
Epoch [87/100], Batch [89/147] train loss: 587.16, train corr: 0.01949
Epoch [87/100], Batch [90/147] train loss: 572.16, train corr: 0.02216
Epoch [87/100], Batch [91/147] train loss: 565.50, train corr: 0.02299
Epoch [87/100], Batch [92/147] train loss: 575.31, train corr: 0.02100
Epoch [87/100], Batch [93/147] train loss: 569.15, train corr: 0.02254
Epoch [87/100], Batch [94/147] train loss: 557.99, train corr: 0.02226
Epoch [87/100], Batch [95/147] train loss: 578.04, train corr: 0.02211
Epoch [87/100], Batch [96/147] train loss: 580.03, train corr: 0.01894
Epoch [87/100], Batch [97/147] train loss: 567.35, train corr: 0.02212
Epoch [87/100], Batch [98/147] train loss: 577.29, train corr: 0.01957
Epoch [87/100], Batch [99/147] train loss: 567.78, train corr: 0.02074
Epoch [87/100], Batch [100/147] train loss: 556.17, train corr: 0.02036
Epoch [87/100], Batch [101/147] train loss: 569.52, train corr: 0.02067
Epoch [87/100], Batch [102/147] train loss: 596.68, train corr: 0.01808
Epoch [87/100], Batch [103/147] train loss: 561.64, train corr: 0.02092
Epoch [87/100], Batch [104/147] train loss: 571.60, train corr: 0.02194
Epoch [87/100], Batch [105/147] train loss: 560.14, train corr: 0.02162
Epoch [87/100], Batch [106/147] train loss: 568.50, train corr: 0.02203
Epoch [87/100], Batch [107/147] train loss: 556.72, train corr: 0.02276
Epoch [87/100], Batch [108/147] train loss: 571.69, train corr: 0.02080
Epoch [87/100], Batch [109/147] train loss: 556.22, train corr: 0.02244
Epoch [87/100], Batch [110/147] train loss: 563.63, train corr: 0.02223
Epoch [87/100], Batch [111/147] train loss: 568.10, train corr: 0.02087
Epoch [87/100], Batch [112/147] train loss: 587.78, train corr: 0.02141
Epoch [87/100], Batch [113/147] train loss: 583.07, train corr: 0.02229
Epoch [87/100], Batch [114/147] train loss: 568.36, train corr: 0.02059
Epoch [87/100], Batch [115/147] train loss: 568.78, train corr: 0.02223
Epoch [87/100], Batch [116/147] train loss: 567.89, train corr: 0.02137
Epoch [87/100], Batch [117/147] train loss: 575.19, train corr: 0.02246
Epoch [87/100], Batch [118/147] train loss: 573.66, train corr: 0.02098
Epoch [87/100], Batch [119/147] train loss: 563.46, train corr: 0.02005
Epoch [87/100], Batch [120/147] train loss: 573.20, train corr: 0.01925
Epoch [87/100], Batch [121/147] train loss: 564.94, train corr: 0.02167
Epoch [87/100], Batch [122/147] train loss: 580.37, train corr: 0.02105
Epoch [87/100], Batch [123/147] train loss: 572.44, train corr: 0.02031
Epoch [87/100], Batch [124/147] train loss: 559.76, train corr: 0.02083
Epoch [87/100], Batch [125/147] train loss: 644.96, train corr: 0.01927
Epoch [87/100], Batch [126/147] train loss: 560.52, train corr: 0.02126
Epoch [87/100], Batch [127/147] train loss: 572.65, train corr: 0.02156
Epoch [87/100], Batch [128/147] train loss: 571.11, train corr: 0.02082
Epoch [87/100], Batch [129/147] train loss: 595.77, train corr: 0.01611
Epoch [87/100], Batch [130/147] train loss: 577.72, train corr: 0.01968
Epoch [87/100], Batch [131/147] train loss: 568.13, train corr: 0.01968
Epoch [87/100], Batch [132/147] train loss: 564.90, train corr: 0.01965
Epoch [87/100], Batch [133/147] train loss: 594.61, train corr: 0.01601
Epoch [87/100], Batch [134/147] train loss: 589.11, train corr: 0.02101
Epoch [87/100], Batch [135/147] train loss: 553.55, train corr: 0.02334
Epoch [87/100], Batch [136/147] train loss: 564.88, train corr: 0.02120
Epoch [87/100], Batch [137/147] train loss: 550.68, train corr: 0.02309
Epoch [87/100], Batch [138/147] train loss: 578.84, train corr: 0.01910
Epoch [87/100], Batch [139/147] train loss: 573.10, train corr: 0.02058
Epoch [87/100], Batch [140/147] train loss: 574.50, train corr: 0.01951
Epoch [87/100], Batch [141/147] train loss: 569.12, train corr: 0.02341
Epoch [87/100], Batch [142/147] train loss: 565.11, train corr: 0.02396
Epoch [87/100], Batch [143/147] train loss: 567.07, train corr: 0.02549
Epoch [87/100], Batch [144/147] train loss: 558.33, train corr: 0.02249
Epoch [87/100], Batch [145/147] train loss: 555.83, train corr: 0.02186
Epoch [87/100], Batch [146/147] train loss: 579.13, train corr: 0.02065
Epoch [87/100], Batch [147/147] train loss: 560.60, train corr: 0.02298
Epoch [87/100], validation loss: 598.29, validation correlation: 0.02209
Epoch [88/100], Batch [1/147] train loss: 561.43, train corr: 0.02158
Epoch [88/100], Batch [2/147] train loss: 557.44, train corr: 0.02267
Epoch [88/100], Batch [3/147] train loss: 567.46, train corr: 0.02162
Epoch [88/100], Batch [4/147] train loss: 558.58, train corr: 0.02317
Epoch [88/100], Batch [5/147] train loss: 558.64, train corr: 0.02295
Epoch [88/100], Batch [6/147] train loss: 562.13, train corr: 0.02088
Epoch [88/100], Batch [7/147] train loss: 559.70, train corr: 0.02027
Epoch [88/100], Batch [8/147] train loss: 563.61, train corr: 0.02380
Epoch [88/100], Batch [9/147] train loss: 566.53, train corr: 0.02175
Epoch [88/100], Batch [10/147] train loss: 563.22, train corr: 0.02021
Epoch [88/100], Batch [11/147] train loss: 574.47, train corr: 0.02223
Epoch [88/100], Batch [12/147] train loss: 557.54, train corr: 0.02241
Epoch [88/100], Batch [13/147] train loss: 567.62, train corr: 0.02330
Epoch [88/100], Batch [14/147] train loss: 569.40, train corr: 0.02104
Epoch [88/100], Batch [15/147] train loss: 560.96, train corr: 0.02250
Epoch [88/100], Batch [16/147] train loss: 567.75, train corr: 0.01964
Epoch [88/100], Batch [17/147] train loss: 572.36, train corr: 0.01952
Epoch [88/100], Batch [18/147] train loss: 570.32, train corr: 0.02169
Epoch [88/100], Batch [19/147] train loss: 557.30, train corr: 0.02408
Epoch [88/100], Batch [20/147] train loss: 586.59, train corr: 0.02180
Epoch [88/100], Batch [21/147] train loss: 564.07, train corr: 0.02223
Epoch [88/100], Batch [22/147] train loss: 576.65, train corr: 0.02270
Epoch [88/100], Batch [23/147] train loss: 741.56, train corr: 0.02191
Epoch [88/100], Batch [24/147] train loss: 576.20, train corr: 0.01854
Epoch [88/100], Batch [25/147] train loss: 555.27, train corr: 0.02132
Epoch [88/100], Batch [26/147] train loss: 571.64, train corr: 0.02225
Epoch [88/100], Batch [27/147] train loss: 580.26, train corr: 0.01931
Epoch [88/100], Batch [28/147] train loss: 567.82, train corr: 0.02293
Epoch [88/100], Batch [29/147] train loss: 562.53, train corr: 0.02216
Epoch [88/100], Batch [30/147] train loss: 567.01, train corr: 0.02011
Epoch [88/100], Batch [31/147] train loss: 597.14, train corr: 0.01559
Epoch [88/100], Batch [32/147] train loss: 557.88, train corr: 0.02087
Epoch [88/100], Batch [33/147] train loss: 567.14, train corr: 0.02153
Epoch [88/100], Batch [34/147] train loss: 567.40, train corr: 0.02045
Epoch [88/100], Batch [35/147] train loss: 578.04, train corr: 0.01990
Epoch [88/100], Batch [36/147] train loss: 572.28, train corr: 0.01806
Epoch [88/100], Batch [37/147] train loss: 807.88, train corr: 0.01775
Epoch [88/100], Batch [38/147] train loss: 566.34, train corr: 0.01764
Epoch [88/100], Batch [39/147] train loss: 584.79, train corr: 0.01870
Epoch [88/100], Batch [40/147] train loss: 563.18, train corr: 0.02033
Epoch [88/100], Batch [41/147] train loss: 569.67, train corr: 0.01903
Epoch [88/100], Batch [42/147] train loss: 572.10, train corr: 0.02113
Epoch [88/100], Batch [43/147] train loss: 554.22, train corr: 0.02005
Epoch [88/100], Batch [44/147] train loss: 559.97, train corr: 0.02146
Epoch [88/100], Batch [45/147] train loss: 557.99, train corr: 0.01836
Epoch [88/100], Batch [46/147] train loss: 569.55, train corr: 0.02037
Epoch [88/100], Batch [47/147] train loss: 564.93, train corr: 0.02118
Epoch [88/100], Batch [48/147] train loss: 614.00, train corr: 0.01888
Epoch [88/100], Batch [49/147] train loss: 557.41, train corr: 0.02096
Epoch [88/100], Batch [50/147] train loss: 570.04, train corr: 0.02012
Epoch [88/100], Batch [51/147] train loss: 578.92, train corr: 0.02049
Epoch [88/100], Batch [52/147] train loss: 575.56, train corr: 0.01923
Epoch [88/100], Batch [53/147] train loss: 574.04, train corr: 0.01884
Epoch [88/100], Batch [54/147] train loss: 558.19, train corr: 0.02125
Epoch [88/100], Batch [55/147] train loss: 568.52, train corr: 0.02079
Epoch [88/100], Batch [56/147] train loss: 573.07, train corr: 0.02103
Epoch [88/100], Batch [57/147] train loss: 584.24, train corr: 0.01960
Epoch [88/100], Batch [58/147] train loss: 594.29, train corr: 0.01599
Epoch [88/100], Batch [59/147] train loss: 582.29, train corr: 0.01827
Epoch [88/100], Batch [60/147] train loss: 565.62, train corr: 0.01825
Epoch [88/100], Batch [61/147] train loss: 560.42, train corr: 0.02090
Epoch [88/100], Batch [62/147] train loss: 568.96, train corr: 0.02153
Epoch [88/100], Batch [63/147] train loss: 565.99, train corr: 0.02030
Epoch [88/100], Batch [64/147] train loss: 569.19, train corr: 0.01849
Epoch [88/100], Batch [65/147] train loss: 575.05, train corr: 0.01961
Epoch [88/100], Batch [66/147] train loss: 575.72, train corr: 0.02002
Epoch [88/100], Batch [67/147] train loss: 583.76, train corr: 0.01739
Epoch [88/100], Batch [68/147] train loss: 559.81, train corr: 0.02176
Epoch [88/100], Batch [69/147] train loss: 562.84, train corr: 0.02011
Epoch [88/100], Batch [70/147] train loss: 564.53, train corr: 0.01972
Epoch [88/100], Batch [71/147] train loss: 562.26, train corr: 0.02081
Epoch [88/100], Batch [72/147] train loss: 571.26, train corr: 0.02179
Epoch [88/100], Batch [73/147] train loss: 580.27, train corr: 0.02013
Epoch [88/100], Batch [74/147] train loss: 558.33, train corr: 0.02098
Epoch [88/100], Batch [75/147] train loss: 638.27, train corr: 0.01607
Epoch [88/100], Batch [76/147] train loss: 584.08, train corr: 0.01656
Epoch [88/100], Batch [77/147] train loss: 564.99, train corr: 0.01969
Epoch [88/100], Batch [78/147] train loss: 564.70, train corr: 0.01929
Epoch [88/100], Batch [79/147] train loss: 582.46, train corr: 0.01855
Epoch [88/100], Batch [80/147] train loss: 569.76, train corr: 0.02164
Epoch [88/100], Batch [81/147] train loss: 581.67, train corr: 0.01819
Epoch [88/100], Batch [82/147] train loss: 563.98, train corr: 0.02134
Epoch [88/100], Batch [83/147] train loss: 565.75, train corr: 0.01969
Epoch [88/100], Batch [84/147] train loss: 556.23, train corr: 0.02050
Epoch [88/100], Batch [85/147] train loss: 585.31, train corr: 0.01627
Epoch [88/100], Batch [86/147] train loss: 642.98, train corr: 0.01781
Epoch [88/100], Batch [87/147] train loss: 561.93, train corr: 0.02181
Epoch [88/100], Batch [88/147] train loss: 577.77, train corr: 0.01973
Epoch [88/100], Batch [89/147] train loss: 570.69, train corr: 0.02167
Epoch [88/100], Batch [90/147] train loss: 565.83, train corr: 0.01913
Epoch [88/100], Batch [91/147] train loss: 571.55, train corr: 0.02178
Epoch [88/100], Batch [92/147] train loss: 561.38, train corr: 0.02214
Epoch [88/100], Batch [93/147] train loss: 577.61, train corr: 0.01646
Epoch [88/100], Batch [94/147] train loss: 585.23, train corr: 0.01809
Epoch [88/100], Batch [95/147] train loss: 568.81, train corr: 0.01998
Epoch [88/100], Batch [96/147] train loss: 580.08, train corr: 0.02015
Epoch [88/100], Batch [97/147] train loss: 562.59, train corr: 0.02120
Epoch [88/100], Batch [98/147] train loss: 588.09, train corr: 0.02069
Epoch [88/100], Batch [99/147] train loss: 561.17, train corr: 0.02242
Epoch [88/100], Batch [100/147] train loss: 582.43, train corr: 0.02015
Epoch [88/100], Batch [101/147] train loss: 570.06, train corr: 0.01989
Epoch [88/100], Batch [102/147] train loss: 569.55, train corr: 0.02031
Epoch [88/100], Batch [103/147] train loss: 561.64, train corr: 0.02197
Epoch [88/100], Batch [104/147] train loss: 574.80, train corr: 0.01987
Epoch [88/100], Batch [105/147] train loss: 561.39, train corr: 0.02117
Epoch [88/100], Batch [106/147] train loss: 566.87, train corr: 0.02183
Epoch [88/100], Batch [107/147] train loss: 556.52, train corr: 0.02133
Epoch [88/100], Batch [108/147] train loss: 575.73, train corr: 0.02075
Epoch [88/100], Batch [109/147] train loss: 594.64, train corr: 0.01495
Epoch [88/100], Batch [110/147] train loss: 576.44, train corr: 0.01986
Epoch [88/100], Batch [111/147] train loss: 561.44, train corr: 0.02123
Epoch [88/100], Batch [112/147] train loss: 584.34, train corr: 0.01977
Epoch [88/100], Batch [113/147] train loss: 569.25, train corr: 0.02183
Epoch [88/100], Batch [114/147] train loss: 563.12, train corr: 0.02163
Epoch [88/100], Batch [115/147] train loss: 572.91, train corr: 0.02082
Epoch [88/100], Batch [116/147] train loss: 563.01, train corr: 0.02142
Epoch [88/100], Batch [117/147] train loss: 567.77, train corr: 0.02168
Epoch [88/100], Batch [118/147] train loss: 568.92, train corr: 0.02174
Epoch [88/100], Batch [119/147] train loss: 570.27, train corr: 0.02258
Epoch [88/100], Batch [120/147] train loss: 566.03, train corr: 0.02184
Epoch [88/100], Batch [121/147] train loss: 571.61, train corr: 0.01926
Epoch [88/100], Batch [122/147] train loss: 585.84, train corr: 0.02056
Epoch [88/100], Batch [123/147] train loss: 580.08, train corr: 0.01949
Epoch [88/100], Batch [124/147] train loss: 572.52, train corr: 0.01881
Epoch [88/100], Batch [125/147] train loss: 562.37, train corr: 0.02406
Epoch [88/100], Batch [126/147] train loss: 561.67, train corr: 0.02165
Epoch [88/100], Batch [127/147] train loss: 560.09, train corr: 0.02089
Epoch [88/100], Batch [128/147] train loss: 570.71, train corr: 0.01850
Epoch [88/100], Batch [129/147] train loss: 565.94, train corr: 0.02417
Epoch [88/100], Batch [130/147] train loss: 568.23, train corr: 0.02247
Epoch [88/100], Batch [131/147] train loss: 562.25, train corr: 0.01860
Epoch [88/100], Batch [132/147] train loss: 567.52, train corr: 0.02026
Epoch [88/100], Batch [133/147] train loss: 558.13, train corr: 0.02339
Epoch [88/100], Batch [134/147] train loss: 570.82, train corr: 0.02250
Epoch [88/100], Batch [135/147] train loss: 569.90, train corr: 0.02184
Epoch [88/100], Batch [136/147] train loss: 567.01, train corr: 0.02126
Epoch [88/100], Batch [137/147] train loss: 569.40, train corr: 0.02172
Epoch [88/100], Batch [138/147] train loss: 565.10, train corr: 0.02232
Epoch [88/100], Batch [139/147] train loss: 559.02, train corr: 0.02116
Epoch [88/100], Batch [140/147] train loss: 566.91, train corr: 0.02140
Epoch [88/100], Batch [141/147] train loss: 566.94, train corr: 0.01981
Epoch [88/100], Batch [142/147] train loss: 571.18, train corr: 0.02251
Epoch [88/100], Batch [143/147] train loss: 563.13, train corr: 0.02125
Epoch [88/100], Batch [144/147] train loss: 571.55, train corr: 0.01727
Epoch [88/100], Batch [145/147] train loss: 573.45, train corr: 0.02164
Epoch [88/100], Batch [146/147] train loss: 575.66, train corr: 0.02104
Epoch [88/100], Batch [147/147] train loss: 564.59, train corr: 0.02275
Epoch [88/100], validation loss: 598.15, validation correlation: 0.02172
Epoch [89/100], Batch [1/147] train loss: 563.47, train corr: 0.02227
Epoch [89/100], Batch [2/147] train loss: 568.53, train corr: 0.02154
Epoch [89/100], Batch [3/147] train loss: 558.60, train corr: 0.02125
Epoch [89/100], Batch [4/147] train loss: 573.73, train corr: 0.01956
Epoch [89/100], Batch [5/147] train loss: 560.90, train corr: 0.02096
Epoch [89/100], Batch [6/147] train loss: 573.97, train corr: 0.02088
Epoch [89/100], Batch [7/147] train loss: 586.42, train corr: 0.01853
Epoch [89/100], Batch [8/147] train loss: 568.85, train corr: 0.02122
Epoch [89/100], Batch [9/147] train loss: 558.63, train corr: 0.02232
Epoch [89/100], Batch [10/147] train loss: 549.94, train corr: 0.02259
Epoch [89/100], Batch [11/147] train loss: 557.99, train corr: 0.02085
Epoch [89/100], Batch [12/147] train loss: 586.07, train corr: 0.01995
Epoch [89/100], Batch [13/147] train loss: 568.84, train corr: 0.02252
Epoch [89/100], Batch [14/147] train loss: 583.25, train corr: 0.02110
Epoch [89/100], Batch [15/147] train loss: 568.83, train corr: 0.02079
Epoch [89/100], Batch [16/147] train loss: 580.50, train corr: 0.01814
Epoch [89/100], Batch [17/147] train loss: 569.72, train corr: 0.01972
Epoch [89/100], Batch [18/147] train loss: 555.14, train corr: 0.02332
Epoch [89/100], Batch [19/147] train loss: 566.19, train corr: 0.02186
Epoch [89/100], Batch [20/147] train loss: 574.75, train corr: 0.02170
Epoch [89/100], Batch [21/147] train loss: 573.71, train corr: 0.01878
Epoch [89/100], Batch [22/147] train loss: 556.15, train corr: 0.02266
Epoch [89/100], Batch [23/147] train loss: 575.63, train corr: 0.01751
Epoch [89/100], Batch [24/147] train loss: 568.83, train corr: 0.02446
Epoch [89/100], Batch [25/147] train loss: 570.01, train corr: 0.02490
Epoch [89/100], Batch [26/147] train loss: 643.56, train corr: 0.01847
Epoch [89/100], Batch [27/147] train loss: 576.06, train corr: 0.02074
Epoch [89/100], Batch [28/147] train loss: 561.84, train corr: 0.02339
Epoch [89/100], Batch [29/147] train loss: 565.71, train corr: 0.02198
Epoch [89/100], Batch [30/147] train loss: 572.24, train corr: 0.02209
Epoch [89/100], Batch [31/147] train loss: 560.75, train corr: 0.02227
Epoch [89/100], Batch [32/147] train loss: 581.40, train corr: 0.02007
Epoch [89/100], Batch [33/147] train loss: 561.13, train corr: 0.02250
Epoch [89/100], Batch [34/147] train loss: 551.81, train corr: 0.02253
Epoch [89/100], Batch [35/147] train loss: 554.61, train corr: 0.02315
Epoch [89/100], Batch [36/147] train loss: 549.80, train corr: 0.02464
Epoch [89/100], Batch [37/147] train loss: 562.38, train corr: 0.02264
Epoch [89/100], Batch [38/147] train loss: 560.09, train corr: 0.02162
Epoch [89/100], Batch [39/147] train loss: 559.18, train corr: 0.02232
Epoch [89/100], Batch [40/147] train loss: 573.20, train corr: 0.01998
Epoch [89/100], Batch [41/147] train loss: 577.32, train corr: 0.02257
Epoch [89/100], Batch [42/147] train loss: 618.18, train corr: 0.02182
Epoch [89/100], Batch [43/147] train loss: 547.36, train corr: 0.02202
Epoch [89/100], Batch [44/147] train loss: 571.93, train corr: 0.02245
Epoch [89/100], Batch [45/147] train loss: 564.01, train corr: 0.02261
Epoch [89/100], Batch [46/147] train loss: 582.87, train corr: 0.01808
Epoch [89/100], Batch [47/147] train loss: 583.04, train corr: 0.02010
Epoch [89/100], Batch [48/147] train loss: 549.74, train corr: 0.02310
Epoch [89/100], Batch [49/147] train loss: 566.32, train corr: 0.02229
Epoch [89/100], Batch [50/147] train loss: 565.31, train corr: 0.02025
Epoch [89/100], Batch [51/147] train loss: 571.81, train corr: 0.01900
Epoch [89/100], Batch [52/147] train loss: 565.96, train corr: 0.02235
Epoch [89/100], Batch [53/147] train loss: 569.01, train corr: 0.02184
Epoch [89/100], Batch [54/147] train loss: 577.40, train corr: 0.01939
Epoch [89/100], Batch [55/147] train loss: 577.24, train corr: 0.01974
Epoch [89/100], Batch [56/147] train loss: 574.14, train corr: 0.02238
Epoch [89/100], Batch [57/147] train loss: 566.66, train corr: 0.02270
Epoch [89/100], Batch [58/147] train loss: 569.36, train corr: 0.02292
Epoch [89/100], Batch [59/147] train loss: 565.93, train corr: 0.02315
Epoch [89/100], Batch [60/147] train loss: 576.42, train corr: 0.01644
Epoch [89/100], Batch [61/147] train loss: 559.15, train corr: 0.02331
Epoch [89/100], Batch [62/147] train loss: 569.38, train corr: 0.02139
Epoch [89/100], Batch [63/147] train loss: 574.35, train corr: 0.01853
Epoch [89/100], Batch [64/147] train loss: 553.82, train corr: 0.02305
Epoch [89/100], Batch [65/147] train loss: 559.32, train corr: 0.02176
Epoch [89/100], Batch [66/147] train loss: 572.35, train corr: 0.02099
Epoch [89/100], Batch [67/147] train loss: 570.59, train corr: 0.01990
Epoch [89/100], Batch [68/147] train loss: 595.87, train corr: 0.01723
Epoch [89/100], Batch [69/147] train loss: 576.35, train corr: 0.01982
Epoch [89/100], Batch [70/147] train loss: 563.65, train corr: 0.02118
Epoch [89/100], Batch [71/147] train loss: 576.04, train corr: 0.02209
Epoch [89/100], Batch [72/147] train loss: 575.22, train corr: 0.02053
Epoch [89/100], Batch [73/147] train loss: 578.74, train corr: 0.01801
Epoch [89/100], Batch [74/147] train loss: 565.41, train corr: 0.02015
Epoch [89/100], Batch [75/147] train loss: 565.28, train corr: 0.01985
Epoch [89/100], Batch [76/147] train loss: 570.83, train corr: 0.01905
Epoch [89/100], Batch [77/147] train loss: 572.66, train corr: 0.01947
Epoch [89/100], Batch [78/147] train loss: 573.51, train corr: 0.01935
Epoch [89/100], Batch [79/147] train loss: 571.65, train corr: 0.01836
Epoch [89/100], Batch [80/147] train loss: 570.08, train corr: 0.02197
Epoch [89/100], Batch [81/147] train loss: 608.09, train corr: 0.01197
Epoch [89/100], Batch [82/147] train loss: 544.73, train corr: 0.02173
Epoch [89/100], Batch [83/147] train loss: 572.05, train corr: 0.02127
Epoch [89/100], Batch [84/147] train loss: 557.57, train corr: 0.02127
Epoch [89/100], Batch [85/147] train loss: 828.99, train corr: 0.01680
Epoch [89/100], Batch [86/147] train loss: 575.42, train corr: 0.01809
Epoch [89/100], Batch [87/147] train loss: 568.33, train corr: 0.02197
Epoch [89/100], Batch [88/147] train loss: 568.10, train corr: 0.01994
Epoch [89/100], Batch [89/147] train loss: 574.91, train corr: 0.02076
Epoch [89/100], Batch [90/147] train loss: 571.50, train corr: 0.01951
Epoch [89/100], Batch [91/147] train loss: 577.22, train corr: 0.01983
Epoch [89/100], Batch [92/147] train loss: 563.72, train corr: 0.02040
Epoch [89/100], Batch [93/147] train loss: 567.72, train corr: 0.01844
Epoch [89/100], Batch [94/147] train loss: 565.20, train corr: 0.01999
Epoch [89/100], Batch [95/147] train loss: 570.85, train corr: 0.01954
Epoch [89/100], Batch [96/147] train loss: 566.26, train corr: 0.02006
Epoch [89/100], Batch [97/147] train loss: 579.06, train corr: 0.01982
Epoch [89/100], Batch [98/147] train loss: 566.28, train corr: 0.01926
Epoch [89/100], Batch [99/147] train loss: 559.30, train corr: 0.01998
Epoch [89/100], Batch [100/147] train loss: 567.39, train corr: 0.01866
Epoch [89/100], Batch [101/147] train loss: 571.65, train corr: 0.01911
Epoch [89/100], Batch [102/147] train loss: 575.94, train corr: 0.02008
Epoch [89/100], Batch [103/147] train loss: 569.43, train corr: 0.02032
Epoch [89/100], Batch [104/147] train loss: 573.46, train corr: 0.02029
Epoch [89/100], Batch [105/147] train loss: 566.69, train corr: 0.01961
Epoch [89/100], Batch [106/147] train loss: 560.75, train corr: 0.02153
Epoch [89/100], Batch [107/147] train loss: 565.86, train corr: 0.02085
Epoch [89/100], Batch [108/147] train loss: 553.78, train corr: 0.01982
Epoch [89/100], Batch [109/147] train loss: 573.66, train corr: 0.01547
Epoch [89/100], Batch [110/147] train loss: 738.02, train corr: 0.02003
Epoch [89/100], Batch [111/147] train loss: 570.64, train corr: 0.01794
Epoch [89/100], Batch [112/147] train loss: 564.33, train corr: 0.02007
Epoch [89/100], Batch [113/147] train loss: 560.29, train corr: 0.02021
Epoch [89/100], Batch [114/147] train loss: 581.99, train corr: 0.01859
Epoch [89/100], Batch [115/147] train loss: 607.02, train corr: 0.01720
Epoch [89/100], Batch [116/147] train loss: 590.24, train corr: 0.01514
Epoch [89/100], Batch [117/147] train loss: 567.98, train corr: 0.01736
Epoch [89/100], Batch [118/147] train loss: 572.40, train corr: 0.01780
Epoch [89/100], Batch [119/147] train loss: 569.64, train corr: 0.01769
Epoch [89/100], Batch [120/147] train loss: 576.07, train corr: 0.01569
Epoch [89/100], Batch [121/147] train loss: 576.90, train corr: 0.01799
Epoch [89/100], Batch [122/147] train loss: 567.42, train corr: 0.01849
Epoch [89/100], Batch [123/147] train loss: 572.73, train corr: 0.01742
Epoch [89/100], Batch [124/147] train loss: 570.01, train corr: 0.01767
Epoch [89/100], Batch [125/147] train loss: 578.12, train corr: 0.01454
Epoch [89/100], Batch [126/147] train loss: 566.89, train corr: 0.01798
Epoch [89/100], Batch [127/147] train loss: 571.41, train corr: 0.01691
Epoch [89/100], Batch [128/147] train loss: 560.85, train corr: 0.01839
Epoch [89/100], Batch [129/147] train loss: 582.24, train corr: 0.01448
Epoch [89/100], Batch [130/147] train loss: 560.21, train corr: 0.01587
Epoch [89/100], Batch [131/147] train loss: 559.94, train corr: 0.01572
Epoch [89/100], Batch [132/147] train loss: 565.29, train corr: 0.01679
Epoch [89/100], Batch [133/147] train loss: 576.85, train corr: 0.01551
Epoch [89/100], Batch [134/147] train loss: 571.05, train corr: 0.01434
Epoch [89/100], Batch [135/147] train loss: 561.02, train corr: 0.01706
Epoch [89/100], Batch [136/147] train loss: 582.02, train corr: 0.01472
Epoch [89/100], Batch [137/147] train loss: 634.03, train corr: 0.01453
Epoch [89/100], Batch [138/147] train loss: 542.12, train corr: 0.01864
Epoch [89/100], Batch [139/147] train loss: 580.35, train corr: 0.01618
Epoch [89/100], Batch [140/147] train loss: 573.16, train corr: 0.01583
Epoch [89/100], Batch [141/147] train loss: 578.92, train corr: 0.01581
Epoch [89/100], Batch [142/147] train loss: 571.28, train corr: 0.01787
Epoch [89/100], Batch [143/147] train loss: 560.19, train corr: 0.01589
Epoch [89/100], Batch [144/147] train loss: 569.97, train corr: 0.01675
Epoch [89/100], Batch [145/147] train loss: 572.23, train corr: 0.01714
Epoch [89/100], Batch [146/147] train loss: 560.61, train corr: 0.01878
Epoch [89/100], Batch [147/147] train loss: 568.37, train corr: 0.01635
Epoch [89/100], validation loss: 598.57, validation correlation: 0.01755
Epoch [90/100], Batch [1/147] train loss: 576.26, train corr: 0.01792
Epoch [90/100], Batch [2/147] train loss: 564.20, train corr: 0.01739
Epoch [90/100], Batch [3/147] train loss: 591.55, train corr: 0.01231
Epoch [90/100], Batch [4/147] train loss: 561.04, train corr: 0.01826
Epoch [90/100], Batch [5/147] train loss: 572.71, train corr: 0.01670
Epoch [90/100], Batch [6/147] train loss: 553.51, train corr: 0.01896
Epoch [90/100], Batch [7/147] train loss: 580.96, train corr: 0.01458
Epoch [90/100], Batch [8/147] train loss: 559.03, train corr: 0.01697
Epoch [90/100], Batch [9/147] train loss: 559.11, train corr: 0.01798
Epoch [90/100], Batch [10/147] train loss: 578.42, train corr: 0.01593
Epoch [90/100], Batch [11/147] train loss: 565.52, train corr: 0.01701
Epoch [90/100], Batch [12/147] train loss: 567.61, train corr: 0.01901
Epoch [90/100], Batch [13/147] train loss: 571.18, train corr: 0.01878
Epoch [90/100], Batch [14/147] train loss: 574.31, train corr: 0.01659
Epoch [90/100], Batch [15/147] train loss: 560.20, train corr: 0.01734
Epoch [90/100], Batch [16/147] train loss: 558.03, train corr: 0.01744
Epoch [90/100], Batch [17/147] train loss: 565.97, train corr: 0.01746
Epoch [90/100], Batch [18/147] train loss: 559.26, train corr: 0.01835
Epoch [90/100], Batch [19/147] train loss: 563.30, train corr: 0.01833
Epoch [90/100], Batch [20/147] train loss: 567.71, train corr: 0.01855
Epoch [90/100], Batch [21/147] train loss: 560.42, train corr: 0.01764
Epoch [90/100], Batch [22/147] train loss: 571.84, train corr: 0.01469
Epoch [90/100], Batch [23/147] train loss: 557.89, train corr: 0.01643
Epoch [90/100], Batch [24/147] train loss: 577.12, train corr: 0.01666
Epoch [90/100], Batch [25/147] train loss: 557.41, train corr: 0.01829
Epoch [90/100], Batch [26/147] train loss: 563.62, train corr: 0.01765
Epoch [90/100], Batch [27/147] train loss: 565.33, train corr: 0.01789
Epoch [90/100], Batch [28/147] train loss: 610.12, train corr: 0.01767
Epoch [90/100], Batch [29/147] train loss: 567.35, train corr: 0.01916
Epoch [90/100], Batch [30/147] train loss: 557.21, train corr: 0.01864
Epoch [90/100], Batch [31/147] train loss: 575.55, train corr: 0.01733
Epoch [90/100], Batch [32/147] train loss: 564.61, train corr: 0.01888
Epoch [90/100], Batch [33/147] train loss: 568.89, train corr: 0.01937
Epoch [90/100], Batch [34/147] train loss: 576.37, train corr: 0.01560
Epoch [90/100], Batch [35/147] train loss: 565.08, train corr: 0.01743
Epoch [90/100], Batch [36/147] train loss: 568.26, train corr: 0.01824
Epoch [90/100], Batch [37/147] train loss: 561.06, train corr: 0.01726
Epoch [90/100], Batch [38/147] train loss: 566.42, train corr: 0.01831
Epoch [90/100], Batch [39/147] train loss: 563.15, train corr: 0.01727
Epoch [90/100], Batch [40/147] train loss: 560.26, train corr: 0.01986
Epoch [90/100], Batch [41/147] train loss: 564.25, train corr: 0.01827
Epoch [90/100], Batch [42/147] train loss: 565.67, train corr: 0.01961
Epoch [90/100], Batch [43/147] train loss: 568.62, train corr: 0.01725
Epoch [90/100], Batch [44/147] train loss: 563.46, train corr: 0.01970
Epoch [90/100], Batch [45/147] train loss: 564.30, train corr: 0.01661
Epoch [90/100], Batch [46/147] train loss: 554.16, train corr: 0.01846
Epoch [90/100], Batch [47/147] train loss: 576.15, train corr: 0.01759
Epoch [90/100], Batch [48/147] train loss: 574.56, train corr: 0.01535
Epoch [90/100], Batch [49/147] train loss: 567.48, train corr: 0.01657
Epoch [90/100], Batch [50/147] train loss: 590.69, train corr: 0.01611
Epoch [90/100], Batch [51/147] train loss: 584.73, train corr: 0.01701
Epoch [90/100], Batch [52/147] train loss: 581.68, train corr: 0.01385
Epoch [90/100], Batch [53/147] train loss: 557.91, train corr: 0.01803
Epoch [90/100], Batch [54/147] train loss: 570.77, train corr: 0.01804
Epoch [90/100], Batch [55/147] train loss: 572.99, train corr: 0.01771
Epoch [90/100], Batch [56/147] train loss: 574.86, train corr: 0.01802
Epoch [90/100], Batch [57/147] train loss: 579.28, train corr: 0.01575
Epoch [90/100], Batch [58/147] train loss: 577.67, train corr: 0.01665
Epoch [90/100], Batch [59/147] train loss: 583.80, train corr: 0.01709
Epoch [90/100], Batch [60/147] train loss: 560.07, train corr: 0.01705
Epoch [90/100], Batch [61/147] train loss: 573.47, train corr: 0.01606
Epoch [90/100], Batch [62/147] train loss: 577.74, train corr: 0.01542
Epoch [90/100], Batch [63/147] train loss: 564.68, train corr: 0.01567
Epoch [90/100], Batch [64/147] train loss: 554.55, train corr: 0.01786
Epoch [90/100], Batch [65/147] train loss: 562.30, train corr: 0.01815
Epoch [90/100], Batch [66/147] train loss: 568.54, train corr: 0.01707
Epoch [90/100], Batch [67/147] train loss: 560.77, train corr: 0.01685
Epoch [90/100], Batch [68/147] train loss: 570.65, train corr: 0.01617
Epoch [90/100], Batch [69/147] train loss: 562.29, train corr: 0.01487
Epoch [90/100], Batch [70/147] train loss: 554.72, train corr: 0.01838
Epoch [90/100], Batch [71/147] train loss: 570.59, train corr: 0.01709
Epoch [90/100], Batch [72/147] train loss: 558.17, train corr: 0.01689
Epoch [90/100], Batch [73/147] train loss: 561.30, train corr: 0.01720
Epoch [90/100], Batch [74/147] train loss: 576.48, train corr: 0.01786
Epoch [90/100], Batch [75/147] train loss: 571.73, train corr: 0.01661
Epoch [90/100], Batch [76/147] train loss: 571.36, train corr: 0.01641
Epoch [90/100], Batch [77/147] train loss: 561.10, train corr: 0.01768
Epoch [90/100], Batch [78/147] train loss: 580.56, train corr: 0.01669
Epoch [90/100], Batch [79/147] train loss: 567.08, train corr: 0.01649
Epoch [90/100], Batch [80/147] train loss: 566.59, train corr: 0.01529
Epoch [90/100], Batch [81/147] train loss: 571.36, train corr: 0.01827
Epoch [90/100], Batch [82/147] train loss: 557.57, train corr: 0.01686
Epoch [90/100], Batch [83/147] train loss: 574.60, train corr: 0.01671
Epoch [90/100], Batch [84/147] train loss: 561.14, train corr: 0.01491
Epoch [90/100], Batch [85/147] train loss: 630.12, train corr: 0.01405
Epoch [90/100], Batch [86/147] train loss: 742.97, train corr: 0.01433
Epoch [90/100], Batch [87/147] train loss: 597.27, train corr: 0.01084
Epoch [90/100], Batch [88/147] train loss: 560.41, train corr: 0.01474
Epoch [90/100], Batch [89/147] train loss: 576.35, train corr: 0.01274
Epoch [90/100], Batch [90/147] train loss: 592.91, train corr: 0.01541
Epoch [90/100], Batch [91/147] train loss: 573.58, train corr: 0.01285
Epoch [90/100], Batch [92/147] train loss: 563.90, train corr: 0.01065
Epoch [90/100], Batch [93/147] train loss: 588.42, train corr: 0.00832
Epoch [90/100], Batch [94/147] train loss: 579.88, train corr: 0.00919
Epoch [90/100], Batch [95/147] train loss: 589.77, train corr: 0.00871
Epoch [90/100], Batch [96/147] train loss: 581.71, train corr: 0.01007
Epoch [90/100], Batch [97/147] train loss: 563.46, train corr: 0.01073
Epoch [90/100], Batch [98/147] train loss: 555.18, train corr: 0.00911
Epoch [90/100], Batch [99/147] train loss: 586.35, train corr: 0.00809
Epoch [90/100], Batch [100/147] train loss: 571.01, train corr: 0.00710
Epoch [90/100], Batch [101/147] train loss: 571.46, train corr: 0.00717
Epoch [90/100], Batch [102/147] train loss: 572.81, train corr: 0.00800
Epoch [90/100], Batch [103/147] train loss: 568.46, train corr: 0.00739
Epoch [90/100], Batch [104/147] train loss: 568.45, train corr: 0.00773
Epoch [90/100], Batch [105/147] train loss: 552.88, train corr: 0.00789
Epoch [90/100], Batch [106/147] train loss: 576.10, train corr: 0.00640
Epoch [90/100], Batch [107/147] train loss: 568.37, train corr: 0.00679
Epoch [90/100], Batch [108/147] train loss: 558.42, train corr: 0.00904
Epoch [90/100], Batch [109/147] train loss: 830.11, train corr: 0.00677
Epoch [90/100], Batch [110/147] train loss: 573.28, train corr: 0.00529
Epoch [90/100], Batch [111/147] train loss: 577.87, train corr: 0.00544
Epoch [90/100], Batch [112/147] train loss: 586.22, train corr: 0.00425
Epoch [90/100], Batch [113/147] train loss: 572.36, train corr: 0.00585
Epoch [90/100], Batch [114/147] train loss: 607.39, train corr: 0.00555
Epoch [90/100], Batch [115/147] train loss: 565.59, train corr: 0.00545
Epoch [90/100], Batch [116/147] train loss: 574.58, train corr: 0.00403
Epoch [90/100], Batch [117/147] train loss: 565.17, train corr: 0.00369
Epoch [90/100], Batch [118/147] train loss: 563.64, train corr: 0.00370
Epoch [90/100], Batch [119/147] train loss: 556.79, train corr: 0.00453
Epoch [90/100], Batch [120/147] train loss: 555.36, train corr: 0.00542
Epoch [90/100], Batch [121/147] train loss: 581.75, train corr: 0.00510
Epoch [90/100], Batch [122/147] train loss: 563.84, train corr: 0.00546
Epoch [90/100], Batch [123/147] train loss: 568.04, train corr: 0.00412
Epoch [90/100], Batch [124/147] train loss: 572.74, train corr: 0.00408
Epoch [90/100], Batch [125/147] train loss: 556.36, train corr: 0.00456
Epoch [90/100], Batch [126/147] train loss: 568.12, train corr: 0.00458
Epoch [90/100], Batch [127/147] train loss: 593.49, train corr: 0.00400
Epoch [90/100], Batch [128/147] train loss: 574.67, train corr: 0.00479
Epoch [90/100], Batch [129/147] train loss: 562.79, train corr: 0.00388
Epoch [90/100], Batch [130/147] train loss: 639.41, train corr: 0.00402
Epoch [90/100], Batch [131/147] train loss: 580.22, train corr: 0.00476
Epoch [90/100], Batch [132/147] train loss: 555.50, train corr: 0.00589
Epoch [90/100], Batch [133/147] train loss: 579.54, train corr: 0.00693
Epoch [90/100], Batch [134/147] train loss: 578.45, train corr: 0.00699
Epoch [90/100], Batch [135/147] train loss: 571.36, train corr: 0.00568
Epoch [90/100], Batch [136/147] train loss: 581.29, train corr: 0.00657
Epoch [90/100], Batch [137/147] train loss: 574.23, train corr: 0.00625
Epoch [90/100], Batch [138/147] train loss: 569.42, train corr: 0.00809
Epoch [90/100], Batch [139/147] train loss: 561.12, train corr: 0.00819
Epoch [90/100], Batch [140/147] train loss: 547.33, train corr: 0.00967
Epoch [90/100], Batch [141/147] train loss: 570.01, train corr: 0.00788
Epoch [90/100], Batch [142/147] train loss: 557.90, train corr: 0.00822
Epoch [90/100], Batch [143/147] train loss: 565.07, train corr: 0.00808
Epoch [90/100], Batch [144/147] train loss: 564.19, train corr: 0.01003
Epoch [90/100], Batch [145/147] train loss: 561.61, train corr: 0.00956
Epoch [90/100], Batch [146/147] train loss: 554.35, train corr: 0.00957
Epoch [90/100], Batch [147/147] train loss: 576.89, train corr: 0.00852
Epoch [90/100], validation loss: 598.21, validation correlation: 0.00889
Epoch [91/100], Batch [1/147] train loss: 571.43, train corr: 0.00757
Epoch [91/100], Batch [2/147] train loss: 582.66, train corr: 0.00860
Epoch [91/100], Batch [3/147] train loss: 556.68, train corr: 0.01078
Epoch [91/100], Batch [4/147] train loss: 566.25, train corr: 0.00821
Epoch [91/100], Batch [5/147] train loss: 567.75, train corr: 0.00916
Epoch [91/100], Batch [6/147] train loss: 565.72, train corr: 0.00886
Epoch [91/100], Batch [7/147] train loss: 569.31, train corr: 0.00962
Epoch [91/100], Batch [8/147] train loss: 574.81, train corr: 0.00834
Epoch [91/100], Batch [9/147] train loss: 597.06, train corr: 0.00929
Epoch [91/100], Batch [10/147] train loss: 560.63, train corr: 0.01080
Epoch [91/100], Batch [11/147] train loss: 561.15, train corr: 0.00985
Epoch [91/100], Batch [12/147] train loss: 559.91, train corr: 0.01012
Epoch [91/100], Batch [13/147] train loss: 556.67, train corr: 0.01044
Epoch [91/100], Batch [14/147] train loss: 556.37, train corr: 0.01152
Epoch [91/100], Batch [15/147] train loss: 565.34, train corr: 0.00967
Epoch [91/100], Batch [16/147] train loss: 560.87, train corr: 0.01048
Epoch [91/100], Batch [17/147] train loss: 578.71, train corr: 0.00828
Epoch [91/100], Batch [18/147] train loss: 576.50, train corr: 0.00899
Epoch [91/100], Batch [19/147] train loss: 573.83, train corr: 0.00981
Epoch [91/100], Batch [20/147] train loss: 565.59, train corr: 0.00932
Epoch [91/100], Batch [21/147] train loss: 555.48, train corr: 0.01003
Epoch [91/100], Batch [22/147] train loss: 570.74, train corr: 0.00947
Epoch [91/100], Batch [23/147] train loss: 579.84, train corr: 0.00997
Epoch [91/100], Batch [24/147] train loss: 590.71, train corr: 0.00702
Epoch [91/100], Batch [25/147] train loss: 558.30, train corr: 0.00976
Epoch [91/100], Batch [26/147] train loss: 574.12, train corr: 0.00876
Epoch [91/100], Batch [27/147] train loss: 560.36, train corr: 0.00951
Epoch [91/100], Batch [28/147] train loss: 560.13, train corr: 0.00919
Epoch [91/100], Batch [29/147] train loss: 564.61, train corr: 0.00934
Epoch [91/100], Batch [30/147] train loss: 560.91, train corr: 0.00791
Epoch [91/100], Batch [31/147] train loss: 568.67, train corr: 0.00757
Epoch [91/100], Batch [32/147] train loss: 558.01, train corr: 0.00915
Epoch [91/100], Batch [33/147] train loss: 570.17, train corr: 0.00704
Epoch [91/100], Batch [34/147] train loss: 552.71, train corr: 0.01016
Epoch [91/100], Batch [35/147] train loss: 563.33, train corr: 0.00869
Epoch [91/100], Batch [36/147] train loss: 553.82, train corr: 0.00874
Epoch [91/100], Batch [37/147] train loss: 569.84, train corr: 0.00744
Epoch [91/100], Batch [38/147] train loss: 614.37, train corr: 0.00675
Epoch [91/100], Batch [39/147] train loss: 571.99, train corr: 0.00724
Epoch [91/100], Batch [40/147] train loss: 569.95, train corr: 0.00628
Epoch [91/100], Batch [41/147] train loss: 587.66, train corr: 0.00537
Epoch [91/100], Batch [42/147] train loss: 555.87, train corr: 0.00682
Epoch [91/100], Batch [43/147] train loss: 570.20, train corr: 0.00676
Epoch [91/100], Batch [44/147] train loss: 566.16, train corr: 0.00713
Epoch [91/100], Batch [45/147] train loss: 584.59, train corr: 0.00557
Epoch [91/100], Batch [46/147] train loss: 576.72, train corr: 0.00534
Epoch [91/100], Batch [47/147] train loss: 572.28, train corr: 0.00609
Epoch [91/100], Batch [48/147] train loss: 558.34, train corr: 0.00681
Epoch [91/100], Batch [49/147] train loss: 639.86, train corr: 0.00490
Epoch [91/100], Batch [50/147] train loss: 570.76, train corr: 0.00562
Epoch [91/100], Batch [51/147] train loss: 561.08, train corr: 0.00719
Epoch [91/100], Batch [52/147] train loss: 560.61, train corr: 0.00695
Epoch [91/100], Batch [53/147] train loss: 581.05, train corr: 0.00518
Epoch [91/100], Batch [54/147] train loss: 569.15, train corr: 0.00602
Epoch [91/100], Batch [55/147] train loss: 556.80, train corr: 0.00668
Epoch [91/100], Batch [56/147] train loss: 553.08, train corr: 0.00736
Epoch [91/100], Batch [57/147] train loss: 819.14, train corr: 0.00576
Epoch [91/100], Batch [58/147] train loss: 572.23, train corr: 0.00469
Epoch [91/100], Batch [59/147] train loss: 563.51, train corr: 0.00459
Epoch [91/100], Batch [60/147] train loss: 571.95, train corr: 0.00536
Epoch [91/100], Batch [61/147] train loss: 565.98, train corr: 0.00527
Epoch [91/100], Batch [62/147] train loss: 560.59, train corr: 0.00426
Epoch [91/100], Batch [63/147] train loss: 569.24, train corr: 0.00311
Epoch [91/100], Batch [64/147] train loss: 571.14, train corr: 0.00175
Epoch [91/100], Batch [65/147] train loss: 577.69, train corr: -0.00001
Epoch [91/100], Batch [66/147] train loss: 572.34, train corr: 0.00200
Epoch [91/100], Batch [67/147] train loss: 586.54, train corr: 0.00206
Epoch [91/100], Batch [68/147] train loss: 560.84, train corr: 0.00219
Epoch [91/100], Batch [69/147] train loss: 584.13, train corr: 0.00023
Epoch [91/100], Batch [70/147] train loss: 572.07, train corr: -0.00032
Epoch [91/100], Batch [71/147] train loss: 575.29, train corr: -0.00033
Epoch [91/100], Batch [72/147] train loss: 562.65, train corr: -0.00006
Epoch [91/100], Batch [73/147] train loss: 570.31, train corr: 0.00008
Epoch [91/100], Batch [74/147] train loss: 566.33, train corr: 0.00071
Epoch [91/100], Batch [75/147] train loss: 574.75, train corr: -0.00048
Epoch [91/100], Batch [76/147] train loss: 578.33, train corr: -0.00054
Epoch [91/100], Batch [77/147] train loss: 568.95, train corr: -0.00153
Epoch [91/100], Batch [78/147] train loss: 552.29, train corr: -0.00119
Epoch [91/100], Batch [79/147] train loss: 565.61, train corr: -0.00037
Epoch [91/100], Batch [80/147] train loss: 568.17, train corr: -0.00039
Epoch [91/100], Batch [81/147] train loss: 568.82, train corr: -0.00032
Epoch [91/100], Batch [82/147] train loss: 562.32, train corr: -0.00089
Epoch [91/100], Batch [83/147] train loss: 570.65, train corr: -0.00167
Epoch [91/100], Batch [84/147] train loss: 546.03, train corr: -0.00055
Epoch [91/100], Batch [85/147] train loss: 561.36, train corr: -0.00079
Epoch [91/100], Batch [86/147] train loss: 583.72, train corr: 0.00004
Epoch [91/100], Batch [87/147] train loss: 571.97, train corr: 0.00009
Epoch [91/100], Batch [88/147] train loss: 582.82, train corr: 0.00019
Epoch [91/100], Batch [89/147] train loss: 564.59, train corr: -0.00020
Epoch [91/100], Batch [90/147] train loss: 571.50, train corr: -0.00009
Epoch [91/100], Batch [91/147] train loss: 583.45, train corr: 0.00000
Epoch [91/100], Batch [92/147] train loss: 570.42, train corr: -0.00023
Epoch [91/100], Batch [93/147] train loss: 566.63, train corr: -0.00020
Epoch [91/100], Batch [94/147] train loss: 572.61, train corr: -0.00051
Epoch [91/100], Batch [95/147] train loss: 556.34, train corr: -0.00008
Epoch [91/100], Batch [96/147] train loss: 579.70, train corr: -0.00021
Epoch [91/100], Batch [97/147] train loss: 573.44, train corr: -0.00029
Epoch [91/100], Batch [98/147] train loss: 574.05, train corr: 0.00003
Epoch [91/100], Batch [99/147] train loss: 560.53, train corr: -0.00064
Epoch [91/100], Batch [100/147] train loss: 561.93, train corr: -0.00082
Epoch [91/100], Batch [101/147] train loss: 575.02, train corr: -0.00019
Epoch [91/100], Batch [102/147] train loss: 583.86, train corr: -0.00009
Epoch [91/100], Batch [103/147] train loss: 633.54, train corr: -0.00078
Epoch [91/100], Batch [104/147] train loss: 553.42, train corr: -0.00028
Epoch [91/100], Batch [105/147] train loss: 570.80, train corr: -0.00057
Epoch [91/100], Batch [106/147] train loss: 572.98, train corr: -0.00061
Epoch [91/100], Batch [107/147] train loss: 578.18, train corr: -0.00137
Epoch [91/100], Batch [108/147] train loss: 591.36, train corr: -0.00082
Epoch [91/100], Batch [109/147] train loss: 576.41, train corr: -0.00066
Epoch [91/100], Batch [110/147] train loss: 568.00, train corr: -0.00011
Epoch [91/100], Batch [111/147] train loss: 572.82, train corr: -0.00043
Epoch [91/100], Batch [112/147] train loss: 565.94, train corr: -0.00046
Epoch [91/100], Batch [113/147] train loss: 574.98, train corr: -0.00048
Epoch [91/100], Batch [114/147] train loss: 566.85, train corr: 0.00044
Epoch [91/100], Batch [115/147] train loss: 567.12, train corr: 0.00046
Epoch [91/100], Batch [116/147] train loss: 560.86, train corr: 0.00054
Epoch [91/100], Batch [117/147] train loss: 566.00, train corr: 0.00017
Epoch [91/100], Batch [118/147] train loss: 560.34, train corr: 0.00082
Epoch [91/100], Batch [119/147] train loss: 567.92, train corr: 0.00128
Epoch [91/100], Batch [120/147] train loss: 581.61, train corr: 0.00037
Epoch [91/100], Batch [121/147] train loss: 570.63, train corr: 0.00054
Epoch [91/100], Batch [122/147] train loss: 570.36, train corr: 0.00071
Epoch [91/100], Batch [123/147] train loss: 557.01, train corr: 0.00148
Epoch [91/100], Batch [124/147] train loss: 577.30, train corr: 0.00150
Epoch [91/100], Batch [125/147] train loss: 558.25, train corr: 0.00123
Epoch [91/100], Batch [126/147] train loss: 561.43, train corr: 0.00102
Epoch [91/100], Batch [127/147] train loss: 570.72, train corr: 0.00153
Epoch [91/100], Batch [128/147] train loss: 567.04, train corr: 0.00158
Epoch [91/100], Batch [129/147] train loss: 554.34, train corr: 0.00209
Epoch [91/100], Batch [130/147] train loss: 562.69, train corr: 0.00136
Epoch [91/100], Batch [131/147] train loss: 564.30, train corr: 0.00155
Epoch [91/100], Batch [132/147] train loss: 554.09, train corr: 0.00134
Epoch [91/100], Batch [133/147] train loss: 573.16, train corr: 0.00111
Epoch [91/100], Batch [134/147] train loss: 562.14, train corr: 0.00133
Epoch [91/100], Batch [135/147] train loss: 560.01, train corr: 0.00105
Epoch [91/100], Batch [136/147] train loss: 563.46, train corr: 0.00074
Epoch [91/100], Batch [137/147] train loss: 575.72, train corr: 0.00007
Epoch [91/100], Batch [138/147] train loss: 579.49, train corr: -0.00027
Epoch [91/100], Batch [139/147] train loss: 573.03, train corr: 0.00029
Epoch [91/100], Batch [140/147] train loss: 557.75, train corr: 0.00028
Epoch [91/100], Batch [141/147] train loss: 565.25, train corr: 0.00055
Epoch [91/100], Batch [142/147] train loss: 581.50, train corr: 0.00021
Epoch [91/100], Batch [143/147] train loss: 555.43, train corr: -0.00025
Epoch [91/100], Batch [144/147] train loss: 560.45, train corr: -0.00049
Epoch [91/100], Batch [145/147] train loss: 745.23, train corr: -0.00068
Epoch [91/100], Batch [146/147] train loss: 589.58, train corr: -0.01375
Epoch [91/100], Batch [147/147] train loss: 572.15, train corr: -0.00719
Epoch [91/100], validation loss: 607.22, validation correlation: -0.00043
Epoch [92/100], Batch [1/147] train loss: 574.55, train corr: 0.00025
Epoch [92/100], Batch [2/147] train loss: 589.88, train corr: -0.00079
Epoch [92/100], Batch [3/147] train loss: 565.13, train corr: -0.00724
Epoch [92/100], Batch [4/147] train loss: 567.19, train corr: -0.01606
Epoch [92/100], Batch [5/147] train loss: 577.93, train corr: -0.02247
Epoch [92/100], Batch [6/147] train loss: 572.50, train corr: -0.02004
Epoch [92/100], Batch [7/147] train loss: 577.31, train corr: -0.01560
Epoch [92/100], Batch [8/147] train loss: 573.36, train corr: -0.01149
Epoch [92/100], Batch [9/147] train loss: 563.91, train corr: -0.01509
Epoch [92/100], Batch [10/147] train loss: 570.03, train corr: -0.01603
Epoch [92/100], Batch [11/147] train loss: 563.33, train corr: -0.01957
Epoch [92/100], Batch [12/147] train loss: 599.23, train corr: -0.01492
Epoch [92/100], Batch [13/147] train loss: 565.99, train corr: -0.01565
Epoch [92/100], Batch [14/147] train loss: 576.44, train corr: -0.01190
Epoch [92/100], Batch [15/147] train loss: 559.97, train corr: -0.01124
Epoch [92/100], Batch [16/147] train loss: 578.03, train corr: -0.01047
Epoch [92/100], Batch [17/147] train loss: 569.08, train corr: -0.01443
Epoch [92/100], Batch [18/147] train loss: 561.80, train corr: -0.01555
Epoch [92/100], Batch [19/147] train loss: 562.04, train corr: -0.01221
Epoch [92/100], Batch [20/147] train loss: 572.33, train corr: -0.00731
Epoch [92/100], Batch [21/147] train loss: 568.92, train corr: -0.00455
Epoch [92/100], Batch [22/147] train loss: 611.03, train corr: -0.00326
Epoch [92/100], Batch [23/147] train loss: 571.52, train corr: -0.00591
Epoch [92/100], Batch [24/147] train loss: 562.73, train corr: -0.00772
Epoch [92/100], Batch [25/147] train loss: 577.73, train corr: -0.00416
Epoch [92/100], Batch [26/147] train loss: 572.41, train corr: 0.00008
Epoch [92/100], Batch [27/147] train loss: 563.57, train corr: 0.00353
Epoch [92/100], Batch [28/147] train loss: 571.57, train corr: 0.00487
Epoch [92/100], Batch [29/147] train loss: 561.23, train corr: 0.00335
Epoch [92/100], Batch [30/147] train loss: 569.35, train corr: 0.00232
Epoch [92/100], Batch [31/147] train loss: 550.51, train corr: 0.00290
Epoch [92/100], Batch [32/147] train loss: 566.37, train corr: 0.00691
Epoch [92/100], Batch [33/147] train loss: 633.25, train corr: 0.00820
Epoch [92/100], Batch [34/147] train loss: 554.97, train corr: 0.01147
Epoch [92/100], Batch [35/147] train loss: 575.82, train corr: 0.00948
Epoch [92/100], Batch [36/147] train loss: 627.09, train corr: 0.00960
Epoch [92/100], Batch [37/147] train loss: 558.83, train corr: 0.01181
Epoch [92/100], Batch [38/147] train loss: 553.47, train corr: 0.01568
Epoch [92/100], Batch [39/147] train loss: 567.18, train corr: 0.01446
Epoch [92/100], Batch [40/147] train loss: 565.47, train corr: 0.01640
Epoch [92/100], Batch [41/147] train loss: 568.23, train corr: 0.01528
Epoch [92/100], Batch [42/147] train loss: 565.80, train corr: 0.01535
Epoch [92/100], Batch [43/147] train loss: 564.94, train corr: 0.01477
Epoch [92/100], Batch [44/147] train loss: 558.28, train corr: 0.01788
Epoch [92/100], Batch [45/147] train loss: 586.11, train corr: 0.01524
Epoch [92/100], Batch [46/147] train loss: 570.19, train corr: 0.01557
Epoch [92/100], Batch [47/147] train loss: 579.79, train corr: 0.01321
Epoch [92/100], Batch [48/147] train loss: 580.78, train corr: 0.01251
Epoch [92/100], Batch [49/147] train loss: 575.32, train corr: 0.01415
Epoch [92/100], Batch [50/147] train loss: 591.11, train corr: 0.01162
Epoch [92/100], Batch [51/147] train loss: 570.82, train corr: 0.01049
Epoch [92/100], Batch [52/147] train loss: 560.71, train corr: 0.00980
Epoch [92/100], Batch [53/147] train loss: 560.85, train corr: 0.00834
Epoch [92/100], Batch [54/147] train loss: 574.76, train corr: 0.00588
Epoch [92/100], Batch [55/147] train loss: 552.35, train corr: 0.00552
Epoch [92/100], Batch [56/147] train loss: 567.12, train corr: 0.00445
Epoch [92/100], Batch [57/147] train loss: 552.10, train corr: 0.00423
Epoch [92/100], Batch [58/147] train loss: 565.04, train corr: 0.00294
Epoch [92/100], Batch [59/147] train loss: 565.23, train corr: 0.00128
Epoch [92/100], Batch [60/147] train loss: 554.49, train corr: -0.00012
Epoch [92/100], Batch [61/147] train loss: 564.72, train corr: -0.00037
Epoch [92/100], Batch [62/147] train loss: 554.86, train corr: -0.00202
Epoch [92/100], Batch [63/147] train loss: 571.86, train corr: -0.00167
Epoch [92/100], Batch [64/147] train loss: 557.66, train corr: -0.00237
Epoch [92/100], Batch [65/147] train loss: 581.98, train corr: -0.00324
Epoch [92/100], Batch [66/147] train loss: 574.14, train corr: -0.00424
Epoch [92/100], Batch [67/147] train loss: 587.02, train corr: -0.00382
Epoch [92/100], Batch [68/147] train loss: 560.17, train corr: -0.00329
Epoch [92/100], Batch [69/147] train loss: 556.30, train corr: -0.00261
Epoch [92/100], Batch [70/147] train loss: 567.94, train corr: -0.00226
Epoch [92/100], Batch [71/147] train loss: 558.81, train corr: -0.00229
Epoch [92/100], Batch [72/147] train loss: 559.01, train corr: -0.00257
Epoch [92/100], Batch [73/147] train loss: 586.06, train corr: -0.00187
Epoch [92/100], Batch [74/147] train loss: 580.60, train corr: -0.00020
Epoch [92/100], Batch [75/147] train loss: 559.38, train corr: -0.00078
Epoch [92/100], Batch [76/147] train loss: 563.81, train corr: -0.00023
Epoch [92/100], Batch [77/147] train loss: 556.58, train corr: 0.00140
Epoch [92/100], Batch [78/147] train loss: 560.76, train corr: 0.00021
Epoch [92/100], Batch [79/147] train loss: 557.12, train corr: 0.00085
Epoch [92/100], Batch [80/147] train loss: 573.78, train corr: 0.00114
Epoch [92/100], Batch [81/147] train loss: 572.53, train corr: 0.00284
Epoch [92/100], Batch [82/147] train loss: 573.87, train corr: 0.00278
Epoch [92/100], Batch [83/147] train loss: 562.81, train corr: 0.00339
Epoch [92/100], Batch [84/147] train loss: 561.53, train corr: 0.00334
Epoch [92/100], Batch [85/147] train loss: 558.52, train corr: 0.00440
Epoch [92/100], Batch [86/147] train loss: 567.45, train corr: 0.00507
Epoch [92/100], Batch [87/147] train loss: 590.81, train corr: 0.00415
Epoch [92/100], Batch [88/147] train loss: 572.54, train corr: 0.00638
Epoch [92/100], Batch [89/147] train loss: 551.57, train corr: 0.00774
Epoch [92/100], Batch [90/147] train loss: 571.51, train corr: 0.00701
Epoch [92/100], Batch [91/147] train loss: 568.96, train corr: 0.00669
Epoch [92/100], Batch [92/147] train loss: 560.05, train corr: 0.00796
Epoch [92/100], Batch [93/147] train loss: 575.36, train corr: 0.00946
Epoch [92/100], Batch [94/147] train loss: 563.61, train corr: 0.01061
Epoch [92/100], Batch [95/147] train loss: 572.09, train corr: 0.01003
Epoch [92/100], Batch [96/147] train loss: 560.67, train corr: 0.01141
Epoch [92/100], Batch [97/147] train loss: 576.10, train corr: 0.01004
Epoch [92/100], Batch [98/147] train loss: 558.99, train corr: 0.01229
Epoch [92/100], Batch [99/147] train loss: 591.26, train corr: 0.00929
Epoch [92/100], Batch [100/147] train loss: 561.82, train corr: 0.01192
Epoch [92/100], Batch [101/147] train loss: 559.09, train corr: 0.01158
Epoch [92/100], Batch [102/147] train loss: 577.09, train corr: 0.01181
Epoch [92/100], Batch [103/147] train loss: 559.18, train corr: 0.01206
Epoch [92/100], Batch [104/147] train loss: 583.96, train corr: 0.01151
Epoch [92/100], Batch [105/147] train loss: 557.77, train corr: 0.01229
Epoch [92/100], Batch [106/147] train loss: 572.17, train corr: 0.01270
Epoch [92/100], Batch [107/147] train loss: 555.13, train corr: 0.01242
Epoch [92/100], Batch [108/147] train loss: 571.25, train corr: 0.01294
Epoch [92/100], Batch [109/147] train loss: 573.66, train corr: 0.01117
Epoch [92/100], Batch [110/147] train loss: 566.13, train corr: 0.01281
Epoch [92/100], Batch [111/147] train loss: 581.25, train corr: 0.01108
Epoch [92/100], Batch [112/147] train loss: 576.65, train corr: 0.01273
Epoch [92/100], Batch [113/147] train loss: 560.23, train corr: 0.01246
Epoch [92/100], Batch [114/147] train loss: 582.81, train corr: 0.00954
Epoch [92/100], Batch [115/147] train loss: 556.59, train corr: 0.01286
Epoch [92/100], Batch [116/147] train loss: 565.23, train corr: 0.01207
Epoch [92/100], Batch [117/147] train loss: 570.35, train corr: 0.01168
Epoch [92/100], Batch [118/147] train loss: 562.16, train corr: 0.01120
Epoch [92/100], Batch [119/147] train loss: 580.66, train corr: 0.01249
Epoch [92/100], Batch [120/147] train loss: 558.35, train corr: 0.01247
Epoch [92/100], Batch [121/147] train loss: 575.89, train corr: 0.01056
Epoch [92/100], Batch [122/147] train loss: 566.50, train corr: 0.01075
Epoch [92/100], Batch [123/147] train loss: 560.50, train corr: 0.00961
Epoch [92/100], Batch [124/147] train loss: 577.90, train corr: 0.00911
Epoch [92/100], Batch [125/147] train loss: 566.94, train corr: 0.01040
Epoch [92/100], Batch [126/147] train loss: 562.96, train corr: 0.01037
Epoch [92/100], Batch [127/147] train loss: 762.92, train corr: 0.00901
Epoch [92/100], Batch [128/147] train loss: 585.28, train corr: -0.01692
Epoch [92/100], Batch [129/147] train loss: 577.66, train corr: -0.00103
Epoch [92/100], Batch [130/147] train loss: 586.88, train corr: 0.01084
Epoch [92/100], Batch [131/147] train loss: 578.14, train corr: 0.01262
Epoch [92/100], Batch [132/147] train loss: 575.98, train corr: -0.00181
Epoch [92/100], Batch [133/147] train loss: 564.00, train corr: -0.01940
Epoch [92/100], Batch [134/147] train loss: 571.66, train corr: -0.02499
Epoch [92/100], Batch [135/147] train loss: 567.43, train corr: -0.02140
Epoch [92/100], Batch [136/147] train loss: 573.03, train corr: -0.01116
Epoch [92/100], Batch [137/147] train loss: 592.79, train corr: -0.00081
Epoch [92/100], Batch [138/147] train loss: 585.12, train corr: -0.00187
Epoch [92/100], Batch [139/147] train loss: 577.36, train corr: -0.00855
Epoch [92/100], Batch [140/147] train loss: 576.71, train corr: -0.01718
Epoch [92/100], Batch [141/147] train loss: 567.27, train corr: -0.01423
Epoch [92/100], Batch [142/147] train loss: 564.09, train corr: -0.00041
Epoch [92/100], Batch [143/147] train loss: 563.40, train corr: 0.01217
Epoch [92/100], Batch [144/147] train loss: 566.74, train corr: 0.01466
Epoch [92/100], Batch [145/147] train loss: 576.13, train corr: 0.01301
Epoch [92/100], Batch [146/147] train loss: 576.83, train corr: 0.00845
Epoch [92/100], Batch [147/147] train loss: 1093.19, train corr: 0.00734
Epoch [92/100], validation loss: 602.76, validation correlation: 0.02257
Epoch [93/100], Batch [1/147] train loss: 565.40, train corr: 0.02312
Epoch [93/100], Batch [2/147] train loss: 606.35, train corr: 0.02053
Epoch [93/100], Batch [3/147] train loss: 582.10, train corr: 0.02369
Epoch [93/100], Batch [4/147] train loss: 576.64, train corr: 0.02271
Epoch [93/100], Batch [5/147] train loss: 586.16, train corr: 0.01825
Epoch [93/100], Batch [6/147] train loss: 570.88, train corr: 0.01812
Epoch [93/100], Batch [7/147] train loss: 583.10, train corr: 0.02236
Epoch [93/100], Batch [8/147] train loss: 586.54, train corr: 0.02493
Epoch [93/100], Batch [9/147] train loss: 595.53, train corr: 0.02593
Epoch [93/100], Batch [10/147] train loss: 577.63, train corr: 0.02403
Epoch [93/100], Batch [11/147] train loss: 581.53, train corr: 0.02378
Epoch [93/100], Batch [12/147] train loss: 582.69, train corr: 0.02309
Epoch [93/100], Batch [13/147] train loss: 588.07, train corr: 0.02275
Epoch [93/100], Batch [14/147] train loss: 575.38, train corr: 0.02503
Epoch [93/100], Batch [15/147] train loss: 574.45, train corr: 0.02362
Epoch [93/100], Batch [16/147] train loss: 551.45, train corr: 0.02556
Epoch [93/100], Batch [17/147] train loss: 572.66, train corr: 0.02531
Epoch [93/100], Batch [18/147] train loss: 582.20, train corr: 0.02354
Epoch [93/100], Batch [19/147] train loss: 557.07, train corr: 0.02145
Epoch [93/100], Batch [20/147] train loss: 563.01, train corr: 0.02266
Epoch [93/100], Batch [21/147] train loss: 574.19, train corr: 0.02140
Epoch [93/100], Batch [22/147] train loss: 563.50, train corr: 0.02065
Epoch [93/100], Batch [23/147] train loss: 577.54, train corr: 0.02120
Epoch [93/100], Batch [24/147] train loss: 582.80, train corr: 0.01463
Epoch [93/100], Batch [25/147] train loss: 574.82, train corr: 0.01676
Epoch [93/100], Batch [26/147] train loss: 571.26, train corr: 0.01912
Epoch [93/100], Batch [27/147] train loss: 569.86, train corr: 0.01733
Epoch [93/100], Batch [28/147] train loss: 582.31, train corr: 0.01764
Epoch [93/100], Batch [29/147] train loss: 563.29, train corr: 0.01871
Epoch [93/100], Batch [30/147] train loss: 577.06, train corr: 0.01879
Epoch [93/100], Batch [31/147] train loss: 561.36, train corr: 0.01683
Epoch [93/100], Batch [32/147] train loss: 565.97, train corr: 0.01765
Epoch [93/100], Batch [33/147] train loss: 564.55, train corr: 0.01750
Epoch [93/100], Batch [34/147] train loss: 585.77, train corr: 0.01803
Epoch [93/100], Batch [35/147] train loss: 585.53, train corr: 0.01669
Epoch [93/100], Batch [36/147] train loss: 565.74, train corr: 0.01717
Epoch [93/100], Batch [37/147] train loss: 570.84, train corr: 0.01691
Epoch [93/100], Batch [38/147] train loss: 550.55, train corr: 0.01786
Epoch [93/100], Batch [39/147] train loss: 562.43, train corr: 0.01968
Epoch [93/100], Batch [40/147] train loss: 638.63, train corr: 0.01832
Epoch [93/100], Batch [41/147] train loss: 566.24, train corr: 0.01893
Epoch [93/100], Batch [42/147] train loss: 576.37, train corr: 0.01782
Epoch [93/100], Batch [43/147] train loss: 580.49, train corr: 0.01615
Epoch [93/100], Batch [44/147] train loss: 574.83, train corr: 0.01678
Epoch [93/100], Batch [45/147] train loss: 581.38, train corr: 0.01777
Epoch [93/100], Batch [46/147] train loss: 567.21, train corr: 0.01808
Epoch [93/100], Batch [47/147] train loss: 586.77, train corr: 0.01656
Epoch [93/100], Batch [48/147] train loss: 563.16, train corr: 0.01652
Epoch [93/100], Batch [49/147] train loss: 580.04, train corr: 0.01540
Epoch [93/100], Batch [50/147] train loss: 572.25, train corr: 0.01771
Epoch [93/100], Batch [51/147] train loss: 561.10, train corr: 0.01832
Epoch [93/100], Batch [52/147] train loss: 582.29, train corr: 0.01602
Epoch [93/100], Batch [53/147] train loss: 566.08, train corr: 0.01623
Epoch [93/100], Batch [54/147] train loss: 569.56, train corr: 0.01377
Epoch [93/100], Batch [55/147] train loss: 558.63, train corr: 0.01666
Epoch [93/100], Batch [56/147] train loss: 563.65, train corr: 0.01956
Epoch [93/100], Batch [57/147] train loss: 586.98, train corr: 0.01413
Epoch [93/100], Batch [58/147] train loss: 561.25, train corr: 0.01761
Epoch [93/100], Batch [59/147] train loss: 559.18, train corr: 0.01881
Epoch [93/100], Batch [60/147] train loss: 570.25, train corr: 0.01797
Epoch [93/100], Batch [61/147] train loss: 577.07, train corr: 0.01893
Epoch [93/100], Batch [62/147] train loss: 570.84, train corr: 0.01830
Epoch [93/100], Batch [63/147] train loss: 586.23, train corr: 0.01824
Epoch [93/100], Batch [64/147] train loss: 560.49, train corr: 0.02078
Epoch [93/100], Batch [65/147] train loss: 635.85, train corr: 0.01513
Epoch [93/100], Batch [66/147] train loss: 558.27, train corr: 0.01979
Epoch [93/100], Batch [67/147] train loss: 562.26, train corr: 0.02097
Epoch [93/100], Batch [68/147] train loss: 564.51, train corr: 0.02133
Epoch [93/100], Batch [69/147] train loss: 565.42, train corr: 0.02074
Epoch [93/100], Batch [70/147] train loss: 574.29, train corr: 0.01976
Epoch [93/100], Batch [71/147] train loss: 556.35, train corr: 0.02353
Epoch [93/100], Batch [72/147] train loss: 555.77, train corr: 0.02255
Epoch [93/100], Batch [73/147] train loss: 578.52, train corr: 0.02049
Epoch [93/100], Batch [74/147] train loss: 574.06, train corr: 0.02011
Epoch [93/100], Batch [75/147] train loss: 560.73, train corr: 0.02221
Epoch [93/100], Batch [76/147] train loss: 580.49, train corr: 0.02257
Epoch [93/100], Batch [77/147] train loss: 577.64, train corr: 0.01940
Epoch [93/100], Batch [78/147] train loss: 593.61, train corr: 0.02019
Epoch [93/100], Batch [79/147] train loss: 582.00, train corr: 0.02140
Epoch [93/100], Batch [80/147] train loss: 554.35, train corr: 0.02257
Epoch [93/100], Batch [81/147] train loss: 563.62, train corr: 0.02197
Epoch [93/100], Batch [82/147] train loss: 577.56, train corr: 0.01775
Epoch [93/100], Batch [83/147] train loss: 555.39, train corr: 0.01898
Epoch [93/100], Batch [84/147] train loss: 568.90, train corr: 0.01829
Epoch [93/100], Batch [85/147] train loss: 579.53, train corr: 0.01794
Epoch [93/100], Batch [86/147] train loss: 565.15, train corr: 0.01691
Epoch [93/100], Batch [87/147] train loss: 580.11, train corr: 0.01643
Epoch [93/100], Batch [88/147] train loss: 573.29, train corr: 0.01839
Epoch [93/100], Batch [89/147] train loss: 571.39, train corr: 0.01639
Epoch [93/100], Batch [90/147] train loss: 574.27, train corr: 0.01493
Epoch [93/100], Batch [91/147] train loss: 551.39, train corr: 0.01795
Epoch [93/100], Batch [92/147] train loss: 557.90, train corr: 0.01904
Epoch [93/100], Batch [93/147] train loss: 555.03, train corr: 0.01799
Epoch [93/100], Batch [94/147] train loss: 564.52, train corr: 0.01844
Epoch [93/100], Batch [95/147] train loss: 562.80, train corr: 0.01843
Epoch [93/100], Batch [96/147] train loss: 575.60, train corr: 0.02036
Epoch [93/100], Batch [97/147] train loss: 568.20, train corr: 0.02113
Epoch [93/100], Batch [98/147] train loss: 551.25, train corr: 0.02134
Epoch [93/100], Batch [99/147] train loss: 550.02, train corr: 0.01985
Epoch [93/100], Batch [100/147] train loss: 565.82, train corr: 0.02149
Epoch [93/100], Batch [101/147] train loss: 561.39, train corr: 0.02286
Epoch [93/100], Batch [102/147] train loss: 576.60, train corr: 0.02003
Epoch [93/100], Batch [103/147] train loss: 560.76, train corr: 0.02145
Epoch [93/100], Batch [104/147] train loss: 571.47, train corr: 0.01954
Epoch [93/100], Batch [105/147] train loss: 734.33, train corr: 0.01926
Epoch [93/100], Batch [106/147] train loss: 587.35, train corr: -0.01428
Epoch [93/100], Batch [107/147] train loss: 565.00, train corr: 0.01017
Epoch [93/100], Batch [108/147] train loss: 584.17, train corr: 0.01947
Epoch [93/100], Batch [109/147] train loss: 592.20, train corr: 0.01900
Epoch [93/100], Batch [110/147] train loss: 568.38, train corr: 0.00876
Epoch [93/100], Batch [111/147] train loss: 554.19, train corr: -0.01680
Epoch [93/100], Batch [112/147] train loss: 828.47, train corr: -0.01575
Epoch [93/100], Batch [113/147] train loss: 585.68, train corr: 0.01315
Epoch [93/100], Batch [114/147] train loss: 576.50, train corr: 0.02769
Epoch [93/100], Batch [115/147] train loss: 617.74, train corr: 0.02144
Epoch [93/100], Batch [116/147] train loss: 587.60, train corr: 0.02502
Epoch [93/100], Batch [117/147] train loss: 604.22, train corr: 0.02357
Epoch [93/100], Batch [118/147] train loss: 573.10, train corr: 0.02278
Epoch [93/100], Batch [119/147] train loss: 574.83, train corr: 0.02416
Epoch [93/100], Batch [120/147] train loss: 572.07, train corr: 0.02599
Epoch [93/100], Batch [121/147] train loss: 576.79, train corr: 0.02995
Epoch [93/100], Batch [122/147] train loss: 566.00, train corr: 0.02721
Epoch [93/100], Batch [123/147] train loss: 569.44, train corr: 0.02759
Epoch [93/100], Batch [124/147] train loss: 577.24, train corr: 0.02788
Epoch [93/100], Batch [125/147] train loss: 559.41, train corr: 0.02867
Epoch [93/100], Batch [126/147] train loss: 576.51, train corr: 0.02767
Epoch [93/100], Batch [127/147] train loss: 579.75, train corr: 0.02199
Epoch [93/100], Batch [128/147] train loss: 590.93, train corr: 0.02274
Epoch [93/100], Batch [129/147] train loss: 570.54, train corr: 0.02831
Epoch [93/100], Batch [130/147] train loss: 551.80, train corr: 0.02877
Epoch [93/100], Batch [131/147] train loss: 572.85, train corr: 0.02593
Epoch [93/100], Batch [132/147] train loss: 574.04, train corr: 0.02787
Epoch [93/100], Batch [133/147] train loss: 565.13, train corr: 0.02519
Epoch [93/100], Batch [134/147] train loss: 571.76, train corr: 0.02271
Epoch [93/100], Batch [135/147] train loss: 558.71, train corr: 0.02926
Epoch [93/100], Batch [136/147] train loss: 565.95, train corr: 0.02238
Epoch [93/100], Batch [137/147] train loss: 553.16, train corr: 0.03038
Epoch [93/100], Batch [138/147] train loss: 571.38, train corr: 0.02475
Epoch [93/100], Batch [139/147] train loss: 552.37, train corr: 0.02733
Epoch [93/100], Batch [140/147] train loss: 563.30, train corr: 0.02298
Epoch [93/100], Batch [141/147] train loss: 569.47, train corr: 0.02898
Epoch [93/100], Batch [142/147] train loss: 578.90, train corr: 0.02429
Epoch [93/100], Batch [143/147] train loss: 566.92, train corr: 0.02445
Epoch [93/100], Batch [144/147] train loss: 575.40, train corr: 0.02632
Epoch [93/100], Batch [145/147] train loss: 546.57, train corr: 0.02433
Epoch [93/100], Batch [146/147] train loss: 566.56, train corr: 0.01885
Epoch [93/100], Batch [147/147] train loss: 567.92, train corr: 0.02465
Epoch [93/100], validation loss: 598.25, validation correlation: 0.02428
Epoch [94/100], Batch [1/147] train loss: 565.33, train corr: 0.02667
Epoch [94/100], Batch [2/147] train loss: 586.82, train corr: 0.02082
Epoch [94/100], Batch [3/147] train loss: 582.07, train corr: 0.02223
Epoch [94/100], Batch [4/147] train loss: 742.12, train corr: 0.01910
Epoch [94/100], Batch [5/147] train loss: 591.21, train corr: -0.01406
Epoch [94/100], Batch [6/147] train loss: 559.08, train corr: 0.01115
Epoch [94/100], Batch [7/147] train loss: 590.33, train corr: 0.01851
Epoch [94/100], Batch [8/147] train loss: 579.81, train corr: 0.02536
Epoch [94/100], Batch [9/147] train loss: 563.81, train corr: 0.01848
Epoch [94/100], Batch [10/147] train loss: 573.69, train corr: -0.00372
Epoch [94/100], Batch [11/147] train loss: 577.75, train corr: -0.01932
Epoch [94/100], Batch [12/147] train loss: 567.53, train corr: -0.02085
Epoch [94/100], Batch [13/147] train loss: 559.12, train corr: -0.01389
Epoch [94/100], Batch [14/147] train loss: 574.47, train corr: 0.00502
Epoch [94/100], Batch [15/147] train loss: 577.88, train corr: 0.01389
Epoch [94/100], Batch [16/147] train loss: 573.47, train corr: 0.01631
Epoch [94/100], Batch [17/147] train loss: 567.46, train corr: 0.00821
Epoch [94/100], Batch [18/147] train loss: 586.22, train corr: 0.00078
Epoch [94/100], Batch [19/147] train loss: 563.64, train corr: 0.00302
Epoch [94/100], Batch [20/147] train loss: 556.25, train corr: 0.01593
Epoch [94/100], Batch [21/147] train loss: 581.91, train corr: 0.02293
Epoch [94/100], Batch [22/147] train loss: 555.53, train corr: 0.02558
Epoch [94/100], Batch [23/147] train loss: 569.29, train corr: 0.02445
Epoch [94/100], Batch [24/147] train loss: 590.40, train corr: 0.02397
Epoch [94/100], Batch [25/147] train loss: 575.35, train corr: 0.02263
Epoch [94/100], Batch [26/147] train loss: 567.30, train corr: 0.02654
Epoch [94/100], Batch [27/147] train loss: 546.10, train corr: 0.02727
Epoch [94/100], Batch [28/147] train loss: 565.72, train corr: 0.02620
Epoch [94/100], Batch [29/147] train loss: 559.67, train corr: 0.02431
Epoch [94/100], Batch [30/147] train loss: 580.77, train corr: 0.02235
Epoch [94/100], Batch [31/147] train loss: 553.27, train corr: 0.02823
Epoch [94/100], Batch [32/147] train loss: 581.13, train corr: 0.02329
Epoch [94/100], Batch [33/147] train loss: 561.46, train corr: 0.02548
Epoch [94/100], Batch [34/147] train loss: 559.49, train corr: 0.02679
Epoch [94/100], Batch [35/147] train loss: 572.86, train corr: 0.02129
Epoch [94/100], Batch [36/147] train loss: 555.77, train corr: 0.02782
Epoch [94/100], Batch [37/147] train loss: 559.42, train corr: 0.02659
Epoch [94/100], Batch [38/147] train loss: 565.13, train corr: 0.02530
Epoch [94/100], Batch [39/147] train loss: 567.66, train corr: 0.02493
Epoch [94/100], Batch [40/147] train loss: 565.85, train corr: 0.02713
Epoch [94/100], Batch [41/147] train loss: 584.36, train corr: 0.02342
Epoch [94/100], Batch [42/147] train loss: 552.32, train corr: 0.02617
Epoch [94/100], Batch [43/147] train loss: 563.27, train corr: 0.02651
Epoch [94/100], Batch [44/147] train loss: 559.69, train corr: 0.02341
Epoch [94/100], Batch [45/147] train loss: 561.39, train corr: 0.02596
Epoch [94/100], Batch [46/147] train loss: 580.56, train corr: 0.02253
Epoch [94/100], Batch [47/147] train loss: 626.51, train corr: 0.02313
Epoch [94/100], Batch [48/147] train loss: 574.47, train corr: 0.02291
Epoch [94/100], Batch [49/147] train loss: 554.88, train corr: 0.02414
Epoch [94/100], Batch [50/147] train loss: 576.19, train corr: 0.02385
Epoch [94/100], Batch [51/147] train loss: 558.49, train corr: 0.02396
Epoch [94/100], Batch [52/147] train loss: 571.03, train corr: 0.02108
Epoch [94/100], Batch [53/147] train loss: 576.13, train corr: 0.02035
Epoch [94/100], Batch [54/147] train loss: 561.77, train corr: 0.02343
Epoch [94/100], Batch [55/147] train loss: 567.17, train corr: 0.02363
Epoch [94/100], Batch [56/147] train loss: 573.36, train corr: 0.02253
Epoch [94/100], Batch [57/147] train loss: 588.39, train corr: 0.02272
Epoch [94/100], Batch [58/147] train loss: 566.45, train corr: 0.02093
Epoch [94/100], Batch [59/147] train loss: 564.20, train corr: 0.02303
Epoch [94/100], Batch [60/147] train loss: 569.30, train corr: 0.02165
Epoch [94/100], Batch [61/147] train loss: 575.53, train corr: 0.02263
Epoch [94/100], Batch [62/147] train loss: 564.54, train corr: 0.02253
Epoch [94/100], Batch [63/147] train loss: 570.93, train corr: 0.01999
Epoch [94/100], Batch [64/147] train loss: 592.10, train corr: 0.02296
Epoch [94/100], Batch [65/147] train loss: 554.07, train corr: 0.02585
Epoch [94/100], Batch [66/147] train loss: 575.05, train corr: 0.02247
Epoch [94/100], Batch [67/147] train loss: 556.82, train corr: 0.02628
Epoch [94/100], Batch [68/147] train loss: 575.98, train corr: 0.02472
Epoch [94/100], Batch [69/147] train loss: 574.91, train corr: 0.02246
Epoch [94/100], Batch [70/147] train loss: 557.77, train corr: 0.02436
Epoch [94/100], Batch [71/147] train loss: 554.36, train corr: 0.02608
Epoch [94/100], Batch [72/147] train loss: 566.13, train corr: 0.02687
Epoch [94/100], Batch [73/147] train loss: 574.79, train corr: 0.02713
Epoch [94/100], Batch [74/147] train loss: 550.59, train corr: 0.02742
Epoch [94/100], Batch [75/147] train loss: 568.13, train corr: 0.02662
Epoch [94/100], Batch [76/147] train loss: 558.07, train corr: 0.02350
Epoch [94/100], Batch [77/147] train loss: 579.44, train corr: 0.02529
Epoch [94/100], Batch [78/147] train loss: 562.82, train corr: 0.02562
Epoch [94/100], Batch [79/147] train loss: 557.78, train corr: 0.02555
Epoch [94/100], Batch [80/147] train loss: 561.00, train corr: 0.02418
Epoch [94/100], Batch [81/147] train loss: 593.98, train corr: 0.02644
Epoch [94/100], Batch [82/147] train loss: 564.34, train corr: 0.02526
Epoch [94/100], Batch [83/147] train loss: 565.08, train corr: 0.02449
Epoch [94/100], Batch [84/147] train loss: 560.12, train corr: 0.02775
Epoch [94/100], Batch [85/147] train loss: 571.52, train corr: 0.02406
Epoch [94/100], Batch [86/147] train loss: 571.59, train corr: 0.03039
Epoch [94/100], Batch [87/147] train loss: 569.54, train corr: 0.02482
Epoch [94/100], Batch [88/147] train loss: 568.60, train corr: 0.02401
Epoch [94/100], Batch [89/147] train loss: 564.41, train corr: 0.02512
Epoch [94/100], Batch [90/147] train loss: 561.61, train corr: 0.02592
Epoch [94/100], Batch [91/147] train loss: 562.17, train corr: 0.02419
Epoch [94/100], Batch [92/147] train loss: 576.63, train corr: 0.02333
Epoch [94/100], Batch [93/147] train loss: 562.43, train corr: 0.02597
Epoch [94/100], Batch [94/147] train loss: 809.43, train corr: 0.02148
Epoch [94/100], Batch [95/147] train loss: 562.92, train corr: 0.02095
Epoch [94/100], Batch [96/147] train loss: 586.31, train corr: 0.01753
Epoch [94/100], Batch [97/147] train loss: 572.93, train corr: 0.01731
Epoch [94/100], Batch [98/147] train loss: 564.71, train corr: 0.01952
Epoch [94/100], Batch [99/147] train loss: 565.50, train corr: 0.01747
Epoch [94/100], Batch [100/147] train loss: 571.81, train corr: 0.00995
Epoch [94/100], Batch [101/147] train loss: 583.95, train corr: 0.00291
Epoch [94/100], Batch [102/147] train loss: 555.91, train corr: 0.00275
Epoch [94/100], Batch [103/147] train loss: 565.82, train corr: 0.00911
Epoch [94/100], Batch [104/147] train loss: 562.68, train corr: 0.01393
Epoch [94/100], Batch [105/147] train loss: 575.69, train corr: 0.01501
Epoch [94/100], Batch [106/147] train loss: 624.46, train corr: 0.01556
Epoch [94/100], Batch [107/147] train loss: 561.51, train corr: 0.01439
Epoch [94/100], Batch [108/147] train loss: 558.08, train corr: 0.01507
Epoch [94/100], Batch [109/147] train loss: 559.35, train corr: 0.02023
Epoch [94/100], Batch [110/147] train loss: 561.46, train corr: 0.02129
Epoch [94/100], Batch [111/147] train loss: 574.89, train corr: 0.01921
Epoch [94/100], Batch [112/147] train loss: 568.07, train corr: 0.02358
Epoch [94/100], Batch [113/147] train loss: 553.21, train corr: 0.02432
Epoch [94/100], Batch [114/147] train loss: 572.11, train corr: 0.02075
Epoch [94/100], Batch [115/147] train loss: 573.01, train corr: 0.02315
Epoch [94/100], Batch [116/147] train loss: 567.50, train corr: 0.02310
Epoch [94/100], Batch [117/147] train loss: 578.77, train corr: 0.02623
Epoch [94/100], Batch [118/147] train loss: 575.01, train corr: 0.01966
Epoch [94/100], Batch [119/147] train loss: 564.91, train corr: 0.02106
Epoch [94/100], Batch [120/147] train loss: 573.69, train corr: 0.02399
Epoch [94/100], Batch [121/147] train loss: 566.29, train corr: 0.02529
Epoch [94/100], Batch [122/147] train loss: 561.77, train corr: 0.02527
Epoch [94/100], Batch [123/147] train loss: 578.38, train corr: 0.02212
Epoch [94/100], Batch [124/147] train loss: 553.97, train corr: 0.02426
Epoch [94/100], Batch [125/147] train loss: 550.44, train corr: 0.02732
Epoch [94/100], Batch [126/147] train loss: 572.82, train corr: 0.02498
Epoch [94/100], Batch [127/147] train loss: 580.58, train corr: 0.02059
Epoch [94/100], Batch [128/147] train loss: 566.47, train corr: 0.02459
Epoch [94/100], Batch [129/147] train loss: 578.03, train corr: 0.02181
Epoch [94/100], Batch [130/147] train loss: 562.85, train corr: 0.02813
Epoch [94/100], Batch [131/147] train loss: 659.53, train corr: 0.01957
Epoch [94/100], Batch [132/147] train loss: 578.78, train corr: 0.02158
Epoch [94/100], Batch [133/147] train loss: 567.27, train corr: 0.02446
Epoch [94/100], Batch [134/147] train loss: 567.34, train corr: 0.02606
Epoch [94/100], Batch [135/147] train loss: 573.58, train corr: 0.02628
Epoch [94/100], Batch [136/147] train loss: 578.46, train corr: 0.02361
Epoch [94/100], Batch [137/147] train loss: 580.58, train corr: 0.02402
Epoch [94/100], Batch [138/147] train loss: 558.12, train corr: 0.02776
Epoch [94/100], Batch [139/147] train loss: 576.43, train corr: 0.02143
Epoch [94/100], Batch [140/147] train loss: 570.07, train corr: 0.02583
Epoch [94/100], Batch [141/147] train loss: 574.08, train corr: 0.02505
Epoch [94/100], Batch [142/147] train loss: 579.46, train corr: 0.02460
Epoch [94/100], Batch [143/147] train loss: 569.90, train corr: 0.02314
Epoch [94/100], Batch [144/147] train loss: 579.86, train corr: 0.02312
Epoch [94/100], Batch [145/147] train loss: 563.09, train corr: 0.02574
Epoch [94/100], Batch [146/147] train loss: 571.49, train corr: 0.02156
Epoch [94/100], Batch [147/147] train loss: 558.29, train corr: 0.02681
Epoch [94/100], validation loss: 597.45, validation correlation: 0.02498
Epoch [95/100], Batch [1/147] train loss: 564.77, train corr: 0.02417
Epoch [95/100], Batch [2/147] train loss: 555.13, train corr: 0.02436
Epoch [95/100], Batch [3/147] train loss: 572.00, train corr: 0.02412
Epoch [95/100], Batch [4/147] train loss: 560.59, train corr: 0.02598
Epoch [95/100], Batch [5/147] train loss: 564.91, train corr: 0.02350
Epoch [95/100], Batch [6/147] train loss: 562.43, train corr: 0.02535
Epoch [95/100], Batch [7/147] train loss: 558.77, train corr: 0.02213
Epoch [95/100], Batch [8/147] train loss: 554.47, train corr: 0.02270
Epoch [95/100], Batch [9/147] train loss: 560.20, train corr: 0.02460
Epoch [95/100], Batch [10/147] train loss: 574.71, train corr: 0.01729
Epoch [95/100], Batch [11/147] train loss: 573.80, train corr: 0.02202
Epoch [95/100], Batch [12/147] train loss: 555.80, train corr: 0.02437
Epoch [95/100], Batch [13/147] train loss: 575.28, train corr: 0.02521
Epoch [95/100], Batch [14/147] train loss: 583.84, train corr: 0.02080
Epoch [95/100], Batch [15/147] train loss: 798.94, train corr: 0.02107
Epoch [95/100], Batch [16/147] train loss: 574.47, train corr: 0.01544
Epoch [95/100], Batch [17/147] train loss: 651.08, train corr: 0.01400
Epoch [95/100], Batch [18/147] train loss: 565.99, train corr: 0.02034
Epoch [95/100], Batch [19/147] train loss: 575.30, train corr: 0.02035
Epoch [95/100], Batch [20/147] train loss: 579.82, train corr: 0.02296
Epoch [95/100], Batch [21/147] train loss: 553.36, train corr: 0.02097
Epoch [95/100], Batch [22/147] train loss: 566.81, train corr: 0.01434
Epoch [95/100], Batch [23/147] train loss: 566.82, train corr: 0.01806
Epoch [95/100], Batch [24/147] train loss: 575.37, train corr: 0.02523
Epoch [95/100], Batch [25/147] train loss: 566.39, train corr: 0.02623
Epoch [95/100], Batch [26/147] train loss: 583.55, train corr: 0.02524
Epoch [95/100], Batch [27/147] train loss: 570.72, train corr: 0.02586
Epoch [95/100], Batch [28/147] train loss: 573.18, train corr: 0.02422
Epoch [95/100], Batch [29/147] train loss: 558.51, train corr: 0.02922
Epoch [95/100], Batch [30/147] train loss: 582.27, train corr: 0.02412
Epoch [95/100], Batch [31/147] train loss: 553.80, train corr: 0.02798
Epoch [95/100], Batch [32/147] train loss: 554.87, train corr: 0.02743
Epoch [95/100], Batch [33/147] train loss: 574.83, train corr: 0.02358
Epoch [95/100], Batch [34/147] train loss: 548.22, train corr: 0.02620
Epoch [95/100], Batch [35/147] train loss: 581.21, train corr: 0.02597
Epoch [95/100], Batch [36/147] train loss: 560.00, train corr: 0.02606
Epoch [95/100], Batch [37/147] train loss: 563.95, train corr: 0.02416
Epoch [95/100], Batch [38/147] train loss: 565.72, train corr: 0.02540
Epoch [95/100], Batch [39/147] train loss: 596.30, train corr: 0.02426
Epoch [95/100], Batch [40/147] train loss: 579.57, train corr: 0.02352
Epoch [95/100], Batch [41/147] train loss: 556.13, train corr: 0.02763
Epoch [95/100], Batch [42/147] train loss: 586.20, train corr: 0.02282
Epoch [95/100], Batch [43/147] train loss: 578.47, train corr: 0.02505
Epoch [95/100], Batch [44/147] train loss: 566.97, train corr: 0.02418
Epoch [95/100], Batch [45/147] train loss: 545.07, train corr: 0.02715
Epoch [95/100], Batch [46/147] train loss: 555.57, train corr: 0.02596
Epoch [95/100], Batch [47/147] train loss: 576.78, train corr: 0.02602
Epoch [95/100], Batch [48/147] train loss: 565.30, train corr: 0.02558
Epoch [95/100], Batch [49/147] train loss: 553.71, train corr: 0.02748
Epoch [95/100], Batch [50/147] train loss: 568.08, train corr: 0.02692
Epoch [95/100], Batch [51/147] train loss: 562.16, train corr: 0.02619
Epoch [95/100], Batch [52/147] train loss: 592.68, train corr: 0.02301
Epoch [95/100], Batch [53/147] train loss: 562.96, train corr: 0.02542
Epoch [95/100], Batch [54/147] train loss: 578.32, train corr: 0.02447
Epoch [95/100], Batch [55/147] train loss: 581.07, train corr: 0.02419
Epoch [95/100], Batch [56/147] train loss: 603.41, train corr: 0.01893
Epoch [95/100], Batch [57/147] train loss: 753.31, train corr: 0.02114
Epoch [95/100], Batch [58/147] train loss: 574.82, train corr: -0.00379
Epoch [95/100], Batch [59/147] train loss: 570.77, train corr: 0.01398
Epoch [95/100], Batch [60/147] train loss: 570.40, train corr: 0.02191
Epoch [95/100], Batch [61/147] train loss: 585.57, train corr: 0.02472
Epoch [95/100], Batch [62/147] train loss: 583.47, train corr: 0.01777
Epoch [95/100], Batch [63/147] train loss: 568.35, train corr: -0.00589
Epoch [95/100], Batch [64/147] train loss: 574.17, train corr: -0.01944
Epoch [95/100], Batch [65/147] train loss: 572.00, train corr: -0.01773
Epoch [95/100], Batch [66/147] train loss: 562.55, train corr: 0.00107
Epoch [95/100], Batch [67/147] train loss: 567.20, train corr: 0.01721
Epoch [95/100], Batch [68/147] train loss: 578.06, train corr: 0.02036
Epoch [95/100], Batch [69/147] train loss: 575.49, train corr: 0.01610
Epoch [95/100], Batch [70/147] train loss: 555.19, train corr: 0.00824
Epoch [95/100], Batch [71/147] train loss: 573.09, train corr: 0.00735
Epoch [95/100], Batch [72/147] train loss: 560.53, train corr: 0.02160
Epoch [95/100], Batch [73/147] train loss: 558.97, train corr: 0.02656
Epoch [95/100], Batch [74/147] train loss: 574.29, train corr: 0.02490
Epoch [95/100], Batch [75/147] train loss: 565.36, train corr: 0.02671
Epoch [95/100], Batch [76/147] train loss: 569.72, train corr: 0.02582
Epoch [95/100], Batch [77/147] train loss: 567.09, train corr: 0.02805
Epoch [95/100], Batch [78/147] train loss: 562.39, train corr: 0.02785
Epoch [95/100], Batch [79/147] train loss: 560.63, train corr: 0.02633
Epoch [95/100], Batch [80/147] train loss: 587.54, train corr: 0.02151
Epoch [95/100], Batch [81/147] train loss: 558.44, train corr: 0.02674
Epoch [95/100], Batch [82/147] train loss: 571.83, train corr: 0.02239
Epoch [95/100], Batch [83/147] train loss: 569.71, train corr: 0.02711
Epoch [95/100], Batch [84/147] train loss: 580.44, train corr: 0.02431
Epoch [95/100], Batch [85/147] train loss: 549.75, train corr: 0.02918
Epoch [95/100], Batch [86/147] train loss: 554.72, train corr: 0.03004
Epoch [95/100], Batch [87/147] train loss: 576.60, train corr: 0.02595
Epoch [95/100], Batch [88/147] train loss: 568.08, train corr: 0.02872
Epoch [95/100], Batch [89/147] train loss: 560.14, train corr: 0.02714
Epoch [95/100], Batch [90/147] train loss: 568.92, train corr: 0.02114
Epoch [95/100], Batch [91/147] train loss: 573.86, train corr: 0.02309
Epoch [95/100], Batch [92/147] train loss: 579.11, train corr: 0.02602
Epoch [95/100], Batch [93/147] train loss: 568.14, train corr: 0.02634
Epoch [95/100], Batch [94/147] train loss: 550.22, train corr: 0.02821
Epoch [95/100], Batch [95/147] train loss: 579.35, train corr: 0.02430
Epoch [95/100], Batch [96/147] train loss: 621.78, train corr: 0.02394
Epoch [95/100], Batch [97/147] train loss: 583.40, train corr: 0.02697
Epoch [95/100], Batch [98/147] train loss: 561.12, train corr: 0.02839
Epoch [95/100], Batch [99/147] train loss: 568.07, train corr: 0.02863
Epoch [95/100], Batch [100/147] train loss: 560.34, train corr: 0.02741
Epoch [95/100], Batch [101/147] train loss: 562.67, train corr: 0.02630
Epoch [95/100], Batch [102/147] train loss: 570.29, train corr: 0.02414
Epoch [95/100], Batch [103/147] train loss: 579.80, train corr: 0.02462
Epoch [95/100], Batch [104/147] train loss: 570.91, train corr: 0.02716
Epoch [95/100], Batch [105/147] train loss: 561.94, train corr: 0.02876
Epoch [95/100], Batch [106/147] train loss: 558.29, train corr: 0.02721
Epoch [95/100], Batch [107/147] train loss: 602.23, train corr: 0.02436
Epoch [95/100], Batch [108/147] train loss: 560.40, train corr: 0.02522
Epoch [95/100], Batch [109/147] train loss: 568.65, train corr: 0.02583
Epoch [95/100], Batch [110/147] train loss: 559.47, train corr: 0.02566
Epoch [95/100], Batch [111/147] train loss: 568.44, train corr: 0.02810
Epoch [95/100], Batch [112/147] train loss: 570.30, train corr: 0.02461
Epoch [95/100], Batch [113/147] train loss: 563.46, train corr: 0.02776
Epoch [95/100], Batch [114/147] train loss: 564.64, train corr: 0.02738
Epoch [95/100], Batch [115/147] train loss: 560.48, train corr: 0.02607
Epoch [95/100], Batch [116/147] train loss: 574.07, train corr: 0.02790
Epoch [95/100], Batch [117/147] train loss: 568.84, train corr: 0.02647
Epoch [95/100], Batch [118/147] train loss: 582.13, train corr: 0.02374
Epoch [95/100], Batch [119/147] train loss: 589.26, train corr: 0.02612
Epoch [95/100], Batch [120/147] train loss: 565.21, train corr: 0.02886
Epoch [95/100], Batch [121/147] train loss: 572.56, train corr: 0.02677
Epoch [95/100], Batch [122/147] train loss: 569.82, train corr: 0.03126
Epoch [95/100], Batch [123/147] train loss: 568.27, train corr: 0.02670
Epoch [95/100], Batch [124/147] train loss: 562.70, train corr: 0.02833
Epoch [95/100], Batch [125/147] train loss: 576.66, train corr: 0.02540
Epoch [95/100], Batch [126/147] train loss: 568.22, train corr: 0.02784
Epoch [95/100], Batch [127/147] train loss: 575.10, train corr: 0.02534
Epoch [95/100], Batch [128/147] train loss: 575.88, train corr: 0.02347
Epoch [95/100], Batch [129/147] train loss: 562.13, train corr: 0.02466
Epoch [95/100], Batch [130/147] train loss: 561.27, train corr: 0.02805
Epoch [95/100], Batch [131/147] train loss: 583.32, train corr: 0.02222
Epoch [95/100], Batch [132/147] train loss: 577.60, train corr: 0.02074
Epoch [95/100], Batch [133/147] train loss: 570.97, train corr: 0.02369
Epoch [95/100], Batch [134/147] train loss: 562.42, train corr: 0.02623
Epoch [95/100], Batch [135/147] train loss: 572.60, train corr: 0.02754
Epoch [95/100], Batch [136/147] train loss: 567.87, train corr: 0.02457
Epoch [95/100], Batch [137/147] train loss: 580.59, train corr: 0.02352
Epoch [95/100], Batch [138/147] train loss: 551.99, train corr: 0.02670
Epoch [95/100], Batch [139/147] train loss: 577.94, train corr: 0.02639
Epoch [95/100], Batch [140/147] train loss: 569.64, train corr: 0.02590
Epoch [95/100], Batch [141/147] train loss: 571.08, train corr: 0.02651
Epoch [95/100], Batch [142/147] train loss: 561.50, train corr: 0.02704
Epoch [95/100], Batch [143/147] train loss: 580.91, train corr: 0.02411
Epoch [95/100], Batch [144/147] train loss: 565.26, train corr: 0.02549
Epoch [95/100], Batch [145/147] train loss: 558.40, train corr: 0.02702
Epoch [95/100], Batch [146/147] train loss: 559.60, train corr: 0.02658
Epoch [95/100], Batch [147/147] train loss: 562.11, train corr: 0.02703
Epoch [95/100], validation loss: 597.24, validation correlation: 0.02591
Epoch [96/100], Batch [1/147] train loss: 557.76, train corr: 0.02455
Epoch [96/100], Batch [2/147] train loss: 553.12, train corr: 0.02635
Epoch [96/100], Batch [3/147] train loss: 560.78, train corr: 0.02591
Epoch [96/100], Batch [4/147] train loss: 566.03, train corr: 0.02703
Epoch [96/100], Batch [5/147] train loss: 570.69, train corr: 0.02775
Epoch [96/100], Batch [6/147] train loss: 567.44, train corr: 0.02773
Epoch [96/100], Batch [7/147] train loss: 562.39, train corr: 0.02521
Epoch [96/100], Batch [8/147] train loss: 569.71, train corr: 0.02633
Epoch [96/100], Batch [9/147] train loss: 586.40, train corr: 0.02099
Epoch [96/100], Batch [10/147] train loss: 572.59, train corr: 0.02470
Epoch [96/100], Batch [11/147] train loss: 562.69, train corr: 0.02502
Epoch [96/100], Batch [12/147] train loss: 579.92, train corr: 0.02125
Epoch [96/100], Batch [13/147] train loss: 576.55, train corr: 0.02309
Epoch [96/100], Batch [14/147] train loss: 567.14, train corr: 0.02653
Epoch [96/100], Batch [15/147] train loss: 557.82, train corr: 0.02814
Epoch [96/100], Batch [16/147] train loss: 568.22, train corr: 0.02777
Epoch [96/100], Batch [17/147] train loss: 561.47, train corr: 0.02648
Epoch [96/100], Batch [18/147] train loss: 557.53, train corr: 0.02697
Epoch [96/100], Batch [19/147] train loss: 555.82, train corr: 0.02641
Epoch [96/100], Batch [20/147] train loss: 571.49, train corr: 0.02414
Epoch [96/100], Batch [21/147] train loss: 568.72, train corr: 0.02576
Epoch [96/100], Batch [22/147] train loss: 557.32, train corr: 0.02671
Epoch [96/100], Batch [23/147] train loss: 559.71, train corr: 0.02761
Epoch [96/100], Batch [24/147] train loss: 594.69, train corr: 0.02245
Epoch [96/100], Batch [25/147] train loss: 569.47, train corr: 0.02482
Epoch [96/100], Batch [26/147] train loss: 557.50, train corr: 0.02789
Epoch [96/100], Batch [27/147] train loss: 557.71, train corr: 0.02724
Epoch [96/100], Batch [28/147] train loss: 556.14, train corr: 0.02496
Epoch [96/100], Batch [29/147] train loss: 556.88, train corr: 0.02766
Epoch [96/100], Batch [30/147] train loss: 564.62, train corr: 0.02540
Epoch [96/100], Batch [31/147] train loss: 581.88, train corr: 0.02353
Epoch [96/100], Batch [32/147] train loss: 561.83, train corr: 0.02609
Epoch [96/100], Batch [33/147] train loss: 558.57, train corr: 0.02637
Epoch [96/100], Batch [34/147] train loss: 578.11, train corr: 0.02382
Epoch [96/100], Batch [35/147] train loss: 588.95, train corr: 0.02292
Epoch [96/100], Batch [36/147] train loss: 570.91, train corr: 0.02549
Epoch [96/100], Batch [37/147] train loss: 568.25, train corr: 0.02406
Epoch [96/100], Batch [38/147] train loss: 572.49, train corr: 0.02240
Epoch [96/100], Batch [39/147] train loss: 565.65, train corr: 0.02578
Epoch [96/100], Batch [40/147] train loss: 574.72, train corr: 0.02614
Epoch [96/100], Batch [41/147] train loss: 566.10, train corr: 0.02754
Epoch [96/100], Batch [42/147] train loss: 816.82, train corr: 0.01956
Epoch [96/100], Batch [43/147] train loss: 578.31, train corr: 0.02455
Epoch [96/100], Batch [44/147] train loss: 575.13, train corr: 0.02132
Epoch [96/100], Batch [45/147] train loss: 582.95, train corr: 0.02294
Epoch [96/100], Batch [46/147] train loss: 562.37, train corr: 0.02080
Epoch [96/100], Batch [47/147] train loss: 583.41, train corr: 0.02301
Epoch [96/100], Batch [48/147] train loss: 583.53, train corr: 0.01504
Epoch [96/100], Batch [49/147] train loss: 562.48, train corr: 0.01592
Epoch [96/100], Batch [50/147] train loss: 570.38, train corr: 0.01666
Epoch [96/100], Batch [51/147] train loss: 569.97, train corr: 0.02303
Epoch [96/100], Batch [52/147] train loss: 578.96, train corr: 0.02052
Epoch [96/100], Batch [53/147] train loss: 574.85, train corr: 0.02266
Epoch [96/100], Batch [54/147] train loss: 578.76, train corr: 0.02504
Epoch [96/100], Batch [55/147] train loss: 563.41, train corr: 0.02599
Epoch [96/100], Batch [56/147] train loss: 571.19, train corr: 0.02487
Epoch [96/100], Batch [57/147] train loss: 557.88, train corr: 0.02684
Epoch [96/100], Batch [58/147] train loss: 554.13, train corr: 0.02640
Epoch [96/100], Batch [59/147] train loss: 565.20, train corr: 0.02554
Epoch [96/100], Batch [60/147] train loss: 567.60, train corr: 0.02443
Epoch [96/100], Batch [61/147] train loss: 564.84, train corr: 0.02514
Epoch [96/100], Batch [62/147] train loss: 569.21, train corr: 0.02333
Epoch [96/100], Batch [63/147] train loss: 571.27, train corr: 0.02671
Epoch [96/100], Batch [64/147] train loss: 567.86, train corr: 0.02800
Epoch [96/100], Batch [65/147] train loss: 567.32, train corr: 0.02820
Epoch [96/100], Batch [66/147] train loss: 579.30, train corr: 0.02615
Epoch [96/100], Batch [67/147] train loss: 561.27, train corr: 0.02729
Epoch [96/100], Batch [68/147] train loss: 570.10, train corr: 0.02317
Epoch [96/100], Batch [69/147] train loss: 554.08, train corr: 0.02922
Epoch [96/100], Batch [70/147] train loss: 549.87, train corr: 0.02792
Epoch [96/100], Batch [71/147] train loss: 567.20, train corr: 0.02597
Epoch [96/100], Batch [72/147] train loss: 594.37, train corr: 0.02634
Epoch [96/100], Batch [73/147] train loss: 558.09, train corr: 0.02896
Epoch [96/100], Batch [74/147] train loss: 561.80, train corr: 0.02678
Epoch [96/100], Batch [75/147] train loss: 582.62, train corr: 0.02157
Epoch [96/100], Batch [76/147] train loss: 575.93, train corr: 0.02374
Epoch [96/100], Batch [77/147] train loss: 566.23, train corr: 0.02747
Epoch [96/100], Batch [78/147] train loss: 630.23, train corr: 0.02325
Epoch [96/100], Batch [79/147] train loss: 543.09, train corr: 0.02854
Epoch [96/100], Batch [80/147] train loss: 564.99, train corr: 0.02894
Epoch [96/100], Batch [81/147] train loss: 574.93, train corr: 0.02414
Epoch [96/100], Batch [82/147] train loss: 563.18, train corr: 0.02719
Epoch [96/100], Batch [83/147] train loss: 568.38, train corr: 0.02780
Epoch [96/100], Batch [84/147] train loss: 543.60, train corr: 0.02868
Epoch [96/100], Batch [85/147] train loss: 592.85, train corr: 0.02077
Epoch [96/100], Batch [86/147] train loss: 560.56, train corr: 0.02744
Epoch [96/100], Batch [87/147] train loss: 557.55, train corr: 0.02800
Epoch [96/100], Batch [88/147] train loss: 570.45, train corr: 0.02499
Epoch [96/100], Batch [89/147] train loss: 584.22, train corr: 0.02275
Epoch [96/100], Batch [90/147] train loss: 565.93, train corr: 0.02714
Epoch [96/100], Batch [91/147] train loss: 573.00, train corr: 0.02776
Epoch [96/100], Batch [92/147] train loss: 577.45, train corr: 0.02438
Epoch [96/100], Batch [93/147] train loss: 573.36, train corr: 0.02519
Epoch [96/100], Batch [94/147] train loss: 571.20, train corr: 0.02332
Epoch [96/100], Batch [95/147] train loss: 576.71, train corr: 0.02410
Epoch [96/100], Batch [96/147] train loss: 569.27, train corr: 0.02656
Epoch [96/100], Batch [97/147] train loss: 574.27, train corr: 0.02251
Epoch [96/100], Batch [98/147] train loss: 556.76, train corr: 0.02808
Epoch [96/100], Batch [99/147] train loss: 570.53, train corr: 0.02315
Epoch [96/100], Batch [100/147] train loss: 573.38, train corr: 0.02470
Epoch [96/100], Batch [101/147] train loss: 568.56, train corr: 0.02577
Epoch [96/100], Batch [102/147] train loss: 559.96, train corr: 0.02770
Epoch [96/100], Batch [103/147] train loss: 558.55, train corr: 0.02800
Epoch [96/100], Batch [104/147] train loss: 595.31, train corr: 0.02639
Epoch [96/100], Batch [105/147] train loss: 562.73, train corr: 0.02843
Epoch [96/100], Batch [106/147] train loss: 569.95, train corr: 0.02713
Epoch [96/100], Batch [107/147] train loss: 554.72, train corr: 0.02618
Epoch [96/100], Batch [108/147] train loss: 567.60, train corr: 0.02739
Epoch [96/100], Batch [109/147] train loss: 555.68, train corr: 0.02729
Epoch [96/100], Batch [110/147] train loss: 563.30, train corr: 0.02488
Epoch [96/100], Batch [111/147] train loss: 577.25, train corr: 0.02483
Epoch [96/100], Batch [112/147] train loss: 576.59, train corr: 0.02450
Epoch [96/100], Batch [113/147] train loss: 552.08, train corr: 0.02806
Epoch [96/100], Batch [114/147] train loss: 649.15, train corr: 0.02090
Epoch [96/100], Batch [115/147] train loss: 571.02, train corr: 0.02529
Epoch [96/100], Batch [116/147] train loss: 565.78, train corr: 0.02709
Epoch [96/100], Batch [117/147] train loss: 565.87, train corr: 0.02667
Epoch [96/100], Batch [118/147] train loss: 577.88, train corr: 0.02362
Epoch [96/100], Batch [119/147] train loss: 554.16, train corr: 0.02493
Epoch [96/100], Batch [120/147] train loss: 562.35, train corr: 0.02616
Epoch [96/100], Batch [121/147] train loss: 568.56, train corr: 0.02750
Epoch [96/100], Batch [122/147] train loss: 555.40, train corr: 0.02762
Epoch [96/100], Batch [123/147] train loss: 565.10, train corr: 0.02835
Epoch [96/100], Batch [124/147] train loss: 580.66, train corr: 0.02398
Epoch [96/100], Batch [125/147] train loss: 583.66, train corr: 0.02541
Epoch [96/100], Batch [126/147] train loss: 567.45, train corr: 0.02661
Epoch [96/100], Batch [127/147] train loss: 560.38, train corr: 0.02656
Epoch [96/100], Batch [128/147] train loss: 558.06, train corr: 0.02639
Epoch [96/100], Batch [129/147] train loss: 563.35, train corr: 0.02847
Epoch [96/100], Batch [130/147] train loss: 566.17, train corr: 0.02500
Epoch [96/100], Batch [131/147] train loss: 560.63, train corr: 0.02551
Epoch [96/100], Batch [132/147] train loss: 557.97, train corr: 0.02778
Epoch [96/100], Batch [133/147] train loss: 557.19, train corr: 0.02784
Epoch [96/100], Batch [134/147] train loss: 740.08, train corr: 0.02716
Epoch [96/100], Batch [135/147] train loss: 579.53, train corr: -0.00460
Epoch [96/100], Batch [136/147] train loss: 561.89, train corr: 0.02489
Epoch [96/100], Batch [137/147] train loss: 570.51, train corr: 0.02518
Epoch [96/100], Batch [138/147] train loss: 597.82, train corr: 0.02472
Epoch [96/100], Batch [139/147] train loss: 585.98, train corr: 0.02217
Epoch [96/100], Batch [140/147] train loss: 575.51, train corr: -0.00259
Epoch [96/100], Batch [141/147] train loss: 614.20, train corr: -0.01882
Epoch [96/100], Batch [142/147] train loss: 576.10, train corr: -0.01060
Epoch [96/100], Batch [143/147] train loss: 567.19, train corr: 0.01750
Epoch [96/100], Batch [144/147] train loss: 614.73, train corr: 0.02486
Epoch [96/100], Batch [145/147] train loss: 574.55, train corr: 0.02814
Epoch [96/100], Batch [146/147] train loss: 569.97, train corr: 0.01460
Epoch [96/100], Batch [147/147] train loss: 575.13, train corr: -0.00407
Epoch [96/100], validation loss: 602.18, validation correlation: 0.00065
Epoch [97/100], Batch [1/147] train loss: 568.03, train corr: 0.00083
Epoch [97/100], Batch [2/147] train loss: 569.93, train corr: 0.02159
Epoch [97/100], Batch [3/147] train loss: 564.92, train corr: 0.02587
Epoch [97/100], Batch [4/147] train loss: 578.79, train corr: 0.02567
Epoch [97/100], Batch [5/147] train loss: 568.03, train corr: 0.02551
Epoch [97/100], Batch [6/147] train loss: 582.81, train corr: 0.02708
Epoch [97/100], Batch [7/147] train loss: 555.96, train corr: 0.02891
Epoch [97/100], Batch [8/147] train loss: 559.38, train corr: 0.02968
Epoch [97/100], Batch [9/147] train loss: 563.94, train corr: 0.02711
Epoch [97/100], Batch [10/147] train loss: 573.04, train corr: 0.02647
Epoch [97/100], Batch [11/147] train loss: 589.45, train corr: 0.02497
Epoch [97/100], Batch [12/147] train loss: 572.83, train corr: 0.02728
Epoch [97/100], Batch [13/147] train loss: 561.30, train corr: 0.02804
Epoch [97/100], Batch [14/147] train loss: 559.04, train corr: 0.02519
Epoch [97/100], Batch [15/147] train loss: 576.67, train corr: 0.02511
Epoch [97/100], Batch [16/147] train loss: 558.57, train corr: 0.02693
Epoch [97/100], Batch [17/147] train loss: 561.41, train corr: 0.02351
Epoch [97/100], Batch [18/147] train loss: 569.25, train corr: 0.02809
Epoch [97/100], Batch [19/147] train loss: 565.27, train corr: 0.02873
Epoch [97/100], Batch [20/147] train loss: 561.75, train corr: 0.02763
Epoch [97/100], Batch [21/147] train loss: 562.51, train corr: 0.02787
Epoch [97/100], Batch [22/147] train loss: 577.32, train corr: 0.02809
Epoch [97/100], Batch [23/147] train loss: 586.22, train corr: 0.02366
Epoch [97/100], Batch [24/147] train loss: 586.31, train corr: 0.01657
Epoch [97/100], Batch [25/147] train loss: 558.72, train corr: 0.02839
Epoch [97/100], Batch [26/147] train loss: 563.28, train corr: 0.02929
Epoch [97/100], Batch [27/147] train loss: 561.11, train corr: 0.02690
Epoch [97/100], Batch [28/147] train loss: 562.95, train corr: 0.02680
Epoch [97/100], Batch [29/147] train loss: 555.58, train corr: 0.02884
Epoch [97/100], Batch [30/147] train loss: 561.39, train corr: 0.02797
Epoch [97/100], Batch [31/147] train loss: 562.05, train corr: 0.02777
Epoch [97/100], Batch [32/147] train loss: 564.33, train corr: 0.02852
Epoch [97/100], Batch [33/147] train loss: 562.73, train corr: 0.02762
Epoch [97/100], Batch [34/147] train loss: 569.71, train corr: 0.02790
Epoch [97/100], Batch [35/147] train loss: 561.50, train corr: 0.02770
Epoch [97/100], Batch [36/147] train loss: 571.43, train corr: 0.02516
Epoch [97/100], Batch [37/147] train loss: 560.38, train corr: 0.02431
Epoch [97/100], Batch [38/147] train loss: 577.43, train corr: 0.02440
Epoch [97/100], Batch [39/147] train loss: 564.43, train corr: 0.02472
Epoch [97/100], Batch [40/147] train loss: 574.36, train corr: 0.02378
Epoch [97/100], Batch [41/147] train loss: 562.74, train corr: 0.02481
Epoch [97/100], Batch [42/147] train loss: 558.51, train corr: 0.02832
Epoch [97/100], Batch [43/147] train loss: 655.15, train corr: 0.02234
Epoch [97/100], Batch [44/147] train loss: 560.13, train corr: 0.02586
Epoch [97/100], Batch [45/147] train loss: 582.14, train corr: 0.02543
Epoch [97/100], Batch [46/147] train loss: 567.24, train corr: 0.02467
Epoch [97/100], Batch [47/147] train loss: 558.03, train corr: 0.02788
Epoch [97/100], Batch [48/147] train loss: 573.12, train corr: 0.02780
Epoch [97/100], Batch [49/147] train loss: 573.81, train corr: 0.02499
Epoch [97/100], Batch [50/147] train loss: 560.11, train corr: 0.02723
Epoch [97/100], Batch [51/147] train loss: 564.57, train corr: 0.02852
Epoch [97/100], Batch [52/147] train loss: 577.62, train corr: 0.02722
Epoch [97/100], Batch [53/147] train loss: 570.46, train corr: 0.02736
Epoch [97/100], Batch [54/147] train loss: 567.16, train corr: 0.02554
Epoch [97/100], Batch [55/147] train loss: 586.68, train corr: 0.02348
Epoch [97/100], Batch [56/147] train loss: 558.23, train corr: 0.02862
Epoch [97/100], Batch [57/147] train loss: 656.12, train corr: 0.02152
Epoch [97/100], Batch [58/147] train loss: 563.76, train corr: 0.02714
Epoch [97/100], Batch [59/147] train loss: 563.88, train corr: 0.02495
Epoch [97/100], Batch [60/147] train loss: 572.92, train corr: 0.02567
Epoch [97/100], Batch [61/147] train loss: 571.80, train corr: 0.02577
Epoch [97/100], Batch [62/147] train loss: 560.92, train corr: 0.02804
Epoch [97/100], Batch [63/147] train loss: 562.54, train corr: 0.02664
Epoch [97/100], Batch [64/147] train loss: 573.85, train corr: 0.02423
Epoch [97/100], Batch [65/147] train loss: 557.82, train corr: 0.02677
Epoch [97/100], Batch [66/147] train loss: 564.37, train corr: 0.02784
Epoch [97/100], Batch [67/147] train loss: 565.94, train corr: 0.02632
Epoch [97/100], Batch [68/147] train loss: 580.84, train corr: 0.02588
Epoch [97/100], Batch [69/147] train loss: 572.85, train corr: 0.02609
Epoch [97/100], Batch [70/147] train loss: 571.35, train corr: 0.02467
Epoch [97/100], Batch [71/147] train loss: 559.22, train corr: 0.02616
Epoch [97/100], Batch [72/147] train loss: 559.64, train corr: 0.02702
Epoch [97/100], Batch [73/147] train loss: 575.15, train corr: 0.02613
Epoch [97/100], Batch [74/147] train loss: 558.49, train corr: 0.02852
Epoch [97/100], Batch [75/147] train loss: 570.39, train corr: 0.02574
Epoch [97/100], Batch [76/147] train loss: 558.13, train corr: 0.02648
Epoch [97/100], Batch [77/147] train loss: 572.89, train corr: 0.02520
Epoch [97/100], Batch [78/147] train loss: 559.00, train corr: 0.02763
Epoch [97/100], Batch [79/147] train loss: 566.40, train corr: 0.02816
Epoch [97/100], Batch [80/147] train loss: 560.40, train corr: 0.02487
Epoch [97/100], Batch [81/147] train loss: 579.65, train corr: 0.02822
Epoch [97/100], Batch [82/147] train loss: 573.62, train corr: 0.02632
Epoch [97/100], Batch [83/147] train loss: 582.43, train corr: 0.02373
Epoch [97/100], Batch [84/147] train loss: 560.52, train corr: 0.02777
Epoch [97/100], Batch [85/147] train loss: 589.60, train corr: 0.02525
Epoch [97/100], Batch [86/147] train loss: 572.66, train corr: 0.02668
Epoch [97/100], Batch [87/147] train loss: 574.30, train corr: 0.02454
Epoch [97/100], Batch [88/147] train loss: 550.14, train corr: 0.02883
Epoch [97/100], Batch [89/147] train loss: 561.35, train corr: 0.02794
Epoch [97/100], Batch [90/147] train loss: 568.86, train corr: 0.02806
Epoch [97/100], Batch [91/147] train loss: 587.07, train corr: 0.02341
Epoch [97/100], Batch [92/147] train loss: 550.90, train corr: 0.02789
Epoch [97/100], Batch [93/147] train loss: 569.56, train corr: 0.02698
Epoch [97/100], Batch [94/147] train loss: 580.95, train corr: 0.02536
Epoch [97/100], Batch [95/147] train loss: 568.45, train corr: 0.02588
Epoch [97/100], Batch [96/147] train loss: 748.84, train corr: 0.02455
Epoch [97/100], Batch [97/147] train loss: 602.76, train corr: 0.00993
Epoch [97/100], Batch [98/147] train loss: 581.26, train corr: 0.02371
Epoch [97/100], Batch [99/147] train loss: 582.53, train corr: 0.02614
Epoch [97/100], Batch [100/147] train loss: 576.96, train corr: 0.02616
Epoch [97/100], Batch [101/147] train loss: 577.17, train corr: 0.02682
Epoch [97/100], Batch [102/147] train loss: 599.00, train corr: 0.00505
Epoch [97/100], Batch [103/147] train loss: 831.27, train corr: -0.01730
Epoch [97/100], Batch [104/147] train loss: 581.30, train corr: 0.02301
Epoch [97/100], Batch [105/147] train loss: 571.48, train corr: 0.02853
Epoch [97/100], Batch [106/147] train loss: 570.54, train corr: 0.02690
Epoch [97/100], Batch [107/147] train loss: 586.98, train corr: 0.02717
Epoch [97/100], Batch [108/147] train loss: 593.71, train corr: 0.01985
Epoch [97/100], Batch [109/147] train loss: 581.00, train corr: 0.02859
Epoch [97/100], Batch [110/147] train loss: 572.95, train corr: 0.02996
Epoch [97/100], Batch [111/147] train loss: 575.61, train corr: 0.02793
Epoch [97/100], Batch [112/147] train loss: 581.67, train corr: 0.02449
Epoch [97/100], Batch [113/147] train loss: 567.43, train corr: 0.02464
Epoch [97/100], Batch [114/147] train loss: 566.73, train corr: 0.02862
Epoch [97/100], Batch [115/147] train loss: 568.64, train corr: 0.02969
Epoch [97/100], Batch [116/147] train loss: 568.19, train corr: 0.02631
Epoch [97/100], Batch [117/147] train loss: 584.98, train corr: 0.02520
Epoch [97/100], Batch [118/147] train loss: 583.71, train corr: 0.02728
Epoch [97/100], Batch [119/147] train loss: 566.83, train corr: 0.02628
Epoch [97/100], Batch [120/147] train loss: 595.62, train corr: 0.02563
Epoch [97/100], Batch [121/147] train loss: 578.27, train corr: 0.02306
Epoch [97/100], Batch [122/147] train loss: 565.98, train corr: 0.02810
Epoch [97/100], Batch [123/147] train loss: 565.34, train corr: 0.02712
Epoch [97/100], Batch [124/147] train loss: 587.96, train corr: 0.02305
Epoch [97/100], Batch [125/147] train loss: 568.64, train corr: 0.02467
Epoch [97/100], Batch [126/147] train loss: 564.17, train corr: 0.02903
Epoch [97/100], Batch [127/147] train loss: 562.68, train corr: 0.02806
Epoch [97/100], Batch [128/147] train loss: 575.81, train corr: 0.02858
Epoch [97/100], Batch [129/147] train loss: 556.19, train corr: 0.02950
Epoch [97/100], Batch [130/147] train loss: 574.65, train corr: 0.02533
Epoch [97/100], Batch [131/147] train loss: 566.02, train corr: 0.02680
Epoch [97/100], Batch [132/147] train loss: 569.96, train corr: 0.02658
Epoch [97/100], Batch [133/147] train loss: 552.63, train corr: 0.02890
Epoch [97/100], Batch [134/147] train loss: 561.68, train corr: 0.02771
Epoch [97/100], Batch [135/147] train loss: 563.36, train corr: 0.02115
Epoch [97/100], Batch [136/147] train loss: 548.21, train corr: 0.02906
Epoch [97/100], Batch [137/147] train loss: 559.24, train corr: 0.02495
Epoch [97/100], Batch [138/147] train loss: 582.13, train corr: 0.02594
Epoch [97/100], Batch [139/147] train loss: 563.14, train corr: 0.02732
Epoch [97/100], Batch [140/147] train loss: 596.10, train corr: 0.02550
Epoch [97/100], Batch [141/147] train loss: 553.84, train corr: 0.02946
Epoch [97/100], Batch [142/147] train loss: 555.01, train corr: 0.02941
Epoch [97/100], Batch [143/147] train loss: 553.98, train corr: 0.02812
Epoch [97/100], Batch [144/147] train loss: 563.00, train corr: 0.02460
Epoch [97/100], Batch [145/147] train loss: 565.59, train corr: 0.02683
Epoch [97/100], Batch [146/147] train loss: 576.99, train corr: 0.02815
Epoch [97/100], Batch [147/147] train loss: 561.31, train corr: 0.02528
Epoch [97/100], validation loss: 597.69, validation correlation: 0.02716
Epoch [98/100], Batch [1/147] train loss: 559.36, train corr: 0.02680
Epoch [98/100], Batch [2/147] train loss: 565.71, train corr: 0.02461
Epoch [98/100], Batch [3/147] train loss: 567.68, train corr: 0.03173
Epoch [98/100], Batch [4/147] train loss: 585.84, train corr: 0.02861
Epoch [98/100], Batch [5/147] train loss: 571.29, train corr: 0.02772
Epoch [98/100], Batch [6/147] train loss: 578.92, train corr: 0.02425
Epoch [98/100], Batch [7/147] train loss: 555.35, train corr: 0.02836
Epoch [98/100], Batch [8/147] train loss: 559.22, train corr: 0.02680
Epoch [98/100], Batch [9/147] train loss: 558.95, train corr: 0.02828
Epoch [98/100], Batch [10/147] train loss: 558.77, train corr: 0.02865
Epoch [98/100], Batch [11/147] train loss: 578.25, train corr: 0.02523
Epoch [98/100], Batch [12/147] train loss: 586.83, train corr: 0.02449
Epoch [98/100], Batch [13/147] train loss: 573.84, train corr: 0.02736
Epoch [98/100], Batch [14/147] train loss: 549.37, train corr: 0.03026
Epoch [98/100], Batch [15/147] train loss: 567.65, train corr: 0.02472
Epoch [98/100], Batch [16/147] train loss: 558.26, train corr: 0.02930
Epoch [98/100], Batch [17/147] train loss: 576.85, train corr: 0.02603
Epoch [98/100], Batch [18/147] train loss: 556.33, train corr: 0.02879
Epoch [98/100], Batch [19/147] train loss: 553.71, train corr: 0.02648
Epoch [98/100], Batch [20/147] train loss: 576.79, train corr: 0.02422
Epoch [98/100], Batch [21/147] train loss: 568.21, train corr: 0.02868
Epoch [98/100], Batch [22/147] train loss: 574.76, train corr: 0.02536
Epoch [98/100], Batch [23/147] train loss: 560.06, train corr: 0.02827
Epoch [98/100], Batch [24/147] train loss: 553.52, train corr: 0.02978
Epoch [98/100], Batch [25/147] train loss: 575.44, train corr: 0.02344
Epoch [98/100], Batch [26/147] train loss: 562.36, train corr: 0.02644
Epoch [98/100], Batch [27/147] train loss: 563.59, train corr: 0.02766
Epoch [98/100], Batch [28/147] train loss: 566.16, train corr: 0.02595
Epoch [98/100], Batch [29/147] train loss: 574.11, train corr: 0.02466
Epoch [98/100], Batch [30/147] train loss: 597.44, train corr: 0.02517
Epoch [98/100], Batch [31/147] train loss: 566.62, train corr: 0.01946
Epoch [98/100], Batch [32/147] train loss: 626.39, train corr: 0.02655
Epoch [98/100], Batch [33/147] train loss: 633.53, train corr: 0.02457
Epoch [98/100], Batch [34/147] train loss: 562.54, train corr: 0.02630
Epoch [98/100], Batch [35/147] train loss: 561.88, train corr: 0.02673
Epoch [98/100], Batch [36/147] train loss: 585.85, train corr: 0.02580
Epoch [98/100], Batch [37/147] train loss: 573.52, train corr: 0.02742
Epoch [98/100], Batch [38/147] train loss: 563.11, train corr: 0.02798
Epoch [98/100], Batch [39/147] train loss: 573.88, train corr: 0.02441
Epoch [98/100], Batch [40/147] train loss: 574.46, train corr: 0.02539
Epoch [98/100], Batch [41/147] train loss: 572.12, train corr: 0.02853
Epoch [98/100], Batch [42/147] train loss: 580.05, train corr: 0.02552
Epoch [98/100], Batch [43/147] train loss: 752.94, train corr: 0.02781
Epoch [98/100], Batch [44/147] train loss: 586.06, train corr: 0.02424
Epoch [98/100], Batch [45/147] train loss: 566.21, train corr: 0.02774
Epoch [98/100], Batch [46/147] train loss: 568.53, train corr: 0.02692
Epoch [98/100], Batch [47/147] train loss: 578.50, train corr: 0.02298
Epoch [98/100], Batch [48/147] train loss: 579.84, train corr: 0.02437
Epoch [98/100], Batch [49/147] train loss: 570.13, train corr: 0.00077
Epoch [98/100], Batch [50/147] train loss: 583.23, train corr: -0.01944
Epoch [98/100], Batch [51/147] train loss: 553.01, train corr: -0.01770
Epoch [98/100], Batch [52/147] train loss: 559.30, train corr: -0.01022
Epoch [98/100], Batch [53/147] train loss: 565.23, train corr: 0.00309
Epoch [98/100], Batch [54/147] train loss: 569.83, train corr: 0.00838
Epoch [98/100], Batch [55/147] train loss: 559.91, train corr: 0.00468
Epoch [98/100], Batch [56/147] train loss: 574.27, train corr: -0.00138
Epoch [98/100], Batch [57/147] train loss: 586.08, train corr: -0.00318
Epoch [98/100], Batch [58/147] train loss: 578.27, train corr: 0.00984
Epoch [98/100], Batch [59/147] train loss: 555.05, train corr: 0.02455
Epoch [98/100], Batch [60/147] train loss: 571.93, train corr: 0.02568
Epoch [98/100], Batch [61/147] train loss: 572.15, train corr: 0.02442
Epoch [98/100], Batch [62/147] train loss: 569.14, train corr: 0.02574
Epoch [98/100], Batch [63/147] train loss: 568.77, train corr: 0.02881
Epoch [98/100], Batch [64/147] train loss: 572.61, train corr: 0.02725
Epoch [98/100], Batch [65/147] train loss: 573.84, train corr: 0.02751
Epoch [98/100], Batch [66/147] train loss: 572.46, train corr: 0.02625
Epoch [98/100], Batch [67/147] train loss: 574.77, train corr: 0.02599
Epoch [98/100], Batch [68/147] train loss: 571.78, train corr: 0.02283
Epoch [98/100], Batch [69/147] train loss: 597.45, train corr: 0.02182
Epoch [98/100], Batch [70/147] train loss: 560.78, train corr: 0.02955
Epoch [98/100], Batch [71/147] train loss: 552.32, train corr: 0.02804
Epoch [98/100], Batch [72/147] train loss: 568.63, train corr: 0.02650
Epoch [98/100], Batch [73/147] train loss: 571.89, train corr: 0.02773
Epoch [98/100], Batch [74/147] train loss: 561.54, train corr: 0.02991
Epoch [98/100], Batch [75/147] train loss: 561.03, train corr: 0.02755
Epoch [98/100], Batch [76/147] train loss: 575.20, train corr: 0.02335
Epoch [98/100], Batch [77/147] train loss: 587.43, train corr: 0.02493
Epoch [98/100], Batch [78/147] train loss: 570.50, train corr: 0.02722
Epoch [98/100], Batch [79/147] train loss: 570.34, train corr: 0.02742
Epoch [98/100], Batch [80/147] train loss: 567.83, train corr: 0.02970
Epoch [98/100], Batch [81/147] train loss: 566.35, train corr: 0.02760
Epoch [98/100], Batch [82/147] train loss: 561.56, train corr: 0.02597
Epoch [98/100], Batch [83/147] train loss: 550.56, train corr: 0.02865
Epoch [98/100], Batch [84/147] train loss: 581.85, train corr: 0.02462
Epoch [98/100], Batch [85/147] train loss: 549.57, train corr: 0.02826
Epoch [98/100], Batch [86/147] train loss: 556.54, train corr: 0.02898
Epoch [98/100], Batch [87/147] train loss: 569.77, train corr: 0.02306
Epoch [98/100], Batch [88/147] train loss: 560.45, train corr: 0.02727
Epoch [98/100], Batch [89/147] train loss: 576.78, train corr: 0.02564
Epoch [98/100], Batch [90/147] train loss: 571.33, train corr: 0.02533
Epoch [98/100], Batch [91/147] train loss: 574.30, train corr: 0.02801
Epoch [98/100], Batch [92/147] train loss: 794.94, train corr: 0.02318
Epoch [98/100], Batch [93/147] train loss: 576.89, train corr: 0.02427
Epoch [98/100], Batch [94/147] train loss: 556.39, train corr: 0.02639
Epoch [98/100], Batch [95/147] train loss: 564.89, train corr: 0.02078
Epoch [98/100], Batch [96/147] train loss: 565.99, train corr: 0.02560
Epoch [98/100], Batch [97/147] train loss: 568.31, train corr: 0.02391
Epoch [98/100], Batch [98/147] train loss: 562.21, train corr: 0.02102
Epoch [98/100], Batch [99/147] train loss: 570.41, train corr: 0.01157
Epoch [98/100], Batch [100/147] train loss: 571.91, train corr: 0.01168
Epoch [98/100], Batch [101/147] train loss: 603.02, train corr: 0.01884
Epoch [98/100], Batch [102/147] train loss: 573.20, train corr: 0.02190
Epoch [98/100], Batch [103/147] train loss: 574.61, train corr: 0.02888
Epoch [98/100], Batch [104/147] train loss: 570.64, train corr: 0.02447
Epoch [98/100], Batch [105/147] train loss: 551.60, train corr: 0.02856
Epoch [98/100], Batch [106/147] train loss: 563.91, train corr: 0.02841
Epoch [98/100], Batch [107/147] train loss: 582.51, train corr: 0.02471
Epoch [98/100], Batch [108/147] train loss: 569.05, train corr: 0.02620
Epoch [98/100], Batch [109/147] train loss: 568.58, train corr: 0.02799
Epoch [98/100], Batch [110/147] train loss: 580.46, train corr: 0.02618
Epoch [98/100], Batch [111/147] train loss: 566.91, train corr: 0.02691
Epoch [98/100], Batch [112/147] train loss: 575.88, train corr: 0.02773
Epoch [98/100], Batch [113/147] train loss: 568.56, train corr: 0.02737
Epoch [98/100], Batch [114/147] train loss: 584.25, train corr: 0.02184
Epoch [98/100], Batch [115/147] train loss: 574.53, train corr: 0.02439
Epoch [98/100], Batch [116/147] train loss: 560.16, train corr: 0.02907
Epoch [98/100], Batch [117/147] train loss: 559.60, train corr: 0.02488
Epoch [98/100], Batch [118/147] train loss: 566.80, train corr: 0.02858
Epoch [98/100], Batch [119/147] train loss: 567.26, train corr: 0.02807
Epoch [98/100], Batch [120/147] train loss: 566.24, train corr: 0.02352
Epoch [98/100], Batch [121/147] train loss: 566.88, train corr: 0.02745
Epoch [98/100], Batch [122/147] train loss: 573.54, train corr: 0.02673
Epoch [98/100], Batch [123/147] train loss: 563.11, train corr: 0.02774
Epoch [98/100], Batch [124/147] train loss: 564.32, train corr: 0.02676
Epoch [98/100], Batch [125/147] train loss: 576.24, train corr: 0.02698
Epoch [98/100], Batch [126/147] train loss: 558.90, train corr: 0.02621
Epoch [98/100], Batch [127/147] train loss: 553.83, train corr: 0.02864
Epoch [98/100], Batch [128/147] train loss: 572.66, train corr: 0.02586
Epoch [98/100], Batch [129/147] train loss: 588.04, train corr: 0.02290
Epoch [98/100], Batch [130/147] train loss: 561.36, train corr: 0.02752
Epoch [98/100], Batch [131/147] train loss: 559.41, train corr: 0.02541
Epoch [98/100], Batch [132/147] train loss: 572.24, train corr: 0.02848
Epoch [98/100], Batch [133/147] train loss: 567.76, train corr: 0.02557
Epoch [98/100], Batch [134/147] train loss: 558.74, train corr: 0.02822
Epoch [98/100], Batch [135/147] train loss: 562.94, train corr: 0.02809
Epoch [98/100], Batch [136/147] train loss: 567.70, train corr: 0.02476
Epoch [98/100], Batch [137/147] train loss: 563.97, train corr: 0.02599
Epoch [98/100], Batch [138/147] train loss: 556.70, train corr: 0.02880
Epoch [98/100], Batch [139/147] train loss: 582.47, train corr: 0.02167
Epoch [98/100], Batch [140/147] train loss: 556.21, train corr: 0.02574
Epoch [98/100], Batch [141/147] train loss: 578.74, train corr: 0.02551
Epoch [98/100], Batch [142/147] train loss: 556.56, train corr: 0.02662
Epoch [98/100], Batch [143/147] train loss: 591.16, train corr: 0.02393
Epoch [98/100], Batch [144/147] train loss: 577.25, train corr: 0.02766
Epoch [98/100], Batch [145/147] train loss: 574.98, train corr: 0.02571
Epoch [98/100], Batch [146/147] train loss: 581.45, train corr: 0.02534
Epoch [98/100], Batch [147/147] train loss: 555.74, train corr: 0.02809
Epoch [98/100], validation loss: 597.46, validation correlation: 0.02732
Epoch [99/100], Batch [1/147] train loss: 557.37, train corr: 0.02662
Epoch [99/100], Batch [2/147] train loss: 549.60, train corr: 0.02647
Epoch [99/100], Batch [3/147] train loss: 564.13, train corr: 0.02680
Epoch [99/100], Batch [4/147] train loss: 563.89, train corr: 0.02625
Epoch [99/100], Batch [5/147] train loss: 565.56, train corr: 0.02604
Epoch [99/100], Batch [6/147] train loss: 558.99, train corr: 0.02572
Epoch [99/100], Batch [7/147] train loss: 579.21, train corr: 0.02993
Epoch [99/100], Batch [8/147] train loss: 564.55, train corr: 0.02837
Epoch [99/100], Batch [9/147] train loss: 568.56, train corr: 0.02459
Epoch [99/100], Batch [10/147] train loss: 547.79, train corr: 0.02854
Epoch [99/100], Batch [11/147] train loss: 573.49, train corr: 0.02797
Epoch [99/100], Batch [12/147] train loss: 567.64, train corr: 0.02666
Epoch [99/100], Batch [13/147] train loss: 568.45, train corr: 0.02943
Epoch [99/100], Batch [14/147] train loss: 555.11, train corr: 0.02991
Epoch [99/100], Batch [15/147] train loss: 557.66, train corr: 0.02879
Epoch [99/100], Batch [16/147] train loss: 574.66, train corr: 0.02888
Epoch [99/100], Batch [17/147] train loss: 565.53, train corr: 0.02530
Epoch [99/100], Batch [18/147] train loss: 612.83, train corr: 0.02243
Epoch [99/100], Batch [19/147] train loss: 557.36, train corr: 0.02803
Epoch [99/100], Batch [20/147] train loss: 563.92, train corr: 0.02591
Epoch [99/100], Batch [21/147] train loss: 560.65, train corr: 0.02693
Epoch [99/100], Batch [22/147] train loss: 570.66, train corr: 0.02714
Epoch [99/100], Batch [23/147] train loss: 565.43, train corr: 0.02612
Epoch [99/100], Batch [24/147] train loss: 567.05, train corr: 0.02650
Epoch [99/100], Batch [25/147] train loss: 559.75, train corr: 0.02955
Epoch [99/100], Batch [26/147] train loss: 559.40, train corr: 0.02573
Epoch [99/100], Batch [27/147] train loss: 576.61, train corr: 0.02742
Epoch [99/100], Batch [28/147] train loss: 570.69, train corr: 0.02810
Epoch [99/100], Batch [29/147] train loss: 587.36, train corr: 0.01812
Epoch [99/100], Batch [30/147] train loss: 567.17, train corr: 0.02740
Epoch [99/100], Batch [31/147] train loss: 563.10, train corr: 0.02536
Epoch [99/100], Batch [32/147] train loss: 550.29, train corr: 0.02861
Epoch [99/100], Batch [33/147] train loss: 567.39, train corr: 0.02751
Epoch [99/100], Batch [34/147] train loss: 585.21, train corr: 0.02656
Epoch [99/100], Batch [35/147] train loss: 757.85, train corr: 0.02145
Epoch [99/100], Batch [36/147] train loss: 573.80, train corr: 0.02346
Epoch [99/100], Batch [37/147] train loss: 582.17, train corr: 0.02136
Epoch [99/100], Batch [38/147] train loss: 574.47, train corr: 0.02865
Epoch [99/100], Batch [39/147] train loss: 580.50, train corr: 0.02634
Epoch [99/100], Batch [40/147] train loss: 565.38, train corr: 0.02512
Epoch [99/100], Batch [41/147] train loss: 576.91, train corr: -0.00293
Epoch [99/100], Batch [42/147] train loss: 614.37, train corr: -0.01357
Epoch [99/100], Batch [43/147] train loss: 569.42, train corr: -0.01672
Epoch [99/100], Batch [44/147] train loss: 561.20, train corr: -0.00011
Epoch [99/100], Batch [45/147] train loss: 574.96, train corr: 0.01518
Epoch [99/100], Batch [46/147] train loss: 575.85, train corr: 0.02080
Epoch [99/100], Batch [47/147] train loss: 573.78, train corr: 0.01782
Epoch [99/100], Batch [48/147] train loss: 574.07, train corr: 0.01662
Epoch [99/100], Batch [49/147] train loss: 565.07, train corr: 0.02245
Epoch [99/100], Batch [50/147] train loss: 567.46, train corr: 0.02408
Epoch [99/100], Batch [51/147] train loss: 557.83, train corr: 0.02806
Epoch [99/100], Batch [52/147] train loss: 564.72, train corr: 0.02523
Epoch [99/100], Batch [53/147] train loss: 580.84, train corr: 0.02305
Epoch [99/100], Batch [54/147] train loss: 565.33, train corr: 0.02540
Epoch [99/100], Batch [55/147] train loss: 571.46, train corr: 0.02558
Epoch [99/100], Batch [56/147] train loss: 566.68, train corr: 0.02687
Epoch [99/100], Batch [57/147] train loss: 567.98, train corr: 0.02820
Epoch [99/100], Batch [58/147] train loss: 563.78, train corr: 0.02839
Epoch [99/100], Batch [59/147] train loss: 579.40, train corr: 0.02560
Epoch [99/100], Batch [60/147] train loss: 576.97, train corr: 0.02496
Epoch [99/100], Batch [61/147] train loss: 567.47, train corr: 0.02624
Epoch [99/100], Batch [62/147] train loss: 570.71, train corr: 0.02526
Epoch [99/100], Batch [63/147] train loss: 566.58, train corr: 0.02752
Epoch [99/100], Batch [64/147] train loss: 574.43, train corr: 0.02687
Epoch [99/100], Batch [65/147] train loss: 569.79, train corr: 0.02789
Epoch [99/100], Batch [66/147] train loss: 559.36, train corr: 0.02721
Epoch [99/100], Batch [67/147] train loss: 572.79, train corr: 0.02420
Epoch [99/100], Batch [68/147] train loss: 578.27, train corr: 0.02225
Epoch [99/100], Batch [69/147] train loss: 551.09, train corr: 0.02751
Epoch [99/100], Batch [70/147] train loss: 555.33, train corr: 0.02892
Epoch [99/100], Batch [71/147] train loss: 561.75, train corr: 0.02804
Epoch [99/100], Batch [72/147] train loss: 565.65, train corr: 0.02738
Epoch [99/100], Batch [73/147] train loss: 582.02, train corr: 0.02366
Epoch [99/100], Batch [74/147] train loss: 568.96, train corr: 0.02598
Epoch [99/100], Batch [75/147] train loss: 571.54, train corr: 0.02597
Epoch [99/100], Batch [76/147] train loss: 562.77, train corr: 0.02927
Epoch [99/100], Batch [77/147] train loss: 553.22, train corr: 0.02864
Epoch [99/100], Batch [78/147] train loss: 575.70, train corr: 0.02328
Epoch [99/100], Batch [79/147] train loss: 568.22, train corr: 0.02707
Epoch [99/100], Batch [80/147] train loss: 575.47, train corr: 0.02867
Epoch [99/100], Batch [81/147] train loss: 555.66, train corr: 0.02931
Epoch [99/100], Batch [82/147] train loss: 562.02, train corr: 0.02726
Epoch [99/100], Batch [83/147] train loss: 581.28, train corr: 0.02406
Epoch [99/100], Batch [84/147] train loss: 558.95, train corr: 0.02494
Epoch [99/100], Batch [85/147] train loss: 574.62, train corr: 0.02663
Epoch [99/100], Batch [86/147] train loss: 552.45, train corr: 0.02813
Epoch [99/100], Batch [87/147] train loss: 555.93, train corr: 0.02678
Epoch [99/100], Batch [88/147] train loss: 584.74, train corr: 0.02850
Epoch [99/100], Batch [89/147] train loss: 571.21, train corr: 0.02637
Epoch [99/100], Batch [90/147] train loss: 586.03, train corr: 0.02148
Epoch [99/100], Batch [91/147] train loss: 561.64, train corr: 0.02633
Epoch [99/100], Batch [92/147] train loss: 575.14, train corr: 0.02672
Epoch [99/100], Batch [93/147] train loss: 567.72, train corr: 0.02619
Epoch [99/100], Batch [94/147] train loss: 576.48, train corr: 0.02462
Epoch [99/100], Batch [95/147] train loss: 557.53, train corr: 0.03010
Epoch [99/100], Batch [96/147] train loss: 569.38, train corr: 0.02884
Epoch [99/100], Batch [97/147] train loss: 562.33, train corr: 0.02880
Epoch [99/100], Batch [98/147] train loss: 570.71, train corr: 0.02798
Epoch [99/100], Batch [99/147] train loss: 575.42, train corr: 0.02582
Epoch [99/100], Batch [100/147] train loss: 555.62, train corr: 0.02932
Epoch [99/100], Batch [101/147] train loss: 585.71, train corr: 0.02270
Epoch [99/100], Batch [102/147] train loss: 869.34, train corr: 0.02189
Epoch [99/100], Batch [103/147] train loss: 574.21, train corr: 0.02566
Epoch [99/100], Batch [104/147] train loss: 564.95, train corr: 0.02724
Epoch [99/100], Batch [105/147] train loss: 574.58, train corr: 0.02668
Epoch [99/100], Batch [106/147] train loss: 575.99, train corr: 0.02480
Epoch [99/100], Batch [107/147] train loss: 577.93, train corr: 0.02637
Epoch [99/100], Batch [108/147] train loss: 555.82, train corr: 0.02694
Epoch [99/100], Batch [109/147] train loss: 574.56, train corr: 0.02021
Epoch [99/100], Batch [110/147] train loss: 572.49, train corr: 0.02121
Epoch [99/100], Batch [111/147] train loss: 575.28, train corr: 0.02506
Epoch [99/100], Batch [112/147] train loss: 582.21, train corr: 0.02636
Epoch [99/100], Batch [113/147] train loss: 578.24, train corr: 0.02723
Epoch [99/100], Batch [114/147] train loss: 561.30, train corr: 0.02827
Epoch [99/100], Batch [115/147] train loss: 569.44, train corr: 0.02716
Epoch [99/100], Batch [116/147] train loss: 567.09, train corr: 0.02626
Epoch [99/100], Batch [117/147] train loss: 566.41, train corr: 0.02772
Epoch [99/100], Batch [118/147] train loss: 550.42, train corr: 0.02615
Epoch [99/100], Batch [119/147] train loss: 561.89, train corr: 0.02595
Epoch [99/100], Batch [120/147] train loss: 584.63, train corr: 0.02482
Epoch [99/100], Batch [121/147] train loss: 572.19, train corr: 0.02651
Epoch [99/100], Batch [122/147] train loss: 579.56, train corr: 0.02192
Epoch [99/100], Batch [123/147] train loss: 564.65, train corr: 0.02816
Epoch [99/100], Batch [124/147] train loss: 553.10, train corr: 0.02699
Epoch [99/100], Batch [125/147] train loss: 566.18, train corr: 0.02696
Epoch [99/100], Batch [126/147] train loss: 569.21, train corr: 0.02707
Epoch [99/100], Batch [127/147] train loss: 579.31, train corr: 0.02599
Epoch [99/100], Batch [128/147] train loss: 563.33, train corr: 0.02742
Epoch [99/100], Batch [129/147] train loss: 567.11, train corr: 0.02897
Epoch [99/100], Batch [130/147] train loss: 562.20, train corr: 0.02592
Epoch [99/100], Batch [131/147] train loss: 562.49, train corr: 0.02591
Epoch [99/100], Batch [132/147] train loss: 587.97, train corr: 0.02480
Epoch [99/100], Batch [133/147] train loss: 567.93, train corr: 0.02520
Epoch [99/100], Batch [134/147] train loss: 580.39, train corr: 0.02677
Epoch [99/100], Batch [135/147] train loss: 554.08, train corr: 0.02727
Epoch [99/100], Batch [136/147] train loss: 571.07, train corr: 0.02647
Epoch [99/100], Batch [137/147] train loss: 570.24, train corr: 0.02675
Epoch [99/100], Batch [138/147] train loss: 556.29, train corr: 0.03001
Epoch [99/100], Batch [139/147] train loss: 633.67, train corr: 0.02326
Epoch [99/100], Batch [140/147] train loss: 569.46, train corr: 0.02810
Epoch [99/100], Batch [141/147] train loss: 584.62, train corr: 0.02149
Epoch [99/100], Batch [142/147] train loss: 573.17, train corr: 0.02078
Epoch [99/100], Batch [143/147] train loss: 562.06, train corr: 0.02825
Epoch [99/100], Batch [144/147] train loss: 574.63, train corr: 0.02714
Epoch [99/100], Batch [145/147] train loss: 550.19, train corr: 0.02763
Epoch [99/100], Batch [146/147] train loss: 568.38, train corr: 0.02803
Epoch [99/100], Batch [147/147] train loss: 566.85, train corr: 0.02728
Epoch [99/100], validation loss: 597.78, validation correlation: 0.02735
Epoch [100/100], Batch [1/147] train loss: 562.35, train corr: 0.02706
Epoch [100/100], Batch [2/147] train loss: 557.86, train corr: 0.02914
Epoch [100/100], Batch [3/147] train loss: 556.56, train corr: 0.02790
Epoch [100/100], Batch [4/147] train loss: 803.65, train corr: 0.02428
Epoch [100/100], Batch [5/147] train loss: 564.74, train corr: 0.02761
Epoch [100/100], Batch [6/147] train loss: 580.64, train corr: 0.02282
Epoch [100/100], Batch [7/147] train loss: 569.68, train corr: 0.02643
Epoch [100/100], Batch [8/147] train loss: 576.86, train corr: 0.02261
Epoch [100/100], Batch [9/147] train loss: 581.63, train corr: 0.02425
Epoch [100/100], Batch [10/147] train loss: 565.27, train corr: 0.02117
Epoch [100/100], Batch [11/147] train loss: 573.24, train corr: 0.01285
Epoch [100/100], Batch [12/147] train loss: 561.22, train corr: 0.01564
Epoch [100/100], Batch [13/147] train loss: 586.49, train corr: 0.02127
Epoch [100/100], Batch [14/147] train loss: 569.76, train corr: 0.02351
Epoch [100/100], Batch [15/147] train loss: 577.57, train corr: 0.02555
Epoch [100/100], Batch [16/147] train loss: 556.75, train corr: 0.02620
Epoch [100/100], Batch [17/147] train loss: 577.79, train corr: 0.02557
Epoch [100/100], Batch [18/147] train loss: 585.52, train corr: 0.02780
Epoch [100/100], Batch [19/147] train loss: 551.97, train corr: 0.02965
Epoch [100/100], Batch [20/147] train loss: 560.35, train corr: 0.02689
Epoch [100/100], Batch [21/147] train loss: 543.59, train corr: 0.02876
Epoch [100/100], Batch [22/147] train loss: 566.60, train corr: 0.02393
Epoch [100/100], Batch [23/147] train loss: 572.09, train corr: 0.02791
Epoch [100/100], Batch [24/147] train loss: 585.25, train corr: 0.02470
Epoch [100/100], Batch [25/147] train loss: 553.95, train corr: 0.02832
Epoch [100/100], Batch [26/147] train loss: 569.10, train corr: 0.02765
Epoch [100/100], Batch [27/147] train loss: 564.42, train corr: 0.02579
Epoch [100/100], Batch [28/147] train loss: 570.08, train corr: 0.02589
Epoch [100/100], Batch [29/147] train loss: 574.86, train corr: 0.02383
Epoch [100/100], Batch [30/147] train loss: 560.32, train corr: 0.02850
Epoch [100/100], Batch [31/147] train loss: 640.44, train corr: 0.02651
Epoch [100/100], Batch [32/147] train loss: 570.81, train corr: 0.02826
Epoch [100/100], Batch [33/147] train loss: 579.06, train corr: 0.02414
Epoch [100/100], Batch [34/147] train loss: 575.80, train corr: 0.02777
Epoch [100/100], Batch [35/147] train loss: 564.48, train corr: 0.02812
Epoch [100/100], Batch [36/147] train loss: 580.76, train corr: 0.02417
Epoch [100/100], Batch [37/147] train loss: 574.23, train corr: 0.03078
Epoch [100/100], Batch [38/147] train loss: 573.34, train corr: 0.02562
Epoch [100/100], Batch [39/147] train loss: 569.74, train corr: 0.02718
Epoch [100/100], Batch [40/147] train loss: 567.08, train corr: 0.02715
Epoch [100/100], Batch [41/147] train loss: 554.98, train corr: 0.02770
Epoch [100/100], Batch [42/147] train loss: 579.59, train corr: 0.02570
Epoch [100/100], Batch [43/147] train loss: 568.13, train corr: 0.02536
Epoch [100/100], Batch [44/147] train loss: 556.60, train corr: 0.02847
Epoch [100/100], Batch [45/147] train loss: 562.92, train corr: 0.02808
Epoch [100/100], Batch [46/147] train loss: 550.91, train corr: 0.02901
Epoch [100/100], Batch [47/147] train loss: 564.49, train corr: 0.02625
Epoch [100/100], Batch [48/147] train loss: 574.34, train corr: 0.02791
Epoch [100/100], Batch [49/147] train loss: 558.25, train corr: 0.02729
Epoch [100/100], Batch [50/147] train loss: 587.83, train corr: 0.02409
Epoch [100/100], Batch [51/147] train loss: 559.83, train corr: 0.02725
Epoch [100/100], Batch [52/147] train loss: 555.71, train corr: 0.03060
Epoch [100/100], Batch [53/147] train loss: 572.87, train corr: 0.02694
Epoch [100/100], Batch [54/147] train loss: 557.87, train corr: 0.02973
Epoch [100/100], Batch [55/147] train loss: 564.44, train corr: 0.02779
Epoch [100/100], Batch [56/147] train loss: 561.86, train corr: 0.02470
Epoch [100/100], Batch [57/147] train loss: 555.96, train corr: 0.02683
Epoch [100/100], Batch [58/147] train loss: 556.50, train corr: 0.02809
Epoch [100/100], Batch [59/147] train loss: 574.82, train corr: 0.02381
Epoch [100/100], Batch [60/147] train loss: 584.26, train corr: 0.02127
Epoch [100/100], Batch [61/147] train loss: 574.38, train corr: 0.02511
Epoch [100/100], Batch [62/147] train loss: 577.30, train corr: 0.02636
Epoch [100/100], Batch [63/147] train loss: 573.41, train corr: 0.02441
Epoch [100/100], Batch [64/147] train loss: 567.39, train corr: 0.02750
Epoch [100/100], Batch [65/147] train loss: 557.05, train corr: 0.02826
Epoch [100/100], Batch [66/147] train loss: 571.51, train corr: 0.02722
Epoch [100/100], Batch [67/147] train loss: 566.62, train corr: 0.02553
Epoch [100/100], Batch [68/147] train loss: 566.60, train corr: 0.02451
Epoch [100/100], Batch [69/147] train loss: 573.35, train corr: 0.02394
Epoch [100/100], Batch [70/147] train loss: 563.64, train corr: 0.02860
Epoch [100/100], Batch [71/147] train loss: 567.57, train corr: 0.02839
Epoch [100/100], Batch [72/147] train loss: 568.42, train corr: 0.02499
Epoch [100/100], Batch [73/147] train loss: 563.57, train corr: 0.02768
Epoch [100/100], Batch [74/147] train loss: 561.40, train corr: 0.02694
Epoch [100/100], Batch [75/147] train loss: 650.43, train corr: 0.02296
Epoch [100/100], Batch [76/147] train loss: 571.13, train corr: 0.02604
Epoch [100/100], Batch [77/147] train loss: 583.40, train corr: 0.02521
Epoch [100/100], Batch [78/147] train loss: 564.32, train corr: 0.02736
Epoch [100/100], Batch [79/147] train loss: 563.98, train corr: 0.02495
Epoch [100/100], Batch [80/147] train loss: 557.06, train corr: 0.02778
Epoch [100/100], Batch [81/147] train loss: 564.59, train corr: 0.02742
Epoch [100/100], Batch [82/147] train loss: 578.44, train corr: 0.02650
Epoch [100/100], Batch [83/147] train loss: 572.05, train corr: 0.02557
Epoch [100/100], Batch [84/147] train loss: 566.67, train corr: 0.02567
Epoch [100/100], Batch [85/147] train loss: 556.43, train corr: 0.02943
Epoch [100/100], Batch [86/147] train loss: 583.69, train corr: 0.02346
Epoch [100/100], Batch [87/147] train loss: 563.88, train corr: 0.02721
Epoch [100/100], Batch [88/147] train loss: 571.15, train corr: 0.02605
Epoch [100/100], Batch [89/147] train loss: 576.41, train corr: 0.02624
Epoch [100/100], Batch [90/147] train loss: 557.33, train corr: 0.02810
Epoch [100/100], Batch [91/147] train loss: 553.51, train corr: 0.02706
Epoch [100/100], Batch [92/147] train loss: 588.58, train corr: 0.02477
Epoch [100/100], Batch [93/147] train loss: 567.16, train corr: 0.02616
Epoch [100/100], Batch [94/147] train loss: 622.52, train corr: 0.02408
Epoch [100/100], Batch [95/147] train loss: 550.96, train corr: 0.02624
Epoch [100/100], Batch [96/147] train loss: 564.86, train corr: 0.02873
Epoch [100/100], Batch [97/147] train loss: 566.18, train corr: 0.02718
Epoch [100/100], Batch [98/147] train loss: 558.85, train corr: 0.02787
Epoch [100/100], Batch [99/147] train loss: 583.64, train corr: 0.02190
Epoch [100/100], Batch [100/147] train loss: 573.26, train corr: 0.02360
Epoch [100/100], Batch [101/147] train loss: 554.27, train corr: 0.02722
Epoch [100/100], Batch [102/147] train loss: 756.07, train corr: 0.02679
Epoch [100/100], Batch [103/147] train loss: 585.23, train corr: 0.02283
Epoch [100/100], Batch [104/147] train loss: 585.01, train corr: 0.02693
Epoch [100/100], Batch [105/147] train loss: 580.08, train corr: 0.02587
Epoch [100/100], Batch [106/147] train loss: 582.80, train corr: 0.02416
Epoch [100/100], Batch [107/147] train loss: 583.23, train corr: 0.01390
Epoch [100/100], Batch [108/147] train loss: 570.72, train corr: -0.01277
Epoch [100/100], Batch [109/147] train loss: 578.82, train corr: -0.02075
Epoch [100/100], Batch [110/147] train loss: 584.97, train corr: -0.01589
Epoch [100/100], Batch [111/147] train loss: 571.10, train corr: 0.00478
Epoch [100/100], Batch [112/147] train loss: 566.07, train corr: 0.02599
Epoch [100/100], Batch [113/147] train loss: 584.23, train corr: 0.02737
Epoch [100/100], Batch [114/147] train loss: 569.70, train corr: 0.02238
Epoch [100/100], Batch [115/147] train loss: 567.53, train corr: 0.02676
Epoch [100/100], Batch [116/147] train loss: 565.57, train corr: 0.02701
Epoch [100/100], Batch [117/147] train loss: 573.82, train corr: 0.02700
Epoch [100/100], Batch [118/147] train loss: 554.25, train corr: 0.02587
Epoch [100/100], Batch [119/147] train loss: 559.73, train corr: 0.02982
Epoch [100/100], Batch [120/147] train loss: 584.23, train corr: 0.02274
Epoch [100/100], Batch [121/147] train loss: 561.28, train corr: 0.02334
Epoch [100/100], Batch [122/147] train loss: 564.66, train corr: 0.02811
Epoch [100/100], Batch [123/147] train loss: 566.22, train corr: 0.02964
Epoch [100/100], Batch [124/147] train loss: 556.72, train corr: 0.02713
Epoch [100/100], Batch [125/147] train loss: 585.29, train corr: 0.02440
Epoch [100/100], Batch [126/147] train loss: 562.26, train corr: 0.02650
Epoch [100/100], Batch [127/147] train loss: 578.98, train corr: 0.02739
Epoch [100/100], Batch [128/147] train loss: 560.17, train corr: 0.02718
Epoch [100/100], Batch [129/147] train loss: 569.86, train corr: 0.02703
Epoch [100/100], Batch [130/147] train loss: 567.38, train corr: 0.02813
Epoch [100/100], Batch [131/147] train loss: 576.74, train corr: 0.02679
Epoch [100/100], Batch [132/147] train loss: 595.04, train corr: 0.02264
Epoch [100/100], Batch [133/147] train loss: 562.01, train corr: 0.02424
Epoch [100/100], Batch [134/147] train loss: 569.05, train corr: 0.02808
Epoch [100/100], Batch [135/147] train loss: 563.19, train corr: 0.03097
Epoch [100/100], Batch [136/147] train loss: 561.30, train corr: 0.02618
Epoch [100/100], Batch [137/147] train loss: 575.91, train corr: 0.02363
Epoch [100/100], Batch [138/147] train loss: 571.86, train corr: 0.02797
Epoch [100/100], Batch [139/147] train loss: 585.19, train corr: 0.02326
Epoch [100/100], Batch [140/147] train loss: 550.83, train corr: 0.02819
Epoch [100/100], Batch [141/147] train loss: 568.61, train corr: 0.02907
Epoch [100/100], Batch [142/147] train loss: 577.07, train corr: 0.02528
Epoch [100/100], Batch [143/147] train loss: 564.42, train corr: 0.02568
Epoch [100/100], Batch [144/147] train loss: 557.85, train corr: 0.02634
Epoch [100/100], Batch [145/147] train loss: 575.07, train corr: 0.02804
Epoch [100/100], Batch [146/147] train loss: 555.21, train corr: 0.02928
Epoch [100/100], Batch [147/147] train loss: 570.18, train corr: 0.02728
Epoch [100/100], validation loss: 597.71, validation correlation: 0.02712
Test loss: 425.1812744140625, Test correlation: nan
